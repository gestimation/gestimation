[
  {
    "objectID": "kanji_jp/index.html",
    "href": "kanji_jp/index.html",
    "title": "Coffee and Research",
    "section": "",
    "text": "日本や中国で今も用いられている漢字のおもしろい性質のひとつは, 文字の構成要素に古い意味が残っているという点です. Causal inferenceに対応する漢字を眺めていると 時代を超えた構造の輪郭がくっきりと浮かび上がります.\nひとつ目の漢字は 因（in） です. まず大きな四角をイメージしてください. これはもともと敷物のことでしたが, 実は宇宙や空間のモチーフとして用いられています. その四角の上に, 人間が一人, 手足を広げて横たわっている. この字形には、人間が世界や自然の中に置かれているという感覚が残っています。\nふたつ目の果（ga）はもっと具体的であり, 当時の人々が何を見てこの漢字を記したのか, その足跡が残されています. この漢字は上下2つにわかれます. 下の部分である「木」は, もちろん樹木のことです. そして木の上には「田」が描かれており, これは木の上で成熟した果実を図案化したものです. 成長の過程を経て、最終的に実ったもの──それが「果」です。\nみっつ目は推（sui）です. これもまた「因」, 「果」と同じように2つにわけられますが 今度の分割では左右にわかれ, 左は手, 右は鳥を表します. もともとは具体的な動作を想起させる字でしたが, 時代を経て意味は抽象化されました. 現代的には, ここに行為（action）と対象（object）を読み取る方が自然でしょう。\n最後の漢字である論（ron）もまた抽象的です. 今度は右側の部品からみてみましょう. それは「侖」です. これ自体もひとつの漢字ですが, この字の下をみてください. 縦に四つの線が並んでいます. これはたくさんの要素が整然と並んでいる様子です. この「侖」という漢字は, 何かを秩序（order）だてて考えることを意味しています. そして「論」の左側の部品は, 今ではもともとの形を留めてはいませんが, 現代でも言語（language）を意味する漢字そのものです.\nつまり, 日本語のcausal inferenceは8つの部品から構成されています. そしてそれは, 宇宙, 人間, 木, 果実, 行為, 対象, 言葉, 秩序をそれぞれ意味しています.\n因果とは, 自然の法則であると同時に, 人間の視点と操作を含む概念であり, その構造を言語として整え, 社会で共有する営みでもあります. 研究者や哲学者が今も関心を持ち続けているcausal inferenceの骨格が, 思っていたよりずっと古い場所に残されていた─そう読めても, 不思議ではないと思いませんか.\n\n\n\n\n\n\nkanji characters representing causal inference\n\n\n\n\n\n Calligraphy by Eiji Sakurai."
  },
  {
    "objectID": "kanji_jp/index.html#日本語が保持していたcausal-inferenceの8つの部品",
    "href": "kanji_jp/index.html#日本語が保持していたcausal-inferenceの8つの部品",
    "title": "Coffee and Research",
    "section": "",
    "text": "日本や中国で今も用いられている漢字のおもしろい性質のひとつは, 文字の構成要素に古い意味が残っているという点です. Causal inferenceに対応する漢字を眺めていると 時代を超えた構造の輪郭がくっきりと浮かび上がります.\nひとつ目の漢字は 因（in） です. まず大きな四角をイメージしてください. これはもともと敷物のことでしたが, 実は宇宙や空間のモチーフとして用いられています. その四角の上に, 人間が一人, 手足を広げて横たわっている. この字形には、人間が世界や自然の中に置かれているという感覚が残っています。\nふたつ目の果（ga）はもっと具体的であり, 当時の人々が何を見てこの漢字を記したのか, その足跡が残されています. この漢字は上下2つにわかれます. 下の部分である「木」は, もちろん樹木のことです. そして木の上には「田」が描かれており, これは木の上で成熟した果実を図案化したものです. 成長の過程を経て、最終的に実ったもの──それが「果」です。\nみっつ目は推（sui）です. これもまた「因」, 「果」と同じように2つにわけられますが 今度の分割では左右にわかれ, 左は手, 右は鳥を表します. もともとは具体的な動作を想起させる字でしたが, 時代を経て意味は抽象化されました. 現代的には, ここに行為（action）と対象（object）を読み取る方が自然でしょう。\n最後の漢字である論（ron）もまた抽象的です. 今度は右側の部品からみてみましょう. それは「侖」です. これ自体もひとつの漢字ですが, この字の下をみてください. 縦に四つの線が並んでいます. これはたくさんの要素が整然と並んでいる様子です. この「侖」という漢字は, 何かを秩序（order）だてて考えることを意味しています. そして「論」の左側の部品は, 今ではもともとの形を留めてはいませんが, 現代でも言語（language）を意味する漢字そのものです.\nつまり, 日本語のcausal inferenceは8つの部品から構成されています. そしてそれは, 宇宙, 人間, 木, 果実, 行為, 対象, 言葉, 秩序をそれぞれ意味しています.\n因果とは, 自然の法則であると同時に, 人間の視点と操作を含む概念であり, その構造を言語として整え, 社会で共有する営みでもあります. 研究者や哲学者が今も関心を持ち続けているcausal inferenceの骨格が, 思っていたよりずっと古い場所に残されていた─そう読めても, 不思議ではないと思いませんか.\n\n\n\n\n\n\nkanji characters representing causal inference\n\n\n\n\n\n Calligraphy by Eiji Sakurai."
  },
  {
    "objectID": "jp/truth-3.html",
    "href": "jp/truth-3.html",
    "title": "What Is It That You Want to Know?",
    "section": "",
    "text": "Truth III − What Is It That You Want to Know?\n\nKeywords: causal model, language &writing, probability model, research hypothesis\n\n\n\n研究仮説を言葉にするということ\n\n\nお父さん「はい、コーヒーのおかわり。ミルクはいる？」\n\n\n私「いる。お父さんのいいたいことがわかってきたよ。データを集めてロジスティック回帰をすると、自動的に結論が出るわけじゃないんだ。それは、うちの診療科だけのデータでRを試してたときから気づいてたよ。有意だったら因果関係あり、有意じゃなかったら因果関係なしみたいに、白黒はっきりしてないんだなって。でも、どんな集団が解析対象なのかや、ストーマ保有者をどんな集団と比べているのか、足りない交絡因子はなにかなど、どの部分の詰めが甘いのかがだんだん見えてきた」\n\n\nお父さん「それはよかった。最近はデータ駆動型で結論まで行けそうな空気があるから、なおさらね。AIもそうだ。でも、どんな真実を知りたいのか言葉にしないと、正しい解析も存在しない」\n\n\n私「この場合の正しさってなんだろう？計算があってるっていう意味じゃないよね」\n\n\nお父さん「電卓やそろばんの時代はそれでよかったけど今は違う。どんな情報処理系も汎用化されると、与えた目的を目的関数として解釈して解を求めるんだ。目的が精密になればなるほど答えも欲しいものに近づく。合目的的な正しさなんだ」\n\n\n私「なるほどね。目的は因果の問いのことだよね」\n\n\nお父さん「そうだね、問いへの答えとその確からしさを知ることだね。臨床試験のように研究仮説を立てて、それにあわせて研究計画書を書けば、精密な答えが返ってくるはず。ランダム誤差とバイアスを統計的に扱うのは、答えの不確実性にもまた興味があるからじゃない？」\n\n\n私「確かに、的の中心が決まらないと、矢の狙いが偏っているか調整もできないな。逆算すると、研究仮説の形で真値を固めておかないと、オッズ比が正しいかどうか判断できないんだ」\n\n\nお父さん「そう。研究仮説や因果モデルは、調査票やデータよりずっと抽象的に見えるよね。どちらかというと確率モデル寄りに見える。だけどこれは医療者の疑問そのもの。治療効果や予防方法に関する仮説は、自然の摂理ではなく、よりよい医療技術はどれかという人間側の問いなんだ」\n\n\n私「…じゃあ、真値ってよく聞く言葉だけど、自然のどこかに転がっている数字じゃないんだね」\n\n\n\n\nThis concludes the Truth series. If you’d like to keep reading over your next cup of coffee, further episodes are waiting:\n\nThree-Variable DAGs: The Smallest Building Blocks of Causal Structure\n\n\n\nTo clarify which conceptual layers the issues in the series belong to, it may help to revisit the previous series:\n1. Study Design — 研究の出発点\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\n\n2. Glossary — 統計学のことば\n\nStatistical Terms in Plain Language\n\n3. Frequentist Thinking — 統計学の思考\n\nReading a Paper over a Cup of Coffee\nP-Value Explanations That Seem Plausible at First Glance\nBeyond 0.05: Interpreting P-Values in a Clinical Trial\n\n4. Frequentist Experiments — 統計学の実証\n\nR Demonstration of Bias in Kaplan-Meier Under Competing Risks\nUnderstanding Confidence Intervals via Hypothetical Replications in R\nAlpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size\n\n5. Effects and Time — 効果は時間とともに\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nA First Note on Cox Regression\nAfter Cox Regression: A Case Study and R Demonstration\n\n6. Adjusting for Bias — 回帰モデリングの風景\n\nUnderstanding Collapsibility of Effect Measures: Marginal vs Stratified\nFrom Risk to Logistic Regression\nLogit: How a Transformation Shapes an Effect\nWhere My Logistic Regression Went Wrong\nWhy Logistic Regression Fails in Small Samples\nUnderstanding Confounding in Effect Measures: Marginal vs Stratified\n\n7. Truth — 真実\n\nWhat Data Cannot Tell Us\nWhat Could Have Happened\nWhat Is It That You Want to Know?"
  },
  {
    "objectID": "jp/truth-1.html",
    "href": "jp/truth-1.html",
    "title": "What Data Cannot Tell Us",
    "section": "",
    "text": "Truth I − What Data Cannot Tell Us\n\nKeywords: causal model, language & writing, probability model, research hypothesis\n\n\n\n\n\n\n\n\nSimpsonのパラドックス\n\n\n\n\n\n前回のテーマであるSimpsonのパラドックスは、調整前後で関連の程度が変わる現象のことです。詳しい中身は覚えていなくてもかまいません。ここでは「調整前と調整後で話が変わりうる」という点だけ思い出してください。\n表1は、コーヒーと膵がんを想定した仮想データです。コーヒー摂取群とコーヒー非摂取群で、それぞれ膵がん発生ありとなしが調べられています。膵がんを発生したのはそれぞれの群で15人と12人、膵がんがなかったのは365人と868人です。オッズ比を計算してみましょう。コーヒー摂取群では膵がんリスクは3.9%で、コーヒーを摂取しない群の1.4%に比べて、オッズ比は3倍です。これは、コーヒーを摂取すると、膵がんリスクが高くなることを意味しています。\n表2には、交絡因子（喫煙）によって対象者を層別した結果が示されています。ここから膵がんのオッズ比を求めるとどうなるでしょうか。コーヒー摂取でも非摂取でもリスクは同じですよね。つまりオッズ比は1倍です。\n表1. 層別前の膵がんリスクとオッズ比\n\n\n\n\nコーヒー摂取\nコーヒー非摂取\nオッズ比\n\n\n\n\n合計\n\n\n\n\n\n　膵がんあり\n15\n12\n\n\n\n　膵がんなし\n365\n868\n\n\n\n　リスク\n3.9%\n1.4%\n3倍\n\n\n\n表2. 層別後の膵がんリスクとオッズ比\n\n\n\n\nコーヒー摂取\nコーヒー非摂取\nオッズ比\n\n\n\n\n喫煙\n\n\n\n\n\n　膵がんあり\n14\n4\n\n\n\n　膵がんなし\n266\n76\n\n\n\n　リスク\n5.0%\n5.0%\n1倍\n\n\n非喫煙\n\n\n\n\n\n　膵がんあり\n1\n8\n\n\n\n　膵がんなし\n99\n792\n\n\n\n　リスク\n1.0%\n1.0%\n1倍\n\n\n\n\n\n\n\nロジスティック回帰の限界\n\n\nお父さん「熱いコーヒー淹れてくれる？」\n\n\n私「いいよ。いっしょに大福もどうぞ」\n\n\nお父さん「ありがとう。この前の”コーヒーと膵がん”の話、覚えてる？層別解析やロジスティック回帰で交絡を調整したときのこと」\n\n\n私「その節はどうも」\n\n\nお父さん「じゃあ、振り返って考えてみようか。喫煙が交絡因子だったよね。喫煙を調整した結果と調整しない結果がある。どっちを報告する？」\n\n\n私「ん？そりゃ調整した方でしょ」\n\n\nお父さん「だよね。でも交絡因子がAとBの2つあって、ともに曝露とアウトカムの関係をゆがめているとする。AとBの両方を調整したときのオッズ比を、仮に3だとしよう。Aだけ調整したらオッズ比は2、どちらも調整しなかったらオッズ比は3。さあ、Aだけ調整した結果とどちらも調整しない結果、どちらが正しいと思う？」\n\n\n私「えーっと、真値が3なんだから調整しない方かな」\n\n\nお父さん「ところがね、Bのデータはそもそも集めていなかったら？“AとBを調整したときオッズ比は3”なんてわからないよね。これでも”調整しない方が正しい”？」\n\n\n私「なにがいいたいの？私、ロジスティック回帰は苦手なんだよ」\n\n\nお父さん「真値が見えない状況では、ただのオッズ比と調整したオッズ比のどちらが真実に近いかなんていえないってことだよ。データとは別に、手がかりになるような知識や概念が必要だって思わない？」\n\n\n私「そんなこといわれてもね。知識を得るために調査してるわけだし。Rに四苦八苦している私にとっては、がんばって調整した結果が正しいって信じるしかないよね」\n\n\nお父さん「気持ちはわかるけど、もうちょっとつきあって。このSimpsonのパラドックスは、交絡という現象そのものだと思ってない？」\n\n\n私「え？調整したらバイアスが消えるんだよね。そうじゃないの？」\n\n\nお父さん「いや、そこは別物なんだ。交絡はそんなに単純な問題じゃない。直感的な説明をするとね。層別前の解析は集団全体のオッズ比でしょ」\n\n\n私「そうだね」\n\n\nお父さん「当たり前だけど、層別後のオッズ比は、喫煙集団のオッズ比と非喫煙集団のオッズ比だよね。どっちが真値なんだろう？ターゲット集団によって真値が変わっていいの？」\n\n\n私「ん？えっと、そうだね、コーヒーが健康に悪いかどうかは個人差ないと思う」\n\n\nお父さん「うん。この事例でいえば喫煙が交絡因子なのは間違いないんだよ。でも一般には、層別前と層別後のどっちのオッズ比が真値なのか、統計学の枠組みで決めるロジックはないんだ。もちろん、Simpsonのパラドックスは数字のパズルではないし、どっちの解析が正しいかという命題も言葉遊びじゃない。データと真値の関係をどう認識するかに関わる問題なんだ。専門家以外のほとんどが、ここを逆にとらえてしまう。そろそろ本当のことを話そう」\n\n\n\n\n次のエピソード\n\nWhat Could Have Happened"
  },
  {
    "objectID": "jp/study-design-4.html",
    "href": "jp/study-design-4.html",
    "title": "A First Step into Survival and Competing Risks Analysis with R",
    "section": "",
    "text": "Study Design IV − A First Step into Survival and Competing Risks Analysis with R\n\nKeywords: bias, R simulation, study design, survival & competing risks\n\n\n\n調査項目とデータの型\n\n\n私「あれ、懐かしい。私が小学生の頃に買ったルービックキューブじゃない、そんなのやってるの。時間があるならちょっといい？がんサバイバーの復職率を調査する話があったでしょ。患者さんに送る調査票をつくってみたんだけど、見てくれる？あ、この前のRも参考になったよ、調査結果が想像できた」\n\n\nお父さん「どれどれ」\n\n\n\nお父さん「復職率の定義はなに？」\n\n\n私「どういうこと？」\n\n\nお父さん「調査票を見ただけじゃ、この質問項目で十分かどうかわからないってこと。手術日から調査日の間に、復職を希望した患者さんが、希望どおり復職できたかどうかを調べたいのかな？」\n\n\n私「それもいいんだけど、復職を希望してないって回答した患者さんのなかに、会社の方針などの理由で復職をあきらめた患者さんも含まれるかもしれない。だから、復職率を計算するとき、分母は、復職を希望した患者さんじゃなくて、手術を受けた患者さん全員にしたいわ。そうした方が、就労実態がわかりやすそうだもの」\n\n\nお父さん「手術日から調査日の間の復職を調べたいかどうかについては？」\n\n\n私「えーっと。調査票に回答してもらうタイミングは患者さんによってまちまちになりそうだから、調査日は使いたくない。1年以内に復職できるかを定義にするのはどうかな？あ！ 復職日を答えてもらえばいいのかも！」\n\n\nお父さん「復職日はあった方がいいよね。そうすると、復職状況から解析用の“変数”をつくるには、分類データと生存時間データの2通りが考えられる。それはさておき、手術後に亡くなった場合はどうするの？」\n\n\n私「入院中に亡くなった場合は、調査対象に含めない。でも、術後再発による死亡を分母から除外するのは変な気がする」\n\n\nお父さん「そうだね。除外するとバイアスが生じると思う。ターゲットにしている集団からずれちゃうからね。がん患者を追跡するような研究をするとき、大切なことが3つある。1つ、どのタイミングを時間原点にするかを決める必要があるよね。この場合、時間原点は退院日にするといい。2つ、追跡期間の目標を設定して、その時点までは、可能な限り情報を収集すること。情報が取れないとバイアスが生じる原因になる。3つ、時間原点後に生じたイベントは除外してはならない」\n\n\n\n時間原点を定義する\n追跡期間の目標を設定し、その時点までは可能な限り情報を収集する\n時間原点後に生じたイベントは除外したり、層別に用いたりしない\n\n\n\n私「後からバイアスがあるとか言われたくないもんね。ふむふむ」\n\n\nお父さん「以前、“PECO”という要素を使って臨床疑問を構造化したらってアドバイスしたよね。Pが根治切除後の直腸がん患者さんだったら、その集団をもれなく調査しないといけない」\n\n\n私「分類データと生存時間データってなに？」\n\n\nお父さん「これもこの前話したでしょ。統計解析を行ううえで基本になるのが“データの型”で、分類データと生存時間データはその種類だよ」\n\n\n私「いや、先週の話だし、私忙しいし」\n\n\nお父さん「調査票を少し手直ししたから、これを使ってもう一度話すよ」\n\n\n\nお父さん「分類データは、この場合、患者のアウトカムを分類したものだよ。1年以内に復職したかどうかをアウトカムにしたらどうかなっていってたよね」\n\n\n私「うん」\n\n\nお父さん「たとえば、“1年以内に復職あり”を分類1、“1年以内に復職なし”を分類2にしたら、2値データと呼ばれる分類データの一種になる。これは調査票から調べられるし、復職率も計算できるよね」\n\n\n私「うん。1年以内の死亡を復職なしって扱えばね」\n\n\nお父さん「でも就労状況を集計するときは2値データではなく、3カテゴリの分類データの方がいい。“1年以内に復職あり”を分類1、“1年以内に復職なし（死亡以外の理由のため）”を分類2、“1年以内に復職なし（死亡のため）”を分類3にしたらどう？もっと詳細にアウトカムが把握できるでしょ」\n\n\n私「うんうん。じゃあ生存時間データはなんだっけ？OSってこと？」\n\n\nお父さん「たしかに全生存期間（OS）は生存時間データの一種だよ。名前から誤解されがちだけど、それ以外にもあるんだ。生存時間データがどういうものかっていうと、時間原点から“イベント”までにかかった時間を表す変数のこと」\n\n\n私「復職状況も生存時間データになるの？」\n\n\nお父さん「そうすることもできる。この場合は、“退院日から復職日までの期間”を考えればいい。たとえばね、4月1日に退院して、4月30日に復職したとしたら、この患者の生存時間データは30-1+1=30日になる。これだとただの日数だから、連続データとの違いがはっきりしないけど、生存時間データの本質は、打ち切り （censoring）があることなんだ。調査日までに復職しなかった場合、退院日から復職日までの期間は存在しないでしょ」\n\n\n私「まあそうだけど、それでいいんじゃないの？」\n\n\nお父さん「統計解析のソフトウェアを使うとき一工夫が必要で、調査日の時点で復職しなかった、つまり復職の追跡が打ち切られたという情報を、入力してあげなければならない。だから生存時間データは、2つの変数が組になっているんだ。\n\n\n\n時間変数\nイベント変数\n\n\n\nお父さん「イベント変数は、いわゆる生存時間データの場合は、イベントが観察されたか、打ち切りになったかを表す2値データ。時間変数は、この場合は“退院日から復職日までの期間”か“退院日から調査日までの期間”のどちらかになる」\n\n\n\n\n\n\n\n生存時間データの入力\n\n\n\n\n\n生存時間データは2つの変数の組であるため、Rの関数に入力するときもペアで指定する必要があります。survivalパッケージのsurvfit()やcoxph()では、実は入力専用の関数Surv()を用意しています。入力の仕様はパッケージによってまちまちで、たとえばmetsパッケージではEvent()を別に定義して用いています。cifmodelingパッケージのcifplot()は、Surv()とEvent()の両方に対応しています。\n\nlibrary(survival)\nlibrary(cifmodeling)\n\nsurvfit(Surv(time, status) ~ stoma,\n  data         = dat\n)\ncifplot(Surv(time, status) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\ncifplot(Event(time, status) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\n\n\n\n\n\n私「えーっと、イベント変数は2値データってことは、すべての患者さんで復職か、打ち切りかの2択しかないってこと？死亡はどうなるの？」\n\n\nお父さん「いま話したような扱いをするなら、死亡した患者さんは、打ち切りという分類に含まれることになる。ただし、競合リスク （competing risk）という別の扱い方もある。簡単にいうと、それが起こると研究で調べたいイベント（たとえば死亡や復職）が観察されなくなる、競合するイベントのことだよ」\n\n\n私「ああ、死亡が競合リスクってことね」\n\n\nお父さん「生存時間データは、英語ではsurvival data以外にtime-to-event dataっていったりもするんだけどね。時間とともに起きるイベントって、生存か死亡かだけじゃないでしょ。競合リスクを解析できるようにしたのが競合リスクモデルなんだ。この場合、さっきのイベント変数は、イベント、競合リスク、打ち切りという3カテゴリを表す変数になる。イベント変数はこんな感じでコーディングされる」\n\n\nイベント変数=0: イベントが観察される前に打ち切りになった\nイベント変数=1: イベントが観察された\nイベント変数=2: イベントが観察される前に競合リスクが生じた\n\n\n私「そうなんだ。イベント変数ってなんとなく0と1だと思ってたわ」\n\n\n生存時間解析と競合リスク解析\n\nお父さん「競合リスクとあわせて知ってほしいのが、Kaplan-Meier曲線が生存曲線じゃなくなるってこと」\n\n\n私「どういう意味？」\n\n\nお父さん「ほら、生存と死亡しかなかったら、死亡確率の裏返しが生存確率でしょ。でも死因の内訳、たとえば原病死と他因死があって、他因死が競合リスクだったらどう？原病死の確率の裏返しは生存確率にならない。だから、競合リスク解析では、Kaplan-Meier曲線じゃなくてAalen-Johansen曲線を使う。ちょっとRの結果をみてほしい」\n\n\n\n\n\n\n\n\n\nシミュレーションデータ（再発あり）の生成\n\n\n\n前回より少しだけがんの臨床研究を意識して、シミュレーションデータにおける、全生存期間（OS）・無再発生存期間（RFS）・累積再発率（CIR）の違いをみてみましょう。CIRの解析では、再発の前に死亡した患者が存在するため、その扱いを決める必要があります。これを競合リスク（competing risk）といいます。\n以下のコードでは、死亡だけではなく再発を伴った生存時間アウトカム3種類をRで生成する「関数」generate_data()を定義しています。OSのイベントは「死亡」、RFSのイベントは「死亡と再発」です。CIRのイベントは「再発」ですが、死亡を競合リスクとして扱います。なお、generate_data()やこのシミュレーションデータは、今後の解説でも再利用する予定です。\n\nストーマ保有：2項分布（rbinom）から生成した2値データ\n生存時間：指数分布（rexp）から生成した生存時間データ（t_relapse, t_death, t_censoringの乱数から計算）\n\n前回、競合リスクのない生存時間データを要約しましたが、そこで用いたのはKaplan-Meier曲線でしたよね。それに対して、競合リスク解析では、Kaplan-Meier曲線ではなく、Aalen-Johansen曲線を用いるのが正式です。\n\n\n\n\n\n\n\n\ngenerate_data()のコードはこちら（データ生成に使用）\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # 再発のハザード（大きいほど早く起こる）\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # 死亡のハザード（大きいほど早く起こる）\n  hazard_censoring &lt;- 0.05                               # 打ち切りハザード（群に依存しない）\n  \n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)   # 再発までの潜在時間\n  t_death     &lt;- rexp(n, rate = hazard_death)     # 死亡までの潜在時間\n  t_censoring &lt;- rexp(n, rate = hazard_censoring) # 打ち切りまでの潜在時間\n  \n  ## --- 全生存期間（OS） ----------------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = 死亡, 0 = 打ち切り\n  \n  ## --- 無再発生存期間（RFS） -----------------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # 再発\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # 死亡\n  \n  ## --- 累積再発率（CIR） + 競合リスク --------------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # イベント1: 再発\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # イベント2: 競合リスクとしての死亡\n  \n  ## --- データフレームにまとめる --------------------------------\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n  return(dat)\n}\n\n\n\n\n\n\n\n\n\n\n全生存期間（OS）のKaplan-Meier曲線\n\n\n\nOSとRFSは通常の生存時間データですから、前回と同様にcifmodelingパッケージのcifplot()を使って、Kaplan-Meier曲線で記述します。まずはOS。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\n# devtools::install_github(\"gestimation/cifmodeling\") #インストールが必要なら実行 \nlibrary(cifmodeling)\nset.seed(46)\ndat &lt;- generate_data(hr1=2, hr2=1.5) #再発ハザード比2, 死亡ハザード比1.5のデータ生成\n\ncifplot(Event(time_os, status_os) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n無再発生存期間（RFS）のKaplan-Meier曲線\n\n\n\n次にRFSです。Event()で指定する変数以外は変わりません。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\ncifplot(Event(time_rfs, status_rfs) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Relapse-free survival\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積再発率（CIR）のAalen-Johansen曲線\n\n\n\n以下のコードでは、Event(time_cir, status_cir)のコーディングによって競合リスクを入力しています。\n\nstatus_cir=1 : 関心のあるイベント（再発）\nstatus_cir=2 : 競合リスク（再発を経験しない死亡）\nstatus_cir=0 : 打ち切り\n\nさらにoutcome.type = \"competing-risk\"を指定することで、Aalen-Johansen曲線を描いています。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\ncifplot(Event(time_cir, status_cir) ~ stoma,\n  data         = dat,\n  outcome.type = \"competing-risk\",\n  label.y      = \"Cumulative incidence of relapse\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n私「CIRの解析に使ったのがAalen-Johansen曲線ね。でもこれって、Kaplan-Meier曲線のY軸を逆さにしただけじゃないの」\n\n\nお父さん「グラフ上は見分けられないからそう思っても仕方ないよね。でもこのふたつは区別してほしい。\n\n生存曲線（Kaplan-Meier曲線）と累積発生曲線（Aalen-Johansen曲線）は別の統計手法なので 競合リスクがあるときはAalen-Johansen曲線を用いる。\n\nちなみに、relapse-free timeじゃなくてcumulative incidence of relapseを使いたいっていったけど、それは累積発生曲線（cumulative incidence curve）が、専門的にはAalen-Johansen曲線と同じ意味だからなんだよね。やろうと思えばCIRを解析するとき、Kaplan-Meier曲線を計算することもできるよ。このとき、再発を経験しない死亡は、競合リスク（status_cir=2）ではなく打ち切り（status_cir=0）として入力することになる。でも本来なら、死亡は、追跡期間終了や追跡不能による打ち切りとは、違う転帰だよね。だから競合リスクとして扱うのが正しい。\n\n\n私「じゃあ死亡と再発を両方イベントにしたRFSを解析するのは間違い？」\n\n\nお父さん「もちろん間違いじゃないよ。でも、RFS曲線の差は、再発だけでなく他因死の影響も反映しているよね。だから、さっきいったみたいに、OS、RFS、CIRは使い分けが必要になる」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nCDISC ADaM ADTTE（Analysis Data Model for Time-to-Event Endpoints）は、製薬企業が行う臨床試験データの標準規格です。この規格では、打ち切りにはCNSRという変数名の変数を用いることになっています。打ち切りを表すコーディングは、次のうちどちらでしょう。\n\nCNSR=0\nCNSR=1\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は2です\n\nCDISC ADaM ADTTEでは、1がTRUEを表しています。Event()やSurv()など多くの統計パッケージのデフォルトでは、イベント=1、打ち切り=0というコーディングを想定しています。CNSRをそのまま用いることはできません。\n\n\n\n\n\nエピソード、用語集、Rスクリプト\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\nStatistical Terms in Plain Language\nstudy-design.R"
  },
  {
    "objectID": "jp/study-design-2.html",
    "href": "jp/study-design-2.html",
    "title": "Data Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes",
    "section": "",
    "text": "Study Design II − Data Have Types\n\nKeywords: language & writing, probability model, R simulation, survival & competing risks\n\n\n\nデータには型がある\n\n\n私「コーヒー淹れたから、もう少し相談させてよ。さっきRの話がでたでしょ。そのとき、どの関数を使うかもアウトカムによって違うんだよっていってたじゃない？あれ、いまいちピンとこないんだけど。データなんて、全部数字じゃないの？」\n\n\nお父さん「いいね、最近秋めいてきたからコーヒーがあるとありがたい。数字には違いないんだけどね。統計解析では、データの型がとても大事なんだ。代表的なのはこの4つ」\n\n\n\n連続データ\n2値データなどの分類データ\n計数データ\n生存時間データ\n\n\n\n私「連続データって、年齢とか血圧みたいな測るやつでしょ？2値データもわかるよ。私の調査で比較したいストーマ保有あり・なしとか」\n\n\nお父さん「ご名答。で、計数データは、交通事故の発生件数のような、数をカウントしたデータのこと。生存時間データは、たとえば寿命とかだね。死亡など特定のイベントが起こるまでの時間を扱うデータだよ。今回のがんサバイバー調査でいえば、手術から復職までの時間とか、再発までの時間とかね」\n\n\n私「いわれてみれば、たしかに種類が違うね。でも、昔受けたRの授業では、言われた通りにコード打ってただけだったなあ。glm()とかsurvfit()とか、なんかよくわからないことばを」\n\n\nお父さん「そうだね。パソコンある？」\n\n\n私「へ」\n\n\nお父さん「パソコン。あるでしょ。RStudioインストールしよう」\n\n\n私「はあ、まあ声を掛けたのはこっちだからいいけど」\n\n\nお父さん「Rではね、連続データを解析するなら、mean()、t.test() なんかがよく使われる」\n\n\n私「はあ」\n\n\nお父さん「2値データを集計するときはtable()。p値を計算するときはfisher.test()。複雑な解析はglm(family = binomial) みたいな回帰モデル。生存時間データだと、survfit()、coxph()、それからcifplot()みたいな関数が出てくる」\n\n\nそんなにいっぱい覚えられるわけないでしょ。Rの授業でも思ってたけど、そんなのあたかも呪詛なんだって」\n\n\nお父さん「覚えなくていいよ」\n\n\n私「え、いいの？」\n\n\nお父さん「大事なのは、どの型のデータに、どんなR関数をあてるのかをイメージできること。もっといえば、どんな確率分布を仮定しているかを、なんとなくでいいから思い浮かべてほしいんだ」\n\n\n私「確率分布？」\n\n\nお父さん「学部でやったでしょ。正規分布（normal distribution）は聞いたことある？2値データの2項分布（binomial distribution）は？」\n\n\n私「それくらいはね」\n\n\nお父さん「単なるデータの記述より高度な統計手法では、裏でなんらかの確率モデル（probability model）を考えてる。生存時間データだと、標準的に使われるモデルってわけじゃないんだけど、一番シンプルな分布は指数分布（exponential distribution）っていうんだ」\n\n\n私「知らんな。呪詛」\n\n\nお父さん「そうだね、人間が使う言葉とは思えないとはこっちも思うよ。でも、本題に入る前につまづいたらもったいない。もし、統計でわからない言葉が出てきたら、いつでも質問においで。まあ、とにかく、どのデータの型にどんな確率モデルを使うのか、パターンを知ることだね」\n\n\n私「はあ。それとRが関係するわけ？」\n\n\nお父さん「うん。たとえばさ、これは覚えてほしいんだけど、割合（proportion）と率（rate）っていう指標がある。日常生活でもよく使うでしょ？交通事故の発生率とか。でも、日常では、割合と率の違いを意識しないよね。でも、統計の世界では、割合は2項分布のパラメータ、率はPoisson分布っていう別の確率分布のパラメータなんだ。Poisson分布は少しマニアックだけど」\n\n\n私「割合と率なんて同じ意味でしょ？」\n\n\nお父さん「違う違う。割合ってパーセントで表すでしょ、女性割合が60%とか。でも、“東京都の1年あたりの交通事故の発生率”を例に考えてみてよ。パーセントにならなくない？交通事故が何回、起きたかを年で割ってるだけだから」\n\n\n私「ふーん。続けたまえ」\n\n\nお父さん「教科書どおりじゃなくていいんだ。“あ、これは正規分布っぽい連続データだから、このあたりの関数かな”とか、0/1のデータだから、このへんの関数かなって、感覚で結びつけられるといいよ。そうするとRの関数もずっと覚えやすくなる」\n\n\n私「なるほどね。データの型と分布をイメージできれば、R関数丸暗記不要ってことね。そいつははかどるわ」\n\n\nお父さん「そうそう。イメージがあれば、あとでマニュアルや本を見たときに、ああ、これのことかってつながるからね。じゃあ、Rでちょっとだけデモを見せてみようか。年齢（連続）、性別とストーマ（2値）、生存時間（生存時間データ）をシミュレーションして、簡単な解析をやってみるよ。使うのは正規分布、2項分布、指数分布」\n\n\n私「また呪文が出てくるんでしょ？」\n\n\nお父さん「そうだね。とりあえずlibrary(ggplot2)、library(cifmodeling)って打って。ヒストグラムとKaplan-Meier曲線を教えるよ」\n\n\n私「とりあえず思考停止で打つわ」\n\n\nお父さん「教えてあげてるんだから思考停止しない。Rの機能を追加するとき、install.packages()とlibrary()を使う。ざっくりいうとね、それぞれ、“Rパッケージをパソコンにインストールする”コマンドと、“インストール済みのパッケージを使えるようにする”コマンドなんだ」\n\n\n私「ふむふむ。じゃあインストールの方は、一度やったら、それで終わり？」\n\n\nお父さん「基本的にはそう。同じパソコンなら、インストールは原則1回でOK。たとえば、install.packages(\"ggplot2\")は、CRANっていうパッケージの倉庫から、自分のパソコンにダウンロードする。library(ggplot2)は、ggplot2を取り出して、“これからグラフを描くからこの道具を使います”ってRに宣言する」\n\n\n私「なるほど。ちょっとスッキリした。今まで毎回インストールしなきゃいけないのかなって思ってた」\n\n\nお父さん「毎回インストールすると、“コーヒー淹れるたびに豆を買いに行く”ようなものだからね。豆はまとめて買っておいて、飲むときに挽けばいい。パッケージも同じだよ」\n\n\n\n\n\n\n\n\nシミュレーションデータの生成\n\n\n\nここでは、Rを使って簡単なシミュレーションデータを作り、連続データ・2値データ・生存時間データそれぞれについて、代表的な統計解析のデモをします。題材は「ストーマ保有者と非保有者の2群比較」です。\n\n年齢：正規分布rnorm()から生成した連続データ\n性別・ストーマ保有：2項分布rbinom()から生成した2値データ\n生存時間：指数分布rexp()から生成した生存時間データ\n\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\nset.seed(46)\n\n# ストーマ保有あり(1)/なし(0)\nstoma &lt;- rbinom(200, size = 1, prob = 0.4)\n\n# 性別 0 = 女性, 1 = 男性\nsex &lt;- rbinom(200, size = 1, prob = 0.5)\n\n# 年齢：正規分布から生成（ストーマあり群を少し高齢に）\nage &lt;- rnorm(200, mean = 65 + 3 * stoma, sd = 8)\n\n# 生存時間：指数分布（ストーマあり群の予後の期待値10年、ストーマなし群の予後の期待値15年）\nhazard &lt;- ifelse(stoma == 1, 1 / 10, 1 / 15)\ntime   &lt;- rexp(200, rate = hazard)\n\n# ランダムな打ち切り（0 = 打ち切り, 1 = イベント）\nstatus &lt;- rbinom(200, size = 1, prob = 0.9)\n\ndat &lt;- data.frame(\n  age    = age,\n  sex    = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n  stoma  = factor(stoma, levels = c(0, 1), labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n  time   = time,\n  status = status\n)\nhead(dat)\n\n       age   sex         stoma      time status\n1 59.19077 WOMAN WITHOUT STOMA 17.939751      1\n2 59.46486   MAN WITHOUT STOMA 18.189251      1\n3 55.34491   MAN WITHOUT STOMA  2.445121      1\n4 60.68207   MAN WITHOUT STOMA 46.737429      1\n5 61.79577   MAN WITHOUT STOMA  0.149128      1\n6 62.84530 WOMAN    WITH STOMA  0.298167      1\n\n\n\n\n\n\n\n\n\n\n\n連続データと2値データの要約\n\n\n\nまず、ggplot2パッケージのggplot()と、table()を使って、ストーマあり群とストーマなし群のデータをヒストグラムと分割表で記述しています。データを生成したときの設定を踏まえると、ヒストグラムでは、ストーマありとなしの間で、年齢の分布がずれているはずです。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\n# install.packages(\"ggplot2\") #インストールが必要なら実行\nlibrary(ggplot2)\n\nggplot(dat, aes(x = age, fill = stoma)) +\ngeom_histogram(alpha = 0.5, position = \"identity\", bins = 10) +\nlabs(x = \"AGE\", y = \"FREQUENCY\", fill = \"STOMA\") +\ntheme_minimal()\n\n\n\n\n\n\n\ntable(STOMA = dat$stoma, SEX = dat$sex)\n\n               SEX\nSTOMA           WOMAN MAN\n  WITHOUT STOMA    43  76\n  WITH STOMA       44  37\n\n\n\n\n\n\n\n\n\n\n\n生存曲線による生存時間データの要約\n\n\n\n次の生存時間データでは、cifmodelingパッケージのcifplot()を使って、Kaplan–Meier曲線を描いてみます。ストーマ保有者より、非保有者の方が、生存曲線が高くなる（生存期間が長くなる）はずです。生存時間データとその扱いについては、次とその次のエピソードでお話しします。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\n# install.packages(\"cifmodeling\") #インストールが必要なら実行\nlibrary(cifmodeling)\ncifplot(Event(time, status) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n2009～2014年にFDAによって承認されたがん領域の医薬品は、83品目あったそうです。奏効率（腫瘍縮小や完全寛解）がエンドポイントの臨床試験を根拠として承認されたのは、83品目のうち何割だったか、正しいものを選びなさい。\n\n0～24%\n25～49%\n50～74%\n75～100%\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は2です\n\nKim and Prasad（2016）の総説論文によると、奏効率の結果に基づいて承認されたのは83品目のうち31品目と報告されています。また、エンドポイントの内訳は通常承認と加速承認では異なります。通常承認では、55品目のうち48品目が全生存期間、無増悪生存期間、無病生存期間で評価されたのに対し、加速承認では、奏効率を主要エンドポイントとする第II相試験の結果を根拠にした品目が大多数でした。\n\n\n\n\n\n文献\n\nKim C and Prasad V. Strength of validation for surrogate end points used in the US Food and Drug Administration’s approval of oncology drugs. Mayo Clin Proc 2016; S0025-6196(16)00125-7\n\n\n\nエピソード、用語集、Rスクリプト\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\nStatistical Terms in Plain Language\nstudy-design.R"
  },
  {
    "objectID": "jp/publish-a-paper-4.html",
    "href": "jp/publish-a-paper-4.html",
    "title": "A Morning Just Before Submission",
    "section": "",
    "text": "Publish a Paper IV − A Morning Just Before Submission\n\n\n\n梅雨の雨音は、夜の静けさをなぐさめてくれる。診療の後、私たちはパソコンに向かう時間をとることが多い。今夜も私は、モニターに映る原稿を眺めていた。\n机の上には、論文と調査票が無造作に散らばっている。 紙ナプキンに書かれたメモのそばに、ルービックキューブがそっと置かれている。冷めかけたコーヒーに手を伸ばした。\n書いては止まり、 止まっては、また戻る。\n\n「背景」\n\n論文の冒頭に置かれるこのセクションでは、多くの論文が著者名とともに引用される。それはきっと私と同じ空間で書かれたものだ。\n\n「本研究の目的は―」\n\nこんなに短い一文に、こんなにも多くの意味が乗ることを、今の私は知っている。\n目的は、個人のものじゃない。研究仮説というフォーマットで、普遍的に共有できるように開かれていなければならない。それは私がどの地点から世界を眺め、どんな方向へ歩こうとしているのかを、そっと誰かに手渡すような行為だ。\n次に目が留まる。\n\n「方法」\n\n一番時間が掛かった節だ。自分がこれまで行ってきたことを文章にすればいいだけなのに、知らない誰かに、一から正しく伝えることは難しい。当然と思って見落としていたことを補わなければならない。共有され、一意に決まる言葉を選ぶ必要もある。\n書いては直し、読み返しては直す。この時間を、私はきらいではない。\n\n「本研究の主な結果は―」\n\nそこに置かれた数字も、以前とは違って見えた。数字は、患者さんに何が起きたかを記録したもの。同時に、世界への問いかけに返ってきた答えでもある。\n私たちは、よい診療をしてきたのだろうか。 問い方が変われば、返ってくる数字も変わる。 並んでいるだけに見える数字は、実は多くを語っている。そのことを今では知っている。患者さんを対象にした研究だからこそ、仮説には医療の価値観が滲む。それは「正しいかどうかを知る」というより、「よりよい技術に近づくための知識を得る」という態度に近い。\nたくさんのことが、仕事をしているときや、コーヒーを飲みながら人と話しているときには、通り過ぎてしまう。ひとりになると、それがよくわかる。\nコーヒーは机の端で、静かに冷えていた。モニターには、書き上げたばかりのConclusionが映っている。調査をデザインしたときに抱いていた疑問に、答えられているか。ひとつひとつ確かめる。\n私は軽く頷き、 ゆっくりとキーボードを叩いた。\n\n\nAcknowledgements ― We appreciate the advice from an anonymous statistician.\n\nThis concludes the story."
  },
  {
    "objectID": "jp/publish-a-paper-2.html",
    "href": "jp/publish-a-paper-2.html",
    "title": "Three Tips for Writing a Paper",
    "section": "",
    "text": "Publish a Paper II − Three Tips for Writing a Paper\n\nKeywords: language/writing\n\n\n\nあ、相談してよかった\n\n\n私「この前はピアレビューの仕組みについて話してくれたけど、次は論文の書き方を教えてよ」\n\n\nお父さん「いいよ。じゃあ最初のアドバイスはこれ」\n\n\n図表を作ってメッセージを決める\n\n\nお父さん「この前みせた抄録を、もう一度通して読んでみてよ。冒頭から結論まで、余計なことを書かず、ひとつのテーマに沿って書かれてない？」\n\n\n私「ほんとだ」\n\n\nお父さん「これは論文全体を書くときのコツでもある。読者になにを伝えたいかをひとつに絞っておくってこと」\n\n\n私「そうね。”Further support for employment is necessary”、つまりストーマ保有者は再就職が難しいから、さらなる就労支援が求められることを伝えてる文章になってる。ってことは、テーマっていうか、読者へのメッセージをひとつ決めなさいっていいたいのね」\n\n\nお父さん「うん、メッセージっていってもいい。でもね、論文なんだから、データに基づくことしか主張できないでしょ。だから、論文を書き始めるときは、論文に載せる図表を作ることから手をつけるといいよ。データからどこまでのことがいえるか、図表をみながらメッセージを決めると、文章を書くときの目標がはっきりするんじゃないかな」\n\n\n私「図表ねえ。まだ2個しかないよ。背景因子と復職率の表しか」\n\n\nお父さん「一部じゃなくて、すべての図表をセットで作っておいた方がいい。どうしてかっていうと、解析結果のバージョン管理がしやすくなるから」\n\n\n私「どういうこと？必要になったらそのときに図表を作るのじゃだめなの？」\n\n\nお父さん「図表を固定できるなら困らないんだけどね。データの扱いや統計手法の細かい違いで、同じような図表を作ることになりがちで、なかなか固定できないものなんだ。もちろん、いい結果が出るようにいろんな解析を試すっていう意味じゃないよ。載せる図表をひとまとめにしてセットにした方が、どのデータセットでいつ作ったかとか、管理しやすいでしょ。そういうこと」\n\n\n私「じゃあ、とりあえず図表作成から始めるか」\n\n\nお父さん「投稿規定にいくつ図表を載せられるか書いてあるから、確認してね。きっと図表を作る過程で、足りない図表を追加したり、図表を取捨選択したりすると思うんだ。そうしていくうちにメッセージも洗練されていくはず」\n\n\n私「図表を作ってメッセージを決めるっていうけど、いうほど簡単じゃなくない？私に説得力のあるメッセージが書けるかな」\n\n\nお父さん「説得力か。それはメッセージだけの問題じゃないよね。主張の裏付けは確かかどうかだもの。二つ目にこんなアドバイスをしようと思ってた」\n\n\n研究の限界を考察して説得力を高める\n\n\nお父さん「メッセージを考えるときに、批判的な視点を取り入れてみたらどうかな」\n\n\n私「批判的っていうのは、エディターとかレビュワーの視点っていう意味？批判的吟味って言葉は聞いたことあるけど」\n\n\nお父さん「そんな感じ。査読でどんなコメントがきそうか、予想することはよくあるよ。データの欠点についてどんな指摘がきそうか、統計手法につっこみはこないか、結果からロジカルに主張を導けてるか、とかね。思考の積み重ねが説得力を高めるんじゃないかな」\n\n\n私「じゃあさ、どの程度の欠点だったら許される？どのくらいのクオリティが要求されてるかわかんないんだよね」\n\n\nお父さん「それは一概にはいえない。たとえば結論の価値が高いなら、多少の欠点があっても採択したくなる。別の研究の二番煎じだったり、新規性が感じられなかったりする論文は、載せる価値がないって思っちゃう。そうだなあ。データがらみで一発リジェクトにしそうな理由って、診断方法が不正確なケースや、測定しておくべきデータがとられていないケースくらいじゃない？それ以外には、統計解析が間違っていたり、解析結果に明らかにバイアスが生じていたり、著者の論理が一貫しないってケースもあるかな」\n\n\n私「一発リジェクトじゃないってことは、メジャーリビジョンってこと？」\n\n\nお父さん「そういうこと。研究の弱みについて、著者はどう考えているか確認する必要があるし、バイアスがあっても、統計解析を工夫したり感度解析で対処できることも多い。でも、その結果が論文に示されていないだけかもしれないからね」\n\n\n私「ふーん。それって臨床試験でも同じなの？臨床試験は、どんな解析をするか、がちがちに決まっているんじゃなかったっけ。統計解析計画書っていう文書をつくるって聞いたことがあるよ。感度解析を追加しても許されるのかな」\n\n\nお父さん「そこは柔軟に考えないといけない。計画外の解析結果を、論文に載せることができなかったとしても、査読コメントへの回答で示すことはできるでしょ。レビュワーの方が間違っていて、論文で出したくないような結果を要求されることもゼロではないけど、そういうときには、レビュワーにだけ見せるっていう手を使うこともある。やっぱり困るのはデータがとられてないケースだよね。データがないと、解析結果を示してレビュワーを説得することもできない」\n\n\n私「なんとか対処できるような査読コメントしかこなかったらいいんだけど。でもさ、考えてみたら欠点なんていくらでもあるよね」\n\n\nお父さん「そう思うのは研究者あるあるだね。対処のしようのない欠点はどの研究にもある。じゃあみんなどうしてるかっていうと、Discussionの研究の限界（study limitations）っていうパラグラフに書くっていうのが、ひとつのやり方だね。たとえば、ストーマ保有者と非保有者を正しく比較できているのかっていう問題があるでしょ。どんな批判がくるか予想するうちに、調整できてない交絡因子を思いついちゃうかもしれない。もしデータをとっているなら、ロジスティック回帰の共変量に入れた方がいいよね。データがないならDiscussionで言い訳しないといけない」\n\n\n私「縁起でもないこといわないでよ」\n\n\nお父さん「まあ研究の限界ってネガティブな話題ではあるけど、きちんと研究の限界について考察しておくと、論文全体の説得力は増すよね」\n\n\n私「そうかもしれないけど」\n\n\nお父さん「それにぜったい批判的じゃなきゃだめってこともないと思う。書いているときとは別の視点で、原稿を見直すのは、いい論文を書くために効果的だよ。別人になったつもりで文章を推敲するっていうか」\n\n\n私「別の視点って誰目線よ」\n\n\nお父さん「たとえば、読者目線でパラグラフをひとつひとつ読む。きっと、読者がもっと説明してほしいところ、逆に冗長で読みにくいところ、そのパラグラフで言いたいことがはっきりしないところがあるはず」\n\n\n私「それはあるかもね。冷静に文章を読み直したら、自分でもなにいってるかわからんってなることあるよね」\n\n\nお父さん「そうそう、視点を変えるとクールダウンできるって面もあるね。論文の結論についていうと、賛成・反対の読者がそれぞれどう読むか想像してみるっていうのもいい。たとえば外科医にも、開腹手術派と内視鏡手術派がいるっていうじゃない。開腹手術と内視鏡手術を比較するランダム化臨床試験の論文を読んだとき、それぞれの派閥で、読み方が違いそうじゃない？侵襲性のことばかり考察に書いてあると、開腹手術派はいやな顔をしたり。そんなバランスを欠いた議論にならないように、賛成・反対の両方の視点で、原稿を見直すっていうのも、やり方のひとつ。結論が白黒はっきりするような論文では特に有効じゃないかな」\n\n\n私「それもいいかもね。あえて偏った主張をしたいわけじゃないもの」\n\n\nお父さん「じゃあ三つ目のアドバイス。論文本文の書き方について。本文の方が抄録よりずっと長い。本文を一気に書くのは無理だから、小分けにした方がいい。どのくらい小分けにして書くかっていうと、セクション（節）とパラグラフ（段落）を単位にするのがひとつの基準だよ」\n\n\nセクションとパラグラフごとに書く\n\n\n私「パラグラフは英語の授業で習ったやつだよね。セクションはそれをまとめたものか」\n\n\nパラグラフ数の統計\n\nお父さん「論文の章立てには、Introduction、Methods、Results、Discussion、Conclusionsというセクションを使う。たとえばIntroductionというセクションを書くことを想像してみて。Introductionには、いくつくらいのパラグラフがありそう？」\n\n\n私「え？えーっと、まず直腸がんについて書くでしょ。就労問題について書いて、ストーマについて説明して、先行研究を挙げて、って考えると、4～5パラグラフくらい？」\n\n\nお父さん「それは平均より多いっていわれてる。論文1本あたりの、セクションごとのパラグラフ数の平均（SD）を調べた調査がある。次の表は、1997年1月1日から連続で掲載された50論文を集計したものだよ。ちなみに、この集計が載ってる論文執筆のテキストは、実践的ないい本だよ（Albert 2016）」\n\n\n\n\n\nIntroduction\nMethods\nResults\nDiscussion\n\n\n\n\nN Engl J Med\n2.6（1.1）\n9.2（3.3）\n8.9（3.8）\n6.9（1.8）\n\n\nLancet\n2.6（1.3）\n7.6（3.6）\n6.1（2.9）\n7.0（2.6）\n\n\nBMJ\n2.3（0.9）\n6.0（3.7）\n5.9（3.1）\n7.4（2.8）\n\n\nJ Pediatr\n2.6（1.1）\n6.7（3.4）\n7.0（3.9）\n7.3（2.8）\n\n\nPediatr Res\n2.6（1.3）\n9.6（3.8）\n6.3（2.9）\n8.5（3.4）\n\n\nArch Dis Child\n2.6（1.3）\n6.5（4.0）\n6.1（4.0）\n6.9（2.8）\n\n\n\n\nお父さん「臨床系のジャーナルに投稿するなら、Introductionは3パラグラフ、MethodsからDiscussionまではそれぞれ7パラグラフが目安かな。もちろん論文の内容にもよるけどね。もし、がんや消化管外科の専門誌に出すなら、直腸がんの細かい説明を省略すれば、Introductionのパラグラフを減らせるかもしれない。たとえば、”Employment of cancer survivors is an emergent problem”っていうような一文から始まって、就労問題について議論していっても不自然ではないでしょ」\n\n\n私「そっちの出だしの方がこなれてる感じがする」\n\n\nお父さん「こんな経験ない？どんな内容にするか考えながら文章を書くと、知らず知らずのうちに無駄に長くなっちゃうこと。そうならないように、パラグラフごとにトピックを明確にしておくといいよ。調査方法とか研究の限界とか、いろいろなトピックがあるけど、それぞれ読者に伝えないといけない情報があるでしょ」\n\n\n私「うん、パラグラフライティングを意識すると、必要十分な情報が把握しやすくなりそう」\n\n\nお父さん「最後に、論文の構成について話そう。一般的にいうとね。Introductionでは、どのような科学的な背景があってその研究が行われたのか、研究に関わる様々な論拠、研究仮説や研究目的を書く。Methodsは研究方法を、Resultsは結果を書く。Discussionは、研究の意義を説明したり、他の研究と比べたり、研究の限界について述べたりする」\n\n\n私「なんとなくはわかるけどね」\n\n\nお父さん「ピアレビューを意識するなら、Methodsで必要な情報を漏らさず丁寧に説明するように、気をつけなさい。さっきいったように、正しい方法論で研究したんだって、わかってもらうことがポイントだからね」\n\n\n私「漏らさず丁寧に？たった7パラグラフしかないのに？」\n\n\nお父さん「そういうことになっちゃう。それに、論文の文字数には投稿規定による上限がある。だから工夫が必要だよね。よくやる手は、ジャーナルのサイトからダウンロードできる付録（supplementary material）に書くってこと。方法や結果の細かい部分は、MethodsやResultsの本文に入らないことがあるからね。あとは、引用文献をうまく利用すると、説明を省略できるかもしれない。引用文献のスタイルは、間違えてると印象が悪いから注意してね」\n\n\n私「なるほど、論文のボリューム感がわかってきた。思ったより、簡潔に、しかも情報を詰め込むように書くんだね。付録とかにできるんなら、どっちかっていうと、ボリュームの制限より、書き忘れがないことに注意しないと」\n\n\nお父さん「そうだね。書き忘れ対策としては、医学雑誌編集者国際委員会（ICMJE）という団体が、なにを書かなきゃいけないかリストを用意してくれている（EQUATOR Network 2007）。調査や観察研究の論文を書くときは、観察研究の報告のため用意されたSTROBEチェックリストを参考にするといい」\n\n\n私「へー。論文に書くことリストだね。項目をひとつひとつパラグラフにしていけばいいって考えると、気が楽になった。論文書いてみるね」\n\n\n\n\n\n\n\n\n\nSTROBEチェックリスト\n\n\n\n\n\n\n\n\n\n\n\n\n\nセクション\n項目\n内容\n\n\n\n\nTitle and abstract\nタイトルと抄録\n（a）タイトルまたは抄録のなかで、試験デザインを一般に用いられる用語で明示する。（b）抄録では、研究で行われたことと明らかにされたことについて、十分な情報を含み、かつバランスのよい要約を記載する。\n\n\nIntroduction\n背景と論拠\n研究の科学的な背景と論拠を説明する。\n\n\nIntroduction\n目的\n特定の仮説を含む目的を明記する。\n\n\nMethods\n研究デザイン\n研究デザインの重要な要素を、論文のはじめの部分で示す。\n\n\nMethods\nセッティング\nセッティング、実施場所のほか、基準となる日付については、登録、曝露、追跡、データ収集の期間を含めて明記する。\n\n\nMethods\n参加者\n（a）適格基準、参加者の母集団、選定方法を明記する。追跡の方法についても記述する。（b）マッチング研究の場合、マッチングの基準、曝露群と非曝露群の各人数を記載する。\n\n\nMethods\n変数\nすべてのアウトカム、曝露、予測因子、潜在的交絡因子、潜在的な効果修飾因子を明確に定義する。該当する場合は、診断方法を示す。\n\n\nMethods\nデータ源と測定方法\n関連する各因子に対して、データ源、測定・評価方法の詳細を示す。2つ以上の群がある場合は、測定方法の比較可能性を明記する。\n\n\nMethods\nバイアス\n潜在的なバイアス源に対応するためにとられた措置があればすべて示す。\n\n\nMethods\nサンプルサイズ\nサンプルサイズがどのように算出されたかを説明する。\n\n\nMethods\n量的変数\n量的変数の分析方法を説明する。該当する場合は、どのグルーピングがなぜ選ばれたかを記載する。\n\n\nMethods\n統計手法\n（a）交絡因子の調整に用いた方法を含め、すべての統計学的方法を示す。（b）サブグループと交互作用の検証に用いたすべての方法を示す。（c）欠測データをどのように扱ったかを説明する。（d）該当する場合は、脱落例をどのように扱ったかを説明する。（e）あらゆる感度分析の方法を示す。\n\n\nResults\n参加者\n（a）研究の各段階における人数を示す（例：潜在的な適格者数、適格性が調査された数、適格と確認された数、研究に組入れられた数、フォローアップを完了した数、分析された数）。（b）各段階での非参加者の理由を示す。（c）フローチャートによる記載を考慮する。\n\n\nResults\n記述的データ\n（a）参加者の特徴（例：人口統計学的、臨床的、社会学的特徴）と曝露や潜在的交絡因子の情報を示す。（b）それぞれの変数について、データが欠測した参加者数を記載する。（c）追跡期間を平均および合計で要約する。\n\n\nResults\nアウトカムデータ\nアウトカムのイベント発生数や要約指標の数値を経時的に示す。\n\n\nResults\n主な結果\n（a）調整前の推定値と、該当する場合は交絡因子での調整後の推定値、そしてそれらの精度（例：95％信頼区間）を記述する。どの交絡因子が、なぜ調整されたかを明確にする。（b）連続変数がカテゴリー化されているときは、カテゴリー境界を報告する。（c）意味のある場合は、相対リスクを、意味をもつ期間の絶対リスクに換算することを考慮する。\n\n\nResults\n他の解析\nその他に行われたすべての分析（例：サブグループと交互作用の解析や感度分析）の結果を報告する。\n\n\nDiscussion\n鍵となる結果\n研究目的に関しての鍵となる結果を要約する。\n\n\nDiscussion\n限界\n潜在的なバイアスや精度の問題を考慮して、研究の限界を議論する。潜在的バイアスの方向性と大きさを議論する。\n\n\nDiscussion\n解釈\n目的、限界、解析の多重性、同様の研究で得られた結果やその他の関連するエビデンスを考慮し、慎重で総合的な結果の解釈を記載する。\n\n\nDiscussion\n一般化可能性\n研究結果の一般化可能性（外的妥当性）を議論する。\n\n\nOther information\n研究の財源\n研究の資金源と資金提供者の役割を明記する。\n\n\n\n\n\n\n\n\n\n\n\n\n因果関係に基づく変数の分類\n\n\n\nSTROBE声明の「変数」というセクションでは、いくつか基本的で重要な専門用語が出てきます。これまで出てきたものも多いのですが、簡単に振り返っておきます。\n\nアウトカム（outcome）: 因果関係における結果に対応する変数。臨床試験ではエンドポイントという用語を用いる\n曝露（exposure）: 因果関係における原因に対応する変数。治療（treatment）のこともある\n予測因子（predictive factor）: アウトカムの予測に用いられる共変量のこと。または、アウトカムと相関する共変量のことで、この場合は予後因子（prognostic factor）と同じ意味になる\n交絡因子（confounder）: 因果効果の推定においてバイアスを排除できるような共変量の集合\n効果修飾因子（effect modifier）: 因果効果の大きさや方向の違いをもたらす共変量のこと。または、曝露との交互作用がある共変量のこと\n\n\n\n\n\n文献\n\nAlbert T. Winning the Publications Game. Florida: CRC Press; 2016\nThe STROBE reporting guideline for writing up observational studies in epidemiology [Internet]. Oxford: EQUATOR Network; 2007\n\n\n\n次のエピソード\n\nCommunicating with Care"
  },
  {
    "objectID": "jp/logistic-regression-6.html",
    "href": "jp/logistic-regression-6.html",
    "title": "Understanding Confounding in Effect Measures: Marginal vs Stratified",
    "section": "",
    "text": "Adjusting for Bias V − Understanding Confounding in Effect Measures: Marginal vs Stratified\n\nKeywords: confounding & collapsibility, effect measure, observational study, R simulation\n\n\n\nロジスティック回帰で「調整する」ってどういうこと？\n\n\n私「お父さん、ロジスティック回帰でわからないことがあるんだけど。観察研究では交絡因子（confounder）を調整しないといけないって前にいってたよね」\n\n\nお父さん「ああ、そんな話もあったね」\n\n\n私「でも統計学の本を読んでも、なにをどう調整するのか書いてないんだよ」\n\n\nお父さん「いいよ。でも少し長くなる。コーヒーでも飲みながらでいい？」\n\n\n私「賛成。いちご大福あるから、とってくる」\n\n\nお父さん「疫学では有名な話なんだけどね。40年前に、“コーヒーを飲むと膵がんリスクが上がる”という論文が出たことがあった」\n\n\n私「いかにもありそうな話だね」\n\n\nお父さん「そうでしょ。でも、観察研究では、コーヒーを飲む習慣のある集団と、きちんと比較できるようなコントロールを選ぶことは難しい。だから疫学の教科書では、集団同士を比較するときには、第3の因子が隠れていないか注意せよと、必ず書いてある」\n\n\n私「ふんふん」\n\n\nお父さん「それでは問題です。このコーヒー論争で、実際に問題になった第3の因子はなんでしょう？」\n\n\n私「え？えーっと」\n\n\n\nお父さん「答えはこれ」\n\n\n\n\n\n\n\n\nお父さんの答えは？\n\n\n\n\n\nそれは喫煙です。当時は今より喫煙率が高くて、ほとんどの方がコーヒーと一緒にたばこを吸っていたそうです。\n\n\n\n\n\n\n私「へえ、そんな話があったんだ」\n\n\nお父さん「じゃあさ、こういう第3の因子を無視して解析するとどうなる？」\n\n\n私「それくらいわかるよ。バイアスが入るんでしょ」\n\n\nお父さん「そういうこと。これが疫学でいう交絡因子。交絡調整がなにしているかは、数字をみるのが一番早い。Simpsonのパラドックスっていう現象を使って説明しよう」\n\n\n\n\n\n\n\n\nSimpsonのパラドックス\n\n\n\nコーヒーと膵がんの数値例を用いて、統計学でいう調整とはどういう操作のことなのか、一番シンプルな層別解析でみてみましょう。表1は、コーヒーと膵がんを想定した仮想データです。コーヒー摂取群とコーヒー非摂取群で、それぞれ膵がん発生ありとなしが調べられています。膵がんを発生したのはそれぞれの群で15人と12人、膵がんがなかったのは365人と868人です。オッズ比を計算してみましょう。コーヒー摂取群では膵がんリスクは3.9%で、コーヒーを摂取しない群の1.4%に比べて、（未調整の）オッズ比は3倍です。これは、コーヒーを摂取すると、膵がんリスクが高くなることを示唆しているようにみえます。\n表2には、交絡因子（喫煙）によって対象者を層別した結果が示されています。ここから膵がんのオッズ比を求めるとどうなるでしょうか。層ごとの結果ではコーヒー摂取でも非摂取でもリスクは同じですよね。つまりオッズ比は1倍です。\nこのように、調整前後で、関連の程度が変わる現象を、Simpsonのパラドックスといいます（Simpson 1951）。\n表1. 層別前の膵がんリスクとオッズ比\n\n\n\n\nコーヒー摂取\nコーヒー非摂取\nオッズ比\n\n\n\n\n合計\n\n\n\n\n\n　膵がんあり\n15\n12\n\n\n\n　膵がんなし\n365\n868\n\n\n\n　リスク\n3.9%\n1.4%\n3倍\n\n\n\n表2. 層別後の膵がんリスクとオッズ比\n\n\n\n\nコーヒー摂取\nコーヒー非摂取\nオッズ比\n\n\n\n\n喫煙\n\n\n\n\n\n　膵がんあり\n14\n4\n\n\n\n　膵がんなし\n266\n76\n\n\n\n　リスク\n5.0%\n5.0%\n1倍\n\n\n非喫煙\n\n\n\n\n\n　膵がんあり\n1\n8\n\n\n\n　膵がんなし\n99\n792\n\n\n\n　リスク\n1.0%\n1.0%\n1倍\n\n\n\n\n\n\n\n私「単純な解析ではリスク因子だったのに、層別しただけで関連が消えた。でもこれは計算のトリックじゃないよね？以前こうやって雑談してたとき、オッズ比は層別すると数値が安定しないっていってたのは関係ある？」\n\n\nお父さん「さすが、覚えていたね。でもここは区別しないといけない。確かにオッズ比はリスク比と違って、層別したら値が変わりやすい、併合可能ではない（non-collapsible）指標だよ。でもこれは指標の性質の話。ここで問題しているSimpsonのパラドックスは、“比較の土台”が壊れている話なんだ」\n\n\n私「たしかに。この前はランダム化臨床試験、今回は観察研究だものね。コーヒー好きはコーヒーを飲まない人とは別の特徴を持っていて、単純に比較するのはバイアスってわけだ」\n\n\nお父さん「そういうこと。ほとんどの観察研究で、交絡の影響は、効果の指標の違いよりずっと大きい。層別で関連が消える現象は、一般化線型モデルでも再現できるよ」\n\n\n\n\n\n\n\n\nglm()を用いた膵がんデータの解析\n\n\n\n交絡調整のための統計手法として、層別解析以外に一般化線型モデルもよく用いられます。オッズ比のモデルであるロジスティック回帰は、link=\"logit\"を用いたglm()に、リスク比はlink=\"log\"に対応していましたね。以下のコードでは調整前のオッズ比・リスク比はsmokeを入れないモデルで、調整後のオッズ比・リスク比はsmokeを入れたモデルで推定しています。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\ndat &lt;- data.frame(\n  cancer = c(1, 0, 1, 0,   1, 0, 1, 0),\n  coffee = c(1, 1, 0, 0,   1, 1, 0, 0),\n  smoke  = c(1, 1, 1, 1,   0, 0, 0, 0),\n  n      = c(14, 266, 4, 76,  1, 99, 8, 792)\n)\nfit_logit1 &lt;- glm(\n  cancer ~ coffee,\n  family  = binomial(link = \"logit\"),\n  weights = n,\n  data    = dat\n)\nodds_ratio1 &lt;- exp(coef(fit_logit1)[[\"coffee\"]])\nprint(odds_ratio1)\n\n[1] 2.972603\n\nfit_logit2 &lt;- glm(\n  cancer ~ coffee+smoke,\n  family  = binomial(link = \"logit\"),\n  weights = n,\n  data    = dat\n)\nodds_ratio2 &lt;- exp(coef(fit_logit2)[[\"coffee\"]])\nprint(odds_ratio2)\n\n[1] 1\n\nfit_log1 &lt;- glm(\n  cancer ~ coffee,\n  family  = binomial(link = \"log\"),\n  weights = n,\n  data    = dat\n)\nrisk_ratio1 &lt;- exp(coef(fit_log1)[[\"coffee\"]])\nprint(risk_ratio1)\n\n[1] 2.894737\n\nfit_log2 &lt;- glm(\n  cancer ~ coffee+smoke,\n  family  = binomial(link = \"log\"),\n  weights = n,\n  data    = dat\n)\nrisk_ratio2 &lt;- exp(coef(fit_log2)[[\"coffee\"]])\nprint(risk_ratio2)\n\n[1] 1\n\n\n\n\n\n\n\nSimpsonのパラドックスが起きる条件\n\n\n私「やっぱりトリックに見えちゃうな、何が起きてるのやら。とりあえず調整しとけっていいたいの？」\n\n\nお父さん「えっとね、いちばん伝えたいことから話すね。研究の原則としてときどき使う”ceteris paribus”というラテン語があってね。“All other things being equal”くらいの意味なんだけど、比較する集団で条件をそろえたら、交絡によるバイアスは生じない。たとえばランダム化臨床試験とかね」\n\n\n私「うん、その説明はわかりやすい」\n\n\nお父さん「じゃあ、その次になにが起きたか整理しよう。まず前提になるのが、喫煙が膵がんのリスク因子だってこと。OK？」\n\n\n私「うん」\n\n\nお父さん「次に注目してほしいのが、喫煙とコーヒーの関連なんだ。喫煙状況ごとにコーヒー摂取割合を計算してみてよ」\n\n\n私「コーヒー摂取割合ね。層別前は30%。喫煙者では78%、非喫煙者では11%だよ」\n\n\nお父さん「喫煙群と非喫煙群でコーヒー摂取割合に大きな差があるでしょ。この現象が起きた理由は、コーヒー摂取と喫煙に強い関連があったため、ということ。これは、当時、たばこを吸いながらコーヒーを飲んでいたことを表している」\n\n\n私「時代を感じるね、仕事の合間に一服したい気持ちはめっちゃわかる」\n\n\nお父さん「Simpsonのパラドックスのポイントは、3つの変数の相関関係なんだ。2つの条件が揃うとSimpsonのパラドックスが起きやすい（厳密には十分条件で必要条件ではない）」\n\n\n第3の因子と曝露の間に相関がある\n第3の因子とアウトカムの間に相関がある\n\n\n私「曝露とアウトカムと第3の変数の関係性ねえ。ちょっと確認させて。コーヒー摂取群とコーヒー非摂取群で、喫煙率が違う。さらに喫煙は膵がんリスクも上げる。そうすると層別したらオッズ比の値が変わった。ああ、もともとバイアスが入ってたんだから、調整して値が変わるのは当然か。確かにそうなる。交絡の話って、ややこしいね」\n\n\n\n\n文献\n\nSimpson EH. The interpretation of interaction in contingency tables. J Royal Stat Soc B 1951;13:238-41\n\n\n\nThis concludes the Adjusting for Bias series. If you’d like to keep reading over your next cup of coffee, the following episode is waiting:\n\nWhat Data Cannot Tell Us"
  },
  {
    "objectID": "jp/logistic-regression-4.html",
    "href": "jp/logistic-regression-4.html",
    "title": "Where My Logistic Regression Went Wrong",
    "section": "",
    "text": "Adjusting for Bias IV − Where My Logistic Regression Went Wrong\n\nKeywords: confounding & collapsibility, effect measure, generalized linear model, language & writing\n\n\n\nどうしてオッズ比が無限大になっちゃったの？\n\n\nお父さん「あのさ、昨日のロジスティック回帰の表の続きをしない？コーヒー淹れたから」\n\n\n私「えーお手やらわかに。コーヒーもありがとう。この表の話だよね」\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nパラメータ\n自由度\n推定値\n標準誤差\n95%信頼区間\n\\(\\chi^2\\)\np値\n\n\n\n\nIntercept\n1\n-27.25\n3.03\n-33.20～-21.30\n80.55\n&lt;0.01\n\n\nSTOMA\n1\n1.41\n1.54\n-16.1～4.45\n0.84\n0.3588\n\n\nAGE\n1\n1.47\n1.48\n-1.42～4.36\n0.99\n0.3197\n\n\nSEX\n1\n25.72\n0.00\n25.72～25.72\n\n\n\n\nINCOME\n1\n-0.00\n0.00\n-0.00～0.00\n0.58\n0.4481\n\n\n\n\n\nお父さん「そう、これね、間違いではないんだけど、まだよくできる。表を作成するときには、情報が自然に入ってくるように、読者の立場で考えなくちゃ。具体的な注意点はこんなところかな」\n\n\n\n読者の立場で考える\n表のフォーマットに従う\n単位・表示桁数に気を配る\n表タイトル・脚注を利用して補足情報を伝える\n数え尽くしの原則を守る\n\n\n\nお父さん「ロジスティック回帰からいろんな指標が出せるけど、表にはオッズ比、95%信頼区間、p値だけあれば普通はじゅうぶんだよ」\n\n\n私「それはこの表にも載ってるよね」\n\n\nお父さん「載っていません。この表の”推定値”は、みたところ回帰係数の値でしょ。それを換算してオッズ比のスケールに直さないといけない。換算するには、回帰係数\\(\\beta\\)の指数をとって、\\(OR=\\exp(\\beta)\\)を求めればいい」\n\n\n私「そうなのか。ストーマのオッズ比は\\(\\exp(1.41)=4.1\\)ってことね。あれ？\\(\\exp(25.72)\\)を計算してみると、パソコンに表示できないくらいに大きい数字になったんだけど。ほとんど無限大に近い数字だ。性別の影響が強いのかな。年収は\\(\\exp(-0.00)\\)？なんか変だな」\n\n\nお父さん「これはよくあるトラブルだよ」\n\n\n私「そうなの？」\n\n\nお父さん「復職しなかった患者さんはほとんど女性だったんじゃない？擬似完全分離（quasi-complete separation）っていうデータの配置上の問題が起きちゃってて、性別の回帰係数を、うまく推定できていないんだ。この先は少し長くなりそうだから、ちょっとたばこ吸わせてもらうね」\n\n\n\n\n\n\n\n\n完全分離\n\n\n\nロジスティック回帰の回帰係数は、最尤法（maximum likelihood）という汎用的な推定方法によって計算されます。これはある種の方程式を解くことに対応していますが、データから必ずしも解が求まるわけではありません。これが完全分離（complete separation）や擬似完全分離（quasi-complete separation）という問題です。これらの問題が起きると、回帰係数が求まらなかったり、不安定だったりするため、共変量の数の削減や、最尤法以外の推定方法の利用など、なんらかの根本的な対処が必要になります。\n\n\n\n\nお父さん「（灰皿にたばこを押しつけながら）正しい計算ができていないわけだから、ロジスティック回帰の結果を示すのはやめた方がいい。性別だけじゃなくて年収も問題だね。単位が円のまま扱うと、桁が大きすぎて数字が読めない。単位を万円にして、年収が1万円増えたら復職率がどう変化するかを示すといいんじゃないかな。性別と年収の扱いは気になると思うけど、今はこれくらいにしよう。表の体裁を直してあげるよ」\n\n\n\n\n\n\nオッズ比\n95%信頼区間\np値\n\n\n\n\nストーマなし\n（基準）\n\n\n\n\nストーマあり\n4.13\n0.20～85.23\n0.36\n\n\n65歳未満\n（基準）\n\n\n\n\n65歳以上\n4.35\n0.24～78.60\n0.32\n\n\n女性\n（基準）\n\n\n\n\n男性\n∞\n∞～∞\n\n\n\n年収（万円）\n1.00\n0.98～1.01\n0.45\n\n\n\n*手術後1年以内の復職をアウトカムとした多変量ロジスティック回帰\n\n\n私「あれ？オッズ比4.13倍ってことは、復職率がだいたい4倍になったってこと？そんなことある？」\n\n\nお父さん「違う違う。あのね、オッズ比はオッズの比をとったもの。オッズっていうのは、復職率を\\(\\pi\\)で表すと、それを\\(\\pi/(1-\\pi)\\)と変換したものなんだ。\\(\\pi\\)が0に近いときは、オッズ比は\\(\\pi\\)の比に近い値になるんだけど、比の分子と分母の取り方で、向きが変わることに注意しないといけない。今回は、モデルの定義上、ストーマありの方が”復職できない”オッズが約4倍という意味だよ。ただし、2値アウトカムを”復職できない”に取ると、向きは逆になる」\n\n\n私「わかりにくいのう」\n\n\nお父さん「じゃあ、どこに気を付けて手直ししたか説明するね。ロジスティック回帰では、共変量はなにで、どう扱ったかを正確に伝えることが大切なんだ。データをみると、年齢は65歳未満か以上かで分類した2値データみたいだね。そういうときは、何歳で分類したか、どの分類を基準にしたかわからないと、結果を読み取れない。また、連続データでは、忘れがちだけど単位が必要。年収の単位を円から万円にして、表に追記しておいたよ」\n\n\n\n\n\n\n\n\n注意事項1. フォーマット\n\n\n\n\n\n論文で示される表には、決められたフォーマットがあります。表は、行（row）と列（column）から構成され、行と列は概念的には対称ですが、視覚的には役割が異なります。英語圏では、表は左から右に、行ごとに読むことが慣習になっています。そのため、このサイトに示されている表のように、縦線で区切ることはしません。\n数字の意味をわかりやすく伝えるためには、どこにどのような情報を配置するかに気を配るべきです。さきほどの表では、列が指標の種類を表すというシンプルな方針を採用しています。そのため、数字がオッズ比、95%信頼区間、p値に対応することが一目でわかります。また、必要な情報から順に読み取れるように、各行または各列の順序にも気を配りたいところです。\nある程度大きな表であれば、情報はグループにわけられることが普通です。表のフォーマットも、グループが視覚的にわかりやすいように工夫できます。たとえば後に出てくる表1では、行と列でそれぞれグループ化がなされています。行をグループ化するときには字下げ（indent）を用います。性別の内訳を示すために字下げがなされていますよね。また、列をグループ化するときにはスパナ（spanner）を用います。“ストーマ保有者”、“ストーマ非保有者”といった列の見出しを、スパナヘッド（spanner head）といいます。\n\n\n\n\n\n\n\n\n\n注意事項2. 単位・表示桁数\n\n\n\n\n\n表では測定単位（unit）を明らかにすることが重要です。臨床検査値を扱う論文を投稿するときは、その雑誌の編集方針をみて、どのような単位系を採用しているか確認しましょう。\n数字の表示桁数は、ある程度桁数やルールが統一されていなければ、印象を悪くします。統計ソフトウェアが出力する数字は桁数が大きいことがありますが、そのまま表に示す必要はありません。有効数字2桁または3桁か、もともとの測定値より桁数を1桁大きく示すのが基本です。\n日本工業規格（Z 9041-1:1999）によると、平均の有効数字は、測定値より1～2桁大きく、標準偏差の有効数字は、最大でも3桁程度といわれています。つまり、むやみに数字の表示桁数を増やしても精確性が増すわけではないのです。年齢を例に挙げると、測定単位は「歳」なので、小数点1桁まで示すとよいでしょう。表1の年齢の平均・標準偏差では、そのようになっています。p値については、小数点以下2桁か3桁まで報告すれば、有意水準（0.05が多い）との大小関係が読み取ることができるので、必要十分でしょう。\n\n\n\n\n\n私「表の作り方をご助言いただけるのはありがたいんだけどさ、肝心のロジスティック回帰はどうすればいいんだろ」\n\n\nお父さん「擬似完全分離を避けるには、共変量の数を削るのがわかりやすい。今回はサンプルサイズが不足しているみたいだから、他の共変量はすべて使わないで、単にストーマ造設と復職率だけの関連を調べたらどうかな？1パラメータあたり5〜10イベント程度は欲しいといわれるからね。その場合も、通常の\\(\\chi^2\\)検定は使わない方がいいよ。Fisherの正確検定とClopper-Pearson信頼区間っていう方法が推奨されている」\n\n\n\n\n\n\n\n\n2値データの解析においてサンプルサイズが不足したときの指針\n\n\n\n\nロジスティック回帰の共変量の数を減らす（目安としてパラメータの数のおよそ5倍のイベント数が必要）\n\\(\\chi^2\\)検定ではなくFisher正確検定を用いる\n2項分布に基づく信頼区間（Clopper-Pearson信頼区間）を用いる（田中2022）\n\n\n\n\n\n足りなかったたくさんの情報\n\n私「でも、ロジスティック回帰で交絡因子を調整しなさいっていったのはお父さんなんだよ」\n\n\nお父さん「そうだね、それは重要な問題だよね。じゃあ、ストーマ保有者と非保有者で、年齢、性別、年収の分布がどれくらい違うかをまず確認しようか。前にも話したとおり、年収を尋ねたことでバイアスが生じていないかとか、年収を尋ねて欠測が多いんじゃないかとか、いろいろ気になるし。もし分布が揃ってたら、調整しなくても影響は小さいかもしれない」\n\n\n私「あ、その表なら資料にあるよ」\n\n\nお父さん「じゃあ、あとはストーマ造設と復職率の関連を表にするだけだね。資料には、以下の表1と表2を載せればいいよ」\n\n\n表1. 20XX～20YY年にZZ病院で手術を受け、がんサバイバー復職率調査に回答した直腸がん患者80人の背景因子の記述\n\n\n\n\nストーマ保有者（N=20）\nストーマ非保有者（N=60）\n\n\n\n\n年齢（歳）\n57.0 (8.6)\n65.5 (10.4)\n\n\n65歳以上\n10.0%\n51.7%\n\n\n性別\n\n\n\n\n　男性\n35.0%\n53.3%\n\n\n　女性\n60.0%\n46.7%\n\n\n　不明\n5.0%\n0.0%\n\n\n年収（万円）\n508 (77)\n514 (101)\n\n\n\n*平均（SD）または%\n表2. 直腸がん患者のうちストーマ保有者20人と非保有者60人の復職率の比較\n\n\n\n\n\n\n\n\n\n\n\n\nN\n1年以内に復職せず\n復職率\n95%信頼区間*\np値†\n\n\n\n\nストーマあり\n20\n1\n95.0%\n75.1～99.9%\n\n\n\nストーマなし\n60\n2\n96.7%\n88.5～99.6%\n1.00\n\n\n\n*Clopper-Pearson法\n†Fisher正確検定\n\n\nお父さん「集団のアウトカムを比較したいときは、その前に表1のようにそれぞれの集団の背景因子を記述するべきだよ。ストーマ保有者は20人しかいなくて、非保有者に比べて、平均年齢が低くて、女性が多いわけだ。やっぱり最終的にはロジスティック回帰で、背景因子の違いを調整しないといけないかもね。現時点での調査の回答率はどうだった？」\n\n\n私「調査票は100人に送って、80人から回収できたから、回答率は80%かな」\n\n\nお父さん「項目ごとの無回答（item non-response）についてはどう？」\n\n\n私「そっか、調査票を回収できたかと、項目ごとの回答があったかは別だもんね。年齢は全員回答してくれたよ。性別は1人記入していなかった。項目ごとの回答数まで、表に示した方がよかった？」\n\n\nお父さん「ううん、論文ではそこまで細かい数字は示さないことが多い。重要な変数が欠測してたりするなら別だけどね。たとえばさ、ロジスティック回帰を行うとき、性別不明はどう扱ったの？」\n\n\n私「統計ソフトウェアのマニュアル調べたら、欠測は自動的に除外されるんだって」\n\n\nお父さん「そうすると解析対象の人数が80人じゃなくて79人に減るんだから、表を作るときにそこを説明しておかないといけないんじゃない？一般に、ロジスティック回帰の結果を示す表だけだと、どんなデータかわかりにくいっていう問題がある。復職できなかったのは3人しかいないって、表2をみるまで気づかなかったよ？まだ1施設からのデータしか集まってないからでしょ。それじゃあロジスティック回帰はしたくてもできないよね」\n\n\n私「確かにね。そのあたりの状況を、読者に伝えなきゃって気持ちが足りなかったみたい」\n\n\n\n\n\n\n\n\n注意事項3. 表タイトル・脚注\n\n\n\n\n\n読者が表を読むときのことを想像してみてください。最初に目にするのは、表に示された結果自体ではなく、表タイトルの情報です。簡潔な表タイトルをよく目にしますが、これはもったいないことです。表1、表2の表タイトルには、調査が行われた状況、対象疾患、人数、統計解析の目的などが含まれています。表タイトルを決めるときは、可能な限り多くの情報を伝えるように工夫しましょう。\n表には様々な数字が示されますから、どういった指標かわかりにくいときがしばしばあります。もしかしたら、複雑な統計手法から計算されたものかもしれません。データを解析するために用いた統計手法は、方法のセクションで説明することが基本ですが、読者への配慮として、表の脚注（footnote）を利用することもあります。表1でいえば、括弧内の数字の意味は自明ではないので、“平均（SD）または%”と脚注がついていますよね。表2の脚注には、どの統計手法を用いて信頼区間とp値を計算したかが説明されています。このように読者にとってなじみのない指標や表現には、補足説明が必要です。\n脚注を参照するための記号には、a、b、cまたは*、†、‡、§、¶を用いるのが正式です。\n\n\n\n\n\n\n\n\n\n注意事項4. 数え尽くしの原則\n\n\n\n\n\n統計解析の経験があるものなら誰でも、様々な理由で対象者が除外されるため、個々の解析で、人数が必ずしも同じにならないことを知っているものです。透明性を高めるために、統計解析ごとに、何人が対象となったか報告するべきです。\n統計家の間では、数え尽くしの原則（principle of exhaustion）という言葉があります。分類変数の分類が複雑だったり、欠測データがあったりするときには、分類ひとつひとつの人数を合計し、それが全体の人数に合うかどうかを確認せよ、というのがこの原則の教えです。最初に作成した表では人数が示されておらず、どのようなデータが解析されたのかわかりません。一方、表1・表2では、何人が解析対象で、何人が復職したのかが記述されています。さらに、数え尽くすと全体80人や100%に一致することから、正しく集計されたことが読み取れます。\n\n\n\n\n\n私「ちなみにお父さん、もし”臨床疑問と研究仮説”で例を挙げてくれたときの研究仮説3みたいに、研究の目的が復職率と関連する因子の探索だとしたら、何か変わることはある？」\n\n\nお父さん「どんな特徴を持った患者が、復職が難しいのか、予測因子をみつけたいってことかな。予測因子の候補となるデータがあるなら、それをロジスティック回帰の共変量に入れることで、予測因子の探索を行うことができるよね」\n\n\n私「うんうん」\n\n\nお父さん「こういった探索的検討では、特定の因子に関心がないってことが第一の違いだよ。ストーマと復職率の関連を調べるときは、ストーマのオッズ比やp値を求めることがゴールでしょ。予測因子の探索では、予測因子の候補をできるだけたくさん集めて、どの因子をモデルに入れたら予測精度が高いか、逆にどの因子は要らないかを調べることがゴールになる。これを変数選択っていうんだ」\n\n\n私「ゴールは違ってもさ、p値を使えばよくない？有意な因子をモデルに入れたらいいんでしょ」\n\n\nお父さん「そういうやり方もあるけどね。予測2乗誤差、ROC曲線、AICといった予測精度専用の指標を使うことも多い。大事なのはね。予測因子の候補や変数選択の基準を、研究計画書などに書いておくこと。事前に決めておかないと、どうしても研究者の主観が入っているんじゃないかって批判されるからね」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nロジスティック回帰の起源として正しいのは、次の時代のうちどれでしょうか。\n\n1900年以前\n1900～30年\n1931～60年\n1961年以降\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は1です\n\n少なくとも、ベルギーの数学者Queteletが1838年に出版した書籍に、ロジット関数の式が示されています。ロジスティックという単語は、同じくベルギーの数学者Verhulstが1845年にProceeding of Belgian Royal Academyで、初めて用いられたとされています。\n\n\n\n\n文献\n\n田中司朗. 医学研究のための因果推論I. 一般化線型モデル. 東京: 朝倉書店; 2022\n\n\n\n次のエピソードとRスクリプト\n\nWhy Logistic Regression Fails in Small Samples\nlogistic-regression.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nUnderstanding Collapsibility of Effect Measures: Marginal vs Stratified\nFrom Risk to Logistic Regression\nLogit: How a Transformation Shapes an Effect\nWhere My Logistic Regression Went Wrong\nWhy Logistic Regression Fails in Small Samples\nUnderstanding Confounding in Effect Measures: Marginal vs Stratified\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\nEffects and Time I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/logistic-regression-2.html",
    "href": "jp/logistic-regression-2.html",
    "title": "From Risk to Logistic Regression",
    "section": "",
    "text": "Adjusting for Bias II − From Risk to Logistic Regression\n\nKeywords: confounding & collapsibility, effect measure, generalized linear model, language & writing\n\n\n\n\n\n\n\n\n前回までのあらすじ\n\n\n\n\n\nはじめて研究に取り組む娘と統計家の父。父に研究仮説は”PICO”を”PECO”で整理するといいとアドバイスされ、女医である娘は、がんサバイバーにおけるストーマ造設と復職状況の関係を調査することに決める。その後いくつか質問するうちに、父のことを「こいつ使える」と思い始めたのだった。\n\n\n\n\nロジスティック回帰をしてみたんだけど\n\n\n私「これみてよ、お父さん」\n\n\nお父さん「ん？どうしたの、この資料」\n\n\n私「前に相談したがんサバイバーの復職状況を調べる研究についてなんだけどね、うちの診療科だけだけど調査票が集まったから、解析してみたの。その結果をまとめた資料よ」\n\n\nお父さん「ああ、あれね。ストーマ造設と復職率の関連を調べることにしたんだっけ。資料のどこをみればいいの？」\n\n\n私「この表なんだけど。ロジスティック回帰（logistic regression）をしてみたんだ。その結果をまとめたよ。どうかな」\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nパラメータ\n自由度\n推定値\n標準誤差\n95%信頼区間\n\\(\\chi^2\\)\np値\n\n\n\n\nIntercept\n1\n-27.25\n3.03\n-33.20～-21.30\n80.55\n&lt;0.01\n\n\nSTOMA\n1\n1.41\n1.54\n-16.1～4.45\n0.84\n0.3588\n\n\nAGE\n1\n1.47\n1.48\n-1.42～4.36\n0.99\n0.3197\n\n\nSEX\n1\n25.72\n0.00\n25.72～25.72\n\n\n\n\nINCOME\n1\n-0.00\n0.00\n-0.00～0.00\n0.58\n0.4481\n\n\n\n\n\nお父さん「ふむふむ。よくある回帰分析の結果だね。この表、上司にみせるんでしょ。その前にちょっと手直しした方がいいかもね」\n\n\n私「やっぱり？そんな気がしてみてもらおうと思ったんだ」\n\n\nお父さん「まず、Intercept、STOMA、AGE、SEX、INCOMEっていうのがわからないよ。Intercept以外は共変量（covariates）のことだよね」\n\n\n私「共変量って？」\n\n\nお父さん「共変量っていうのは、ロジスティック回帰に入れる説明変数のこと。復職率を規定する要因っていえばいいかな。それと、Interceptは回帰式でいう切片項のこと。統計ソフトウェアのアウトプットをそのまま表にしたんでしょ？きっとストーマ、年齢、性別、年収という変数を使ったんだと思うんだけど、データ上の変数名がそのままになっている。それに、出てきた数字をぜんぶ載せると、表がうるさくない？」\n\n\n私「めっちゃしゃべるな。そうね、実はRのglm()を使ったんだけど、そこもよくわからなかったんだよね。そこから聞こうかな」\n\n\nお父さん「どのあたり？」\n\n\n私「glm()の指定の仕方。引数っていうの？」\n\n\n\nglm(y ~ x1 + x2, family = binomial(), data = dat)\n\n\n\n私「以前、連続データは正規分布、2値データは2項分布ってイメージが大事みたいなこといってたでしょ？glm()もその延長だと思うんだけど、familyとかlinkとか謎で、ロジスティック回帰になってるか自信ない」\n\n\nお父さん「そこはね、単変量分布を一般化線型モデルに広げないと説明できないよ。つまりね、glm()はgeneralized linear modelの略なんだけど、ただの確率分布ってわけじゃなくて、3つのパーツから成り立っているんだ。ざっくりいうとこの3つだよ」\n\n\n確率分布（データの型はなにか）\n回帰係数×共変量\nリンク関数（平均をどう変換して共変量と結びつけるか）\n\n\n私「で、それがfamily、y ~ x1 + x2、linkなの？」\n\n\nお父さん「そう。glm()は、確率分布+回帰係数×共変量+リンクを指定してるだけなんだ」\n\n\n私「y ~ x1 + x2は私もわかるよ。調べたい変数をいれるんでしょ」\n\n\nお父さん「そうだね。Rの中では、この式がデザイン行列\\(X\\)に変換されてる」\n\n\n\nX &lt;- model.matrix(~ x1 + x2, data = dat)\n\n\n\nお父さん「ちょっとマニアックだけど、Rの内部では、model.matrix()っていう関数で、デザイン行列\\(X\\)を作っている。\\(X\\)の最初の列はすべて1になる。これは回帰直線でいう切片に対応している。次の列以降はx1とx2に対応する値が計算される。こうしておくと、たとえばx1が文字列でも数値に置き換えて計算できたり、回帰係数との掛け算が行列として計算できたり、なにかと都合がいい。ここまで覚えなくていいけど、仕組みを知っておくと理解が進むでしょ」\n\n\n私「なるほどね、じゃあfamilyってなに？データの型？」\n\n\nお父さん「そう。familyは日本語では分布族の意味だね。正確には指数型分布族（exponential family）。前にいったみたいに、データの型にあわせて確率分布を選ぶ」\n\n\n\n連続データ: gaussian()\n2値データ: binomial()\n計数データ: poisson()\n\n\nglm(y ~ x1 + x2, family = gaussian(), data = dat)\nglm(y ~ x1 + x2, family = binomial(), data = dat)\nglm(y ~ x1 + x2, family = poisson(), data = dat)\n\n\n\nお父さん「ただしね、一般化線型モデルではデフォルト仕様みたいなものがあって、familyを指定すると以下の3つが一度に決まるっていう特徴がある」\n\n\nyの確率分布\nyの分散\nその確率分布にあったリンク関数\n\n\n私「リンク関数ってなんだ？」\n\n\nお父さん「リンク関数（link function）は、平均をどう変換して回帰係数×共変量にあわせるかだよ。family = binomial()は、デフォルトでロジット関数（logit function）というリンク関数を使っている。ロジット関数が、2項分布の構造にあった”自然な”リンク関数なんだ。これがロジスティック回帰だよ」\n\n\n私「そっか、よかった。うん、けっこうわかったから今日はもういい」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nロジスティック回帰のリンク関数は、ロジット関数以外のものを代わりに使うことができます。リンク関数をうまく指定してリスク\\(\\pi\\)を変換することで、オッズ比以外の関連の指標を求められることが知られています。次の指標のうち、対応するリンク関数がなく、求められないものはどれでしょうか。\n\nリスク差\nリスク比\nハザード比\n1、2、3すべて求めることができる\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は4です\n\n一般化線型モデルはロジスティック回帰を一般化したもので、「リンク関数」を変えることで、さまざまな指標を計算できます（田中2022）。詳しくはのちのエピソードで述べますが、リンク関数は、ロジスティック回帰でいえば、リスク\\(\\pi\\)を関数\\(g(\\pi)\\)を用いて変換しています。\nリスク差を求めるには、\\(g(\\pi)=\\pi\\)つまり恒等関数を指定します。\nリスク比を求めるには、\\(g(\\pi)=\\log(\\pi)\\) つまり対数関数を指定します。\nハザード比を求めるには、\\(g(\\pi)=\\log\\{-\\log⁡(1-\\pi)\\}\\)つまり補2重対数（complementary log-log）関数を指定します。\n\n\n\n\n\n文献\n\n田中司朗. 医学研究のための因果推論I. 一般化線型モデル. 東京: 朝倉書店; 2022\n\n\n\n次のエピソードとRスクリプト\n\nLogit: How a Transformation Shapes an Effect\nlogistic-regression.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nUnderstanding Collapsibility of Effect Measures: Marginal vs Stratified\nFrom Risk to Logistic Regression\nLogit: How a Transformation Shapes an Effect\nWhere My Logistic Regression Went Wrong\nWhy Logistic Regression Fails in Small Samples\nUnderstanding Confounding in Effect Measures: Marginal vs Stratified\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\nEffects and Time I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/index.html#ご案内",
    "href": "jp/index.html#ご案内",
    "title": "A Conversation on Causality at Our Table (JP)",
    "section": "ご案内",
    "text": "ご案内\nどのエピソードも独立していますが、ふたりの会話は研究仮説と研究デザインから始まります。そこから先は、物語を追っても、興味の向くレイヤーを選んでも構いません。ちょっとしたおすすめは臨床試験とp値、研究の中の因果推論あたり。全体を通して読むと、散らばっていた意味どうしがつながり、きっといくつかのことが見えてきます。"
  },
  {
    "objectID": "jp/index.html#エピソード一覧",
    "href": "jp/index.html#エピソード一覧",
    "title": "A Conversation on Causality at Our Table (JP)",
    "section": "エピソード一覧",
    "text": "エピソード一覧\n\n1. Study Design — 研究の出発点\n研究は「どんな問いを立てるか」から始まります。PICO/PECO、アウトカムの選び方、バイアスの防ぎ方…。娘は父に研究の出発点について尋ねます。\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\n\nこのエピソードのRスクリプト一式は、こちらからダウンロードできます。Rパッケージや、ここで紹介した解析手順をもう一度たどってみたい方はぜひ。\n\nstudy-design.R\n\n\n\n\n\n\n\nあらすじ\n\n\n\n\n\n\nA Story of Coffee Chat and Research Hypothesis 　研究の最初のつまずきは、データではなく問いの立て方にあります。PICO/PECO、比較、一般化―「何を答えたいのか」を一度言葉にしてみます。\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes 　呪文に見えるR関数を「アウトカムの型」と「それにあった確率モデル」から整理します。\nOutcomes: The Bridge from Data Collection to Analysis 　OSかPFSか―オンコロジーで繰り返される論点を手がかりに、アウトカム定義によって研究がどう変わるかを眺めます。\nA First Step into Survival and Competing Risks Analysis with R 　生存時間解析は“式”より先に、イベント定義とコーディングで事故が起きます。データ収集の注意点から、競合リスクの入口まで。\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys 　バイアスは解析で帳尻合わせできないことが多い。選択バイアス・情報バイアス・交絡を「どこで混入するか」という視点で点検します。\n\n\n\n\n\n\n2. Glossary — 統計学のことば\n\nStatistical Terms in Plain Language\n\n\n\n3. Frequentist Thinking — 統計学の思考\nがん臨床試験を題材に「仮想的に何度も研究を繰り返したときに、数字はどう振る舞うか？」という頻度論的なものの見方を父は語ります。\n\nReading a Paper over a Cup of Coffee\nP-Value Explanations That Seem Plausible at First Glance\nBeyond 0.05: Interpreting P-Values in a Clinical Trial\n\n\n\n\n\n\n\nあらすじとRスクリプト\n\n\n\n\n\n\nReading a Paper over a Cup of Coffee 　はじめて論文を読んだとき、統計の用語が意味不明だと思いませんでしたか？同じ気持ちを抱いた娘は父に質問します。\nP-Value Explanations That Seem Plausible at First Glance 　「繰り返したら数字はどう振る舞う？」という頻度論の視点を、臨床試験の状況で体に落とします。\nBeyond 0.05: Interpreting P-Values in a Clinical Trial 　p値は「数字」ではなく、Methodsの読み方に接続される。p値について統計家たちがだした声明を扱ったエピソード。\n\nこの回と次のエピソードのRスクリプト一式はこちらから。\n\nfrequentist.R\n\n\n\n\n\n\n4. Frequentist Experiments — 統計学の実証\n頻度論が導く法則は、ただの抽象ではなくシミュレーション実験で確認することができます。Rに不慣れな方も、スクリプトを流すだけですので結果を再現してみてください。\n\nR Demonstration of Bias in Kaplan-Meier Under Competing Risks\nUnderstanding Confidence Intervals via Hypothetical Replications in R\nAlpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size\n\n\n\n\n\n\n\nあらすじとRスクリプト\n\n\n\n\n\n\nR Demonstration of Bias in Kaplan-Meier Under Competing Risks 　頻度論が導く法則は、ただの抽象ではなくシミュレーションで確認することができます。Rに不慣れな方も、スクリプトを流すだけですので結果を再現してみてください。\nUnderstanding Confidence Intervals via Hypothetical Replications in R 　95%信頼区間はどういう意味で95%なのでしょうか？娘はRを用いたシミュレーション実験で確かめます。\nAlpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size 　統計学では、p値とサンプルサイズ設計が対になってエラーをコントロールします。サンプルサイズ設計入門。\n\nこの回と前のエピソードのRスクリプト一式はこちらから。\n\nfrequentist.R\n\n\n\n\n\n\n5. Effects and Time — 効果は時間とともに\nリスク差・リスク比・ハザード比、ワクチン有効率、寄与割合、そして時間とともに変化する効果を、生存曲線・累積発生曲線とともに紐解きます。因果推論に先立って立体的なデータの見方が静かに育ちます。\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nA First Note on Cox Regression\nAfter Cox Regression: A Case Study and R Demonstration\n\n\n\n\n\n\n\nあらすじとRスクリプト\n\n\n\n\n\n\nSilent Confusions Hidden in Percentages 　疫学の研究結果の多くは、わかりやすくパーセントで報告されますが、それが数字が独り歩きする理由だったとは。言葉の意味を知ることの大切さを父は語ります。\nWho Is This Percentage About Target Populations and Attributable Fractions 　数字が独り歩きするのは、計算が理解されていない事だけが理由ではありません。言葉の裏に潜む集団の違いについて。\nWhen Odds Ratios Approximate Risk Ratios and When They Fail 　「オッズ比よりオッズ比の平方根の方がよい一面もあるんだ」父は疫学の常識を揺さぶります。\nFrom Risk and Rate to Survival and Hazard 　「生存曲線やハザード比について納得感が足りないの」娘の視点で学ぶ生存時間解析の入門講義。\nA First Note on Cox Regression 　Cox回帰はハザード比のモデルと言い切っていいのか？より正確な理解に迫ります。\nAfter Cox Regression: A Case Study and R Demonstration 　リスク比、ハザード比、そして時間とともに変化する効果。因果推論に先立って立体的なデータの見方が静かに育ちます。\n\nこのエピソードのRスクリプト一式はこちらから。\n\neffects.R\n\n\n\n\n\n\n6. Adjusting for Bias — 回帰モデリングの風景\n結果の見方、表の作り方から、使用上の落とし穴まで、父からロジスティック回帰と交絡調整の手ほどきを受けるエピソード。\n\n[Understanding Collapsibility of Effect Measures: Marginal vs Stratified]\n[From Risk to Logistic Regression]\n[Logit: How a Transformation Shapes an Effect]\n[Where My Logistic Regression Went Wrong]\n[Why Logistic Regression Fails in Small Samples]\n[Understanding Confounding in Effect Measures: Marginal vs Stratified]\n\n\n\n\n\n\n\nあらすじとRスクリプト\n\n\n\n\n\n\nUnderstanding Collapsibility of Effect Measures: Marginal vs Stratified 　層別解析・ロジスティック回帰とSimpsonのパラドックスの関係は？がん臨床試験で用いられる層別Cox回帰にもつながるエピソード。\nFrom Risk to Logistic Regression 　「教えられた通り、Rのglm関数でロジスティック回帰をしてみたんだけど、なんだかブラックボックスみたい」父は娘の疑問に答えます。\nLogit: How a Transformation Shapes an Effect 　ロジスティック回帰を特徴づけるのはロジット関数です。娘は、なぜロジット関数が用いられるのか統計学の秘密を知らされます。\nWhere My Logistic Regression Went Wrong 　結果の見方、表の作り方から、使用上の落とし穴まで、父から統計解析の手ほどきを受けるエピソード。\nWhy Logistic Regression Fails in Small Samples 　「どうして私のロジスティック回帰は発散しちゃったの？」娘は更なる疑問を父にぶつけます。\nUnderstanding Confounding in Effect Measures: Marginal vs Stratified 　いわゆるSimpsonのパラドックスと交絡の関係は？そしてロジスティック回帰を用いた調整になにが足りないのか？\n\nこのエピソードのRスクリプト一式はこちらから。\n\nlogistic-regression.R\n\n\n\n\n\n\n7. Truth — 真実\n\n[What Data Cannot Tell Us]\n[What Could Have Happened]\n[What Is It That You Want to Know?]\n\n\n\n8. Causal Inference — 因果を見つけるために\n\n[Three-Variable DAGs: The Smallest Building Blocks of Causal Structure]\n[A Subtle Distinction between Common Causes and Confounders]\n[DAGs and Conditional Distributions: Two Languages for the Same Structure]\n[A Circle, an Equation, and a Cylinder]\n[Backdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias]\n[Volatility, Uncertainty, Complexity, and Ambiguity in Causal Inference]\n\n\n\n\n\n\n\nあらすじ\n\n\n\n\n\n\nThree-Variable DAGs: The Smallest Building Blocks of Causal Structure 　DAG、共通原因、合流点、中間因子―因果の語彙を、いちばん小さな図から覚えます。「もし…だったら？」を描くために。\nA Subtle Distinction between Common Causes and Confounders 　「交絡因子」は言葉として便利すぎる。共通原因と交絡のズレを、図で丁寧に区別します。\nDAGs and Conditional Distributions: Two Languages for the Same Structure 　図は直感、式は精密。DAGと条件付き確率が、同じものを別の言語で言っている感覚をつかみます。\nA Circle, an Equation, and a Cylinder 　確率モデルとDAGとRubin因果モデルっていったいなに？娘の疑問への答え。\nBackdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias 　「ブロックする」とは、どのような操作をDAGに加えることなのか。バイアスの源を探す手触りを、最小限の形式で確かめます。\nVolatility, Uncertainty, Complexity, and Ambiguity in Causal Inference 　「DAGは何のためのだろう？」「複雑さを整理し曖昧さを減らす道具だよね」父の教えへの娘からの回答。\n\n\n\n\n\n\n9. Publish a Paper — 研究のその先\n研究結果をどう伝えるか、図表の作り方、推敲のコツ、査読の向き合い方。統計の“その先”を扱う、研究者の営み。\n\n[A Subtle Distinction Between Editors and Reviewers]\n[Three Tips for Writing a Paper]\n[Communicating with Care]\n[A Morning Just Before Submission]"
  },
  {
    "objectID": "jp/frequentist-6.html",
    "href": "jp/frequentist-6.html",
    "title": "Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size",
    "section": "",
    "text": "Frequentist Experiments III − Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size\n\nKeywords: probability model, p-value, R simulation, study design\n\n\n\nあれ？何人に調査すればいいんだろう\n\n\nお父さん「ちょっといいかな」\n\n\n私「なに？お父さん、たばこくわえながら真面目な顔して」\n\n\nお父さん「サンプルサイズって計算した？」\n\n\n私「サンプルサイズってなんのこと？」\n\n\nお父さん「ほら、がんサバイバーの調査するんでしょ。その人数のこと」\n\n\n私「ああ、あれね。100人に調査するつもりだよ」\n\n\nお父さん「この前は話が中途半端だったでしょ。続きを説明したくて。前回は“精度”の話。今日は“差を見つけたいとき”の話」\n\n\n私「ん、わかった。サンプルサイズの話の続きね。なになに」\n\n\nお父さん「前回は信頼区間とサンプルサイズだったよね。でも、もしストーマ造設ありとなしの復職率を比べるような仮説検証を目指した研究をしたいなら、仮説検定の考え方にそってサンプルサイズを計算しないといけない」\n\n\n私「仮説検定ってp値のこと？」\n\n\nお父さん「そうそう。そっちの話をするなら、p値とαエラー・βエラーの関係を説明しないとだな。この前、JCOG9502の論文もってきたとき、どこまで話したっけ？」\n\n\n私「p値とかASA声明については聞いたよね。でも、エラーって言葉はでてこなかったな」\n\n\nお父さん「じゃあ、話はそこからだね。ちょっとそこのナプキンとペンをとって」\n\n\n私「ん？これのこと？」\n\n\nお父さん「ありがとう。αエラー・βエラーは、表にしないと説明できないからね」\n\n\n\n\n\n\n\n\n臨床試験の結果から判断を誤ってしまうふたつのケース\n\n\n\n\n\n\n研究結果\n真に効果がない（帰無仮説）\n真に効果がある（対立仮説）\n\n\n\n\n有意差なし（p値≥有意水準）\n\nβエラー\n\n\n有意差あり（p値&lt;有意水準）\nαエラー\n検出力=1-β\n\n\n\n\n\n\n\n\n\n\n\nαエラーとβエラーの解説\n\n\n\n\n\nこれまで、臨床試験JCOG9502（Sasako, et al. 2006）の文脈に沿って、片側p値と両側p値の違いも交えながら、p値について解説してきました。しかし本質的に重要なのは、p値を用いた判断に、どのような合理性があるのか、ということです。\nJCOG9502を題材に考えてみましょう。この場合の真実は「LTA群はTH群に比べ全生存期間を延長する効果がある」と「効果がない」の2通りがあるといいました。一方で、試験の結果もp&lt;0.05とp≥0.05の2通りです。これらを組み合わせは2×2の4通りがあります。\nこのうち、臨床試験の結果から判断を誤ってしまうケースは2つです。つまり、効果があるのにp≥0.05になってしまうケースと、効果がないのに（帰無仮説が正しいのに）p&lt;0.05になってしまうケースです。仮説検定では、前者をαエラー（alpha error）、後者をβエラー（beta error）と呼んでいます。また、βエラーを1から引いたものを検出力（power）と呼んでいます。\n\n\n\n\n\n私「まあ、このふたつのエラーがあるのは当たり前だよね。左開胸開腹連続切開をしたLTA群で予後がよくならないのに、有意に効いたって判断したら間違いだし、逆にいい術式なのに、結果的に有意にならなかったらそれも研究失敗だし」\n\n\nお父さん「そうだね。でも、正確にいうと、αエラー・βエラーは”統計学的に有意”とかp値とかとは、直接関係する概念じゃない。別に、効果があるかどうか判定する基準は、p値じゃなくてもいいわけだからね。ポイントはね、\n\np&lt;0.05は、αエラーだけを制御する基準\n\nだってこと」\n\n\n\n\n\n\n\n\nαエラー、βエラー、p値\n\n\n\nαエラーとβエラーが生じる確率を考えてみましょう。理論的に考えると、サンプルサイズが大きくなるほど、ランダム誤差は小さくなります。αエラーとβエラーも同じで、サンプルサイズが大きいほど小さくなる（判断を誤りにくくなる）性質があります。しかし、2つのエラーはトレードオフの関係にあります。サンプルサイズが一定だと、両方同時に小さくすることはできません。そこで通常は、αエラーを優先して、事前に決めた水準よりも小さく保たれるような判定方式を用います。これが仮説検定であり、事前に決めた水準のことを有意水準と呼びます。実は、p&lt;0.05で判定することと有意水準を5%と設定することは、同じ意味です。\nややこしいのですが、JCOG9502では症例登録に予定より時間がかかったため、有意水準10%、つまり全生存期間の片側p値を0.1と比べる方式が採用されました。この方式では、LTAに延命効果がなくても、100回に10回はαエラーが生じてしまい、LTAが有効と判定してしまうことになります。つまり、有意水準が5%から10%に高くなると、判断を誤る確率が増える代わりに、サンプルサイズが小さくて済むわけです。\n\n\n\n\nサンプルサイズ設計によるβエラーの制御\n\n\n私「紙ナプキンに描いてくれた表自体はわかるんだけどね。そこからαとかβとか確率とかいわれてもなあ。ついていけないな」\n\n\nお父さん「まずはαエラーとβエラーが臨床試験のどんな結果を表しているか考えると、イメージしやすいかもね。まず、αエラーとβエラーの意味から確認させて」\n\n\nαエラー: 「効果がない」という確率モデル上で計算されたエラーの確率\nβエラー: 「効果がある」という確率モデル上で計算されたエラーの確率\n\n\nお父さん「JCOG9502のように試験治療の有効性を検証する試験では、αエラーは標準治療と差がないかそれより劣る治療方法が普及してしまうことにつながる。いわば、”αエラー=消費者リスク”といえる。一方で、βエラーは試験治療が本当は有効なのに、開発中止してしまうことを意味する。だから”βエラー=生産者リスク”といわれる。医師の視点で気になるのは、やっぱりαエラーの方だよね」\n\n\n私「理屈じゃなくて、数字の実感がないのよ。判断ミスをする確率なんて低い方がいいに決まってるよね。でもどのくらいの確率にするものなの？」\n\n\nお父さん「JCOG9502の論文読んだんでしょ。どう書いてあった？」\n\n\n私「はいはいみますみます。”The amended sample size was 250, with one-sided alpha error of 0.1 and beta error of 0.2”って書いてある。片側検定で、αエラー0.1、βエラー0.2ってことね。そうすると、予定変更後のサンプルサイズは250人になったんだ」\n\n\nお父さん「そういうこと。βエラーは0.1か0.2が一般的かな。米国臨床試験グループSWOGの統計家たちは、教科書で以下のように述べている（Green, et al. 2013）。\n\n新しい治療法が見つかることはさほど多くないため、我々は原則として90%の検出力を推奨している\n\n検出力90%はβエラー0.1のことね」\n\n\n私「私の研究でもサンプルサイズは250人でよくない？」\n\n\nお父さん「雑だけどいい線いってる。大体それくらいになりそうだけど、サンプルサイズの計算結果を表にしてあげるから、ちゃんとそれをみて決めよう。いろんな状況があり得るけど、両側αエラー0.05で、βエラーは0.2（検出力0.8）と0.1（検出力0.9）という設定がもっともよく用いられるから、そのときのサンプルサイズを紹介するね。同じ人数の2つの群を比較することを想定しているから、群ごとの人数はサンプルサイズの半分になる」\n\n\n検出力80%検出力90%\n\n\n表1. 2群の生存曲線を比較するためのサンプルサイズ\n両側 α=0.05, 1−β=0.8\n※ 数値は「2群合計のサンプルサイズ」（割付け比1:1）\n\n\n\n\\(\\pi_2\\)\n\\(\\pi_1=0.1\\)\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n\n\n\n\n0.15\n964\n—\n—\n—\n—\n—\n—\n—\n\n\n0.20\n296\n—\n—\n—\n—\n—\n—\n—\n\n\n0.25\n156\n1826\n—\n—\n—\n—\n—\n—\n\n\n0.30\n102\n506\n—\n—\n—\n—\n—\n—\n\n\n0.35\n74\n246\n2486\n—\n—\n—\n—\n—\n\n\n0.40\n58\n152\n658\n—\n—\n—\n—\n—\n\n\n0.45\n48\n104\n308\n2894\n—\n—\n—\n—\n\n\n0.50\n42\n78\n182\n744\n—\n—\n—\n—\n\n\n0.55\n36\n62\n122\n340\n3034\n—\n—\n—\n\n\n0.60\n32\n52\n90\n198\n764\n—\n—\n—\n\n\n0.65\n28\n42\n70\n130\n342\n2900\n—\n—\n\n\n0.70\n26\n38\n54\n92\n194\n712\n—\n—\n\n\n0.75\n24\n34\n38\n70\n124\n312\n2492\n—\n\n\n0.80\n22\n30\n38\n56\n86\n174\n592\n—\n\n\n0.85\n22\n26\n34\n46\n66\n110\n254\n1818\n\n\n0.90\n20\n26\n30\n38\n50\n136\n136\n414\n\n\n\n\n\n表1. 2群の生存曲線を比較するためのサンプルサイズ\n両側 α=0.05, 1−β=0.9\n※ 数値は「2群合計のサンプルサイズ」（割付け比1:1）\n\n\n\n\\(\\pi_2\\)\n\\(\\pi_1=0.1\\)\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n\n\n\n\n0.15\n1290\n—\n—\n—\n—\n—\n—\n—\n\n\n0.20\n396\n—\n—\n—\n—\n—\n—\n—\n\n\n0.25\n208\n2444\n—\n—\n—\n—\n—\n—\n\n\n0.30\n136\n676\n—\n—\n—\n—\n—\n—\n\n\n0.35\n100\n330\n3330\n—\n—\n—\n—\n—\n\n\n0.40\n78\n202\n880\n—\n—\n—\n—\n—\n\n\n0.45\n64\n138\n412\n3876\n—\n—\n—\n—\n\n\n0.50\n54\n104\n242\n996\n—\n—\n—\n—\n\n\n0.55\n46\n82\n162\n454\n4060\n—\n—\n—\n\n\n0.60\n42\n68\n120\n264\n1022\n—\n—\n—\n\n\n0.65\n38\n56\n90\n172\n456\n3880\n—\n—\n\n\n0.70\n34\n48\n72\n124\n258\n952\n—\n—\n\n\n0.75\n32\n42\n60\n92\n166\n416\n3336\n—\n\n\n0.80\n30\n40\n52\n74\n116\n232\n796\n—\n\n\n0.85\n28\n34\n46\n60\n88\n146\n338\n2436\n\n\n0.90\n26\n32\n38\n50\n68\n100\n180\n548\n\n\n\n\n\n\n\nお父さん「ストーマ造設あり・なしの2群があるとして、復職率はそれぞれどれくらいになりそうなの？仮の値でいいよ」\n\n\n私「むずいな。どのくらいなんだろう。なにも不利なことがないなら、手術した後、1年以内に80%は復職してほしいかな。ストーマがあると20%から30%くらいは復職率が下がるんじゃない？調査してみないとわかんないけどね」\n\n\nお父さん「なるほど。もし復職状況を生存時間データとして解析するとしたらね。復職できた時点でイベントが発生し、それ以外の患者は打ち切りになる。表1と2は、2群の生存確率を比較するためのもので、生存確率を\\(\\pi_1\\)と\\(\\pi_2\\)と表記している。\\(\\pi_1\\)と\\(\\pi_2\\)は、がんサバイバー研究でいうとグループごとの”非復職確率”に対応する。つまり復職率が80%と60%だったら、\\(\\pi_1=0.2\\)と\\(\\pi_2=0.4\\)になる。この数字を使うってことは、暗黙の裡に、1年間追跡することを想定してるんだけどね。表2の対応箇所をみてみてよ」\n\n\n私「202人って書いてある。これが調査しないといけない人数ってこと？」\n\n\nお父さん「そういうこと」\n\n\n私「もし、202人の全員が1年間で追跡できなかったらどうするの？半年までしか調査できなかったとか」\n\n\nお父さん「この表のサンプルサイズは、術後1年間100%追跡できるという前提で計算している。サンプルサイズの計算では、本来、それぞれの群のハザード比や生存期間中央値から必要なイベント数を求め、それを観察するために必要な期間を考慮したうえで人数を決める。結構ややこしいでしょ。今回は、2パターンの検出力だけみればいいように状況を単純化している。さっき検出力について説明したじゃない、対立仮説の下で有意になる確率ね。表2は、検出力90%の検定を行うために必要なサンプルサイズで、表1はそれを検出力80%に緩めたときのもの。表1をみると、検出力80%でよければ、152人に調査すればいいみたいだね」\n\n\n私「ふむ。この人数も、確率モデルで計算したの？」\n\n\nお父さん「もちろん、この書籍の著者が、別世界の誰かに手紙を出してね」\n\n\n私「ふむふむ。まだよくわかんないな。JCOG9502では、2本の生存曲線を比べてたでしょ」\n\n\nお父さん「うん」\n\n\n私「いま考えてる統計解析って、ストーマ造設あり・なしと復職状況の関係を調べてたんだよね。以前に聞いた話だと、2値データだとロジスティック回帰、生存時間データだとCox回帰を使うんじゃなかったっけ。生存曲線とCox回帰は別の統計手法じゃない？」\n\n\nお父さん「正確にいうとね、生存曲線を比較するためのp値はいくつかの統計手法で計算できる。よく使うのはログランク検定とCox回帰のふたつで、表1と2は、ほんとはログランク検定用なんだけど。Cox回帰を使ったとしても、ストーマ造設あり・なし以外の因子がなければ、ログランク検定とほとんど同じ結果になる。特にサンプルサイズが大きければね」\n\n\n私「お父さん、あとね。表1と2に割付け比1:1って書いてあるでしょ。これって2群の人数が同じってことだよね」\n\n\nお父さん「そうだよ、たいていの臨床試験の割付け比は1:1だからね」\n\n\n私「でもストーマ保有者って、非保有者より少ないと思うんだけど。半数くらいかな」\n\n\nお父さん「調査や観察研究だと、群ごとの人数は同じにならないよね。さっきは、書籍（Machin, et al. 2022）の表を利用させてもらったんだけど、設定が複雑になると、付録のソフトウェアやRを利用することになる。 powerSurvEpiパッケージで、あの表とほぼ同じ計算ができるはず。割付け比を、1:1から2:1、4:1に変えて、ストーマ保有者が33%、20%のときの計算をしてみよう」\n\n\n\n\n\n\n\n\nRパッケージを用いたサンプルサイズ設計のコードはこちら\n\n\n\n\n\n\n# install.packages(\"powerSurvEpi\") #インストールが必要なら実行\nlibrary(powerSurvEpi)\n\nssizeCT.default(\n  power = 0.9,\n  k     = 1,\n  pE    = 0.6,                     # ストーマあり群の復職率\n  pC    = 0.8,                     # ストーマなし群の復職率\n  RR    = log(1-0.8)/log(1-0.6),   # 復職率からハザード比を計算\n  alpha = 0.05\n)\n\n nE  nC \n100 100 \n\nssizeCT.default(\n  power = 0.9,\n  k     = 0.5,\n  pE    = 0.6,                     # ストーマあり群の復職率\n  pC    = 0.8,                     # ストーマなし群の復職率\n  RR    = log(1-0.8)/log(1-0.6),   # 復職率からハザード比を計算\n  alpha = 0.05\n)\n\n nE  nC \n 59 118 \n\nssizeCT.default(\n  power = 0.9,\n  k     = 0.25,\n  pE    = 0.6,                     # ストーマあり群の復職率\n  pC    = 0.8,                     # ストーマなし群の復職率\n  RR    = log(1-0.8)/log(1-0.6),   # 復職率からハザード比を計算\n  alpha = 0.05\n)\n\n nE  nC \n 41 161 \n\n\n\n\n\n\n\nお父さん「割付け比\\(K\\)は\\(K:1\\)を意味している。\\(K=1\\)（1:1）、\\(K=0.5\\)（2:1）、\\(K=0.25\\)（4:1）だと、必要サンプルサイズ（\\(nE+nC\\)）は100+100人から19+118人、41+161人に変化するみたいだね」\n\n\n私「えー、\\(K\\)ってストーマありの割合だよね、そんなのまだわからないもの。思ったより人数が必要かもってことだよね。調査する施設を増やすかどうか考えないと」\n\n\nお父さん「気持ちはわかるよ。頻度論の立場で厳密に研究をデザインすると、だいたい最初は”そんなに集められないよ”って顔になるからね」\n\n\n私「でも、サンプルサイズの意味がわかったから、しょうがないやるかって思ったよ。シミュレーション1000回のうち失敗しちゃった1回が、私の調査だったらきついもん」\n\n\nお父さん「自分で計算するとリアルでしょ」\n\n\n私「うん、かるく背筋が凍った」\n\n\n\n\n文献\n\nMachin D, Campbell MJ, Tan SB, Tan SH. 医学のためのサンプルサイズ設計（原著第4版）. 京都: 京都大学学術出版会; 2022\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\n\n\n\nThis concludes the Frequentist Experiments series. If you’d like to keep reading over your next cup of coffee, the following episodes are waiting:\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nCollapsibility of Effect Measures in Marginal and Stratified Tables\nRisk Ratios and Odds Ratios: When Approximation Works\nFrom Risk and Rate to Survival and Hazard\nDistinguishing Time-Point, Time-Constant, and Time-Varying Effects: An R Example"
  },
  {
    "objectID": "jp/frequentist-4.html",
    "href": "jp/frequentist-4.html",
    "title": "R Demonstration of Bias in Kaplan-Meier Under Competing Risks",
    "section": "",
    "text": "Frequentist Experiments I − R Demonstration of Bias in Kaplan-Meier Under Competing Risks\n\nKeywords: bias, probability model, simulation, survival & competing risks\n\n\n\nモデルを立ててバイアスを確かめる\n\n\n私「おはよう、今朝は冷えるね。ご飯食べてるところ悪いんだけど、ちょっと気になったことがあって。以前、統計学にはランダム誤差とバイアスがあるっていってたよね、覚えてる？あ、コーヒーもらっていい？」\n\n\nお父さん「覚えてるよ。コーヒーもどうぞ、まだ冷めてないと思う」\n\n\n私「バイアスって疫学で習うものだよね。統計学の本を読んでもバイアスなんて出てこないよ」\n\n\nお父さん「そうだね、不偏推定量（unbiased estimator）っていう概念があるんだけど、数理統計学の話だから目にしないと思う」\n\n\n私「そうなんだ。でも聞いた感じ、疫学のバイアスとは別でしょ？データを解析した結果とどういう関係があるの？」\n\n\nお父さん「ああ、そういうことね。確かに、疫学で出てくる研究実施上のバイアスそのものは、統計学の教科書にあまり登場しないね。でも、推定した結果が真値からずれるっていう意味では同じもの。少し時間ある？カバンの中のパソコン出せる？」\n\n\n私「え？朝からなにするの？」\n\n\nお父さん「統計学ではよく、シミュレーションっていってデータを乱数で発生させて実験するんだ。Kaplan-Meier曲線を描くとき、競合リスクの扱いによってはバイアスが生じるってことをみせてあげるよ、バイアスがどれくらい困ったことなのか実感ないみたいだから。前に使ったRスクリプトをいじるだけですぐ終わるから」\n\n\n私「仕方ないな」\n\n\nお父さん「パソコンを立ち上げる間に何をするか話そう。まずね、いまから見せるのは”研究の不備”のバイアスじゃなくて、“目標としている値と違う値を統計的に推定してしまう”という現象だよ。競合リスクを含むデータは、こういう仕組みで生まれる」\n\n\n再発までの時間を発生させる\n死亡までの時間を発生させる（競合リスク）\n打ち切りまでの時間を発生させる\n\n\nお父さん「実際に観測されるのは、もちろんそのうち一番先に起きたイベント、つまりこの3つの値の最小値をとる」\n\n\n私「なるほど、それなら再発より先に死亡したら、再発は観測されないわけだ。当たり前だけど、シミュレーションはこうやるのね」\n\n\nお父さん「ここで問題になるのが統計手法の選び方なんだ。よく死亡を打ち切りにした解析を見るでしょ。あのKaplan-Meier曲線は、現実世界で再発が生じる確率を過大評価してしまう。これじゃなくてAalen-Johansen曲線を推定すると、正しく再発確率が求められる。ではRでデータを発生させてみよう」\n\n\n\n\n\n\n\n\nシミュレーションデータ（再発あり）におけるKaplan-Meier曲線のバイアス\n\n\n\n以前生成したシミュレーションデータにおける累積再発率（CIR）の解析では、再発の前に死亡した患者（競合リスク）を発生させたことを覚えていますか？競合リスク存在下でKaplan-Meier曲線を用いるとバイアスが生じることは、簡単な実験で確かめることができます。\n\n\n\n\n\n\n\n\ngenerate_data()のコードはこちら（データ生成に使用）\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # 再発のハザード（大きいほど早く起こる）\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # 死亡のハザード（大きいほど早く起こる）\n  hazard_censoring &lt;- 0.05                               # 打ち切りハザード（群に依存しない）\n  \n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)   # 再発までの潜在時間\n  t_death     &lt;- rexp(n, rate = hazard_death)     # 死亡までの潜在時間\n  t_censoring &lt;- rexp(n, rate = hazard_censoring) # 打ち切りまでの潜在時間\n  \n  ## --- 全生存期間（OS） ----------------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = 死亡, 0 = 打ち切り\n  \n  ## --- 無再発生存期間（RFS） -----------------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # 再発\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # 死亡\n  \n  ## --- 累積再発率（CIR） + 競合リスク --------------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # イベント1: 再発\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # イベント2: 競合リスクとしての死亡\n  \n  ## --- データフレームにまとめる --------------------------------\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n}\n\n\n\n\n\n\n\n\n\n\n累積再発率（CIR）のAalen-Johansen曲線\n\n\n\nKaplan-Meier曲線とAalen-Johansen曲線は、どちらもcifmodelingパッケージのcifplot()を使って生成できますが、イベントのコーディングを入力するcode.event1、code.event2とデータの型を表すoutcome.typeを、指定する必要があります。generate_data()で生成したシミュレーションデータでは、CIRのイベントは以下のようにコーディングされていました。\n\nstatus_cir=1 : 再発\nstatus_cir=2 : 再発を経験しない死亡\nstatus_cir=0 : 打ち切り\n\n以下のRスクリプトでは、最初のcifplot()により、再発（code.event1=1）に関するAalen-Johansen曲線（aj_event1）を出力しています。縦軸は累積発生確率ではなく、1-累積発生確率を選んでいる点にも注意してください（type.y=\"surv\"）。そして次のcifplot()ではイベントを入れ替えて、再発を経験しない死亡（code.event1=1）に関するAalen-Johansen曲線（aj_event2）を出力し、cifpanel()に用いて2つの図を左右に配置したひとつの図を表示しています。左右の累積発生確率の和に注目してください。この図からは、再発の累積発生確率と（再発を経験しない）死亡の累積発生確率の和は、時間が経つにつれ1に近づくが、1を超えることはないことがわかります。仮に打ち切りがなかったとしたら、再発と（再発を経験しない）死亡のどちらか一方しか生じないため、Aalen-Johansen曲線の和が1を超えないのは自然なことです。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\n# devtools::install_github(\"gestimation/cifmodeling\") #インストールが必要なら実行 \nlibrary(cifmodeling)\ndat &lt;- generate_data(hr1=2, hr2=1.5) #再発ハザード比2, 死亡ハザード比1.5のデータ生成\n\naj_event1 &lt;- cifplot(Event(time_cir, status_cir) ~ stoma,\n  data         = dat,\n  outcome.type = \"competing-risk\", \n  type.y       = \"surv\",\n  label.y      = \"1-Aalen-Johansen\",\n  code.event1  = 1, \n  code.event2  = 2\n)\naj_event2 &lt;- cifplot(Event(time_cir, status_cir) ~ stoma,\n  data         = dat,\n  outcome.type = \"competing-risk\", \n  type.y       = \"risk\",\n  label.y      = \"Aalen-Johansen\",\n  code.event1  = 2, \n  code.event2  = 1\n)\naj_list &lt;- list(aj_event1$plot, aj_event2$plot)\naj_panel &lt;- cifpanel(rows.columns.panel = c(1,2), plots=aj_list)\nprint(aj_panel)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積再発率（CIR）のKaplan-Meier曲線\n\n\n\n実際の研究では、死亡を打ち切りとして扱った生存時間解析の結果をしばしば目にします。この解析に対応するKaplan-Meier曲線は、以下のようにイベントのコーディングを変更し、outcome.type=\"survival\"を指定することで出力できます。\n\nstatus_cir1=1 : 再発\nstatus_cir1=0 : 再発を経験しない死亡/打ち切り\nstatus_cir2=1 : 再発を経験しない死亡\nstatus_cir2=0 : 再発/打ち切り\n\n新しく作ったイベント変数status_cir1とstatus_cir2を用いると、再発のKaplan-Meier曲線と（再発を経験しない）死亡のKaplan-Meier曲線を描くことができます。これらのKaplan-Meier曲線を左右に配置した図を、先ほどのAalen-Johansen曲線の図と比べてみてください。先ほどのAalen-Johansen曲線の和とは違い、Kaplan-Meier曲線の和が1を超えてしまって計算が合わないことが読み取れたでしょうか。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\ndat$status_cir1 &lt;- as.numeric(dat$status_cir==1)\nkm_event1 &lt;- cifplot(Event(time_cir, status_cir1) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\", \n  type.y       = \"surv\",\n  label.y      = \"Kaplan-Meier\"\n)\ndat$status_cir2 &lt;- as.numeric(dat$status_cir==2)\nkm_event2 &lt;- cifplot(Event(time_cir, status_cir2) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\", \n  type.y       = \"risk\",\n  label.y      = \"1-Kaplan-Meier\"\n)\nkm_list &lt;- list(km_event1$plot, km_event2$plot)\nkm_panel &lt;- cifpanel(rows.columns.panel = c(1,2), plots=km_list)\nprint(km_panel)\n\n\n\n\n\n\n\n\n\n\n\n\n\nお父さん「わかった？打ち切りがランダムっていうのがKaplan-Meier曲線の前提条件なんだ。でも”競合イベントを打ち切り扱いにしていいか”は、ランダム打ち切りとは別問題なんだ。\n\n\n私「なるほどね。再発確率と死亡確率を足して1を超えることはあり得ない、Kaplan-Meier曲線にバイアスが生じていることの証拠だっていいたいのね。確かに、百聞は一見に如かず」\n\n\nお父さん「そう。このシミュレーションとまったく同じことを、統計学の数式は意味している。つまり、データ発生のアルゴリズムは確率モデルっていって、教科書では研究でなにが起きるかを抽象化した数式で書かれているんだ。そして、どんな推定でも使用条件みたいなものがあって、前提にしている確率モデルからずれると、推定値もまた真値からずれる。これは統計手法の誤用でも研究不備でも同じことだけど」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nKaplan-Meier法による生存曲線の推定が妥当な状況として正しいのは、次のうちどれでしょうか。\n\n生存時間が正規分布するとき\n打ち切りの理由が疾患の悪化によらないとき\n2群の打ち切り確率に統計学的な有意差がなかったとき\n試験治療群とコントロール群の間で比例ハザード性が成り立つとき\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は2です\n\nKaplan-Meier法では、生存時間が正規分布したり、比例ハザードが成り立ったりする必要はありません（これはそれぞれt検定とCox回帰の前提条件ですね）。疾患の悪化に伴って、試験の途中で患者が追跡できなくなると、推定された生存曲線にバイアスが生じてしまいます。2群の生存曲線を比べるとき、それぞれの群の打ち切り確率を比較することがあります。有意差があればバイアスがあるといえますが、たとえばサンプルサイズが小さいときは有意差が出ませんから、Kaplan-Meier法が妥当という証拠にはなりません。逆にいうと、打ち切りがランダムに起きていることが、Kaplan-Meier法の基本的な前提条件です。なお、競合イベントを打ち切りとして扱うかどうかは、ランダム打ち切りの条件とは独立に検討すべき問題ですよね。\n\n\n\n\n\n次のエピソードとRスクリプト\n\nUnderstanding Confidence Intervals via Hypothetical Replications in R\nfrequentist.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nR Demonstration of Bias in Kaplan-Meier Under Competing Risks\nUnderstanding Confidence Intervals via Hypothetical Replications in R\nAlpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/frequentist-2.html",
    "href": "jp/frequentist-2.html",
    "title": "P-Value Explanations That Seem Plausible at First Glance",
    "section": "",
    "text": "Frequentist Thinking II − P-Value Explanations That Seem Plausible at First Glance\n\nKeywords: clinical trial, language & writing, p-value, survival & competing risks\n\n\n\n生存曲線とハザード比\n\n\n私「お父さん、コーヒーもう一杯、淹れ直したよ。続けてJCOG9502のハザード比について教えてよ」\n\n\nお父さん「あつつ。それは図Aのhazard ratio of death 1.36、図Bのhazard ratio of recurrence or death 1.29についてだね。どちらもKaplan-Meier曲線の違いを要約していて、LTA群よりTH群の方が予後がよかったことを表している。ハザードが高いってことは、Kaplan-Meier曲線が下がりやすいっていう意味だからね。大事なのは、図Aの全生存期間（OS）、図Bの無病生存期間（DFS）のどちらも、ハザード比で要約しやすい形状をしていることかな」\n\n\n\n私「要約しやすい？」\n\n\nお父さん「うん。どちらの図でもTH群のKaplan-Meier曲線が、きれいにLTA群の上にあるでしょ、右端の人数が4人しかいないところでは交差しているけど。ハザード比は、2本の生存曲線が、ハザードのスケールで比例関係にあることが前提なんだ。ハザード比の基準は書かれていないけど、TH群を比の分母にとっている。この関係を、Cox回帰（Cox regression）とか比例ハザードモデル（proportional hazards model）って呼ぶんだ」\n\n\n私「比例関係だったら交差したらまずいよね」\n\n\nお父さん「そういうこと。それに、OSとDFSの結果が一貫している。これもすごく素直な結果だよね。解釈しやすい。後でRを用いたCox回帰をみせるよ」\n\n\n私「ありがとう、後でね。それよりさ。この図のハザード比は1.36と1.29だよね。ハザードが高いほどKaplan-Meier曲線が下がる、比の分母はTH群だっけ。ということは、ハザード比が1より大きいと、TH群よりLTA群の方がOSやDFSの成績が下がるんだよね？あと、p値は0.05より小さいと統計学的に有意なんでしょ。つまり、LTA群の方が、治療成績がわるかったけど、p値をみると2群に有意差はないんだよね」\n\n\nお父さん「そういうことだね。ハザードは死亡や再発が起きるスピードを表していて、ハザード比はその2群間の“比”だから」\n\n\n\n\np値に関する一見正しそうな説明\n\n\nお父さん「p値の正確な意味は誤解されてることが多いんだよ。論文を読むときの注意点としては、まず、試験によってはp値と比べる基準（有意水準）が5%でないかもしれないってこと。たとえば中間解析（interim analysis）とか。論文の抄録を読んでごらん。実はJCOG9502では最終解析の前に、中間解析をする計画になっていて、この論文はそのとき早期中止になった結果を報告しているみたいだよ。中間解析では、5%より低い有意水準で検定するのが一般的なんだ」\n\n\n私「じゃあ有意差がついたから早期中止したってこと？」\n\n\nお父さん「いや、この試験が早期中止した理由は、有意差がついたからではなく、LTA群が有意に勝つ見込みがないと、効果安全性評価委員会が判断したためだね。他にも誤解はいくつもある。これをみてよ」\n\n\np値は帰無仮説（null hypothesis）が正しい確率である\np値が小さく、統計学的に有意であることは、科学的に重要な知見が得られたことを意味する\n統計学的に有意でない結果とは、帰無仮説が正しいので採択すべきという意味である\n\n\nお父さん「JCOG9502の場合、帰無仮説は”LTA群の全生存曲線は、TH群の全生存曲線と等しい”ってことだよ。このp値に関する説明のうち、まず1について聞くね。JCOG9502のp値は、”LTA群とTH群の生存曲線に差がない確率”を意味すると思う？」\n\n\n私「黒板くさくなってきた。統計の教科書って私がいったの、地雷だったか？まあ、1はそれでいいんじゃない？p値が0.05だったら100回に5回は正しい」\n\n\nお父さん「ここではね、言葉を正確に選んで考えてみてほしいんだ。“生存曲線に差がない”っていう命題や仮説は、確率変数かな？確率変数ではないよね。命題は、正しいかどうかのどちらかしかないもの。確率変数ではないのに、確率が定義されるのは学問的におかしい」\n\n\n私「はーん。そういう理屈っぽいことがいいたかったわけね。じゃあそういう言い回しはやめます」\n\n\nお父さん「うんうん。じゃあ100回に5回ってどういう意味でいった？」\n\n\n私「へ。言葉通りだけど？JCOG9502を100回やったらどうなるかって意味」\n\n\nお父さん「その通り。同じ試験を100回繰り返したらp値が100個出てくるでしょ。これがこの場合の確率の定義なんだ。頻度論的確率（frequentist probability）とかいうね。じゃあ確率の意味の次は、p値の解釈。p値が小さいことは、“科学的に重要な知見が得られたこと”を意味すると思う？」\n\n\n私「普通そう考えるんじゃない？」\n\n\nお父さん「でもさっきの図のp値を見てよ。p=0.15からp=0.92まで4つのp値が示されているけど、どれも小さくはないでしょ」\n\n\n私「うん」\n\n\nお父さん「じゃあ科学的に重要じゃないってこと？」\n\n\n私「そういう意味でいったわけじゃないけど」\n\n\nお父さん「だよね。p値が小さい方が重要な研究結果だって考えがちだけど、それははっきりとした間違いだと考えてください。論文を読むとき、p値に注目すると見方が偏ってしまう」\n\n\n私「はいはい。お父さん、話長くない？」\n\n\nお父さん「三つ目の説明“統計学的に有意でない結果とは、帰無仮説が正しいので採択すべきという意味である”まで考えようよ。これは正しい？」\n\n\n私「教科書かなにかで、p値は、仮説を棄却するためのもので、採択しちゃだめって読んだ気がする。この最後の説明も、やっぱり間違いなんでしょ、空気でわかる。でもさ、実際問題として、有意差がつかなかったらどうなるの？たとえば実薬AとBを比較する臨床試験だったとして、AとBの効果は同等と結論に書いていいの？」\n\n\nお父さん「それはルール違反だよ。この問いは、そういう間違いをさせないために出したんだ。帰無仮説が正しいことは、AとBの効果は同等っていう意味になるけど、有意差がないからって、それを採択してはいけない。“同等”や“劣らない”という結論を出すには、同等性 （equivalence）試験や非劣性 （non-inferiority）試験を組む必要がある」\n\n\n私「やっぱりね。そう思ったけど、はっきりいってくれて納得だわ」\n\n\nお父さん「この区別はルールに組み込まないとまずいことを歴史が証明している。これはもう30年ほど前の日本の話なんだけど。昔、薬事承認の根拠として非劣性試験を国が求めていた時代があってね。その時代の経験を踏まえると、研究仮説と統計的な判断基準の関係は、厳密に考えとかないとちょっとまずいと思うんだ」\n\n\n\n\n標準規格としてのp値\n\n\n私「教科書的な説明は、それはそれでいいんだけどさ。なんだか、現実とギャップを感じるよ、私は。2の”p値が小さいと科学的に重要”についてなんだけどね。そうはいっても基礎研究だと、有意差がつかない結果はいまいち扱いじゃない？それが現実だと思う。でもJCOG9502は違うのもわかる。LTAの有効性が示されたわけでも、術式が同等ってわかったわけでもない。でもどうしてLancet Oncologyに載るほど評価されたんだろう」\n\n\nお父さん「ん？有意差がつかない臨床試験結果に価値がないとは思わないけど。臨床試験って、技術の性能評価が目的じゃない？手術や薬といった医療技術のね。有効性が示されるかどうかに関わらず、評価が定まったということに変わりはないよね」\n\n\n私「…ネガティブ試験でも価値が変わらないってことをいってるよね？」\n\n\nお父さん「うん。たとえるならさ、臨床試験はペーパーテストと同じ”試験”ってことだよ。合格・不合格と試験成績という情報の価値は無関係でしょ。さっき話したp値に関する説明は、採点ルールや試験の”標準規格”みたいなもので避けて通れないんだ。まあ、点数がすべてじゃないけどね」\n\n\n私「臨床試験は技術を評価するのが目的ってこと？科学的発見じゃなくて？」\n\n\nお父さん「うん。臨床試験が行われてきた文脈は、技術評価の制度の中だったといえると思うよ。p値の使い方や、有効性エンドポイントの定義の標準化も、“試験の規格”を一定に保つための工夫だった。古い話だけど、製薬企業が承認取得のために行う臨床試験って、90年代はまだ各国の共通ルールがなかった。90年代後半になって、米国、欧州、日本の規制当局が集まってICHガイドラインという臨床試験の標準規格を決めたんだ」\n\n\n私「それは医師主導臨床試験じゃなくて治験だよね。お父さんさ、やっぱり臨床試験はパラダイムシフトを起こしてない？殺細胞薬、抗PD-1、ADC。あれを”技術評価”って呼ぶのは、あんまり納得いかないな」\n\n\nお父さん「それは技術評価の結果が科学を刺激しただけじゃないかなあ」\n\n\n私「お父さんって、技術と科学を区別したがるね。まあ、企業治験は技術評価のくくりでも私はいいよ。でも、科学の営み全体をみたとき、臨床試験はその一部だと思う。結果が仮説を更新して、次の問いを生む。私はそれを科学って呼びたい」\n\n\n\n\n\n\n\n\nホパテの悲劇\n\n\n\n\n\n脳循環改善薬という古い薬をご存知でしょうか？この薬はかつて脳血管障害の後遺症や認知症などに使われ、累計8,000億円ほどの売上げがあったようです。脳循環改善薬にはいくつかの類似薬がありましたが、そのほとんどが、最初に承認されたホパンテン酸カルシウム（販売名ホパテ）と比較した「非劣性試験」を根拠に承認されていました。しかし当時行われていたのは、正式な非劣性の解析ではなく、「ホパンテン酸カルシウムと比べて有意差がない」ことにもとづいて非劣性を判定していました。1989年にホパンテン酸カルシウムは副作用のため市場から撤退しました。同時期に、厚生省（当時）は製薬企業にプラセボ対照試験による再評価を求めました。その結果、脳循環改善薬は、すべてプラセボに勝てなかったのです（厚生省医薬安全局1998）。この悲劇は、有意差がつかなかったとき、同等や非劣性と結論するのは間違いであることをはっきり示しています。\n\n\n\n\n\n\n\n\n\ncoxph()を用いたハザード比の推定\n\n\n\nハザード比を推定する方法はいくつかありますが、もっともポピュラーなのはsurvivalパッケージのcoxph()です。以前のエピソードでは、関数generate_data(hr1, hr2)を用いて、ストーマの有無やOSのデータを生成しました。今回は同じデータにCox回帰を当てはめ、ストーマあり群とストーマなし群のハザード比を計算してみます。generate_data(hr1, hr2)では、死亡ハザード比の真値はhr2という引数で指定できます。\n\n\n\n\n\n\n\n\ngenerate_data()のコードはこちら（データ生成に使用）\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # 再発のハザード（大きいほど早く起こる）\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # 死亡のハザード（大きいほど早く起こる）\n  hazard_censoring &lt;- 0.05                               # 打ち切りハザード（群に依存しない）\n  \n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)   # 再発までの潜在時間\n  t_death     &lt;- rexp(n, rate = hazard_death)     # 死亡までの潜在時間\n  t_censoring &lt;- rexp(n, rate = hazard_censoring) # 打ち切りまでの潜在時間\n  \n  ## --- 全生存期間（OS） ----------------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = 死亡, 0 = 打ち切り\n  \n  ## --- 無再発存期間（RFS） -------------------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # 再発\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # 死亡\n  \n  ## --- 累積再発率（CIR） + 競合リスク --------------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # イベント1: 再発\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # イベント2: 競合リスクとしての死亡\n  \n  ## --- データフレームにまとめる --------------------------------\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n}\n\n\n\n\n\n\n\n\n\n\ncoxph()のコードと結果はこちら\n\n\n\n\n\n\n# install.packages(\"survival\") #インストールが必要なら実行\nlibrary(survival)\ndat &lt;- generate_data(hr1=2, hr2=1.5) #再発ハザード比2, 死亡ハザード比1.5のデータ生成\nfit &lt;- coxph(Surv(time_os, status_os) ~ stoma, data = dat)\nsummary(fit)\n\nCall:\ncoxph(formula = Surv(time_os, status_os) ~ stoma, data = dat)\n\n  n= 200, number of events= 139 \n\n                  coef exp(coef) se(coef)     z Pr(&gt;|z|)  \nstomaWITH STOMA 0.3793    1.4612   0.1719 2.206   0.0274 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\nstomaWITH STOMA     1.461     0.6844     1.043     2.047\n\nConcordance= 0.558  (se = 0.024 )\nLikelihood ratio test= 4.78  on 1 df,   p=0.03\nWald test            = 4.87  on 1 df,   p=0.03\nScore (logrank) test = 4.92  on 1 df,   p=0.03\n\n\n\n\n\n\n\n文献\n\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\n脳循環代謝改善薬ニセルゴリンの再評価について [Internet]. 東京: 厚生省医薬安全局; 1998\n\n\n\n次のエピソードとRスクリプト\n\nBeyond 0.05: Interpreting P-Values in a Clinical Trial\nfrequentist.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nReading a Paper over a Cup of Coffee\nP-Value Explanations That Seem Plausible at First Glance\nBeyond 0.05: Interpreting P-Values in a Clinical Trial\n\n過去のシリーズ\n\nStudy Design I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/effects-6.html",
    "href": "jp/effects-6.html",
    "title": "After Cox Regression: A Case Study and R Demonstration",
    "section": "",
    "text": "Effects and Time VI − After Cox Regression: A Case Study and R Demonstration\n\nKeywords: bias, effect measure, R simulation, survival & competing risks\n\n\n\nハザード比が意味を持つとき、持たないとき\n\n\nお父さん「もう一杯コーヒーをもらっていい？」\n\n\n私「私も欲しい」\n\n\nお父さん「うん、ゆっくり考えよう、大事なところだ。比例ハザード性はCox回帰の特徴そのもので、これさえ満たされれば、Cox回帰は幅広いデータにも使えるんだけど、たまに比例ハザード性が崩れたデータをみることがある。これはオンコロジー領域では必須知識かもしれない。このKaplan-Meier曲線をみてよ（Mok, et al, 2009）。生存曲線がクロスした有名なケースなんだ」\n\n\n私「あ、よかった。数式ばかりで眠くなりかけてた」\n\n\n\n\n\nお父さん「これはステージIIIB～IVの肺がん患者の臨床試験で、ゲフィチニブと化学療法を比較している。図Aでは6ヶ月まではゲフィチニブ群の無増悪生存確率が低く、それ以降は高くなっているでしょ。こういうときは比例ハザード性が成り立っていないから、ハザード比に意味はない」\n\n\n私「どうしてこうなっちゃったの？」\n\n\nお父さん「それはゲフィチニブがEGFR変異陽性の肺がん患者に特に有効だったからだといわれている。図Bは、EGFR変異陽性だった261人を対象にしたKaplan-Meier曲線なんだけど、生存曲線はクロスせず、最初から最後までゲフィチニブ群の方が化学療法群より予後がいいでしょ」\n\n\n私「そうだね。この試験のKaplan-Meier曲線では、治療成績が交差して、どっちが効くのか悩ましいってことはわかるよ、数式はともかくとして」\n\n\nお父さん「はっきりいうとね、ハザードやハザード比が直感的にわかる人の方が少ないよ。だから安心していい」\n\n\n私「え、そうなの？なんか“知らないといけない基本”みたいに思って焦った」\n\n\nお父さん「ハザードはね、患者さんの健康状態を表す“見えない時計”だと思うといい」\n\n\n私「見えない時計？」\n\n\nお父さん「治療Aを受けた患者は、ちょっと速く進む時計を持っている。治療Bの人は、少し遅い時計を持っている。ハザード比は、2つの時計が“どれくらい違う速さで動くか”の比なんだ」\n\n\n私「なるほど、時間が進むスピードの違いなら、イメージしやすいかも」\n\n\nお父さん「ただし、ここが重要。時計の進み方は、必ずしも一定とは限らない。最初は治療Bが有利でも、途中から追いつかれることだってある」\n\n\n私「それ、診療していてもあるかも」\n\n\nお父さん「まとめると、このたとえ話の主張はこんなこと。\n\nハザード比は、2つの時計が“どれくらい違う速さで動くか”の比に例えられる。 比例ハザード性が成り立たないと、最初は一方の治療が有利でも、途中から追いつかれることもある\n\nそれなのに多くの論文で“ハザード比＝一定”という前提で解析する。Cox回帰が標準的に使われるからね。だから、比例ハザード性が破綻すると、ハザード比の解釈が急に怪しくなる」\n\n\n私「んなこといっても、論文にはだいたいハザード比しか書いてないよね」\n\n\nお父さん「だから次の一手が必要になる。“ある時点のリスク”や”ある時点までの生存曲線”を比べるんだ。曲線が交差していたら、5年生存率とか10年死亡率のようにどこを比較するか決める。ハザード比も重要だから、それとあわせてね」\n\n\n\n\n\n\n\n\nシミュレーションデータにおける時点ごとのリスク比の推定\n\n\n\nさっきの「見えない時計」をデータで眺めてみましょう。以前と同じ、ストーマ造設の有無で死亡のハザードが異なる生存時間データをシミュレーションし、時点ごとのリスク比（RR） を推定してみます。ハザード比は「時計の速さの比」でしたが、「術後10年時点の死亡リスクは、ストーマあり群が何倍か」のようにリスク比の方が、解釈しやすいこともあります。Cox回帰では時点を通じて1つのハザード比を仮定するのに対して、cifmodelingパッケージのpolyreg()では、時点を通じて一定のリスク比だけでなく、任意の時点ごとのリスク比も推定できます。\n先ほどのシミュレーションデータを使って、time.pointを変えたpolyreg()を当てはめることで、術後5年・10年・20年時点の死亡リスク比を推定します。アウトカム（OS）はEvent(time_os,status_os)、曝露変数であるストーマの有無はexposure=\"stoma\"で指定しています。\n\n\n\n\n\n\n\n\ngenerate_data()のコードはこちら（データ生成に使用）\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # 再発のハザード（大きいほど早く起こる）\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # 死亡のハザード（大きいほど早く起こる）\n  hazard_censoring &lt;- 0.05                               # 打ち切りハザード（群に依存しない）\n  \n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)   # 再発までの潜在時間\n  t_death     &lt;- rexp(n, rate = hazard_death)     # 死亡までの潜在時間\n  t_censoring &lt;- rexp(n, rate = hazard_censoring) # 打ち切りまでの潜在時間\n  \n  ## --- 全生存期間（OS） ----------------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = 死亡, 0 = 打ち切り\n  \n  ## --- 無再発存期間（RFS） -------------------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # 再発\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # 死亡\n  \n  ## --- 累積再発率（CIR） + 競合リスク --------------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # イベント1: 再発\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # イベント2: 競合リスクとしての死亡\n  \n  ## --- データフレームにまとめる --------------------------------\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n}\n\n\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\nlibrary(cifmodeling)\ndat &lt;- generate_data(hr1=2, hr2=1.5) #再発ハザード比2, 死亡ハザード比1.5のデータ生成\nrr_at_5 &lt;- polyreg(nuisance.model=Event(time_os,status_os)~1, exposure=\"stoma\", data=dat, \n                    effect.measure1=\"RR\", time.point=5, outcome.type=\"survival\")\nsummary(rr_at_5)\n\n\n                      event 1 (no competing risk)\n---------------------------------- \nstoma, WITH STOMA vs WITHOUT STOMA \n                      1.116       \n                      [0.793, 1.571]\n                      (p=0.529)   \n\n---------------------------------- \n\neffect.measure        RR at 5     \nn.events              85 in N = 200\nmedian.follow.up      3.71        \nrange.follow.up       [0.01, 25.30]\nn.parameters          2           \nconverged.by          Converged in objective function\nnleqslv.message       Function criterion near zero\n\nrr_at_10 &lt;- polyreg(nuisance.model=Event(time_os,status_os)~1, exposure=\"stoma\", data=dat, \n                    effect.measure1=\"RR\", time.point=10, outcome.type=\"survival\")\nsummary(rr_at_10)\n\n\n                      event 1 (no competing risk)\n---------------------------------- \nstoma, WITH STOMA vs WITHOUT STOMA \n                      1.282       \n                      [0.940, 1.750]\n                      (p=0.117)   \n\n---------------------------------- \n\neffect.measure        RR at 10    \nn.events              112 in N = 200\nmedian.follow.up      3.71        \nrange.follow.up       [0.01, 25.30]\nn.parameters          2           \nconverged.by          Converged in objective function\nnleqslv.message       Function criterion near zero\n\nrr_at_20 &lt;- polyreg(nuisance.model=Event(time_os,status_os)~1, exposure=\"stoma\", data=dat, \n                    effect.measure1=\"RR\", time.point=20, outcome.type=\"survival\")\nsummary(rr_at_20)\n\n\n                      event 1 (no competing risk)\n---------------------------------- \nstoma, WITH STOMA vs WITHOUT STOMA \n                      0.934       \n                      [0.599, 1.456]\n                      (p=0.762)   \n\n---------------------------------- \n\neffect.measure        RR at 20    \nn.events              129 in N = 200\nmedian.follow.up      3.71        \nrange.follow.up       [0.01, 25.30]\nn.parameters          2           \nconverged.by          Converged in objective function\nnleqslv.message       Function criterion near zero\n\n\n\n\n\n\n\n私「ハザード比は一定のデータを作ったのに、リスク比は1.367、1.126、1.078と徐々に小さく推定されてる。冒頭のKaplan-Meier曲線でも、最初の5年あたりがいちばん差が開いているもんね。時間と効果って、分けて考えられないんだね」\n\n\nお父さん「だってそうでしょ？効果って時間とともに生じるものだもの。それが因果の定義のひとつでもある。時間とともに効果の大きさが変化するなら、ハザード比に頼ることはできない。もっと丁寧に時点ごとにリスクを比べないと」\n\n\nTime-constant effect: 1つのハザード比で全期間を説明する（Cox回帰）\nTime-varying effect: 効果の大きさが時間とともに変わる（Kaplan-Meier曲線で記述）\nTime-point effect: ある時点のリスクや生存確率に注目して比べる（polyreg）\n\n\n私「そういわれると納得感あるなあ、ハザード比だけ使えばいいって方がシンプルで私好みだったんだけど。生存曲線を見るっていうのは、因果効果に時間の視点を加えるってことなんだね」\n\n\n\n\n文献\n\nMok TS, Wu YL, Thongprasert S, Yang CH, Chu DT, Saijo N, Sunpaweravong P, Han B, Margono B, Ichinose Y, Nishiwaki Y, Ohe Y, Yang JJ, Chewaskulyong B, Jiang H, Duffield EL, Watkins CL, Armour AA, Fukuoka M. Gefitinib or carboplatin-paclitaxel in pulmonary adenocarcinoma. N Engl J Med 2009;361(10):947-57\n\n\n\nThis concludes the Effects and Time series. If you’d like to keep reading over your next cup of coffee, the following episodes are waiting:\n\nUnderstanding Collapsibility of Effect Measures: Marginal vs Stratified\nFrom Risk to Logistic Regression\nLogit: How a Transformation Shapes an Effect\nWhere My Logistic Regression Went Wrong\nWhy Logistic Regression Fails in Small Samples\nUnderstanding Confounding in Effect Measures: Marginal vs Stratified"
  },
  {
    "objectID": "jp/effects-4.html",
    "href": "jp/effects-4.html",
    "title": "From Risk and Rate to Survival and Hazard",
    "section": "",
    "text": "Effects and Time V − From Risk and Rate to Survival and Hazard\n\nKeywords: effect measure, probability model, R simulation, survival & competing-risks\n\n\n\nリスクと時間の関係\n\n\n私「お父さんさ、以前聞いた寄与割合の話を思い返して気づいたんだけどね。まだ納得感が足りないの」\n\n\nお父さん「なに？コーヒーと一緒にこういう話をするのは歓迎だよ」\n\n\n私「がん検診後、10年、12年、20年って見ていくと、寄与割合が変わるって話だったでしょ。リスクには時間の概念があるって。あれって、2値データじゃなくて生存時間データになってない？ていうか、あれは生存曲線か」\n\n\nお父さん「そうだよ。リスクと生存曲線は表裏一体なんだ」\n\n\n私「生存曲線からある時点の生存確率を読み取ると、1-リスクになっているっていう意味ね。うんうん。そして、疫学の教科書に出てくる率（rate）が、生存時間解析のハザード（hazard）に対応しているっていうのもわかる。でも、気になるのはハザード比（hazard ratio）なんだ。寄与割合とかリスク比とかって、時間とともに変化するっていうけど、ハザード比は変化しないんだっけ」\n\n\nお父さん「変化しない。正確にいうと、生存曲線をみると変化している状況もあり得るんだけど、時間を通じてハザード比は一定と、無理やり仮定して計算してる」\n\n\n私「リスク比は変化するけどハザード比は変化しないの？矛盾してない？」\n\n\nお父さん「えーっと、リスク比が変化しないわけじゃなくて…。リスクはハザードの時間積分だから、どちらか一方の比を固定したらもう一方は固定できなくて…。ちょっと紙ナプキンとペンをとってくれる？教科書通りに説明するとこうなるんだけど。まずはリスクとハザードからはじめるね」\n\n\n\n\n\n\n\n\n生存曲線とハザードの関係\n\n\n\nこれまでのエピソードでは、ある時点までのリスクを扱ってきましたが、今度は“時間に沿って変化するリスク”を推定したKaplan-Meier曲線について正式に説明します。Kaplan-Meier曲線は、そもそも2値データではなく生存時間データに用いられる手法でした。そのため、Kaplan-Meier曲線は時間軸を横にとったグラフですし、いわゆるハザード比との関係も知りたいところですよね。ここでは、ハザードが時間を通じて一定という単純な状況で、そのあたりを整理しましょう。\nKaplan-Meier曲線は、生存時間データから計算された推定値を、時間軸（\\(x\\)軸）に沿ってグラフにしたものです。これを数式で書くなら、「生存曲線を時間\\(x\\)の関数\\(S(x)\\)で表す」ということになります。\n関数\\(S(x)\\)を具体的に書くこともできます。生存時間が、ハザードが時間を通じて一定ということは、指数分布に従うと仮定したことになります（これはKaplan-Meier曲線とは別ものです）。指数分布の形状を決めるパラメータ（ハザード）は、\\(λ\\)という記号で表すことが普通です。このとき指数分布の生存関数とハザードには、以下のような関係があります。\n\\(S(x)=\\mathrm{exp}(-\\lambda x)\\)\nここまでくればあと一息です。最後に、疾患リスクとハザードの関係を確認しましょう。疾患リスク\\(π\\)は、特定時点\\(x\\)までに疾患を発症する確率を表しています。つまり、疾患リスク\\(π\\)とハザード\\(λ\\)は、時点\\(x\\)の生存関数を\\(S(x)\\)を介して、以下の式で結びついています。\n\\(\\pi=1-S(x)=1-\\mathrm{exp}(-\\lambda x)\\)\n\n\n\n\n私「わからん。数式はわからん」\n\n\nお父さん「そう？数学の難しさというより、この等式が何と何を結びつけているかが、慣れないと読み取りにくいんだと思う。ちょっとしたポイントは指数分布だとハザードは定数扱いで、生存関数は時間の関数だってところかなあ」\n\n\n私「結びつきねえ。とりあえず生存曲線とハザードの関係式ってことまでかな、確実なのは」\n\n\nお父さん「まずはそこからだね。多分、指数分布からデータを発生させるシミュレーションをやってみると、この式とデータの関係が見えてくると思う」\n\n\n\n\n\n\n\n\ngenerate_data()のコードはこちら（データ生成に使用）\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # 再発のハザード（大きいほど早く起こる）\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # 死亡のハザード（大きいほど早く起こる）\n  hazard_censoring &lt;- 0.05                               # 打ち切りハザード（群に依存しない）\n  \n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)   # 再発までの潜在時間\n  t_death     &lt;- rexp(n, rate = hazard_death)     # 死亡までの潜在時間\n  t_censoring &lt;- rexp(n, rate = hazard_censoring) # 打ち切りまでの潜在時間\n  \n  ## --- 全生存期間（OS） ----------------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = 死亡, 0 = 打ち切り\n  \n  ## --- 無再発生存期間（RFS） -----------------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # 再発\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # 死亡\n  \n  ## --- 累積再発率（CIR） + 競合リスク --------------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # イベント1: 再発\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # イベント2: 競合リスクとしての死亡\n  \n  ## --- データフレームにまとめる --------------------------------\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n}\n\n\n\n\n\n\n\n\n\n\ncifplot()によるKaplan-Meier曲線\n\n\n\nどのようなシミュレーションデータが得られるかイメージしやすいように、cifplot()で描いたKaplan–Meier曲線とcoxph()の結果を置いておきます。\n\n\n\n\n\n\n\n\ncifplot()のRコードと結果はこちら\n\n\n\n\n\n\n# devtools::install_github(\"gestimation/cifmodeling\") #インストールが必要なら実行 \nlibrary(cifmodeling)\nset.seed(46)\ndat &lt;- generate_data(hr1=2, hr2=1.5) #再発ハザード比2, 死亡ハザード比1.5のデータ生成\ncifplot(Event(time_os, status_os) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncoxph()のRコードと結果はこちら\n\n\n\n\n\n\n# install.packages(\"survival\") #インストールが必要なら実行\nlibrary(survival)\nfit &lt;- coxph(Surv(time_os, status_os) ~ stoma, data = dat)\nsummary(fit)\n\nCall:\ncoxph(formula = Surv(time_os, status_os) ~ stoma, data = dat)\n\n  n= 200, number of events= 144 \n\n                  coef exp(coef) se(coef)     z Pr(&gt;|z|)  \nstomaWITH STOMA 0.3199    1.3769   0.1693 1.889   0.0589 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\nstomaWITH STOMA     1.377     0.7262    0.9881     1.919\n\nConcordance= 0.544  (se = 0.024 )\nLikelihood ratio test= 3.51  on 1 df,   p=0.06\nWald test            = 3.57  on 1 df,   p=0.06\nScore (logrank) test = 3.6  on 1 df,   p=0.06\n\n\n\n\n\n\n\n私「ふむふむ。ハザードで指数分布を指定すると生存曲線が決まるわけね」\n\n\nお父さん「そういうこと。次に気になるはハザードだよね。このパラメータの具体的なイメージを持つのは難しいけど、生存時間中央値と結びつけるのがよくやる手だよ。中央値（median）は生存曲線がちょうど50%まで落ちる時点のこと」\n\n\n\n\n\n\n\n\nハザードと生存時間中央値の関係\n\n\n\nさて、ハザードは生存曲線が下がるスピードを決める数値です。生存時間がどのくらいの長さなのかは、中央値で測ることができます。生存時間中央値\\(M\\)は、生存確率50%つまり\\(S(x)=0.5\\)になるような時間\\(x\\)のことです。つまり、指数分布では\n\\(0.5=\\mathrm{exp}(-\\lambda M)\\)\nと関係が成り立つので、生存時間中央値\\(M\\)は、ハザード\\(λ\\)から以下のように計算することができます。\n\\(M = \\frac{\\log 2}{\\lambda} \\approx \\frac{0.7}{\\lambda}\\)\n\n\n\n\n私「あ、これはちょっとわかった気がする。寿命（生存時間中央値）とハザードが逆数の関係ってことね。つまり寿命が2倍になったらハザードは1/2になる」\n\n\nお父さん「そうだね、たとえるならハザードはコーヒーにとっての気温みたいなもの。寒いとコーヒーが覚める時間が短くなる。これがハザードが高いってこと。正確に逆数になるのは、指数分布の下で計算するときだけどね。ハザード比は、まさにハザードの比をとったものだよ。指数分布ではこういう式になる。2つの集団の生存曲線を比較するときによく使うよね」\n\n\n指数分布のハザード比 \\[\nHR=\\frac{\\lambda_1}{\\lambda_2}\n\\]\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n生存時間中央値を報告してよいのは、どのような場合でしょうか？\n\n目安としてサンプルサイズが100人以上のとき\nすべての対象者が予定された追跡期間を終了したとき\n半数以上の対象者がイベントを起こしたとき\n1、2、3すべて誤り\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です\n\n生存時間データでは一部の対象者で打ち切りがあること（これ以上生存時間が長いことしかわからない）、中央値（median）の定義を思い出してください。半数以上の対象者がイベントを起こし、生存時間が確定しないと、生存確率は50%以下になりません。\n\n\n\n\n\n次のエピソードとRスクリプト\n\nA First Note on Cox Regression\neffects.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nA First Note on Cox Regression\nAfter Cox Regression: A Case Study and R Demonstration\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/effects-2.html",
    "href": "jp/effects-2.html",
    "title": "Who Is This Percentage About? Target Populations and Attributable Fractions",
    "section": "",
    "text": "Effects and Time II − Who Is This Percentage About? Target Populations and Attributable Fractions\n\nKeywords: effect measure, language & writing, observational study, research hypothesis\n\n\n\n疾患リスクとターゲット集団\n\n\n私「コーヒーおかわりいる？お父さん」\n\n\nお父さん「ああ、ありがとう。ワクチンとは別の話題なんだけど、喫煙歴のあるがんの患者さんって、減ったと思う？」\n\n\n私「そうね、昔よりは少なくなったんじゃない？」\n\n\nお父さん「でも、日本のがんの統計上は、まだまだ喫煙は健康問題のひとつなんだ。がん罹患のリスク要因は、感染症、喫煙、飲酒の順に影響が大きいと推定されている」\n\n\n私「喫煙率は下がってるのにちょっと意外だね。でもどのがん登録でも、喫煙情報は絶対調べるよね」\n\n\nお父さん「感染症、喫煙、飲酒が、がん罹患に寄与する割合は、16%、15%、6%っていわれてる。この指標を、集団寄与割合っていうんだけど、これもただのパーセントじゃない」\n\n\n私「それはそうだよね。喫煙者の15%ががんになる、なんて思わないもの。でも正確な意味はぱっとわかんないな」\n\n\nお父さん「ほら、喫煙者のがん罹患を真っ先にイメージしちゃうでしょ。そこも誤解ポイント。集団寄与割合が想定している集団は、喫煙者じゃないんだ」\n\n\n\n\n\n\n\n\n集団寄与割合\n\n\n\n疫学研究では、一般集団を対象にして、環境物質や生活習慣といったリスク因子を調べることが多く、そのために寄与割合（attributable fraction/excess fraction）という指標も用いられます。寄与割合は、特定の集団におけるリスク因子への曝露が、どのくらい疾患発症に寄与するかを表す指標です。ただし、寄与割合には、歴史的に異なる定義のものが複数あり、どのような集団をターゲットとするかで計算方法も変わるので、じゅうぶん意味を確認する必要がある指標です。\nあるリスク因子が国民全体の疾患発症にどの程度寄与するかを反映する指標は、集団寄与割合（population attributable fraction）と呼ばれています。ここで\\(RR\\)はリスク比、\\(p\\)は集団全体のうち群1が占める割合を意味しています。\n\n集団寄与割合（population attributable fraction）\n\n\\[\nPAF=\\frac{p(RR-1)}{p(RR-1)+1}\n\\]\n\n\n\n\n私「ふーん。集団寄与割合はリスク比だけじゃなくて、リスク因子の割合がわからないと計算できないんだね。でも、まあ、これもワクチン有効率と同じパターンだね。パーセントっていわれるとただの割合と思っちゃう。集団寄与割合のパーセントって、よく考えるとなにを意味するのか謎」\n\n\nお父さん「うん。でもね、問題はそこだけじゃない。集団寄与割合にすごく似た別の指標が説明なしに使われることが結構あるってこと。リスク因子の割合が不要な指標もあって、集団寄与割合と混同されていることもある。日本語では定訳があるわけではないけど、海外ではexcess fractionやpreventable fractionという専門用語が当てられているんだ。実はこの2つはワクチン有効率とほとんど同じ式だったりする」\n\n\n\n\n\n\n\n\n3種類の寄与割合\n\n\n\n集団寄与割合以外の寄与割合として、excess fraction（過剰寄与割合）とpreventable fraction（予防寄与割合）がよく用いられます。集団寄与割合との本質的な違いはターゲット集団にあります。このふたつの指標のターゲット集団は曝露集団です。\n\n\n\n\n\n\n\n\n指標\nターゲット集団\n何を表す？\n\n\n\n\nPAF（集団寄与割合）\n曝露+非曝露\n集団全体の疾患のうち、どれだけがその曝露のため生じているか\n\n\nEF（過剰寄与割合）\n曝露だけ\n曝露集団のうち、どれだけの割合が曝露のため疾患を生じたか\n\n\nPF（予防寄与割合）\n曝露だけ\n曝露集団のうち、どれだけ予防的な曝露が疾患を防いだか\n\n\n\n\n\n\n\n\n\n\n\nExcess fractionとpreventable fractionの定義\n\n\n\n\n\nExcess fractionは、曝露がリスク因子として働くときに用いられる指標として、多くの疫学の教科書で説明されており、以下のように定義されます。この指標では、群1が曝露あり、群2が曝露なしと考えています。そして、群1から曝露を取り除いたとき、どのくらい疾患が減るかを表しています。\n\nexcess fraction（過剰寄与割合） \\[\nEF = \\frac{\\pi_1 - \\pi_2}{\\pi_1} = 1 - \\frac{1}{RR}\n\\]\n\nその一方で、たとえば喫煙に対する禁煙のように、曝露が予防的に作用するとき、preventable fractionが用いられます。群1が曝露あり、群2が曝露なしという点は同じですが、ターゲットは群2です。なお、この式はワクチン有効率と同じです。\n\npreventable fraction（予防寄与割合） \\[\nPF=\\frac{\\pi_2-\\pi_1}{\\pi_2}=1-RR\n\\] 集団全体ではなく、曝露集団をターゲットにする意義は、具体的な状況をイメージすると理解しやすくなります。環境疫学では、たとえば化学物質や放射線被ばくなど環境要因の健康影響を評価することが求められます。この場合では、集団全体ではなく、実際に環境要因に曝露した集団における被害を定量化する必要があるため、曝露集団をターゲットとしたexcess fractionがしばしば用いられます。同じような理由で、ワクチン・検診・運動などの予防法の新規導入が、個人のリスクをどれだけ下げたか知りたいときは、preventable fractionが好まれています。\n\n\n\n\n\n\n私「余計にわかんない。使い分けもわかんないしパーセントがなにを意味するのか謎」\n\n\nお父さん「まあコーヒーを飲んでゆっくり考えよう。まずは具体的な計算結果をみてみてよ」\n\n\n\n\n\n\n\n\nコホート研究の数値例\n\n\n\nリスクや効果の指標について数値例をみるとイメージしやすいと思います。この表は、 喫煙と膵がんリスクの関係を調べる仮想的なコホート研究から得られたデータを表しています。上の式を用いて、リスク差、リスク比、オッズ比、excess fractionを求めると、以下のような結果が得られます。ワクチン有効率と同じように、excess fractionもパーセントで示すことがあるため、要注意です。\n\n\n\n\n喫煙あり\n喫煙なし\n効果の指標\n\n\n\n\n合計\n\n\n\n\n\n　膵がんあり\n15\n12\n\n\n\n　膵がんなし\n365\n868\n\n\n\n　リスク\n3.9%\n1.4%\n\n\n\n　リスク差\n\n\n2.5%\n\n\n　リスク比\n\n\n3倍\n\n\n　オッズ比\n\n\n3倍\n\n\n　Excess fraction\n\n\n74%\n\n\n\n\n\n\n\n私「同じパーセントでも、リスク差の2.5%とexcess fractionの74%は印象がだいぶ違う。まあ、私が公衆衛生やっていないのもあるけど」\n\n\nお父さん「でしょ。同じパーセントで言葉と認識にギャップがあるよね。まあ臨床試験のハザード比は”どの治療を選ぶか”、寄与割合は”社会に介入すると疾患がどれだけ減るか”だから、慣れの問題もあるかもだけど。効果の指標って、ただの計算だと思うとかえって理解しにくいところもある。たとえ話をさせてよ。60歳になってがん検診にきた人が4人いたとする。話をわかりやすくするために、4人の健康状態はまったく同じだとしよう。そのうち、最初の2人はがん検診が陽性で、根治切除できたとする。その後、71歳と79歳まで生きることができた。つまり、がん検診後の生存期間は11年と19年」\n\n\n私「ふんふん」\n\n\nお父さん「残りの2人は、本当はがんだったのに、検診では見つけられなかった。そのため、67歳と73歳で亡くなった。つまり、がん検診後の生存期間は7年と13年」\n\n\n60歳がん検診で陽性になり根治手術、71歳まで生存\n60歳がん検診で陽性になり根治手術、79歳まで生存\n60歳がん検診で偽陰性、手術を受けず、67歳まで生存\n60歳がん検診で偽陰性、手術を受けず、73歳まで生存\n\n\nお父さん「仮にこの2人を60歳のとき根治切除できたとしたら、生存期間は何割長くなるだろう」\n\n\n私「えっと、がん検診陽性の2人の生存期間は平均15年でしょ。がん検診陰性の2人の生存期間は平均10年。だから、(15-10)/10=0.5だから、50%の延長」\n\n\nお父さん「じゃあ、別の質問をするよ。もし、がん検診陽性の2人を60歳のとき根治切除できなかったとしたら、生存期間はどれくらい失われる？」\n\n\n私「(10-15)/15=-0.33だから、33%減っちゃうね」\n\n\nお父さん「そう。つまり、陽性2人と陰性2人のどちらをターゲットにするかで、データは同じでも、根治切除の生存期間に寄与する割合が変わってくる。ここが寄与割合の複雑なところなんだ。この例では生存期間で説明したけど、疾患リスクでもターゲット集団に依存する点は同じ。Excess fractionは、この例でいうと根治切除できなかった2人をターゲットと考えている。Preventable fractionのターゲットは、根治切除できた2人に対応している」\n\n\n私「なるほど、ターゲット集団を分母にとるのね。ターゲットがあるのが、リスク差とかリスク比とかとの違いってわけだ」\n\n\nお父さん「そういうわけでもないんだ。効果の指標にはどれも、表に出ないだけでターゲット集団がある。たとえば術後の大腸がん患者を対象にランダム化臨床試験をして、補助化学療法をすると死亡リスク差が-5%になったとするでしょ。これって、術後の大腸がん患者全体に補助化学療法をすべきって解釈にならない？」\n\n\n私「まあねえ」\n\n\nお父さん「つまり臨床試験の集団全体がターゲット集団になる。因果リスク差とか、因果リスク比っていう言葉があるんだけど、これは集団全体に別の治療をしたときや、集団全体がリスク因子に曝露したとき、リスクがどう変化するかを表してるんだ」\n\n\n私「ふーん。じゃあ効果の指標はどれも、単に数式が違うだけじゃなくて”どの集団について語っているか”という言語の問題が潜んでいるんだね。診療科で論文読むことがあるけど、まさか指標によって集団が変わるなんて認識してないんじゃないかな。この前のワクチン有効率はどうなの？」\n\n\nお父さん「ワクチン有効率も臨床試験で推定するよね。だからそのワクチンのターゲット全体が、ワクチンを接種したとき、それがプラセボだったときに比べ、何割感染症が減るかっていう解釈になる。現場では、既存のワクチンが普及していることがほとんどでしょ。そこにワクチン有効率98%の新しいワクチンを投入しても、感染症が98%減ることにはならない」\n\n\n\n\n\n\n\n\nターゲット集団\n\n\n\n\n\n治療や曝露とアウトカムの因果関係を扱うときには、どのような集団を考えているかをはっきりさせる必要があります。一例として、根治切除後の直腸がん患者におけるストーマ造設の有無と復職率との因果関係を考えてみましょう。このときストーマ保有者と非保有者を比較する因果リスク差は、「根治切除後の直腸がん患者全体」をターゲット集団としています。ストーマ保有者と非保有者という別の集団を比べているのに、患者全体がターゲットというのは奇妙にみえるかもしれません。しかし因果推論では、「患者全体がストーマを造設したとき」と「患者全体がストーマを造設しなかったとき」という仮想的な状況を対比することで、ストーマ造設が復職率を低下させたかがわかる、という反事実の考え方をするのです。\n\n\n\n\n\nお父さん「もうひとつ気を付けないといけないのは、リスクには時間の概念が隠れていること。検診後10年時点の死亡確率を考えてみよう。陽性2人の死亡確率は0%、陰性2人の死亡確率50%だよね。このときのexcess fractionはわかる？」\n\n\n私「うん。(0.5-0)/0.5=1でしょ」\n\n\nお父さん「そう、つまり根治切除していれば、がん陰性の2人の死亡は100%防げたという意味になる。でもさ、がん検診後、12年経つとどうなる？」\n\n\n私「(0.5-0.5)/0.5=0になるね」\n\n\nお父さん「じゃあ、がん検診後、20年経つと？」\n\n\n私「生存者はいなくなるね。(1-1)/1=0かな」\n\n\nお父さん「そういうこと。寄与割合は、時間とともに変化することがあり得るんだ。時間が隠れているっていうのは、リスク比やオッズ比も同じだけどね」\n\n\n私「なるほどね」\n\n\nお父さん「まとめるとね、“何%減る”とか”何%に効く”というパーセントを見たら、どの集団のことなのか、どの時点のリスクかを意識しよう、ということだね」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n今回みたように、寄与割合は、excess fractionやpreventable fraction以外に、曝露・非曝露を合わせた集団全体をターゲットにすることがあります（population attributable fraction）。先ほど用いたがん検診の例で考えましょう。仮にがん検診の精度が高くなって、感度を100%にできたとしましょう。先ほどの状況（感度50%）に比べて、検診後15年後に死亡している人数は、4人のうち、どのくらい減ると期待されるでしょうか。\n\n0%\n33%\n50%\n100%\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は2です\n\nこの4人の生存期間は、11年、19年、7年、13年なので、15年後の死亡数は3人です。また、根治切除後の死亡率は50%なので、根治切除できなかった2人が、仮にがん検診でがんを見つけられて、根治切除できたとしたら、死亡率は50%と期待されます。この仮想的な状況における死亡数は、1+2×50%=2人です。つまり、検診後15年後に死亡している人数は33%減ったことになります。\nこの計算は、集団全体をターゲットとする寄与割合を求めていることに他なりません。集団全体における曝露割合を\\(p\\)で書くと、集団寄与割合は、以下の式で表されます。\n\\(PAF=\\frac{p(RR-1)}{p(RR-1)+1}\\)\nがん検診の例では、\\(p=0.5\\)、15年死亡リスク比は\\(RR=2\\)なので、これを代入すると、\\(PAF=0.5(2-1)/{0.5(2-1)+1}=0.33\\)となり、上の正解と一致します。\n\n\n\n\n\n次のエピソードとRスクリプト\n\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\neffects.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nA First Note on Cox Regression\nAfter Cox Regression: A Case Study and R Demonstration\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/causal-inference-6.html",
    "href": "jp/causal-inference-6.html",
    "title": "Volatility, Uncertainty, Complexity, and Ambiguity in Causal Inference",
    "section": "",
    "text": "Causal Inference VI − Volatility, Uncertainty, Complexity, and Ambiguity in Causal Inference\n\nKeywords: causal model, probability model, p-value, language & writing\n\n\n\nDAGは何に対処するための道具か\n\n\nお父さん「お帰り、今日は遅かったね」\n\n\n私「うん、病院経営のウェブセミナーが夜にあってさ。疲れちゃった」\n\n\nお父さん「ああ、診療後にね。コーヒーでも淹れる？」\n\n\n私「うん。あのね、セミナー聴きながらDAGについて考えてたんだ。お父さんが何を説明してくれていたのかって」\n\n\nお父さん「ふむ」\n\n\n私「セミナーの講師がいうわけよ。変化が激しい時代を乗り越えて経営するには”VUCA”に対処しなければならないって。VUCAっていうのは、volatility、uncertainty、complexity、ambiguityの頭文字をとったビジネス用語みたい。経営問題の特徴や求められる対処能力を、VUCAを使って端的に説明してくれたんだ」\n\n\nVolatility（変動性）\nUncertainty（不確実性）\nComplexity（複雑性）\nAmbiguity（曖昧性）\n\n\nお父さん「へえ、マネジメントではそう整理するんだね。で、画面を見ながら研究のVUCAについて考えてたわけだ」\n\n\n私「そうなんだ。だって、このところ統計と不確実性の話ばっかりしてたから。p値とかランダム誤差・バイアスって、不確実性そのものでしょ、統計の文脈ではあるけどさ。でもDAGはちょっと違うなって考えてた」\n\n\nお父さん「…ふむ」\n\n\n私「でね、この4つにDAGを当てはめるとしたらcomplexityだって思ったんだ。観察研究で交絡因子の候補が多いとき役に立つっぽいし、デザインが単純明快になればなるほど、DAGを使ってcomplexityに対処しなくても済みそうだもの」\n\n\nお父さん「そうだね、因果推論で出てくる課題をVUCAで整理するとしたら、DAGはcomplexityへの対処の道具なんだと思う。相互に関連する多くの変数を、交絡因子、中間媒介因子、合流点のどれかに分類したり、バックドア基準のような単純ルールを作ったりね。それにDAGは、何を仮定しているかを見せてくれるから、ambiguityを減らす道具でもあるね」\n\n\n私「そうそう。複雑さを整理し、曖昧性を減らす道具だね」\n\n\nお父さん「そう考えると、Rを使ったシミュレーションもDAGと同じカテゴリなんじゃないかな。データが複雑になればなるほど、シミュレーションで数値実験をしないと、何が起きるか目に見えない。へえ、“VUCA”っておもしろい分類だね」\n\n\n私「でしょ。臨床研究におけるvolatilityって何だろう。ガイドラインや診断基準の改訂とかかな。新型コロナのとき、臨床研究を行うのが大変だったって聞くけど」\n\n\nお父さん「あのときは研究を取り巻く医療環境そのものの変化が激しかったよね。感染症以外の疾患でも、臨床試験のリクルート・データ収集が難しかった。新型コロナは外部環境におけるvolatilityっぽいけど、それ以外にも、JCOG9502のように中間解析の結果が出たり、未知の副作用が観察されたりすると、何らかの対応が求められるよね。確かに研究を行う上でvolatility対策も大切だね。これからますます変化が激しくなるとしたら、研究計画書を途中で変更しなければならないことも増えるかもしれない」\n\n\n私「ああ、たしかに。それとね、セミナーの途中で思わずうなずいちゃったのはambiguityの話なんだ。研究でも同じだって思って」\n\n\nお父さん「ふむ」\n\n\n私「調査票を作るとき、情報バイアスを減らすには、曖昧な質問をしないのが一番だと思うし、言葉を定義しておくとぶれないってお父さんがいうのもよく分かる。言葉の曖昧性って、考えていたより深刻な問題だよね。データを扱うときって、情報は固定されていても、言語の方がぶれがちなんだ」\n\n\n\n\nThis concludes the Causal Inference series. If you’d like to keep reading over your next cup of coffee, the following episode is waiting:\n\nA Subtle Distinction Between Editors and Reviewers"
  },
  {
    "objectID": "jp/causal-inference-4.html",
    "href": "jp/causal-inference-4.html",
    "title": "A Circle, an Equation, and a Cylinder",
    "section": "",
    "text": "Causal Inference IV − A Circle, an Equation, and a Cylinder\n\nKeywords: causal model, language & writing, probability model\n\n\n\n問いの答えは、どの抽象表現で世界を見るかで変わる\n\n\n私「お父さんさ、丁寧なのはいいんだけど。合流点の説明ってもっと簡単にできないの？この条件付確率分布の式がきっついわ」\n\n\nお父さん「その気持ちはわかるよ、でも式を出さないと正確じゃないと思って」\n\n\n私「それ自体はありがたいんだけどね。たとえ話とかでも十分そうだけど」\n\n\nお父さん「でもさ、最初の質問覚えてる？“確率モデルでもRubin因果モデルでも、交絡の説明が不足しているんじゃないか”、そこが出発点だったよね。だから、合流点を何か別のものに置き換えるだけでは足りないんだ」\n\n\n私「まあそうだけど」\n\n\nお父さん「具体的な式をナプキンを書いたのは理由がある。同じものをDAGと数式の2通りで表現していることを知ってほしかったんだ。抽象的な表現を併用することは意外に多い。ここにマグカップがあるよね」\n\n\n私「いつもコーヒーを飲んでるやつね」\n\n\nお父さん「これを上から見てごらん」\n\n\n私「ん？こう？」\n\n\nお父さん「そう。円が見えるでしょ」\n\n\n私「そうだね。それがどうかしたの？」\n\n\nお父さん「数学の授業で、x軸とy軸をとると円はこんな方程式で表せるって習ったでしょ。DAGと条件付確率の式の関係は、これに似ている」\n\n\\[x^2+y^2=r^2\\]\n\n私「円は見た目、円の式は数式って意味？」\n\n\nお父さん「そう。共通の分析対象を、別の表現で扱ってるでしょ。円の話をするとき、数式が要らなかったら、円の絵を描いた方がはやいよね。DAGもそう。条件付確率の式から、つながり方だけを抜き出した射影なんだ。分布の形やデータの型は捨て、複雑な式をいったん横に置いて必要な構造だけを見るためにね。DAGは、つながり方だけを見るためのトポロジカルな道具なんだ」\n\n\n私「そりゃあ、矢印でつながってるだけの方が、まずはわかりやすいよ」\n\n\nお父さん「じゃあ今度はマグカップを斜めから見てごらん」\n\n\n私「ん。円が立体になるっていいたいんだよね」\n\n\nお父さん「その通り、マグカップが円柱として見える。この円柱はRubin因果モデルの潜在結果変数みたいなものじゃない？上から観測できるデータだけじゃ、全体はわからないよね。それが観測できない潜在結果変数なんだ」\n\n\n私「ほえー詩人だね」\n\n\nお父さん「1つのマグカップの中に、確率モデル、DAG、Rubin因果モデルという3つの構造が隠れている。抽象的な構造に基づいてデータから情報を引き出す。それも、単なる情報処理や圧縮じゃなく、患者さんのための知識を得るためにね。統計解析は人間のためのもの。だからこそ、どの抽象表現で世界を見るかが大事になる」\n\n\n変数をどう選ぶ\n\n私「でもね、私にとっては、モデルよりも変数の選び方の方が切実な問題なんだ。ピロリ菌除菌のDAGでいえば、ピロリ菌除菌の有無の他に、胃がん発生、性格、年齢、体質という変数をDAGに入れたでしょ。実際の研究でどうやって選ぶの？」\n\n\nお父さん「そこが難しいんだけど、医学知識や研究デザインを根拠にもっともらしいDAGを描くしかないね。胃がんリスク因子だとか、ランダム化臨床試験なら治療割付と共変量は独立なはず、だとか」\n\n\n私「そうするとDAGの変数が無限に増えちゃうと思うんだ。だって胃がんが発生するためには、消化管が発生しないといけないでしょ。そうすると、その前にはミクロレベルでは細胞があり、マクロレベルでは生物がないとおかしいよね。ピロリ菌除菌を受ける原因だって、社会的要因かもしれないし」\n\n\nお父さん「ああ、そういう発想もあるね。因果観のなかには、単にある原因と結果を結びつけるだけじゃないものもある。あらゆる物質がNewton力学に従っているようにね」\n\n\n私「いま物質の話をしてないんだけど」\n\n\nお父さん「うん。じゃあ枠組みをもう少し広くしよう。日本語には”因果”と並んで”縁起”という言葉がある。因果は原因と結果を意味するよね。一方の縁起は、あらゆる出来事や認識が重なって、結果が生じるという文脈で使われる。でも、ランダム化臨床試験や観察研究の分析対象は、縁起の文脈より、もっと部分的じゃない？」\n\n\n私「そうだね。知りたいのは医薬品の有効性やピロリ菌除菌の効果だけだね」\n\n\nお父さん「うん。どの枠組みが正しいかっていう話じゃないよ。臨床研究の場合は、DAGに入れる変数は研究仮説や目的に関わると思われるものにフォーカスしてもいいんじゃないかって言いたいわけ。使用目的は、たとえば交絡因子を特定して、推測の妥当性を吟味することだからね」\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nDAGはいくつかのアイデアが元になっていますが、そのひとつにSewall Wrightが描いたパスダイアグラムがあります。その最初のものは、1920年にProceeding of the National Academy of Sciencesで発表された論文に載っていたものといわれています。さて、この図は何の因果関係を分析したものでしょうか？\n\nがんとその原因\n車の故障とその原因\nQOLとその原因\nモルモットの特徴とその原因\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は4です。\n\n\n\n\n\n\n\n次のエピソード\n\nBackdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nThree-Variable DAGs: The Smallest Building Blocks of Causal Structure\nA Subtle Distinction between Common Causes and Confounders\nDAGs and Conditional Distributions: Two Languages for the Same Structure\nA Circle, an Equation, and a Cylinder\nBackdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias\nVolatility, Uncertainty, Complexity, and Ambiguity in Causal Inference\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\nEffects and Time I\nAdjusting for Bias I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/causal-inference-2.html",
    "href": "jp/causal-inference-2.html",
    "title": "A Subtle Distinction between Common Causes and Confounders",
    "section": "",
    "text": "Causal Inference II − A Subtle Distinction between Common Causes and Confounders\n\nKeywords: bias, causal model, confounding & collapsibility, observational study\n\n\n\nDAGと一般因果\n\n\n私「お父さん、共通原因がバイアスってのはわかるんだけど、正直コーヒーと膵がんの話からあんまり進歩した気がしないんだ。その理由はふたつある。まず、私たちが調べてるのは個々の出来事じゃなくて一般法則だよね」\n\n\nお父さん「うん」\n\n\n私「でも、JCOG9502でステージと術式が独立だったのは、ランダム化したからでしょ。それって人工的じゃない？実地医療ではステージと術式は関連するもの。これでいいのかな。今回のDAGっていう矢印を使った図、普遍的じゃない気がする。コーヒーと膵がんのときは違和感なかったんだけど」\n\n\nお父さん「それはランダム化臨床試験が実験的環境を反映しているからかもね。実際、DAGが示している関係は、あくまで研究から得られたデータを反映するもので、どんな環境でも成り立つとは限らない」\n\n\n私「それにさ、いままでのDAGは3変数しかないけど単純すぎない？現実はもっと複雑だよね」\n\n\nお父さん「もちろんDAGの変数を増やすこともできるよ。そうすると、もっと統計学っぽい理屈になっちゃうけど」\n\n\n私「そうなんだ。でもごまかさず説明くらいしてよ」\n\n\nお父さん「じゃあ変数を5つに増やした例を使って、もう少し正式に解説してみようか。それにはちょっとコーヒーがほしいな」\n\n\n\n\n後ろ扉を閉ざすなんて映画みたい\n\n\n\n\n\n\nDAGの例\n\n\n\n因果関係の例として、ピロリ菌と胃がんを取り上げます。このふたつの変数には、抗生物質を飲んでピロリ菌を除菌することで、胃がん発生を予防できることが知られていますよね。言い換えると、ピロリ菌除菌は「原因」、胃がん発生は「結果」に対応します。\nしかし、胃がんに関連する変数は、これだけではありません。たとえば、若いうちは胃がんにはなりませんが、高齢になると胃がんリスクが高くなりますし、同じ年齢でも胃の炎症など様々な体質の違いが胃がんの発生に関連することがわかっています。これを踏まえて、以下の3つの仮定を置くことにします。この仮定は必ずしも正しいわけではなく、あくまで説明のための題材です。\n\n年齢が高くなるにつれ、胃がんリスクは高くなるが、その一部は胃の炎症の程度に反映される。胃の炎症がひどくなると、胃がんにかかりやすくなり、さらに医療機関に受診して、ピロリ菌を除菌してもらう確率が高くなる\n心配性な人もまたピロリ菌除菌を受けやすい。心配性な性格だと、胃の炎症も起こしやすい。ただし、性格はピロリ菌除菌と胃の炎症への影響を通してのみ、胃がんに関連する\n年齢、性格、体質、ピロリ菌以外に、胃がん発生に関連する重要な変数はない\n\n5つの変数をAからEまでの記号で表すと、上の3つの仮定は、以下のようなDAGで表現できます。\n\n\nA: 性格（心配性）\nB: 年齢\nC: 体質（胃の炎症）\nD: 胃がん発生\nE: ピロリ菌除菌\n\n\n\n\n\nお父さん「前回の話を思い出しながら、このDAGを考えてみてよ。交絡因子として調整しないといけない変数はどれだろう」\n\n\n私「ん？共通原因、中間媒介因子、合流点っていう3パターンがあったんだっけ。共通原因を見つければいいから、Cかな。いや、真に近いモデルを当てはめる、なんてことも言ってたよね。だからBとC。どうかな、あってる？」\n\n\nお父さん「結果論だけどあってる。実はね、このDAGはトリッキーで、Cを調整するだけじゃ、バイアスが残る例なんだ。まず、DAGのそもそもの意味は、directedつまり有向パスだけで構成された、acyclicな循環していないグラフっていうこと。つまりDAGでは、ノード間の結びつきがすべて矢印で表されて、しかも矢印がループ状にぐるぐるまわったりしない。そして、有向パスと共有原因を経由するバックドアパスの2種類に注目してほしい」\n\n\n私「ふむ」\n\n\nお父さん「有向パスっていうのは、A→B→C→Dのような矢印で連鎖しているノードの集合のこと。これはAからDの順に因果関係が伝わることを意味している」\n\n\n私「ふむふむ。バックドアパスってなに？」\n\n\nお父さん「あるノードに注目してみて。このノードに入る矢印を通じたパスのこと。矢印は出るか入るかしかないでしょ。バックドアパスは、原因に矢印が入る方向から回り込むような経路なんだ」\n\n\n私「ああ、バックドアっていうから後ろ扉かと思った。後ろ扉を閉じて地震を防ぐっていう映画があってね」\n\n\nお父さん「ふーん。とりあえず、有効パスでは矢印が出る、バックドアパスでは矢印が入る、ここをみてみよう」\n\n\n私「えっと、とりあえず胃がんのやつをみるね。このDAGには、EとDを結ぶパスは、両者を直接結び付ける有向パスが1つ、バックドアパスが4つある（E←A→C←B→D、E←A→C→D、E←C←B→D、E←C→D）」\n\n\nお父さん「そうでしょ。そして、バックドアパスは、必ず共通原因Cを経由している。これがDAGの特徴のひとつ。前回の説明を思い出してみて。共通原因は交絡因子として調整すべきっていったよね。DAGが複雑になると、バックドアパスが増えるけど、基本は同じ。すべてのバックドアパスをブロックできるような共通原因を探して、調整すればいいんだ。共通原因はDAG上のどこにあるかの話、交絡因子はブロックすべき変数の話ってこと」\n\n\n\n\n\n\n\n\nバックドア基準\n\n\n\nあるDAGが与えられたとき、どのノードを交絡因子として調整すればじゅうぶんなのかを判断するための基準のひとつがバックドア基準です。原因と考えているノードをE、結果と考えているノードをDとします。DAG上のノードの集合Sが以下の条件を満たすなら、Sを交絡因子として調整すればじゅうぶんです\n\nEからDへの合流点を含まないバックドアパスは、Sによりブロックできる\nEからDへのバックドアパス内に合流点あり、それがSに含まれるか、Sの子孫だとする。このときSは、そのバックドアパス内の非合流点を含まなければならない\n\n\n\n\n\nお父さん「厳密にいうと、バックドア基準っていう上のようなルールを使うんだけどね。合流点・ブロックについては、後で説明するよ。要は、共通原因を調整して、バックドアパスをブロックすれば、バイアスを防ぐことができる。疫学ではDAGは交絡因子を探すために用いられるんだ」\n\n\n私「やはり要石で後ろ扉を閉じるみたいな話だったか」\n\n\n\n\n\n\n\n\nDAGの用語\n\n\n\n次に、DAGで用いられる用語を整理しておきます（Greenland, Pearl, Robins 1999）。ここで説明する用語は、ノード、矢印、有向パス、バックドアパス（backdoor path）、祖先と子孫です。\nグラフ上の変数を表す点を、ノードといいます。上のグラフには5つのノードがありますよね。2つのノードは、線や矢印で結ばれます。A→Bという矢印で結ぶと、それはAからBへの方向性があることを意味します。因果推論の文脈では、原因から結果への直接的な結びつきを表しています。このグラフでは、AとCは隣接しているが、AはBやDとは結ばれていません。これは、AのCへの直接的影響があるという意味です。直接的影響があるとは、もっというと、グラフ上の他の変数に媒介されない影響がある、ということです。\n胃がんの例では、性格は、ピロリ菌除菌と体質を通じて胃がん発生をもたらすと仮定しました。この仮定は、AからBやDへの矢印がないことに対応しています。\n矢印で結びついたグラフは、必ず、矢印の頭から入り、頭から出るような一続きの矢印で辿ることができます。直接的または間接的にノードを結びつける矢印の組み合わせのことを、パスといいます。特に、矢印の方向に従って辿ることのできるパスを、方向性のあるパスという意味で有向パスと呼んでいます。上のグラフでは、A→C→Dのパスは有向パスです。\n次にE←C→Dについて考えてみましょう。こちらは有向パスではありません。有向パス以外のものを無向パスといいます。\n無向パスのうち重要なのは、あるノードから矢印をさかのぼって出て、別のノードに入るパスです。これをバックドアパスといいます。このグラフでは、EからDへのパスは、直接のパス以外はすべてバックドアパスです。\nそして、あるノードを出て別のノードに入っていく有向パスがあるとき、前者を祖先、後者を子孫といいます。文献によっては、祖先を原因、子孫を結果と呼んでいることもあります。このグラフでいえば、A、B、Cは、すべてEとDの祖先です。逆に、EとDは、A、B、Cの子孫です。そしてEはDの祖先であり、DはEの子孫です。\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n下のDAGにおいて、破線で示したパスA-C-Bに注目してください。このパスにおいて、Cは次のうちどれでしょうか。\n\n中間媒介因子\n共通原因\n合流点\n1、2、3のどれでもない\n\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です。\n\nここで注目してほしいのは、Cは共通原因でもあり、合流点でもある、という点です。このようなとき、機械的にCだけを調整すればいいと、判断することはできません。バックドア基準を使うべきです。\n詳しくは次回述べますが、もし理由を説明するなら、以下のようになります。パスE←A→C←B→Dに注目してください。このパスは合流点Cを含むため、なにも調整しなくてもブロックされています。つまり、これだけをみると、Cは調整しなくてもよいのです。\nその一方で、パスE←A→C→Dについて考えると、AもCも合流点ではありません。つまりこのパスは、なにも調整しないとブロックされていないのです。つまり、このDAG全体でみると、EとDには相関が生じています。さらに、E→Dという因果関係はないことから、この相関は疑似相関です。したがって、なにも調整しなくていい、という判断も間違いです。\n\n\n\n\n\n文献\n\nGreenland S, Pearl J, Robins JM. Causal diagrams for epidemiologic research. Epidemiology 1999;10(1):37-48\n\n\n\n次のエピソード\n\nDAGs and Conditional Distributions: Two Languages for the Same Structure\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nThree-Variable DAGs: The Smallest Building Blocks of Causal Structure\nA Subtle Distinction between Common Causes and Confounders\nDAGs and Conditional Distributions: Two Languages for the Same Structure\nA Circle, an Equation, and a Cylinder\nBackdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias\nVolatility, Uncertainty, Complexity, and Ambiguity in Causal Inference\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\nEffects and Time I\nAdjusting for Bias I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "index.html#r-package-cifmodeling",
    "href": "index.html#r-package-cifmodeling",
    "title": "Coffee and research are best when they’re hot.",
    "section": "R package cifmodeling",
    "text": "R package cifmodeling\nA toolkit for survival and competing risks analysis in R — a more technical side of my work.\n\nKaplan-Meier and Aalen-Johansen estimation and visualization\n\nDirect polytomous regression of cumulative incidence functions\nIntegration with ggsurvfit, modelsummary, and modern R workflows\n\nVisit the R package cifmodeling site"
  },
  {
    "objectID": "index.html#a-conversation-on-causality-at-our-table-how-i-learned-research-from-my-father",
    "href": "index.html#a-conversation-on-causality-at-our-table-how-i-learned-research-from-my-father",
    "title": "Coffee and research are best when they’re hot.",
    "section": "A Conversation on Causality at Our Table — How I Learned Research from My Father",
    "text": "A Conversation on Causality at Our Table — How I Learned Research from My Father\nA series of short, warm stories about learning research, written in both English and Japanese. Through conversations between a father and daughter, the way researchers think unfolds naturally — from questions and assumptions to numbers and conclusions. All of it is shared freely, like something warm to drink in a hallway conversation at a conference, there whenever you need a quiet break.\n\nFor readers who want to grasp the feel of research before opening a textbook\nLight, conversational chapters — each readable on its own, yet forming a larger story when read together\nFrom Study Design → Frequentist Thinking → Understanding Effects and Time → Adjusting for Bias → Causal Inference → Publication\n\nRead in English / Read in Japanese"
  },
  {
    "objectID": "index.html#eight-elements-of-causal-inference-preserved-in-japanese",
    "href": "index.html#eight-elements-of-causal-inference-preserved-in-japanese",
    "title": "Coffee and research are best when they’re hot.",
    "section": "Eight Elements of Causal Inference Preserved in Japanese",
    "text": "Eight Elements of Causal Inference Preserved in Japanese\nThis is a short essay on Japanese language and kanji characters.\nRead in English / Read in Japanese"
  },
  {
    "objectID": "index.html#books-and-learning-materials",
    "href": "index.html#books-and-learning-materials",
    "title": "Coffee and research are best when they’re hot.",
    "section": "Books and learning materials",
    "text": "Books and learning materials\n\nCausal Inference for Medical Research I. Generalized Linear Models (in Japanese)\nPublisher site\nCausal Inference for Medical Research II. Rubin Causal Models (in Japanese)\nPublisher site\nLearning materials for this series\nProfessor Giant Salamander’s Biostatistics Seminar: Paper Reading Level Up 30 (in Japanese)\nPublisher site\nLearning materials for this book\nSample Sizes for Clinical, Laboratory and Epidemiology Studies (Japanese translation)\nPublisher site\nLearning materials for this book"
  },
  {
    "objectID": "index.html#about-the-authorgestimation",
    "href": "index.html#about-the-authorgestimation",
    "title": "Coffee and research are best when they’re hot.",
    "section": "About the author—gestimation",
    "text": "About the author—gestimation\n\nAlongside developing methods and tools, he is interested in how statistical ideas are understood, interpreted, and used in practice — especially where methods, assumptions, and human judgment meet. This site collects some of his research, teaching materials, and essays, shared freely for anyone who finds them useful.\nMore information"
  },
  {
    "objectID": "en/study-design-5.html",
    "href": "en/study-design-5.html",
    "title": "When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys",
    "section": "",
    "text": "Study Design 5 − When Bias Creeps In\n\nKeywords: bias, language & writing, observational study, study design\n\n\n\nBiases to watch for in surveys\n\n\nMe: “I’m back—so tired. Dad, do we have anything sweet left?”\n\n\nDad: “There’s some strawberry daifuku. I just made coffee too.”\n\n\nMe: “That’s a lifesaver. Getting off work at this hour means rush-hour trains, and today was brutal from start to finish.”\n\n\nDad: “Sounds rough. Here you go—coffee’s ready.”\n\n\nMe: “Thanks. Hey—people keep talking about hard endpoints and soft endpoints, right?”\n\n\nDad: “They do.”\n\n\nMe: “There’s a senior doctor who’s very keen on doing clinical trials. They say things like, ‘Return-to-work is a soft endpoint, so it’s no good. Overall survival is a hard endpoint, so that’s better.’ It feels like my survey is being dismissed, but I don’t really understand what they mean.”\n\n\nDad: “It’s true that cancer trials often use overall survival as an endpoint, but judging everything by that standard alone is a bit simple. Also, people often use ‘hard’ and ‘soft’ casually, but if we’re being precise, it’s closer to objective versus subjective.”\n\n\nMe: “Objective? Subjective?”\n\n\nDad: “A common example is this: OS is hard, PFS is soft. OS depends only on the date of death and the last confirmation of survival—that’s why people call it relatively objective. PFS, on the other hand, includes disease progression as an event, so you need information about when progression occurred. Clinically, that judgment can sometimes be subjective—based on symptoms, tumor markers, or imaging interpretation. Because those judgments can vary, some people call PFS a ‘soft’ endpoint.”\n\n\nMe: “I see. So when people say hard and soft, they really mean objective and subjective. Then my questionnaire really is a soft endpoint—it’s asking about patients’ own experiences.”\n\n\nDad: “Maybe. But what your senior probably meant is that, when studying return to work, you should remove ambiguity as much as possible and measure things objectively. If patients can report their actual return-to-work date accurately, that’s already fairly objective.”\n\n\nMe: “So can I think of it like this? Hard endpoints have no bias, and soft endpoints do?”\n\n\nDad: “Not quite. Subjectivity can make bias more likely, but it’s not that simple. If follow-up is sloppy, even death can be misclassified, and mortality can be underestimated. Mind if I have a cigarette?”\n\n\nMe: “Go ahead. Tracking deaths really is hard, isn’t it?”\n\n\nDad: “Right. To be precise, you don’t need 100% complete information all the way to death. That only works, however, when the collection of death information itself is unbiased. If whether death information is obtained depends on the patient’s health condition, that becomes a source of bias. This is because censoring in survival data is no longer random. Remember the Kaplan-Meier and Aalen-Johansen curves I showed you earlier? Those curves can be drawn even with censoring. But for them to be unbiased and valid, censoring must occur independently of disease status or prognosis. For example, everyone being censored at one year by design, or follow-up stopping for external reasons. In the end, once information becomes systematically distorted, bias arises—regardless of whether the endpoint is hard or soft.”\n\n\n\n\n\n\n\n\nRandom error and bias\n\n\n\nStatistics deals with uncertainty, but in clinical research it is crucial to distinguish random error from bias. Random error refers to variability around the true value, typically assumed to be centered around zero. Bias, in contrast, means that an estimate is systematically shifted away from the truth. The goal of statistics in clinical research is to control random error and reduce bias as much as possible.\nAn analogy: random error is like scatter when you aim at the center of a target; bias is when the aim itself is off-center. The bias that arises when Kaplan–Meier curves are misused under competing risks is not random error. Random error can be reduced by increasing sample size, but bias cannot be fixed without improving study design and data collection.\n\n\n\n\n\nMajor categories of bias\n\n\nMe: “I get that biased data lead to bias. But sometimes you just can’t collect everything—like death information. You do your best. Are there other biases I should watch out for in my survey?”\n\n\nDad: “You’re mailing questionnaires, right? Low response rates can easily introduce bias, so you should think about ways to encourage responses. For example—are you asking about income?”\n\n\nMe: “I might.”\n\n\nDad: “Sensitive questions need special care. If people avoid responding because of them, your analytic sample may no longer represent the target population.”\n\n\nMe: “Anything else?”\n\n\nDad: “It’s also possible that patients with a stoma are more likely to respond than those without one. If response rates differ between groups, comparisons can be criticized as biased.”\n\n\nMe: “Is that confounding?”\n\n\nDad: “Where did you hear that word? Good question—but this is a bit different. Differences in response rates affect which patients are sampled from the population. That’s called selection bias. And if the information itself is distorted—like people overstating their income—that’s information bias. In teaching study design, we often group bias into three categories:\n\n\nSelection bias\nInformation bias\nConfounding\n\n\nDad: “Thinking in these three categories at the design stage helps you plan countermeasures early: avoid selective inclusion, collect information carefully, and make groups comparable except for the factor of interest.”\n\n\nMe: “Selection bias, information bias… Clinical research really does have its own language.”\n\n\n\n\nUp to this point, we have been talking about the essence of research — how we frame research questions and plan to obtain unbiased answers. The following episodes step away from study design and begin to reflect on observed effects and their uncertainty, how we reason about causes, and what ultimately becomes publishable.\n\n[Reading a Paper over a Cup of Coffee] (comming soon)\n[P-Value Explanations That Seem Plausible at First Glance]\n[Beyond 0.05: Interpreting P-Values in a Clinical Trial]\n[Understanding Confidence Intervals via Hypothetical Replications in R]\n[Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size]\n\n\n\nPast episodes\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\nStatistical Terms in Plain Language\nstudy-design.R"
  },
  {
    "objectID": "en/study-design-3.html",
    "href": "en/study-design-3.html",
    "title": "Outcomes: The Bridge from Data Collection to Analysis",
    "section": "",
    "text": "Study Design III − Outcomes: The Bridge from Data Collection to Analysis\n\nKeywords: clinical trial, language & writing, research hypothesis, survival & competing risks\n\n\n\nWhat do we mean by “outcome”?\n\n\nMe: “About that outcome thing we talked about earlier. In our department we read clinical trial papers, and they’re full of abbreviations like DFS and RFS. Those are outcomes too, right? To be honest I don’t really understand them, but everyone uses them as if they were obvious, so it’s hard to ask now. DFS and RFS both seem to be about cancer recurrence. Do you know the difference?”\n\n\nDad: “Of course. We often deal with DFS in statistical analyses. The one you probably see most is overall survival (OS). DFS stands for disease-free survival, and RFS stands for relapse-free survival.”\n\n\nMe: “So relapse-free survival is just the number of days until recurrence?”\n\n\nDad: “If we were literally measuring ‘time to recurrence’, I’d probably call that relapse-free time. When we focus on recurrence, we often talk about the cumulative incidence of relapse, or CIR for short.”\n\n\nMe: “That just made it worse. Aren’t all of these basically the same?”\n\n\nDad: “In survival analysis, the differences are subtle but important. Think about this: a patient can die without ever having a recurrence. For DFS, the key idea is that we measure the time from the time origin to the first of three events: recurrence, second primary cancer, or death. So not only recurrence, but also death and second cancers are treated as events.”\n\n\nMe: “What exactly do you mean by ‘treated as events’?”\n\n\nDad: “In general, survival time data represent the time until a specified event. To put it simply: suppose you compute the ‘3-year DFS probability’ from DFS data. That corresponds to the probability that no event has occurred by 3 years. In other words, the probability that at 3 years the patient is alive, with no recurrence and no second cancer.”\n\n\nMe: “Okay, that I can follow.”\n\n\nDad: “For RFS, the event is usually defined as recurrence or death. Second cancers are not included. If we were being strict about relapse-free time, then recurrence alone would be the event. Seeing it as a figure would probably make the picture clearer.”\n\n\n\nMe: “Mm-hmm. Personally, I feel like DFS is the most important. You’d like to avoid both recurrence and second cancers. Relapse-free time doesn’t feel that meaningful to analyze. And death is the most important event, isn’t it? Why would you leave it out?”\n\n\nDad: “You’re right that death is critical. But remember, once a patient has a recurrence and then dies afterwards, they’re already counted as an event for relapse-free survival, even if the death is recorded later.”\n\n\nMe: “That’s true. If I think about it, deaths that occur before recurrence are often due to things like infections or traffic accidents. Such causes may not be clearly related to the cancer treatment or the cancer itself.”\n\n\nDad: “Exactly. In clinical trials, outcomes are often called endpoints. Different trials have different research hypotheses, and endpoints are chosen accordingly. For advanced cancer, we might focus on tumor progression and use progression-free survival. For post-operative adjuvant chemotherapy after curative surgery, we might use relapse-free survival. Let me show you a table summarizing the main survival endpoints in oncology trials (Japan Clinical Oncology Group, 2021).”\n\n\n\n\n\n\n\n\n\n\nEndpoint\nWhat counts as an event?\ncensoring date\n\n\n\n\nOverall survival (OS)\nDeath from any cause\nLast survival confirmation date\n\n\nProgression-free survival (PFS)\nProgression or death\nLast progression-free confirmation date\n\n\nRelapse-free survival (RFS)\nRelapse or death\nLast survival confirmation date\n\n\nRelapse-free time\nRelapse\nLast survival confirmation date\n\n\nCumulative incidence of relapse (CIR)\nRelapse only, with death as a competing risk\nLast survival confirmation date\n\n\nDisease-free survival (DFS)\nRelapse, second cancer, or death\nLast survival confirmation date\n\n\nEvent-free survival (EFS)\nDeath, induction failure, relapse, second cancer (depends on trial)\nLast survival confirmation date\n\n\nTreatment success time\nDeath, treatment failure, progression/relapse (depends on trial)\nLast treatment-continuation/progression-free confirmation date\n\n\n\n\n\nMe: “Nice. This is really helpful.”\n\n\nDad: “This table is used when clinical trial groups write their protocols. Protocols are written by a team of clinicians and statisticians. If they don’t define things clearly in advance, everything gets confusing later on. Their motto is ‘one word, one meaning’.”\n\n\nMe: “Yeah, I can relate. I’m already halfway tangled up.”\n\n\nDad: “For OS, the outcome is the time from the time origin of the analysis until death. For DFS, it’s the time from the time origin until whichever happens first: recurrence, second primary cancer, or death. As I mentioned, people also say ‘3-year OS’ or ‘3-year DFS’. In that case we’re not talking about a time, but about the probability at 3 years. Because DFS includes recurrence and second cancers in addition to death, the 3-year DFS probability is necessarily smaller than the 3-year OS probability.”\n\n\nMe: “Time origin… I’ve never heard that expression before. Can you explain that a bit more?”\n\n\nDad: “Sure. Let’s go over a few typical ways of choosing the time origin. DFS is usually used to evaluate what happens after curative surgery, right? So the date of surgery is a natural candidate for the time origin. When the starting point of treatment is clear, like the day of surgery, the choice is relatively easy.”\n\n\nMe: “Yeah, that’s what I see a lot in papers.”\n\n\nDad: “Exactly. On the other hand, if you used the date of discharge as the time origin, then deaths occurring shortly after surgery but before discharge would not be included in the evaluation. Depending on the study, that could easily become a point of criticism. Another common choice is the date of trial registration. In randomized controlled trials, treatment is assigned at registration, so it’s natural to use the registration date as the time origin when drawing survival curves.”\n\n\nMe: “That makes sense. The exact definitions really do differ a bit from study to study. Actually, I’m in the middle of designing a questionnaire right now. When I told people that you’re ‘picky about outcomes’, it turned out everyone around me was paying more attention to these distinctions than I’d expected. I wanted to properly understand DFS and OS. I’m glad I asked ? I’ll come back for more advice.”\n\n\n\n\n\n\n\n\nClinical endpoints and surrogate endpoints\n\n\n\n\n\nOS, DFS, and RFS are outcomes or endpoints that are frequently used when evaluating the effectiveness of post-operative adjuvant chemotherapy. How are these endpoints chosen and used? One guiding principle comes from how regulatory agencies evaluate anticancer drugs. For example, the Japanese guideline on clinical evaluation of anticancer drugs states that, in order for an anticancer drug to be approved, its efficacy must be demonstrated reliably, typically through evidence such as prolongation of survival. In this framework, overall survival (OS) is treated as a clinical endpoint and given particular weight (Biomarkers Definitions Working Group, 2001).\nAt the same time, in adjuvant chemotherapy trials, endpoints such as DFS are sometimes adopted as surrogate endpoints. A surrogate endpoint is defined as a measure intended to substitute for a clinical endpoint and expected to predict clinical benefit or harm. The main advantage of using surrogate endpoints like DFS is that trials can be completed in a shorter period of time.\nHowever, past regulatory experience has shown that reliance on surrogate endpoints can lead to misleading evaluations of drugs (Fleming and DeMets, 1996). For example, in advanced colorectal cancer, the combination of 5-FU and leucovorin produced promising tumor shrinkage in clinical trials. Yet when the clinical endpoint OS was evaluated, it became clear that the regimen had little or no effect on survival (Fleming and DeMets, 1996).\n\n\n\n\n\n\n\n\n\nA quiz related to this episode\n\n\n\nThis quiz focuses on how we define progression and events when using progression-free survival (PFS) as an endpoint in clinical trials. To measure PFS, we need to determine tumor progression based on imaging. Sometimes a central review committee evaluates images to make this more objective. In that case, there may be discrepancies between:\n\nthe progression date according to the central review, and\n\nthe progression date according to the local investigator.\n\nThis issue is called a disagreement between central and local assessment. Which of the following is not appropriate as a way to handle this in a clinical trial?\n\nIn the primary analysis, use the results of the central review, which is considered more objective.\n\nIn the primary analysis, define progression as whichever date comes first: central or local.\n\nHold a case review meeting and decide how to handle discrepant cases based on medical judgment.\n\nPerform two analyses: one using central assessment, and one using local assessment.\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 2.\n\nIf you define the event as “whichever progression date comes first (central or local)”, you are more likely to shorten PFS artificially, because you systematically choose the earlier of the two dates. That introduces bias.\nThis doesn’t mean you must always use central review; in some contexts, local assessment may better reflect real clinical decision-making. But “always take the earlier date” is not an appropriate general rule.\n\n\n\n\n\nReference\n\nBiomarkers Definitions Working Group. Biomarkers and surrogate endpoints: preferred definitions and conceptual framework. Clin Pharmacol Ther 2001;69(3):89-95\nFleming TR and DeMets DL. Surrogate end points in clinical trials: are we being misled? Ann Intern Med 1996;125(7):605-13\nJCOG protocol manual version 3.8 [Internet]. Tokyo: Japan Clinical Oncology Group; 2025\n\n\n\nEpisodes, glossary, and R-script\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\nStatistical Terms in Plain Language\nstudy-design.R"
  },
  {
    "objectID": "en/study-design-1.html",
    "href": "en/study-design-1.html",
    "title": "A Story of Coffee Chat and Research Hypothesis",
    "section": "",
    "text": "Study Design I − A Story of Coffee Chat and Research Hypothesis\n\nKeywords: language & writing, observational study, research hypothesis, study design\n\n\n\nA daughter’s first study\n\n\nMe: “Dad…you really are a professor of statistics, right?”\n\n\nDad: “In Japan, yes—one of many.”\n\n\nMe: “My boss keeps telling me it’s time I do ‘some research’ and present at a conference. He’s really into supporting cancer patients in return-to-work since the Basic Plan to Promote Cancer Control Programs was revised in 2016. Long story short, I think he wants me to run a survey. I’m not against it, but this feels more like your world than mine. Statistics and all that.”\n\n\nDad: “Half my domain, half yours. You see the patients, I only see the data. Do you have anything clinical you want to know? Any hypothesis?”\n\n\nMe: “Nope. Not really.”\n\n\nDad: “Without at least a working hypothesis, it becomes hard to design a good study.”\n\n\nMe: “Seriously? I thought I could just collect the data first and improvise the rest. Guess not. Hmm…if I had to say, I’d want to know what kind of patients have difficulty returning to work.”\n\n\nDad: “For example, that men might have a higher return-to-work proportion than women?”\n\n\nMe: “I’m interested in sex differences too, but I’m more curious about cancer stage or complications. I work in gastrointestinal surgery, and I wonder whether patients with stomas can return to the same job they had before surgery. Yeah…I’ll start drafting a questionnaire. Thanks!”\n\n\nDad: “Hold on a moment. Before you get too excited—have you decided on your study population yet?”\n\n\nMe: “Hm? Patients who had cancer surgery at our hospital.”\n\n\nDad: “Do gastric cancer patients ever end up with a stoma…?”\n\n\nMe: “It’s extremely rare in gastric cancer, practically negligible.”\n\n\nDad: “Right. If your main interest is stomas, it might make sense to focus on cancers where stomas are common, like rectal cancer.”\n\n\nMe: “…yeah, okay. I guess that’s true when you put it that way.”\n\n\nDad: “It’s important to think about who should be surveyed at the design stage. In general, narrowing the target population allows you to ask more detailed questions. And it also improves comparability between groups. If you want to compare patients with and without stomas, you’d want the cancer type to be consistent.”\n\n\nMe: “There you go again with the technical terms. But fine—I do get the point. If patients’ backgrounds vary too much, it becomes hard to compare them. Keeping them similar makes things easier.”\n\n\nDad: “There are statistical methods and R packages to improve comparability too, like glm() for regression adjustment, or CBPS() for propensity score weighting. But on the other hand, a broader study population increases generalizability. If you want to estimate the return-to-work proportion among cancer survivors, you don’t necessarily need to limit the cancer type. Ideally, you’d collect data from multiple institutions.”\n\n\nMe: “True…it feels strange to call it ‘a survey of cancer survivors’ if it’s only our hospital. Generalizability means the results should hold beyond our hospital, right?”\n\n\nDad: “In class, I usually tell my students something like this:”\n\n\nWhen your clinical question is still vague,\ntry to express it using PICO or PECO before you design the study.\n\n\nDad: “It sounds fancy, but we simply call that ‘structuring’ a study.”\n\n\nMe: “Structuring…? That sounds like something from a meeting. Okay, I’ve heard the word before.”\n\n\nDad: “Then let’s go through it lightly. In PICO/PECO, P stands for Patients or Population. Deciding who your patients are is a key element in study design.”\n\n\n\nWhich patients or population are being studied (P)\nWhat exposure or intervention is of interest (E/I)\nWhat they are compared against (C)\nWhat outcomes will be evaluated (O)\n\n\n\nMe: “I’ve never heard of Exposure or Comparison before…But in my case, it would be patients with versus without a stoma, right? And what’s Outcome?”\n\n\nDad: “Exactly. And O is treatment results, prognosis, and endpoints of patients. In statistical analysis, the outcome variable is the most important part. So it’s crucial to define it before you begin.”\n\n\nMe: “Can you even define it before the data comes in?”\n\n\nDad: “You should, because once the data is collected, you can’t revise it any more. It needs to be decided before finalizing the questionnaire. Right…you probably don’t have a clear picture of your outcome yet. But the outcome determines which data you’ll collect and which statistical methods you’ll use. By the way, which software are you planning to use once the data is ready?”\n\n\nMe: “R. My seniors in the department use it.”\n\n\nDad: “Are you comfortable with R?”\n\n\nMe: “I took a class in college, but I’ve forgotten most of it.”\n\n\nDad: “Then you’ll need to brush up on it. And which R functions you use depends entirely on your outcome.”\n\n\n\n\n\n\n\n\nClinical questions and research hypotheses\n\n\n\nIn clinical practice, many questions naturally arise. A question emerging directly from clinical experience is called a clinical question.\nWhen starting a clinical study, what matters is expressing that clinical question as a research hypothesis. A research hypothesis consists of minimal essential elements, often summarized using PICO/PECO:\n\nP: Patients/Population\nI/E: Intervention/Exposure\nC: Comparison\nO: Outcome\n\nThe I (Intervention) or E (Exposure) differs depending on whether your study is an interventional trial or an observational study such as a cohort, case-control, or cross-sectional study. All can be structured using PECO.\nHere are three examples of research hypotheses using the cancer survivor survey as a theme.\n\n\n\n\n\n\n\n\nResearch hypothesis 1\n\n\n\n\n\nAmong rectal cancer patients after curative resection in Japan, is there a difference in return-to-work within 1 year between those with and without a stoma?\n\nP: Rectal cancer patients after curative resection\n\nE: Stoma present\n\nC: Stoma absent\n\nO: Returned to work within 1 year after surgery (yes/no)\n\nHere you’d compare the return-to-work proportion between the stoma and non-stoma groups.\nWhat to choose for C (Comparison) is important. If you only know the return-to-work proportion in the stoma group, it’s hard to say whether that number is “high” or “low”.\nHaving a clear comparison group improves interpretability.\n\n\n\n\n\n\n\n\n\nResearch hypothesis 2\n\n\n\n\n\nAmong cancer patients after curative surgery, does providing a guidebook on balancing work and cancer treatment increase the proportion who return to work within 1 year?\n\nP: Patients with cancer after curative surgery\n\nE: Received the guidebook\n\nC: Did not receive the guidebook\n\nO: Returned to work within 1 year after surgery (yes/no)\n\nHere P is broader, so the results could potentially apply to a wider range of patients. This is an example of higher generalizability.\n\n\n\n\n\n\n\n\n\nResearch hypothesis 3 (exploratory)\n\n\n\n\n\n“Are sex, age, stage, adjuvant chemotherapy, performance status, comorbidities, stoma, preoperative employment status, household income, cancer insurance, and use of employment support services associated with return-to-work within 1 year?”\nIn exploratory studies like this, P is clear, but E and C are not just one thing — we’re screening multiple potential risk factors.\nSo “structuring the question” doesn’t mean you have to force every study into a clean PECO shape. What matters is to identify the minimal set of elements needed to design a coherent study for your question.\n\n\n\n\n\nMe: “I think I see. Coming up with an original hypothesis still feels intimidating, but breaking it down into pieces like this? I actually don’t mind that part. I suppose it’s something I’ll need to learn eventually.”\n\n\nDad: “Exactly. Plus, replacing your thinking with specialized terminology early on improves communication. Definitions of diseases and outcomes, detailed treatment regimens, and exposure specifics can vary subtly across clinicians and facilities. If the terminology is vague, confusion follows.”\n\n\n\n\n\n\n\n\nQuiz related to this episode\n\n\n\nWhen formulating study design, the Latin expression “ceteris paribus” often appears. Which of the following best describes its meaning?\n\nIf there is a causal relationship, it will inevitably occur\nA universally generalizable law\nAll other conditions being equal\nObserving a sufficiently large amount of data\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 3.\n\nThe concept of “ceteris paribus” is very close to the idea of comparability between groups.\n\n\n\n\n\nEpisodes and R-script\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\nstudy-design.R"
  },
  {
    "objectID": "en/index.html#how-to-read-this-site",
    "href": "en/index.html#how-to-read-this-site",
    "title": "A Conversation on Causality at Our Table (EN)",
    "section": "How to read this site",
    "text": "How to read this site\nNot sure where to begin? Start with Study Design.\nEach episode can be read on its own; from there, you can follow the story or choose whichever layer interests you—clinical trials and p-values, for example, or causal inference in research. When R scripts appear, they are there to make the ideas reproducible—and tangible. Read through the whole series and scattered meanings begin to connect—you’ll likely come away with a few new ways of seeing.\n\n\n\n\n\n\nR scripts for reproducing the episodes\n\n\n\n\n\nIf you came here from an R post, you may want the code first. These scripts are meant to reproduce the figures and ideas, not to teach programming.\n\nStudy Design series: study-design.R\nFrequentist Thinking / Experiments: frequentist.R\nEffects and Time: effects.R\nAdjusting for Bias: logistic-regression.R"
  },
  {
    "objectID": "en/index.html#episodes",
    "href": "en/index.html#episodes",
    "title": "A Conversation on Causality at Our Table (EN)",
    "section": "Episodes",
    "text": "Episodes\n\n1. Study Design — Where research begins\nEvery study starts with a question. How do we frame PICO/PECO? How do we choose outcomes? How do we protect against bias? The daughter asks her father about the very starting point of clinical research.\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\n\n\n\n\n\n\n\nA glimpse ahead\n\n\n\n\n\n\nA Story of Coffee Chat and Research Hypothesis Research often stumbles first not on data, but on how a question is framed.\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes Numbers may look the same, yet describe different worlds—this pause starts from outcome types and the probability models behind them.\nOutcomes: The Bridge from Data Collection to Analysis Once an outcome is defined, much of the study is already decided—pausing over that choice through familiar oncology examples.\nA First Step into Survival and Competing Risks Analysis with R Before analysis begins, trouble often begins with how events are defined and coded—thinking in terms of time and events.\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys Distortion rarely comes from formulas alone—this is where bias quietly enters.\n\n\n\n\n\n\n2. Glossary — The words of statistics\n\nStatistical Terms in Plain Language\n\n\n\n3. Frequentist Thinking — Practicing statistics\nUsing cancer clinical trials as an example, my father explains the frequentist perspective of “How do numbers behave under repeated sampling?”\n\nReading a Paper over a Cup of Coffee\nP-Value Explanations That Seem Plausible at First Glance\nBeyond 0.05: Interpreting P-Values in a Clinical Trial\n\n\n\n\n\n\n\nA glimpse ahead\n\n\n\n\n\n\nReading a Paper over a Cup of Coffee The unease felt while reading a paper often comes from language — pausing over statistical terms.\nP-Value Explanations That Seem Plausible at First Glance What would happen if the same study were repeated again and again — touching the idea of frequentist thinking.\nBeyond 0.05: Interpreting P-Values in a Clinical Trial A p-value is less a number than a shadow of design — watching where interpretation drifts.\n\n\n\n\n\n\n4. Frequentist Experiments — Validation of statistics\nThe laws derived from the frequentist theory are not mere abstractions; they can be verified through simulation experiments. Even if you are unfamiliar with R, simply run the script to reproduce the results.\n\n\n\n\n\n\nA glimpse ahead\n\n\n\n\n\n\nR Demonstration of Bias in Kaplan-Meier Under Competing Risks A curve that looks convincing may still describe another world — checked through simulation.\nUnderstanding Confidence Intervals via Hypothetical Replications in R Where does “95%” come from, and where does it go — lingering over confidence intervals.\nAlpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size Planning of sample size is also the planning of error of the study. Revisiting the foundations of frequentist design.\n\n\n\n\n\n\n5. Effects and Time — How effects evolve\nWe unravel risk differences, risk ratios, hazard ratios, vaccine effectiveness, attributable fractions, and effects that change over time alongside survival curves and cumulative incidence curves. A multidimensional perspective on data quietly develops, paving the way for causal inference.\n\n[Silent Confusions Hidden in Percentages]\n[Who Is This Percentage About? Target Populations and Attributable Fractions]\n[Understanding Collapsibility of Effect Measures: Marginal vs Stratified]\n[When Odds Ratios Approximate Risk Ratios—and When They Fail]\n[From Risk and Rate to Survival and Hazard]\n[Distinguishing Time-Point, Time-Constant, and Time-Varying Effects: An R Example]\n\n\n\n\n\n\n\nA glimpse ahead\n\n\n\n\n\n\nSilent Confusions Hidden in Percentages Percentages feel intuitive, yet they often mislead. Rethinking how effects are communicated.\nWho Is This Percentage About—Target Populations and Attributable Fractions Every number speaks about someone — reconsidering the assumed population.\nUnderstanding Collapsibility of Effect Measures: Marginal vs Stratified When adjustment changes results, the reason is structural — revisiting stratification.\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail Measures that look similar may behave differently — pausing over the odds ratio.\nFrom Risk and Rate to Survival and Hazard Once time enters the picture, effects change shape. An entry point to thinking about effects over time.\nDistinguishing Time-Point, Time-Constant, and Time-Varying Effects Are effects ever constant — considering time-varying perspectives.\n\n\n\n\n\n\n6. Adjusting for Bias — The landscape of regression modeling\nAn episode where she learns from her father — from interpreting logistic regression results and creating tables to avoid pitfalls in its use. And then…\n\n[From Risk to Logistic Regression]\n[Logit: How a Transformation Shapes an Effect]\n[Where My Logistic Regression Went Wrong]\n[Why Logistic Regression Fails in Small Samples]\n[Understanding Confounding in Effect Measures: Marginal vs Stratified]\n[Volatility, Uncertainty, Complexity, and Ambiguity in Causal Inference]\n\n\n\n\n\n\n\nA glimpse ahead\n\n\n\n\n\n\nFrom Risk to Logistic Regression Translating risk into equations inevitably hides something — an entry into regression.\nLogit: How a Transformation Shapes an Effect Why this transformation and not another? A secret behind the choice of logit.\nWhere My Logistic Regression Went Wrong When calculations are correct but conclusions feel wrong — pausing at interpretation.\nWhy Logistic Regression Fails in Small Samples A model that breaks may still be teaching something — about small samples.\nUnderstanding Confounding in Effect Measures: Marginal vs Stratified When overall and subgroup results disagree — revealing a structure of confounding.\nVolatility, Uncertainty, Complexity, and Ambiguity in Causal Inference What exactly is the purpose of the DAG tool? A daughter’s response to her father’s teachings.\n\n\n\n\n\n\n7. Truth — What defines it?\n\n[What Data Cannot Tell Us]\n[What Could Have Happened]\n[What Is It That You Want to Know?]\n\n\n\n8. Causal Inference — To find causality\nDirected acyclic graphs (DAGs), common causes, colliders, mediators, backdoor criteria. We try to talk about the language of causality needed to think about “what if?”, incorporating the minimal necessary mathematical expressions concerning probability.\n\n[Three-Variable DAGs: The Smallest Building Blocks of Causal Structure]\n[A Subtle Distinction between Common Causes and Confounders]\n[DAGs and Conditional Distributions: Two Languages for the Same Structure]\n[A Circle, an Equation, and a Cylinder]\n[Backdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias]\n\n\n\n\n\n\n\nA glimpse ahead\n\n\n\n\n\n\nThree-Variable DAGs: The Smallest Building Blocks of Causal Structure The smallest diagrams that let us speak about causality.\nA Subtle Distinction between Common Causes and Confounders Similar words, different roles—tracing the boundary between common causes and confounding.\nDAGs and Conditional Distributions: Two Languages for the Same Structure Diagrams and equations tell the same story in different languages.\nA Circle, an Equation, and a Cylinder Where causal frameworks overlap and where they diverge — placing causal models side by side.\nBackdoor Paths, Block, and d-Separation What it really means to “adjust” — Understanding blocking as an operation.\n\n\n\n\n\n\n9. Publish a Paper — Beyond the research\nHow to communicate research findings, creating charts and graphs, tips for revising, navigating peer review. A quiet lecture for researchers, exploring what lies beyond statistics.\n\n[A Subtle Distinction Between Editors and Reviewers]\n[Three Tips for Writing a Paper]\n[Communicating with Care]\n[A Morning Just Before Submission]\n\n\nThis site shares selected R-related posts via R-bloggers"
  },
  {
    "objectID": "en/frequentist-3.html",
    "href": "en/frequentist-3.html",
    "title": "Beyond 0.05: Interpreting P-Values in a Clinical Trial",
    "section": "",
    "text": "Frequentist Thinking III − Beyond 0.05: Interpreting P-Values in a Clinical Trial\n\nKeywords: clinical trial, p-value, research hypothesis, survival & competing risks\n\n\n\nA way of thinking for interpreting p-values correctly\n\n\nDaughter: “I’m home, Dad. It’s about time we got the down jackets out. Oh, can I have a cup of hot coffee?”\n\n\nDad: “I figured you’d be back soon, so I made plenty. Hey, remember when we talked about survival curves and p-values in the JCOG9502 paper (Sasako et al. 2006)? Something stuck with me. Why do people say, ‘if the p-value is less than 0.05, it’s statistically significant’?”\n\n\nDaughter: “Isn’t that just the rule?”\n\n\nDad: “That’s a common way to read papers—and it’s the wrong one here. Let me ask you: when you read a paper, you start with the Abstract. Then what do you read next?”\n\n\nDaughter: “The Results. I want to know what happened as quickly as possible.”\n\n\nDad: “I understand. But when it comes to p-values, if you want a correct interpretation, you need to read the Methods first. People have worried for a long time that p-values are widely misunderstood in the scientific community. The American Statistical Association (ASA) even issued a statement aimed at researchers who aren’t statisticians, as well as practitioners and science writers. One trigger was a forum post like this, submitted to the ASA in February 2014.”\n\n\nDaughter: “What is this—a Zen koan?”\n\nQ. Why do so many colleges and grad schools teach p ≤ 0.05?\nA. Because that’s what the scientific community and journal editors use\nQ. Why do so many people still use p ≤ 0.05?\nA. Because that’s what they were taught in college or grad school\n\nDad: “And the ASA summarized six principles for using and interpreting p-values.”\n\n\n\nP-values can indicate how incompatible the data are with a specified statistical model.\n\nP-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.\nScientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.\n\nProper inference requires full reporting and transparency.\n\nA p-value, or statistical significance, does not measure the size of an effect or the importance of a result.\n\nBy itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.\n\n\n\nDaughter: “So that little back-and-forth set off a wave of p-value criticism. But honestly, all six still feel abstract to me.”\n\n\nDad: “Really? ‘Scientific conclusions shouldn’t be based only on whether a p-value crosses a threshold’ is pretty explicit. In JCOG9502, for example, principles 3 and 5 are basically telling you: don’t look only at the p-value—look carefully at the survival curves before you conclude anything. Still, without some background, it’s hard to see what the principles are trying to protect you from. Principle 4, for instance, is closely tied to the problem of multiplicity.”\n\n\nDaughter: “Multiplicity?”\n\n\nDad: “In many modern trials, multiplicity is quietly built in. Let’s use JCOG9502 to make it concrete. Go back to the Statistical Analysis section. The phrase alpha error—also called the significance level—refers to the threshold you compare the p-value against.”\n\n\nAfter 8 years of slow accrual, the JCOG data and safety monitoring committee approved an amendment to the sample size and analysis plan. The amended sample size was 250, with one-sided alpha error of 0.1 and beta error of 0.2, with a 12-year accrual period (in total) and 8-year follow-up. (Sasako, et al. 2006)\n\n\nDaughter: “So they compare the p-value to 0.1? Not 0.05?”\n\n\nDad: “Right. In an ideal world, alpha is the textbook 0.05. And you’re not supposed to change alpha mid-trial. That’s standard practice. But when accrual stalls, sometimes the trial has to be adjusted to stay interpretable. That seems to be what happened here: they loosened alpha to 0.1 as a last resort.”\n\n\nDaughter: “I skipped right past that.”\n\n\nDad: “Now, with Principle 4 and its explanation in mind, look at Figure A and Figure B in JCOG9502. Two survival curves, and four p-values, right? Do you know how to read multiple p-values like this?”\n\n\n\nDaughter: “That’s exactly why I asked you in the first place. Of course I thought about the p-values in Figure A and Figure B. You’re supposed to focus on Figure A: the primary endpoint in JCOG9502 is OS, and Figure A is overall survival. But even in Figure A, there are both one-sided and two-sided p-values. That part made no sense—I got stuck.”\n\n\nDad: “That part isn’t too hard. Imagine you’re comparing an experimental treatment with a standard treatment in a clinical trial. A one-sided p-value is used when you will call the result ‘significant’ only if the experimental arm wins. A two-sided p-value is used when you judge statistical significance regardless of which arm appears better.”\n\n\nDaughter: “Reading the paper, the protocol treated LTA as the experimental treatment and TH as the standard. Maybe because LTA is more invasive. So they’d only declare significance if the LTA group had better outcomes. Is that normal?”\n\n\nDad: “Not really. Two-sided p-values are the usual standard. But in many JCOG trials, the scientific question is specifically whether the experimental arm improves outcomes over standard care—and they often compare treatments that differ in toxicity or invasiveness. In that context, a one-sided hypothesis can feel more ‘natural,’ and JCOG allows one-sided p-values for that reason (Japan Clinical Oncology Group 2025). The idea is: if it isn’t significant on the one-sided test, you keep using the standard treatment—so that’s acceptable. In this paper, the two-sided p-values are more like a reference. In practice, the primary judgment of efficacy hinges on the one-sided p-value in Figure A.”\n\n\nDaughter: “Then for my observational study—stoma vs no stoma and return to work—given what the hypothesis means, two-sided p-values are what you’d recommend. That makes sense. Got it.”\n\n\n\n\n\n\n\n\nThe ASA Statement on Statistical Significance and P-Values\n\n\n\n\n\nP-values appear in nearly every scientific field, but concerns have been raised that they are misused and that they can distort how findings are interpreted. A familiar pattern is that once a small p-value is obtained, the result is treated as ‘important’ by default, or decisions are made mechanically just because p &lt; 0.05. You have likely seen examples of this yourself.\nIn 2016, the American Statistical Association (ASA) summarized six principles to improve the practice and interpretation of quantitative research (Wasserstein and Lazar 2016). For convenience, the six principles are reproduced here.\n\nP-values can indicate how incompatible the data are with a specified statistical model.\n\nP-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.\nScientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.\n\nProper inference requires full reporting and transparency.\n\nA p-value, or statistical significance, does not measure the size of an effect or the importance of a result.\n\nBy itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.\n\nTextbooks often explain p-values mainly through the relationship between the p-value and the null hypothesis. But to interpret a p-value, the null hypothesis is not the only thing that matters. The spirit of the ASA statement is this: unless you use the full context—study design, data collection, analysis choices, and reporting—you cannot interpret p-values properly.\nFocus on Principle 4. In its discussion, the ASA warns that if multiple analyses are performed and only selected p-values are reported, then the reported p-values become fundamentally uninterpretable. Put plainly: when there are many p-values available, it becomes tempting—consciously or not—to choose the convenient ones. This kind of “best-picking” has become widespread in science and is suspected to contribute to an excess of false positives in the literature. In statistics, this cluster of concerns is discussed under terms such as multiplicity or selective inference.\n\n\n\n\n\n\n\n\n\nOne-sided and two-sided p-values\n\n\n\n\n\nP-values and hypothesis tests are statistical procedures designed to make a yes/no judgment about a hypothesis. That may sound intimidating, so let’s use an analogy.\nSuppose you flip a coin and get six heads in a row. Is the coin rigged (i.e., is the probability of heads not 1/2)? A p-value approach thinks like this: under the hypothesis “P(heads) = 1/2,” the probability of six heads in a row is (1/2)^6 = 0.0156. The probability of six tails in a row is the same, 0.0156. So the probability of observing something this extreme is their sum: p = 0.0312. Isn’t it strange to get such an extreme pattern if the coin were fair? That logic is how a p-value is used to doubt the hypothesis “P(heads) = 1/2.”\nA one-sided p-value corresponds to looking at only one direction of extremeness (e.g., “too many heads”): p = 0.0156.\nA two-sided p-value corresponds to looking in both directions (“too many heads or too many tails”): p = 0.0312.\n\nNow return to JCOG9502. Hypothesis testing proceeds in three conceptual steps.\nFirst, you specify hypotheses. In JCOG9502, the truth could be either: “LTA prolongs overall survival compared with TH,” or “it does not.” In hypothesis testing we focus on the “no effect” statement and call it the null hypothesis (this corresponds to “P(heads) = 1/2” in the coin example).\nSecond, you ask how the data would behave under the null. Imagine repeating the same trial—same design, 167 patients—one thousand times. This is the frequentist way of thinking. Even if there were truly no effect, random error would sometimes make the LTA curve look better and sometimes make the TH curve look better. But across many repetitions, the results would center around “no difference.” You then compare that hypothetical distribution with what you actually observed, and compute a p-value.\nA p-value is the probability—under the assumption that the null hypothesis is true (i.e., no difference between survival curves)—of observing a difference as extreme as, or more extreme than, the one you observed. If the p-value is small, you conclude that such an extreme difference would be unlikely under “no difference,” and so you doubt the null. If the p-value is large, you conclude that what you observed is unremarkable under the null.\n\n\n\n\n\n\n\n\n\nA quiz related to this episode\n\n\n\nExcluding non-inferiority and equivalence trials, two-sided p-values are considered standard in most randomized clinical trials. Which of the following is the correct reason?\n\nBecause whether the experimental treatment is better or worse, if there is a difference, we want to conclude there is a difference.\nBecause it is a rule among statisticians.\nBecause using the same standard worldwide reduces confusion.\nBecause random error creates variability in both upward and downward directions around the mean\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 3.\n\nThis is largely historical. When the ICH E9 guideline was established, regulators in the US, Europe, and Japan agreed to treat two-sided p-values as the default in confirmatory trials (Yoshimura 2003).\n\n\n\n\n\nReference\n\nJCOG protocol manual version 3.8 [Internet]. Tokyo: Japan Clinical Oncology Group; 2025\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\n[Wasserstein R and Lazar NI. The ASA’s statement on p-values: Context, process, and purpose. Am Statistician 2016; 70: 129-33]\nYoshimura I. Significance levels and number of trials in confirmatory clinical trials － In relation to “Statistical Principles for Clinical Trials”－. Jpn J Biometrics 2003; 24: S3-9\n\n\n\nThis concludes the Frequentist Thinking series. If you’d like to keep reading over your next cup of coffee, the following episodes are waiting:\n\nR Demonstration of Bias in Kaplan-Meier Under Competing Risks\nUnderstanding Confidence Intervals via Hypothetical Replications in R\nAlpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size\nfrequentist.R"
  },
  {
    "objectID": "en/frequentist-1.html",
    "href": "en/frequentist-1.html",
    "title": "Reading a Paper over a Cup of Coffee",
    "section": "",
    "text": "Frequentist Thinking I − Reading a Paper over a Cup of Coffee\n\nKeywords: clinical trial, language & writing, p-value, survival & competing risks\n\n\n\n\n\n\n\n\nPreviously…\n\n\n\n\n\nA daughter is taking her first steps into research, and her father is a statistician. After advising her to refine her research question into “PECO,” the daughter—a clinician—decides to study the relationship between having a stoma and returning to work among cancer survivors. These coffee-chat dialogues blend story, methods, and ways of thinking—sometimes practical, sometimes abstract—sometimes with a quiz and small R scripts you can rerun.\n\n\n\n\nMaking sense of the numbers around survival curves\n\n\nDad: “Hmm? It’s getting cold—what are you still reading this late? Want me to make some coffee?”\n\n\nDaughter: “Oh—thanks, Dad. Milk too, please. I’m reading a paper on gastric cancer surgery. Hey, you once explained the difference between overall survival (OS) and disease-free survival (DFS), right?”\n\n\nDad: “That does ring a bell.”\n\n\nDaughter: “Do you read clinical papers for work, too?”\n\n\nDad: “Sometimes. I work as a trial statistician, so yes. But more often I’m on the writing side of papers. And I don’t really need the latest clinical details for my day-to-day work.”\n\n\nDaughter: “Good. Because there are details in this paper that I don’t understand—especially the words that feel ‘statistical.’ Look at this figure. It’s from a randomized trial comparing surgical approaches for gastric cancer, called JCOG9502 (Sasako et al. 2006). The TH group received the standard procedure—approaching the lower mediastinum from a laparotomy incision. The LTA group underwent lower mediastinal dissection as well, through a continuous left thoracoabdominal incision.”\n\n\n\n\n\nDad: “This is what people call a Kaplan-Meier curve. Panel A is OS, and Panel B is DFS. In both panels, the TH group (the blue curve) sits above the LTA group (the red curve). That means the TH group had better outcomes.”\n\n\nDaughter: “That part I get. It’s the small details I’m stuck on. The first thing that tripped me up was the number at risk under the curves. That’s the number of patients still under observation at each time point, right? Look at the numbers at time zero. In Panel A it’s 82 and 85, but in Panel B it’s 76 and 75. The sample sizes differ between the two analyses. Do you know why?”\n\n\nDad: “That’s a hard one. In a randomized trial, excluding patients from the analysis usually means something serious—like a major protocol deviation. Can I get a refill?…Hmm. To analyze DFS, you need to be able to ascertain whether relapse occurred. Is there any reason why that might not be assessable for some patients?”\n\n\nDaughter: “Right—if the tumor wasn’t completely resected, maybe they didn’t treat it as ‘relapse’ in the DFS definition. Let me check… The paper says there were 151 patients who had an R0 resection. That’s probably part of it. And another thing: after about 7 year, the number at risk drops to just a handful of patients. What do you make of that?”\n\n\nDad: “That depends. How long was accrual, and how long was follow-up?”\n\n\nDaughter: “Accrual was from 1995 to 2003—8 years. And it says survival data up to 2006 were analyzed. So the minimum follow-up is around 3 years, maybe.”\n\n\nDad: “Then not everyone can be followed for more than 3 years, right? We talked before about censoring. Time-to-event data consists of events and censoring. Having a lot of censoring within the first 3 years would be suspicious—but censoring after 3 years can simply reflect the planned end of follow-up.”\n\n\nDaughter: “But papers don’t tell you when censoring happened, do they?”\n\n\nDad: “They do. See those little tick marks on the curve.”\n\n\nDaughter: “These tiny spikes?”\n\n\nDad: “Yes. Those marks indicate censoring. If you saw many tick marks right after time zero, what would you suspect? It would mean patients were lost to follow-up soon after the study began—so they were censored early. That kind of pattern can hint at bias.”\n\n\nDaughter: “In this figure, there are only a few tick marks within 3 years. So most patients were followed for at least three years. That sounds like a well-run study. Let me summarize what we just said—something like this?”\n\n\n\nThe number at risk shows how many people remain under observation at each time point.\nTick marks indicate censoring.\nThe figure doesn’t show everything; you should also check the accrual period and planned follow-up.\n\n\n\nDaughter: “But textbooks don’t teach you this kind of thing. They’re all means and regression coefficients.”\n\n\nDad: “Survival analysis tends to be pushed to the back of many general statistics textbooks. If you want to learn how cancer clinical trial data are actually analyzed, a clinical trials textbook written by statisticians from the U.S. cooperative group SWOG is often more useful than a general statistics text (Green et al. 2013).”\n\n\nDaughter: “Come to think of it, it took more than ten years to produce this figure. The staff must have worked incredibly hard. By the way—last time we talked about trial protocols. You submit the protocol to each site’s ethics committee, right? And once it’s approved, you basically don’t change it—because changing it means paperwork.”\n\n\nDad: “That’s right.”\n\n\nDaughter: “It’s scary, putting a plan into words while looking ten years ahead—without even knowing who will read it. And more than a hundred patients are involved. I can see why you’d want to pin down what each endpoint means, even at the level of wording. Oh—and about English terms around survival curves: how would you say ‘hazard ratio,’ ‘95% CI,’ ‘one-sided p,’ and ‘two-sided p’ in Japanese?”\n\n\nDad: “Usually: hazard ratio, 95% confidence interval, one-sided p-value, and two-sided p-value—basically loanwords with standard Japanese phrasing. These are classic survival-analysis outputs. Hazard ratios and p-values often come from Cox regression, but we can talk about that properly another day—when we have time.”\n\n\n\n\n\n\n\n\nA quiz related to this episode\n\n\n\nTo explain prognosis, clinicians sometimes talk about “life expectancy” or remaining lifetime. Can you read “life expectancy after gastric cancer surgery” from the JCOG9502 figure?\n\nYou can read it from Panel A (the OS Kaplan-Meier curve).\nYou can read it from Panel B (the DFS Kaplan-Meier curve).\nYou cannot read it from either Panel A or Panel B.\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 1.\n\nTo summarize survival time, people use the mean or the median, but the median survival time is easier to read from a figure.\nSurvival time is numerical (measured in days or years), so it behaves like continuous data in many respects. For continuous data, the median is the value corresponding to the top 50%, right? Once at least half of participants experience the event—so their survival times are “observed”—you can estimate the median survival time even in the presence of censoring.\nConcretely, the median survival time corresponds to the time when survival reaches 50%—that is, the point where the OS Kaplan-Meier curve in Panel A falls to 50%. You simply read off the time at which the curve crosses that level.\n\n\n\n\n\nReference\n\nGreen J, Benedetti J, Smith A, Crowley J. Clinical Trials in Oncology. Boca Raton: CRC Press; 2012\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\n\n\n\nNext episode and R script\n\nP-Value Explanations That Seem Plausible at First Glance\nfrequentist.R\n\n\n\n\n\n\n\nOther episodes\n\n\n\n\n\nEpisodes in this series\n\nReading a Paper over a Cup of Coffee\nP-Value Explanations That Seem Plausible at First Glance\nBeyond 0.05: Interpreting P-Values in a Clinical Trial\n\nEarlier series\n\nStudy Design I\n\nGlossary\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "en/causal-inference-5.html",
    "href": "en/causal-inference-5.html",
    "title": "Backdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias",
    "section": "",
    "text": "Causal Inference V − Backdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias\n\nKeywords: bias, causal model, confounding & collapsibility, probability model\n\n\n\nThe meaning of blocking\n\n\nMe: “Let’s pick up where we left off, Dad. When you explained DAGs last time, you used the term blocking. You said things like ‘a collider blocks a path.’”\n\n\n“I did.”\n\n\nMe: “So blocking means that the causal flow is stopped, right?”\n\n\nDad: “Hm. That phrasing isn’t quite precise. Blocking is a property of paths in a DAG. It doesn’t directly refer to causality itself. A path is said to be blocked if it contains a collider, or if a non-collider on the path is conditioned on as a confounder.”\n\n\nMe: “So if there’s a collider, the path is blocked automatically. And for a non-collider, the path becomes blocked when we adjust for it.”\n\n\nDad: “Exactly. More formally, blocking means that two nodes can be d-separated. It might be worth touching on the definition of d-separation to avoid confusion.”\n\n\n\n\n\n\n\n\nd-Separation\n\n\n\nConsider a DAG with three disjoint sets of nodes, denoted by A, B, and C. If the following two conditions hold, then C is said to d-separate A and B (Greenland, 1999).\nEvery path between A and B that does not contain a collider includes at least one element of C.\nSuppose C contains a collider that lies on a path between A and B. Even if conditioning on that collider opens the path, the path can still be blocked by conditioning on another element of C.\n\n\n\n\nMe: “This is getting complicated.”\n\n\nDad: “It is. As the number of nodes increases, we have to think in terms of sets of nodes, and the definition becomes harder to parse. That’s why it helps to check the meaning in simple cases. Let’s look at these three DAGs. Do you think C d-separates E and D in each of them?”\n\n\n\nMe: “Well, in all three DAGs there’s only one path connecting E and D. In the top two, there’s no collider, and C lies on the path—so C should d-separate them. What about the bottom one? C is a collider there, and the path E–C–D can’t be blocked by any other variable. So it doesn’t satisfy the conditions for d-separation.”\n\n\nDad: “Exactly. Statements like adjusting for a common cause or a mediator blocks a path, or adjusting for a collider opens a path, can all be expressed precisely by that definition. Once DAGs become more complex, you start to see why the definition is useful. Now, in this DAG, which sets of nodes d-separate E and D?”\n\n\nMe: “There’s no collider here. So would it be A and C?”\n\n\n\nDad: “Not just that. Either A alone or C alone also satisfies the conditions for d-separation.”\n\n\nMe: “So that means that if we observe either A or C, we can adjust for confounding?”\n\n\nDad: “That’s right. Now let’s look at one more DAG.”\n\n\n\nMe: “Still going? I know I asked for this, but let’s make this the last one. Okay—looking at this diagram, A and B each d-separate, right? C is a collider, so it doesn’t.”\n\n\nDad: “That’s correct as far as it goes. But those aren’t the only possibilities. What about A and C, or B and C? Even though C is a collider, conditioning on A or B blocks the path E ← A → C ← B → D, doesn’t it?”\n\n\nMe: “I see—you’re using the second condition. I think I understand when d-separation holds now. But what does this actually mean?”\n\n\nDad: “The main goal today was to explain blocking properly, and maybe it didn’t quite click. In the DAG we just discussed, by searching for sets of variables that d-separate E and D, we identified combinations of confounders that prevent bias. And one more thing: when we replace the nodes in a DAG with random variables, d-separation corresponds exactly to conditional independence. Using this result, we can identify which confounders are needed to identify causal effects. That’s the real meaning of the backdoor criterion.”\n\n\n\n\n\n\n\n\nd-Separation and Conditional Independence\n\n\n\nSuppose that, using a DAG, we confirm that C d-separates A and B. Then it also follows that the random variables A and B are conditionally independent given C (Pearl, 1995).\n\n\n\n\n\n\n\n\nA quiz related to this episode\n\n\n\nWhich interpretation of this DAG is correct?\n\nE and D are conditionally independent given C\nE and D remain associated even after conditioning on C\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 2.\n\nThe path E ← C → D is blocked by conditioning on C, but the path E → D is not. Therefore, C does not d-separate E and D. Note that in this case, the reason d-separation fails is that a direct causal path between E and D remains. When estimating the effect of E on D, C should still be adjusted for—regardless of whether the direct path E → D exists.\n\n\n\n\n\n\n\n\n\nOne more quiz related to this episode\n\n\n\nWhich interpretation of this DAG is correct?\n\nE and D are independent without conditioning on C, and also conditionally independent given C\nE and D are associated without conditioning on C, but conditionally independent given C\nE and D are independent without conditioning on C, but become associated after conditioning on C\nE and D are associated without conditioning on C, and remain associated even after conditioning on C\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 4.\n\nIn this case, unlike the first quiz, there is no direct path between E and D. However, C is a collider. Conditioning on C opens the path E ← A → C ← B → D, so C does not d-separate E and D.\n\n\n\n\n\nReference\n\nGreenland S, Pearl J, Robins JM. Causal diagrams for epidemiologic research. Epidemiology 1999;10(1):37-48\nPearl J. Causal diagrams for empirical research. Biometrika 1995; 82(4): 669-88\n\n\n\nNext episodes\n\nVolatility, Uncertainty, Complexity, and Ambiguity in Causal Inference\n\n\n\n\n\n\n\nOther episodes\n\n\n\n\n\nEpisodes in this series\n\nThree-Variable DAGs: The Smallest Building Blocks of Causal Structure\nA Subtle Distinction between Common Causes and Confounders\nDAGs and Conditional Distributions: Two Languages for the Same Structure\nA Circle, an Equation, and a Cylinder\nBackdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias\nVolatility, Uncertainty, Complexity, and Ambiguity in Causal Inference\n\nEarlier series\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\nEffects and Time I\nAdjusting for Bias I\n\nGlossary\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Coffee and Research",
    "section": "",
    "text": "Shiro Tanaka is a biostatistician and a Professor of Clinical Biostatistics at the Graduate School of Medicine, Kyoto University. This site is his small way of giving back to the community that shaped his training—through books, open-source software, and resources shared generously across borders.\nHe has served as a trial statistician in nationwide clinical trial groups in oncology (JCOG), pediatric oncology (JCCG), and osteoporosis (A-TOP). He is an advisory expert for the Pharmaceuticals and Medical Devices Agency (PMDA), serves on the council of the Japanese Society for Pharmacoepidemiology and the Biometric Society of Japan, and is on multiple editorial boards.\nHe has been fortunate to work with researchers such as Marc A. Brookhart, Jason P. Fine, and Thomas H. Scheike.\n\n\n\nThe name comes from g-estimation in causal inference—a class of methods introduced by James Robins. In my own work, I have found this approach especially useful in applied clinical research:\n\nTanaka S, Matsuyama Y, Shiraki M, Ohashi Y. Estimating the effects of time-varying osteoporosis treatments on incidence of fractures among Japanese postmenopausal women. Epidemiology 2007;18(5):529–36.\nTanaka S, Brookhart MA, Fine JP. G-estimation of structural nested mean models for competing risks data using pseudo-observations. Biostatistics 2020;21(4):860–75.\nTanaka S, Brookhart MA, Fine JP. G-estimation of structural nested mean models for interval-censored data using pseudo-observations. Statistics in Medicine 2023;42(21):3877–91.\n\nThese are not required reading for the stories here. But if you ever feel like following the path from coffee chats → DAGs → g-estimation, this is one of the places it eventually leads."
  },
  {
    "objectID": "about/index.html#about-gestimationshiro-tanaka",
    "href": "about/index.html#about-gestimationshiro-tanaka",
    "title": "Coffee and Research",
    "section": "",
    "text": "Shiro Tanaka is a biostatistician and a Professor of Clinical Biostatistics at the Graduate School of Medicine, Kyoto University. This site is his small way of giving back to the community that shaped his training—through books, open-source software, and resources shared generously across borders.\nHe has served as a trial statistician in nationwide clinical trial groups in oncology (JCOG), pediatric oncology (JCCG), and osteoporosis (A-TOP). He is an advisory expert for the Pharmaceuticals and Medical Devices Agency (PMDA), serves on the council of the Japanese Society for Pharmacoepidemiology and the Biometric Society of Japan, and is on multiple editorial boards.\nHe has been fortunate to work with researchers such as Marc A. Brookhart, Jason P. Fine, and Thomas H. Scheike."
  },
  {
    "objectID": "about/index.html#why-gestimation",
    "href": "about/index.html#why-gestimation",
    "title": "Coffee and Research",
    "section": "",
    "text": "The name comes from g-estimation in causal inference—a class of methods introduced by James Robins. In my own work, I have found this approach especially useful in applied clinical research:\n\nTanaka S, Matsuyama Y, Shiraki M, Ohashi Y. Estimating the effects of time-varying osteoporosis treatments on incidence of fractures among Japanese postmenopausal women. Epidemiology 2007;18(5):529–36.\nTanaka S, Brookhart MA, Fine JP. G-estimation of structural nested mean models for competing risks data using pseudo-observations. Biostatistics 2020;21(4):860–75.\nTanaka S, Brookhart MA, Fine JP. G-estimation of structural nested mean models for interval-censored data using pseudo-observations. Statistics in Medicine 2023;42(21):3877–91.\n\nThese are not required reading for the stories here. But if you ever feel like following the path from coffee chats → DAGs → g-estimation, this is one of the places it eventually leads."
  },
  {
    "objectID": "en/causal-inference-4.html",
    "href": "en/causal-inference-4.html",
    "title": "A Circle, an Equation, and a Cylinder",
    "section": "",
    "text": "Causal Inference IV − A Circle, an Equation, and a Cylinder\n\nKeywords: causal model, language & writing, probability model\n\n\n\nThe answer to a question depends on how we choose to view the world abstractly\n\n\nMe: “Dad, I appreciate how careful you are, but isn’t there a simpler way to explain collider bias? That conditional probability formula is pretty brutal.”\n\n\nDad: “I get that. But I thought it wouldn’t be precise enough without writing down the equation.”\n\n\nMe: “I do appreciate the precision. Still, a metaphor might have worked just as well.”\n\n\nDad: “Do you remember your original question? You said that explanations of confounding felt incomplete, whether in probability models or in the Rubin causal model. That was our starting point. Simply replacing colliders with another metaphor wouldn’t really solve that.”\n\n\nMe: “Fair enough.”\n\n\nDad: “There was a reason I wrote the equations on a napkin. I wanted you to see that the same thing can be expressed in two ways: as a DAG and as a set of equations. We often use multiple abstract representations side by side. Look—there’s a coffee mug right here.”\n\n\nMe: “The one you’re always drinking from.”\n\n\nDad: “Try looking at it from directly above.”\n\n\nMe: “Like this?”\n\n\nDad: “Exactly. You see a circle, right?”\n\n\nMe: “Yes. And?”\n\n\nDad: “In math class, you learned that a circle can be described by an equation once you set an x-axis and a y-axis. The relationship between DAGs and conditional probability formulas is similar.”\n\n\\[x^2+y^2=r^2\\]\n\nMe: “So the circle is the picture, and the equation is the mathematical expression?”\n\n\nDad: “Right. It’s the same object, expressed differently. If you’re just talking about circles, it’s faster to draw one than to write down the equation. DAGs work the same way. They project only the pattern of connections from a set of conditional probability formulas. They deliberately set aside distributional forms and data types, and temporarily bracket complicated equations, so that we can focus on structure alone. A DAG is a topological tool for looking only at how things are connected.”\n\n\nMe: “That makes sense. Arrows are easier to grasp at first glance.”\n\n\nDad: “Now try looking at the mug from an angle.”\n\n\nMe: “So now the circle becomes three-dimensional?”\n\n\nDad: “Exactly. You see a cylinder. That cylinder is like the potential outcomes in the Rubin causal model. From the data we can observe—from the top, so to speak—we can’t see the whole object. The unseen part corresponds to the unobserved potential outcomes.”\n\n\nMe:“That’s…surprisingly poetic.”\n\n\nDad: “In a single coffee mug, you can find three structures: a probability model, a DAG, and the Rubin causal model. We extract information from data by choosing an abstract structure. And this isn’t just about processing or compressing information—it’s about producing knowledge for patients. Statistics is for people. That’s why the way we choose to view the world abstractly really matters.”\n\n\nHow do we choose variables?\n\nMe: “But for me, choosing variables feels more urgent than choosing models. In the DAG for H. pylori eradication, we included not just treatment status, but gastric cancer, personality, age, and constitution. How do you actually decide what to include in a real study?”\n\n\nDad: “That’s the hard part. In practice, you have to rely on medical knowledge and study design to draw a plausible DAG. Known risk factors for gastric cancer, for example. Or the assumption that, in a randomized clinical trial, treatment assignment should be independent of baseline covariates.”\n\n\nMe: “But if you think that way, the number of variables could grow without bound. For gastric cancer to occur, you first need a digestive tract. Before that, at the micro level there are cells, and at the macro level there’s a living organism. Even receiving H. pylori treatment might depend on social factors.”\n\n\nDad: “That’s a reasonable way to think about it. Some views of causation aren’t limited to linking one cause to one result. At a very fundamental level, everything follows physical laws, like Newtonian mechanics.”\n\n\nMe: “That’s physics, not what we’re talking about right now.”\n\n\nDad: “Right. Let’s widen the frame just a little. In Japanese, alongside the word in-ga — which means cause and result—we also use the word en-gi. We often use en-gi to express the idea that outcomes arise from many overlapping conditions and events. But the objects of analysis in randomized trials or observational studies are much more limited than that, don’t you think?”\n\n\nMe: “Yes. What we really want to know is the effectiveness of a drug, or the effect of H. pylori eradication.”\n\n\nDad: “Exactly. This isn’t about which framework is ‘correct.’ In clinical research, it’s reasonable to focus on variables that are relevant to the research question and the study’s purpose. One role of DAGs, for example, is to help identify potential confounders and assess the validity of our inferences.”\n\n\n\n\n\nNext episodes\n\nBackdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias\n\n\n\n\n\n\n\nOther episodes\n\n\n\n\n\nEpisodes in this series\n\nThree-Variable DAGs: The Smallest Building Blocks of Causal Structure\nA Subtle Distinction between Common Causes and Confounders\nDAGs and Conditional Distributions: Two Languages for the Same Structure\nA Circle, an Equation, and a Cylinder\nBackdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias\nVolatility, Uncertainty, Complexity, and Ambiguity in Causal Inference\n\nEarlier series\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\nEffects and Time I\nAdjusting for Bias I\n\nGlossary\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "en/effects-1.html",
    "href": "en/effects-1.html",
    "title": "Silent Confusions Hidden in Percentages",
    "section": "",
    "text": "Effects and Time I − Silent Confusions Hidden in Percentages\n\nKeywords: effect measure, language & writing, observational study\n\n\n\n\n\n\n\n\nPreviously\n\n\n\n\n\nA daughter is taking her first steps into research, and her dad is a statistician. After advising her to refine her research question into “PECO,” the daughter—a clinician—decides to study the relationship between having a stoma and returning to work among cancer survivors. Since then, her dad has been quietly looking for chances to bring up statistics in conversation.\n\n\n\n\nWhen you hear “95%,” don’t you think it means it works for 95 out of 100 people?\n\n\nDad: “Oh—you’re out of the bath already? Want me to make some coffee?”\n\n\nMe: “Caffè latte.”\n\n\nDad: “Your usual? That isn’t a caffè latte. It’s just coffee with milk.”\n\n\nMe: “That’s fine. By the way—about that vaccine that was in the news. A patient asked me in clinic what ‘95% efficacy’ means. Honestly, statistics like that confuse me too.”\n\n\nDad: “Yeah, it became a big topic. Vaccine efficacy is surprisingly tricky to compute. First, be careful with the word ‘rate.’”\n\n\nMe: “Really? I use terms like incidence rate and mortality rate all the time.”\n\n\nDad: “This is different. Japanese makes it easy to trip up here, because the same word is used in multiple ways. In this context, ‘95%’ is a percentage—but it isn’t a rate in the epidemiologic sense. And the confusion doesn’t stop there. Here, 95% means the risk of disease is reduced to 5% of the placebo risk.”\n\n\n\nVaccine efficacy is not a rate in the general epidemiologic sense.\nIt is a measure defined by relative comparison with placebo.\n\n\n\nMe: “Huh? So it doesn’t mean ‘it works for 95 out of 100 people’?”\n\n\nDad: “No, no. It’s a relative comparison to the placebo. It’s a percentage that expresses how much infection is prevented compared with what would happen under placebo. In papers it’s fine, but in everyday conversation it almost always gets misunderstood. You can’t really make sense of it unless you trace it back to the underlying risks. Grab that paper napkin and a pen—let me write it out. I’ll list a few measures, but the only thing you need to keep straight is: ‘Which risk is being compared to which risk—and how?’ To do that, picture data summarized in a 2×2 table.”\n\n\n\n\n\n\n\n\nBasic measures for comparing risks\n\n\n\nIn medicine, different fields use different measures, and measures that compare proportions are often harder to interpret than they look. A good first step is to think in terms of a 2×2 table.\n\n\n\n\nGroup 1\nGroup 2\n\n\n\n\nDisease\nA\nB\n\n\nNo disease\nC\nD\n\n\nRisk\n\\(\\pi_1\\)\n\\(\\pi_2\\)\n\n\n\nHere we write the counts and risks using symbols (A, B, C, D and \\(\\pi_1\\), \\(\\pi_2\\)) rather than specific numbers. When comparing risks \\(\\pi_1\\) and \\(\\pi_2\\) across two groups, common measures include:\n\nRisk difference (RD; absolute risk reduction)\n\n\\[\nRD=\\pi_1-\\pi_2\n\\]\n\nRisk ratio (RR)\n\n\\[\nRR=\\frac{\\pi_1}{\\pi_2}\n\\]\n\nOdds ratio (OR)\n\n\\[\nOR=\\frac{\\pi_1/(1-\\pi_1)}{\\pi_2/(1-\\pi_2)}\n\\]\nWhen using these measures, it is important to keep track of which group is treated as the reference. In the formulas above, Group 2 is the reference.\n\n\n\n\n\n\n\n\nMeasures used to compare treatment efficacy\n\n\n\nWhen comparing the effectiveness of two treatments, the following measures are also frequently used. In both cases we assume \\(\\pi_2&gt;\\pi_1\\). For vaccine efficacy, you can think of Group 2 as the placebo group.\n\nNumber needed to treat (NNT)\n\n\\[\nNNT=\\frac{1}{\\pi_2-\\pi_1}=-\\frac{1}{RD}\n\\]\n\nVaccine efficacy (relative risk reduction)\n\n\\[\nVE=\\frac{\\pi_2-\\pi_1}{\\pi_2}=1-RR\n\\]\n\n\n\n\nMe: “Wow—vaccine efficacy isn’t the kind of percentage I pictured. It’s basically just the risk ratio, rearranged. But if you call it ‘efficacy’ and it’s written as a percent, you naturally assume it’s just ‘a proportion.’ Do you always carry these formulas around in your head? It feels strange when equations suddenly appear. Statistics and medicine really do have different vibes.”\n\n\nDad: “Maybe I’ve just gotten used to it. But if I don’t write it as a formula, you can’t tell what vaccine efficacy is, right? And actually—this number has a meaning that’s far more real than the equation.”\n\n\nMe: “What is that supposed to mean? Don’t be so roundabout. This isn’t a lecture.”\n\n\nDad: “You’ll see immediately. Vaccine efficacy is estimated from clinical data, right? A clinical trial is run with many participants, and what was actually observed gets compressed—summarized tightly—into that single number. But what was observed in the data doesn’t come across from vaccine efficacy alone. That’s what people mean when they say ‘the number starts walking around on its own.’”\n\n\n\n\n\n\n\n\nA numerical example from a hypothetical randomized vaccine trial\n\n\n\nThe table below is hypothetical trial data comparing a vaccine with placebo. If you compute vaccine efficacy from these counts, you obtain:\n\n\n\n\nVaccine\nPlacebo\n\n\n\n\nDisease\n40\n800\n\n\nNo disease\n960\n200\n\n\nRisk\n4%\n80%\n\n\n\n\\(\\pi_1 = 40/1000 = 0.04\\)\n\\(\\pi_2 = 800/1000 = 0.8\\)\n\\(VE=\\frac{\\pi_2-\\pi_1}{\\pi_2}=95 \\%\\)\n\n\n\n\nMe: “True. When you see ‘95% effective,’ it’s easy to hear it as ‘it almost certainly saves you.’ But if you think about it, vaccines don’t have that kind of effect. You could get fooled by the rhetoric of percentages.”\n\n\nDad: “Exactly. Interpreting results requires information that isn’t contained in the language itself. ‘70%’ or ‘80%’—the same-looking number can come from completely different calculations. Response rate and vaccine efficacy are not the same thing. But in daily conversation you can’t check definitions every time, can you? That’s why these measures are so often misused. And vaccine efficacy isn’t the only epidemiologic measure where percent formatting creates misunderstanding.”\n\n\n\n\n\n\n\n\nA quiz related to this episode\n\n\n\nResponse rate is the proportion of patients whose tumors shrink after chemotherapy (achieving complete or partial response), or—depending on the context—who achieve complete remission (e.g., disappearance of tumor cells in blood). The term is widely used, but the Japan Clinical Oncology Group (JCOG) prefers the expression response proportion (Japan Clinical Oncology Group 2025).\nNow, which of the following is a rate (in the epidemiologic sense)?\n\nBatting average\n\nSex ratio\n\nPrevalence\n\nMortality rate\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 4.\n\nLet’s clarify the difference among ratio, proportion, and rate.\nA ratio is one quantity divided by another. For example, BMI is weight divided by height squared, so it is a ratio with units of kg/m2.\nA proportion is a special kind of ratio where the numerator is contained within the denominator (a “part over the whole”). Proportions cannot exceed 100% and are unitless.\nA rate reflects speed over time. For example, an incidence rate is often computed using person-time: number of new cases divided by observed person-years. Because the denominator includes time (persons × time), the unit is 1/year (more generally, 1/time).\n\n“Batting average” (hits ÷ at-bats) is a proportion.\n\n“Sex ratio” (number of men ÷ number of women) is a ratio.\n\n“Prevalence” (number with disease ÷ total number) is a proportion.\n\n“Mortality rate” (deaths ÷ person-time) is a rate.\n\n\n\n\n\n\n\nReference\n\nJCOG protocol manual version 3.8 [Internet]. Tokyo: Japan Clinical Oncology Group; 2025\n\n\n\nNext episodes and R script\n\nWho Is This Percentage About? Target Populations and Attributable Fractions\neffects.R\n\n\n\n\n\n\n\nOther episodes\n\n\n\n\n\nEpisodes in this series\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nA First Note on Cox Regression\nAfter Cox Regression: A Case Study and R Demonstration\n\nEarlier series\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\n\nGlossary\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "en/frequentist-2.html",
    "href": "en/frequentist-2.html",
    "title": "P-Value Explanations That Seem Plausible at First Glance",
    "section": "",
    "text": "Frequentist Thinking II − P-Value Explanations That Seem Plausible at First Glance\n\nKeywords: clinical trial, language & writing, p-value, survival & competing risks\n\n\n\nSurvival curves and hazard ratios\n\n\nDaughter: “Dad, I’ve made another cup of coffee. Can you keep going and explain the hazard ratios from JCOG9502?”\n\n\nDad: “Ouch, it’s hot. You’re referring to the hazard ratio of death of 1.36 in Figure A, and the hazard ratio of recurrence or death of 1.29 in Figure B. Both summarize the treatment contrast on the hazard scale, which in turn drives the separation you see in the Kaplan-Meier curves, showing that the TH group had better outcomes than the LTA group. A higher hazard means the Kaplan-Meier curve tends to drop more quickly. What matters here is that both overall survival (OS) in Figure A and disease-free survival (DFS) in Figure B have shapes that are well summarized by a hazard ratio.”\n\n\n\nDaughter: “Summarized well—meaning what, exactly?”\n\n\nDad: “Yes. In both figures, the Kaplan-Meier curve for the TH group lies cleanly above that for the LTA group—except at the far right, where only four patients remain and the curves cross. The hazard ratio assumes that the two survival curves are proportional on the hazard scale. Although it’s not explicitly stated in the figures, the hazard ratios are reported so that values above 1 correspond to worse outcomes in the LTA group relative to TH. This relationship is what we call Cox regression or the proportional hazards model.”\n\n\nDaughter: “So if the curves cross, that breaks the proportional hazards assumption.”\n\n\nDad: “Exactly. And the OS and DFS results are consistent with each other as well. That makes the findings very straightforward and easy to interpret. I’ll show you Cox regression in R later.”\n\n\nDaughter: “Thanks—later then. But looking at these figures, the hazard ratios are 1.36 and 1.29, right? A higher hazard means the Kaplan-Meier curve drops faster, and the reference is the TH group. So if the hazard ratio is greater than one, the LTA group did worse than the TH group in OS and DFS. And p-values below 0.05 are considered statistically significant, right? So the LTA group had worse outcomes, but since the p-values aren’t below the threshold, there’s no statistically significant difference between the two groups?”\n\n\nDad: “That’s right. The hazard reflects the speed at which death or recurrence occurs, and the hazard ratio is simply the ratio between the two groups.”\n\n\n\n\nP-value explanations that seem plausible\n\n\nDad: “The precise meaning of p-values is often misunderstood. One thing to keep in mind when reading papers is that the threshold compared against the p-value—the significance level—may not always be 5%. For example, consider interim analyses. Take a look at the abstract. In JCOG9502, an interim analysis was planned before the final analysis, and this paper reports results after the trial was stopped early. In interim analyses, it’s common to test using a significance level lower than 5%.”\n\n\nDaughter: “So the trial was stopped early because it became statistically significant?”\n\n\nDad: “No. The trial was stopped not because a significant difference was found, but because the data and safety monitoring committee judged that there was no reasonable chance that the LTA group would prove superior. There are several other common misunderstandings. Look at these statements.”\n\n\nA p-value is the probability that the null hypothesis is true.\nA small p-value and statistical significance mean that an important scientific finding has been obtained.\nA statistically non-significant result means that the null hypothesis is true and should be accepted.\n\n\nDad: “In JCOG9502, the null hypothesis is that the overall survival curves of the LTA and TH groups are equal. Let me ask you about the first statement. Do you think the p-value in JCOG9502 represents the probability that ‘there is no difference between the survival curves of the LTA and TH groups’?”\n\n\nDaughter: “This is starting to feel like a blackboard lecture. Was mentioning statistics textbooks a mistake? But sure—statement one sounds fine to me. If the p-value is 0.05, then it’s correct five times out of a hundred, right?”\n\n\nDad: “Here I want you to choose your words carefully. Is the statement ‘there is no difference between the survival curves’ a random variable? It isn’t. A proposition is either true or false. Defining a probability for something that is not a random variable is conceptually problematic.”\n\n\nDaughter: “Ah, that’s the distinction you wanted me to notice. Fine—I’ll stop phrasing it that way.”\n\n\nDad: “Then what did you mean by ‘five times out of a hundred’?”\n\n\nDaughter: “Literally that. If we ran JCOG9502 a hundred times, what would happen?”\n\n\nDad: “Exactly. If you repeat the same trial a hundred times, you get a hundred p-values. That’s the definition of probability in this context—frequentist probability. Now let’s move on. Do you think a small p-value means that an important scientific discovery has been made?”\n\n\nDaughter: “Isn’t that how people usually think about it?”\n\n\nDad: “But look at the p-values shown in the figure—four of them, ranging from 0.15 to 0.92. None are small. Does that mean the results aren’t scientifically important?”\n\n\nDaughter: “No, that’s not what I meant.”\n\n\nDad: “Exactly. The idea that smaller p-values imply more important scientific findings is simply wrong. If you focus too much on p-values, your interpretation of a paper can easily become distorted.”\n\n\nDaughter: “Okay, okay. But aren’t you talking a bit too long?”\n\n\nDad: “Let’s consider the third statement: ‘A statistically non-significant result means that the null hypothesis is true and should be accepted.’ Is that correct?”\n\n\nDaughter: “I remember reading that p-values are used to reject hypotheses, not to accept them. So this must be wrong too. But in practice, what happens when a result isn’t significant? If a clinical trial compares drug A and drug B, can we conclude that they’re equivalent?”\n\n\nDad: “That would be breaking the rules. If the null hypothesis were true, it would mean that A and B are equivalent—but you cannot accept it just because there’s no significant difference. To conclude equivalence or non-inferiority, you need a properly designed equivalence trial or non-inferiority trial.”\n\n\nDaughter: “Right. I suspected that, but it helps to hear it stated clearly.”\n\n\nDad: “This distinction had to be built into the rules, and history shows why. About thirty years ago in Japan, non-inferiority trials were required for drug approval. Based on that experience, the relationship between research hypotheses and statistical decision rules has to be handled very carefully.”\n\n\n\n\nP-values as a standardized rule\n\n\nDaughter: “I understand the textbook explanation, but I still feel a gap between theory and reality. About statement two—the idea that ‘small p-values mean important science.’ In basic research, results without significance often get dismissed. That’s the reality. But JCOG9502 is different. It didn’t show superiority of LTA, nor equivalence of the procedures—yet it was published in Lancet Oncology. Why?”\n\n\nDad: “I don’t think a negative clinical trial lacks value. Clinical trials are primarily evaluations of technical performance—of surgeries or drugs. Whether efficacy is demonstrated or not, the evaluation itself still has value.”\n\n\nDaughter: “So even a negative trial has the same informational value?”\n\n\nDad: “Yes—if it’s well designed and well executed. Think of a clinical trial as an exam. Passing or failing doesn’t change the value of the score itself. The p-value functions like a grading rule or a technical standard—it’s unavoidable. …Though of course, scores aren’t everything.”\n\n\nDaughter: “So clinical trials are about evaluating technology, not making scientific discoveries?”\n\n\nDad: “Historically, clinical trials developed within regulatory systems for technology evaluation. Standardizing p-values and efficacy endpoints was part of maintaining consistent testing standards. In the 1990s, regulatory requirements still differed across countries. In the late 1990s, regulators in the US, Europe, and Japan agreed on common standards—the ICH guidelines.”\n\n\nDaughter: “But that’s for industry-sponsored trials, not investigator-initiated studies. And haven’t clinical trials driven paradigm shifts? Cytotoxic drugs, anti-PD-1 antibodies, ADCs. Calling all that ‘technology evaluation’ feels unsatisfying.”\n\n\nDad: “Perhaps technology evaluation stimulated science.”\n\n\nDaughter: “You really like separating technology and science. I’m fine with classifying industry trials as technology evaluation. But in the broader scientific enterprise, clinical trials generate new hypotheses and new questions. That’s what I want to call science.”\n\n\n\n\n\n\n\n\nA cautionary tale: Hopate\n\n\n\n\n\nThis story is a Japan-specific regulatory episode, but the lesson is general. It’s a cautionary tale about treating ‘no statistically significant difference’ as evidence of equivalence.\nHave you heard of the older drug called cerebral circulation and metabolism enhancing agents? This medication was once used for cerebrovascular disorders and dementia, and reportedly generated cumulative sales of around 800 billion yen in Japan. Several similar drugs existed, but most were approved based on “non-inferiority trials” comparing them to the first-approved drug, calcium hopantenate (brand name Hopate). However, the studies conducted at the time did not perform formal non-inferiority analyses setting a non-inferiority margin; instead, non-inferiority was determined based on the finding that there was “no significant difference compared to calcium hopantenate.” Calcium hopantenate was withdrawn from the market in 1989 due to side effects. Around the same time, the Ministry of Health and Welfare (as it was then) requested pharmaceutical companies to conduct reevaluations using placebo-controlled trials. The results showed that none of the cerebral circulation-improving drugs outperformed placebo (Ministry of Health and Welfare, Pharmaceutical Safety Bureau, 1998). This tragedy clearly demonstrates that concluding equivalence or non-inferiority when no significant difference is found is a mistake.\n\n\n\n\n\n\n\n\n\nEstimation of a hazard ratio using coxph()\n\n\n\nThere are several methods for estimating hazard ratios, but the most popular is the coxph() function in the survival package. In a previous episode, we used the function generate_data(hr1, hr2) to generate data on the presence of a stoma and overall survival (OS). This time, we will apply Cox regression to the same data and calculate the hazard ratio between the stoma group and the non-stoma group. In generate_data(hr1, hr2), the true value of the hazard ratio for death can be specified using the hr2 argument.\n\n\n\n\n\n\n\n\nR code for generate_data()\n\n\n\n\n\n\ngenerate_data &lt;- function(n = 200, hr1, hr2) {\n  # Stoma: 1 = with stoma, 0 = without stoma\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  # Sex: 0 = WOMAN, 1 = MAN\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  # Age: normal distribution (stoma group slightly older)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  \n  # Hazards for relapse and death (larger hazard implies earlier event)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1 * 0.10, 0.10)\n  hazard_death     &lt;- ifelse(stoma == 1, hr2 * 0.10, 0.10)\n  hazard_censoring &lt;- 0.05\n  \n  # Latent times to relapse, death, and censoring\n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)\n  t_death     &lt;- rexp(n, rate = hazard_death)\n  t_censoring &lt;- rexp(n, rate = hazard_censoring)\n  \n  # Overall survival (OS)\n  # status_os = 1 → death (event of interest)\n  # status_os = 0 → censored\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = death, 0 = censored\n  \n  # Relapse-free survival (RFS)\n  # status_rfs = 1 → relapse or death whichever comes first (event of interest)\n  # status_rfs = 0 → censored\n  time_rfs   &lt;- pmin(t_relapse, t_death, t_censoring)\n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1  # relapse\n  status_rfs[time_rfs == t_death   & time_rfs &lt; t_censoring] &lt;- 1  # death\n  \n  # Cumulative incidence of relapse (CIR)\n  # status_cir = 1 → relapse (event of interest)\n  # status_cir = 2 → death as competing risk\n  # status_cir = 0 → censored\n  \n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1\n  status_cir[time_cir == t_death   & time_cir &lt; t_censoring] &lt;- 2\n  \n  data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n}\n\n\n\n\n\n\n\n\n\n\nR code for coxph() and outout\n\n\n\n\n\n\n#- Generation of data frame \"dat\" --------------------------\ndat &lt;- generate_data(hr1 = 2, hr2 = 1.5)  # true HR for death = 1.5\n\n#- Analysis using coxph() ----------------------------------\n# install.packages(\"survival\") # if needed\nlibrary(survival)\n\nfit &lt;- coxph(Surv(time_os, status_os) ~ stoma, data = dat)\nsummary(fit)\n\nCall:\ncoxph(formula = Surv(time_os, status_os) ~ stoma, data = dat)\n\n  n= 200, number of events= 137 \n\n                  coef exp(coef) se(coef)     z Pr(&gt;|z|)    \nstomaWITH STOMA 0.5765    1.7798   0.1740 3.313 0.000922 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\nstomaWITH STOMA      1.78     0.5619     1.266     2.503\n\nConcordance= 0.555  (se = 0.024 )\nLikelihood ratio test= 10.86  on 1 df,   p=0.001\nWald test            = 10.98  on 1 df,   p=9e-04\nScore (logrank) test = 11.27  on 1 df,   p=8e-04\n\n\n\n\n\n\n\nReference\n\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\nRe-assessment of nicergoline, a cerebral circulation and metabolism enhancing agent [Internet]. Tokyo: Ministry of Health and Welfare, Pharmaceutical Safety Bureau; 1998\n\n\n\nNext episode and R script\n\nBeyond 0.05: Interpreting P-Values in a Clinical Trial\nfrequentist.R\n\n\n\n\n\n\n\nOther episodes\n\n\n\n\n\nEpisodes in this series\n\nReading a Paper over a Cup of Coffee\nP-Value Explanations That Seem Plausible at First Glance\nBeyond 0.05: Interpreting P-Values in a Clinical Trial\n\nEarlier series\n\nStudy Design I\n\nGlossary\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "en/glossary.html",
    "href": "en/glossary.html",
    "title": "Statistical Terms in Plain Language",
    "section": "",
    "text": "Glossary − Statistical Terms in Plain Language\n\nKeywords: causal model, language & writing, probability model, survival & competing risks\n\n\n\nHer father explains words in statistics and research\n\n\nMe: “Dad, there’s a paper we’re doing a journal club on in my department right now, and I’m struggling with the nuance of some of the terminology. When you talk, a lot of statistical terms come up. To be honest, some of them still don’t feel very real to me. Would you mind rephrasing statistical terms in more everyday language?”\n\n\nDad: “I’ve got some time today, so sure. Let’s try a few. I’ll go through them in alphabetical order.”\n\n\nAalen-Johansen method\nA method to estimate a cumulative incidence curve in competing risks analysis\nAlpha error\nAn error where we conclude that a treatment is effective, or that an association exists, when in fact it does not. This is also called a false positive. In medical research, it is customary to control this error at 5% or less using p-values or similar criteria.\nAttributable fraction\nA measure obtained by transforming risks or incidence rates to express the proportion of disease occurrence in a specific population that can be attributed to exposure to a particular risk factor. Multiple definitions exist.\nBeta error\nA key quantity in sample size planning. It is the probability of concluding that a truly effective treatment has no effect. When large amounts of data can be collected and beta error is low, the study is said to have high power.\nBias\nIn general usage, bias refers to a distorted perspective or behavior. In statistics, it refers to the tendency of an estimator to deviate from the true value (the estimand), or the magnitude of that deviation. Once bias is detected after data collection, it is often difficult to correct.\nBiostatistician\nA statistical specialist working in medicine or life sciences. Biostatisticians belong to professional societies and communities distinct from those of bioinformaticians, data scientists, or epidemiologists. In a narrow sense, the term refers to professionals specializing in clinical trials, for which formal certification systems exist—though the “bio” prefix often makes the role seem less clear.\nCensoring\nIn survival analysis, a situation in which observation is interrupted at a certain point in time, so that we only know that the event of interest would have occurred after that point.\nCompeting risk\nAn event that, once it occurs, prevents observation of the event of interest—for example, death from an accident when studying death from cancer.\nConfounding\nA type of bias that must be considered when comparing groups.\nCox regression\nA statistical method developed by Professor Cox in 1972 that became widely used. It is a type of regression model, but not a generalized linear model. It treats survival time as the outcome and is used to summarize differences in survival curves via hazard ratios or to examine associations between survival time and various factors.\nDesign\nTraditionally, “design” in statistics referred to experimental design, but the term has expanded to include study planning and the elements decided at that stage. Randomized trials, surveys, and cohort studies are all types of study design.\nDirected acyclic graph (DAG) In this work, a model refers to an abstract way of viewing data. A DAG is one a structural causal model that represents causal relationships across variables using arrows.\nEffect size\nThe magnitude of a treatment effect or the difference between treatments. In sample size planning, an effect size must be specified, which is paradoxical because the study is often conducted precisely to learn that value. This dilemma is sometimes mocked as “the smallest difference that can be calculated backward from the sample size.”\nEstimand\nIn clinical trials, adverse events or treatment discontinuation after treatment initiation can make it unclear what treatment effect is actually being evaluated. An estimand is a statistical term that clarifies exactly what quantity the study aims to estimate. The ICH E9 guideline requires that estimands be specified at the planning stage of a clinical trial. They are the true values in statistical inference.\nFine-Gray model\nA statistical method developed by Professor Fine in 1999 as an extension of Cox regression. It is a regression model for survival data with competing risks.\nGeneralized linear model\nA class of “regression models” that includes regression analysis, analysis of variance, logistic regression, and related methods. In statistical software, it is often abbreviated as “GLM.”\nHazard ratio\nA measure derived from Cox regression, used to compare survival curves.\nInformation bias\nA type of bias that must be considered when collecting information.\nKaplan-Meier method\nA method to estimate a survival curve in survival analysis\nLogistic regression\nA statistical method used to examine the association between the probability of an event and other variables. It is a type of regression model used when the outcome is binary. Taking the exponential of the regression coefficient yields an odds ratio.\nOne-sided p-value\nA p-value used when interest lies only in one direction of an association—either positive or negative. In most situations, however, a two-sided p-value is preferred.\nProbability model In this work, a model refers to an abstract way of viewing data. A probabilistic model is one that assumes what kind of probability distribution data are generated from.\nProportion\nA measure representing the fraction of a whole. It is commonly used to summarize binary or categorical data. Because it is calculated by dividing a count by a count, the units cancel out and it is dimensionless.\nProportional hazards assumption\nThe assumption that the speed at which events such as death or disease progression occur differs between groups by a constant factor, and that this relationship remains unchanged over time.\np-value\nA number that many readers look at first when examining study results. It is used to assess statistical significance—that is, whether an observed association exceeds what could be explained by random variation.\nRandomization\nThe process of randomly assigning participants to interventions—such as a new treatment versus standard care—when comparing intervention effects. This is one way to reduce bias.\nRate\nA measure of the speed at which events occur over time. In epidemiology, rates are often calculated using person-time (number of events divided by person-years), giving units of 1/year (or more generally, 1/time).\nRatio\nA measure obtained by dividing one quantity by another. Proportions and rates are types of ratios.\nRegression model\nA statistical method used to examine how one variable is related to others. Although often used interchangeably with “regression analysis,” the term “model” typically emphasizes the underlying mathematical or probabilistic formulation rather than the analytical procedure itself.\nRisk\nThe probability that a disease will occur. Because risk depends on the population being studied, using risk values without context should be avoided.\nRubin causal model\nIn this work, a model refers to an abstract way of viewing data. The Rubin causal model defines causal effects using potential outcome variables, which represent what the outcome would have been for the same unit had the cause taken a different value. The term is sometimes used to denote a broader framework that includes assignment mechanisms and probability distributions; however, in this work, these components are not made explicit, as the focus is on the definition of causal effects.\nSample size calculation\nThe process of determining the scale of a study, such as the number of participants. By specifying quantities such as the effect size, alpha error, and beta error (or power), the required sample size can be calculated.\nSelection bias\nA type of bias that must be considered when choosing the study population.\nSurrogate endpoint\nWhen a clinically meaningful outcome cannot be obtained, a substitute endpoint may be used. For example, in cancer trials, response rate has often been used as a surrogate for overall survival, though it has been criticized for not necessarily reflecting true survival benefit.\nSurvival curve\nA graph that displays time on the horizontal axis and the proportion of individuals surviving at each time point on the vertical axis. In many disease areas, such as oncology and cardiovascular medicine, study results are often presented as survival curves.\nTwo-sided p-value\nA p-value used when interest lies in both positive and negative associations. In most cases, two-sided p-values are preferred over one-sided ones.\n\n\nMe: “Seeing them all laid out like this, the curse words I saw in the paper are starting to look a bit more like human language.”\n\n\nDad: “Exactly. Once you understand the terminology, you can focus on the clinical questions and the data themselves.”\n\n\n\n\n\n\n\n\nDifferences among statistical terms\n\n\n\nA survival curve is a formal technical term in statistics, but many other expressions with the same or similar meanings are used, such as survival function, survival rate, overall survival curve, and Kaplan-Meier curve. In fact, each has a slightly different meaning.\n\nAlmost synonymous with survival curve Survival function\nSimilar meaning, but referring more to a value at a specific time point than to a curve Survival rate, survival probability, survival proportion\nSpecifying the statistical method used to estimate the survival curve Kaplan-Meier curve, Kaplan-Meier estimator, Kaplan-Meier estimate, Kaplan-Meier method\nSpecifying the type of endpoint Overall survival curve, disease-free survival curve, 5-year OS, 3-year DFS\n\nIn statistics, the method used for estimation is called an estimator, the resulting value is an estimate, and the target quantity is the estimand. This distinction is important when writing papers: in the Methods section, Kaplan-Meier estimator is natural, whereas in the Results section, Kaplan-Meier estimate is often more appropriate. Instead of “estimator,” the expression “method” (e.g., Kaplan-Meier method) can also be used in a broader sense.\nFinally, special attention should be paid to cumulative incidence curves and cumulative incidence functions. They are often mistaken for survival curves, but they are terms used specifically when competing risks are present and are carefully distinguished by statisticians. In technical terms, it is also referred to as the Aalen-Johansen curve, named after the statisticians. Simply flipping a survival curve upside down and calling it “cumulative” is a conventional expression, not a formal statistical term, and can lead to misunderstanding if not clearly distinguished from cumulative incidence curves.\n\n\n\n\n\n\n\n\nQuiz related to this episode\n\n\n\nThe following four terms are not formal statistical terms, but they are often seen in clinical trial literature. Which of them cannot be considered incorrect?\n\nSample number\nCOX regression\nOS curve\nT-test\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 3\n\nSome papers use “sample number” to mean sample size, but in clinical trials “sample number” would correspond to the number of groups, making this usage incorrect. Cox is a proper name, so only the first letter should be capitalized. “OS curve” can reasonably be interpreted as an overall survival curve, so it is not necessarily incorrect. “T-test” is sometimes used, but since it refers to a different statistical method from the t-test and is not used in clinical trials, it should be considered a typographical error."
  },
  {
    "objectID": "en/publish-a-paper-4.html",
    "href": "en/publish-a-paper-4.html",
    "title": "A Morning Just Before Submission",
    "section": "",
    "text": "Publish a Paper − A Morning Just Before Submission\n\n\n\nEarly-summer rain softened the stillness of the night. After clinic hours, we often spent time at our computers. Tonight again, I sat quietly, looking at the manuscript on the monitor.\nOn the desk, papers and survey forms lay scattered. Beside a note scribbled on a paper napkin, a Rubik’s Cube rested. I reached for the coffee, now lukewarm.\nI write, then stop. I stop, then return.\n\n“Background”\n\nIn this opening section, many papers are cited, their authors’ names listed one after another. They were written in rooms much like this one.\n\n“The aim of this study was…”\n\nSuch a short sentence, and yet now I know how much it must carry. An aim is never a private intention. It must be opened to others, shaped into the form of a research hypothesis.\nIt quietly conveys where I stand in the world, and the direction in which I intend to walk.\nMy eyes move downward.\n\n“Methods”\n\nThis was the section that took the longest to write. All I had to do was put into words what I had already done—yet explaining it clearly, from the beginning, to someone I do not know is not easy.\nI had to fill in what I had taken for granted, and choose words that could be shared and understood in only one way. I write, revise, and read again. I do not dislike this time.\n\n“The main results of the study were…”\n\nThe numbers placed there looked different to me than before. They record what happened to patients. At the same time, they are answers returned from the world to the questions we asked.\nDid we provide good care? Change the question, and the numbers respond differently. They may appear simply arranged on the page, but they speak more than I once realized.\nBecause this study involves patients, its hypothesis inevitably reflects clinical values. It is less about knowing what is “correct,” and more about gaining knowledge that brings us closer to better practice.\nMany things pass unnoticed while we are working, or talking with others over coffee. When I am alone, I understand them more clearly.\nThe coffee had cooled at the edge of the desk. On the monitor, the freshly written Conclusion was displayed.\nI checked each line, making sure it answered the questions we held when we designed the study.\nI nodded slightly, and began typing again—slowly.\n\n\nAcknowledgements\nWe thank an anonymous statistician for thoughtful advice.\n\nAnd that was the morning before submission."
  },
  {
    "objectID": "en/study-design-2.html",
    "href": "en/study-design-2.html",
    "title": "Data Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes",
    "section": "",
    "text": "Study Design II − Data Have Types\n\nKeywords: language & writing, probability model, R simulation, survival & competing risks\n\n\n\n\n\n\n\n\nTo those who started with this episode\n\n\n\n\n\nThis post is the second episode of “a conversation on causality” series. Over a cup of coffee, a clinician daughter and her statistician father build a rough mental map from data types (continuous, binary, count, survival) to common R functions: mean(), t.test(), glm(), fisher.test(), survfit(), and cifplot(). We simulate a small stoma-surgery dataset in R, look at histograms, tables, and survival curves, and end with a short quiz about oncology endpoints and FDA approvals. If you’d like to start from the beginning, you can find the first episode here:\nStudy Design I − A Story of Coffee Chat and Research Hypothesis\n\n\n\n\nFour data types\n\n\nMe: “Okay, coffee’s ready. Can I keep you a bit longer—just a bit?”\n\n\nDad: “If coffee is involved, yes. A warm cup is perfect now that the air’s turning autumn-like.”\n\n\nMe: “You said something earlier that stuck with me: the R function we use depends on the outcome. I didn’t really get that part. In my head, data are just…numbers? What’s there to distinguish?”\n\n\nDad: “They’re all numbers, yes. But for statistics, the type of data matters more than people expect.”\n\n\n\nContinuous data\nBinary and categorical data\nCount data\nSurvival data\n\n\n\nMe: “Continuous data are things we measure, right? Like age or blood pressure. Binary data I get — like ‘with stoma’ vs ‘without stoma’ in my survey.”\n\n\nDad: “Perfect. Count data is when you literally count events, like the number of traffic accidents. Survival data is things like lifespan — time from some starting point until an event, such as death. In your case, that could be time from surgery to returning to work, or time to relapse.”\n\n\nMe: “When you say it like that, they definitely feel like different beasts. But in the R course I took, we just typed whatever they put on the slides — t.test(), glm(), survfit(), all those things felt like magic spells.”\n\n\nDad: “That’s a common side effect of R lectures. Do you have your laptop?”\n\n\nMe: “…Wait, what?”\n\n\nDad: “Your laptop. You brought it, didn’t you? Let’s install RStudio.”\n\n\nMe: “…Well, I did ask for help, so fine.”\n\n\nDad: “In R, for continuous data you often use functions like mean() or t.test().”\n\n\nMe: “Okay…”\n\n\nDad: “To summarize binary data you can use table(). For p-values, fisher.test(). For more complex analyses, regression models like glm(family = binomial). For survival data, you’ll see functions like survfit(), coxph(), and cifplot().”\n\n\nMe: “There is no way I can memorize all that. In class I just typed whatever they put on the slides. Those functions are basically incantations to me.”\n\n\nDad: “You don’t need to memorize them—not all at once, at least.”\n\n\nMe: “Wait, I don’t?”\n\n\nDad: “What matters is being able to picture which functions belong to which type of data. Or even better, imagining which probability distribution is being assumed.”\n\n\nMe: “Probability distribution?”\n\n\nDad: “You learned this as an undergrad, didn’t you? You’ve heard of the normal distribution — and binomial distribution?”\n\n\nMe: “At least that one, yes.”\n\n\nDad: “Almost any statistical method beyond simple description rests on some kind of probability model. Normal distributions for continuous data, binomial distributions for binary data, Poisson distributions for count data. For survival data, there isn’t a single standard model, but the simplest is the exponential distribution. You don’t have to remember the formulas, just the general matching.”\n\n\nMe: “So it’s more about rough matching than exact formulas.”\n\n\n\ncontinuous: normal-ish\n\nyes/no: binomial-ish\n\ncounts: Poisson-ish\nsurvival: time-to-event\n\n\n\nMe: “I don’t know Poisson and exponential. Aren’t those basically curse words?”\n\n\nDad: “Yeah, I agree it doesn’t sound like something humans would use. Statistical terms are often the hardest part. If a word ever feels unclear, feel free to come back to it anytime. Anyway, the key is to learn the patterns—which probability model to use for which data type.”\n\n\nMe: “Uh-huh. And what does that have to do with R?”\n\n\nDad: “Quite a lot. I really want you to remember this, there are two common measures: proportions and rates. We use them all the time, like ‘traffic accident rates’. But in everyday language we don’t distinguish them clearly. In statistics, though, a proportion is the parameter of a binomial distribution, and a rate is the parameter of a Poisson distribution.”\n\n\nMe: “Proportions and rates… aren’t they basically the same thing? I’ve never really distinguished them.”\n\n\nDad: “No, they’re not. A proportion is usually a percentage, say, ‘60% of patients are women’. But consider ‘the annual traffic accident rate in Tokyo’. You wouldn’t naturally express that as a percentage. You’re counting events and dividing by person-time or by years.”\n\n\nMe: “Hmm…go on, professor.”\n\n\nDad: “You don’t need rigid textbook definitions. It’s enough if your brain can think: ‘This looks like continuous data, probably close to a normal distribution, then you’ll use functions in this area,’ or ‘This is 0/1 data, so you’ll look for binomial-type functions.’ If you can connect data types and distributions, R functions become much easier to recall.”\n\n\nMe: “I see. So if I imagine the data type and its distribution, I don’t have to memorize R functions by brute force. That does sound efficient.”\n\n\nDad: “Exactly. Once you have that mental image, when you later read manuals or books, you’ll think, ‘Oh, this is that thing I was imagining,’ and everything clicks together. Okay, let me show you a quick demo in R. We’ll simulate age (continuous), sex and stoma status (binary), and survival time, and run simple analyses. We will use the normal distribution, binomial distribution, and exponential distribution.”\n\n\nMe: “There it is again, the spell-casting.”\n\n\nDad: “Pretty much. For now, type library(ggplot2) and library(cifmodeling). I’ll show you a histogram and Kaplan-Meier curves.”\n\n\nMe: “Fine. I’ll type them with my brain temporarily switched off. That’s how I survived my R class anyway.”\n\n\nDad: “Try not to turn your brain off while I’m teaching you. When you add features to R, you use install.packages() and library(). install.packages() installs a package onto your computer, and library() loads that installed package so you can use it.”\n\n\nMe: “Got it. That actually clears things up a lot. I really did think I had to install it every single time.”\n\n\nDad: “Installing every time is like buying coffee beans every time you brew coffee. No one does that. You buy the beans once and just grind when you drink.”\n\n\n\n\n\n\n\n\nGenerating simulated data\n\n\n\nHere we’ll use R to create a simple dataset and run basic analyses for continuous, binary, and survival data. The theme is a two-group comparison: patients with and without a stoma.\n\nAge: continuous, from a normal distribution using rnorm()\nSex, stoma: binary, from a binomial distribution using rbinom()\nSurvival time: from an exponential distribution using rexp()\n\n\n\n\n\n\n\n\n\nR code and output\n\n\n\n\n\n\nset.seed(46)\n\n# Stoma: 1 = with stoma, 0 = without stoma\nstoma &lt;- rbinom(200, size = 1, prob = 0.4)\n\n# Sex: 0 = WOMAN, 1 = MAN\nsex &lt;- rbinom(200, size = 1, prob = 0.5)\n\n# Age: normal distribution (stoma group slightly older)\nage &lt;- rnorm(200, mean = 65 + 3 * stoma, sd = 8)\n\n# Survival time: exponential distribution\n#   expected survival 10 years (with stoma) vs 15 years (without)\nhazard &lt;- ifelse(stoma == 1, 1 / 10, 1 / 15)\ntime   &lt;- rexp(200, rate = hazard)\n\n# Random censoring: 0 = censored, 1 = event\nstatus &lt;- rbinom(200, size = 1, prob = 0.9)\n\ndat &lt;- data.frame(\n  age    = age,\n  sex    = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n  stoma  = factor(stoma, levels = c(0, 1),\n                  labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n  time   = time,\n  status = status\n)\n\nhead(dat)\n\n       age   sex         stoma      time status\n1 59.19077 WOMAN WITHOUT STOMA 17.939751      1\n2 59.46486   MAN WITHOUT STOMA 18.189251      1\n3 55.34491   MAN WITHOUT STOMA  2.445121      1\n4 60.68207   MAN WITHOUT STOMA 46.737429      1\n5 61.79577   MAN WITHOUT STOMA  0.149128      1\n6 62.84530 WOMAN    WITH STOMA  0.298167      1\n\n\n\n\n\n\n\n\n\n\n\nSummarizing continuous and binary data\n\n\n\nFirst, let’s describe age and sex in the stoma vs non-stoma groups using a histogram and contingency table. You should see that the age distribution for the stoma group is slightly shifted to the right (older on average), because that’s how we simulated it.\n\n\n\n\n\n\n\n\nR code and output\n\n\n\n\n\n\n# install.packages(\"ggplot2\") # if needed\nlibrary(ggplot2)\n\nggplot(dat, aes(x = age, fill = stoma)) +\ngeom_histogram(alpha = 0.5, position = \"identity\", bins = 10) +\nlabs(x = \"AGE\", y = \"FREQUENCY\", fill = \"STOMA\") +\ntheme_minimal()\n\n\n\n\n\n\n\ntable(STOMA = dat$stoma, SEX = dat$sex)\n\n               SEX\nSTOMA           WOMAN MAN\n  WITHOUT STOMA    43  76\n  WITH STOMA       44  37\n\n\n\n\n\n\n\n\n\n\n\nSummarizing survival data with survival curves\n\n\n\nFor survival data, we want to describe how long patients survive without the event. Here we use cifplot() from the cifmodeling package to draw the Kaplan-Meier curves. Event(time, status) tells R which variables represent the time and event indicator. outcome.type = \"survival\" asks for a survival curve. Under our simulation, the non-stoma group should have better survival, so its curve will lie above the stoma group.\n\n\n\n\n\n\n\n\nR code and output\n\n\n\n\n\n\n# install.packages(\"cifmodeling\") # if needed\nlibrary(cifmodeling)\ncifplot(Event(time, status) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA quiz related to this episode\n\n\n\nThis quiz connects the idea of outcomes to real drug approvals in oncology. From 2009 to 2014, 83 drugs in the oncology field were approved by the FDA. Select the correct percentage of these 83 drugs that were approved based on clinical trials using response rate (tumor shrinkage or complete remission) as the primary endpoint.\n\n0～24%\n25～49%\n50～74%\n75～100%\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 2.\n\nAccording to the review by Kim and Prasad (2016), 31 out of 83 products were reported to have been approved based on response rate results. Furthermore, the breakdown of endpoints differs between standard approval and accelerated approval. For standard approval, 48 out of 55 products were evaluated based on overall survival, progression-free survival, or disease-free survival. In contrast, for accelerated approval, the majority of products were based on Phase II trial results where response rate was the primary endpoint.\n\n\n\n\n\nReference\n\nKim C and Prasad V. Strength of validation for surrogate end points used in the US Food and Drug Administration’s approval of oncology drugs. Mayo Clin Proc 2016; S0025-6196(16)00125-7\n\n\n\nEpisodes, glossary, and R-script\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\nStatistical Terms in Plain Language\nstudy-design.R"
  },
  {
    "objectID": "en/study-design-4.html",
    "href": "en/study-design-4.html",
    "title": "A First Step into Survival and Competing Risks Analysis with R",
    "section": "",
    "text": "Study Design IV − A First Step into Survival and Competing Risks Analysis with R\n\nKeywords: bias, R simulation, study design, survival & competing risks\n\n\n\nSurvey items and types of data\n\n\nMe: “Oh wow, that takes me back. Is that the Rubik’s Cube I bought when I was in elementary school? You’re still playing with it? If you’ve got a minute, can I ask you something? Remember the study we talked about on return-to-work among cancer survivors? I’ve drafted a questionnaire to send to patients. Could you have a look? Oh, and the R code you showed me last time really helped—I could kind of picture what the results might look like.”\n\n\nDad: “Let’s see.”\n\n\n\n\nTable 1. My original questionnaire\n\n\n\n\n\n\n\nItem\nResponse\n\n\n\n\nSurvey date\n____ Year ____ Month ____ Day\n\n\nSurgery date\n____ Year ____ Month ____ Day\n\n\nWere you employed before surgery?\nYes ____ / No ____\n\n\nFor those who were employed: Did you resign because of the surgery?\nYes ____ / No ____\n\n\nFor those who resigned: Did you wish to return to work?\nYes ____ / No ____\n\n\nFor those who wished to return: Were you able to return to work?\nYes ____ / No ____\n\n\n\n\n\nDad: “How are you defining the return-to-work proportion?”\n\n\nMe: “What do you mean?”\n\n\nDad: “Just from the questionnaire, I can’t tell whether these questions are enough. Are you trying to find out, between the date of surgery and the date of the survey, whether patients who wanted to return to work actually managed to do so?”\n\n\nMe: “That would be good to know, but among the patients who answer that they don’t want to return, there might be some who gave up because of company policy or other reasons. So when I calculate the return-to-work proportion, I don’t want the denominator to be ‘patients who wished to return to work.’ I’d rather use all patients who had surgery. That feels closer to the real employment situation.”\n\n\nDad: “And do you want to look at whether they returned to work between surgery and the survey date?”\n\n\nMe: “Hmm. The timing of the responses will vary from patient to patient, so I’d rather not use the survey date. How about defining it as ‘return-to-work within 1 year’? Oh—maybe we should also ask them to write down the actual date they returned to work.”\n\n\nDad: “Having the date of return-to-work is a good idea. Then, when you turn return-to-work status into analytic ‘variables’, you can think in terms of two options: categorical data and survival data. Setting that aside for a moment—what will you do if a patient dies after surgery?”\n\n\nMe: “If they die during the hospital stay, I won’t include them in the study population. But it feels strange to exclude deaths from postoperative recurrence from the denominator.”\n\n\nDad: “I agree. Excluding them would introduce bias, because you’d be drifting away from your target population. When you follow cancer patients over time, there are three important points. First, you have to decide what the time origin is. In this case, it would be natural to set the time origin at the date of discharge. Second, you set a target follow-up period and try to collect information as completely as possible up to that point. Missing information becomes a source of bias. Third, you must not exclude events that occur after the time origin.”\n\n\nDefine the time origin.\nSet a target follow-up period and, up to that point, collect information as completely as possible.\nDo not exclude events that occur after the time origin or use them as strata.\n\n\nMe: “Right, I don’t want to discover later that we built bias into the design. Got it.”\n\n\nDad: “Earlier I suggested using the ‘PECO’ elements to structure your clinical question. If P is ‘patients with rectal cancer after curative resection’, then you have to survey that population comprehensively.”\n\n\nMe: “So what exactly are categorical data and survival data?”\n\n\nDad: “We talked about this the other day too. For statistical analysis, the starting point is always the ‘type of data.’ Categorical data and survival data are two examples of data types.”\n\n\nMe: “That was last week, and I’ve been busy, you know.”\n\n\nDad: “I made a few tweaks to your questionnaire, so I’ll use this version to explain it again.”\n\n\n\n\nTable 2A. Questionnaire for survivors\n\n\n\n\n\n\n\nItem\nResponse\n\n\n\n\nSurvey date\n____ Year ____ Month ____ Day\n\n\nSurgery date\n____ Year ____ Month ____ Day\n\n\nDischarge date\n____ Year ____ Month ____ Day\n\n\nDate of return-to-work (post-discharge; only if employed before surgery)\n____ Year ____ Month ____ Day\n\n\nWere you employed before surgery?\nYes ____ / No ____\n\n\nFor those who were employed: Did you resign because of the surgery?\nYes ____ / No ____\n\n\nFor those who resigned: Did you wish to return to work?\nYes ____ / No ____\n\n\nFor those who wished to return: Were you able to return to work?\nYes ____ / No ____\n\n\n\n\n\nTable 2B. Questionnaire for deceased patients\n\n\n\nItem\nResponse\n\n\n\n\nSurvey date\n____ Year ____ Month ____ Day\n\n\nSurgery date\n____ Year ____ Month ____ Day\n\n\nDate of death\n____ Year ____ Month ____ Day\n\n\nWere they employed before surgery?\nYes ____ / No ____\n\n\nDid they return to work after surgery?\nYes ____ / No ____\n\n\n\n*Enter data from medical records\n\n\nDad: “In this setting, categorical data means that you classify patients according to their outcome. You were thinking of using ‘returning to work within 1 year’ as the outcome, right?”\n\n\nMe: “Yes.”\n\n\nDad: “For example, if you label ‘returned within 1 year’ as category 1 and ‘did not return within 1 year’ as category 2, that gives you a type of categorical data called binary data. You can derive it from the questionnaire, and you can calculate the return-to-work proportion.”\n\n\nMe: “Right. As long as we treat deaths within 1 year as ‘no return to work’.”\n\n\nDad: “But when you summarize work status, it’s better not to stick with just two categories. A three-category variable would be more informative. For example:”\n\n\ncategory 1: returned within 1 year\ncategory 2: did not return within 1 year (for reasons other than death)\ncategory 3: did not return within 1 year (because of death)\n\n\nDad: “That gives you a more detailed picture of the outcomes.”\n\n\nMe: “Yes, that makes sense. And survival data was…OS, right?”\n\n\nDad: “Overall survival (OS) is indeed one kind of survival data. The name is a bit misleading, though—there are many other types. In general, survival data are variables that represent the time from the time origin until an ‘event’.”\n\n\nMe: “So return-to-work status can also be treated as survival data?”\n\n\nDad: “It can. In this case, discharge is a practical time origin. For OS or DFS in clinical trials, surgery or registration is more common. For example, if a patient is discharged on April 1 and returns to work on April 30, the survival time is 29 days (or 30 days if you count both endpoints). Written just as a number of days, it doesn’t look any different from ordinary continuous data, but the essence of survival data is the presence of censoring. If a patient has not returned to work by the survey date, there simply is no actual interval from discharge to return to work.”\n\n\nMe: “True, but isn’t that fine as it is?”\n\n\nDad: “When you use statistical software, you need to add one more piece of information: at the time of the survey, the patient had not yet returned to work—that is, follow-up for return-to-work was censored. That is why survival data always come as a pair of variables.”\n\n\nA time variable\nAn event variable\n\n\nDad: “For typical survival data, the event variable is binary and indicates whether the event was observed or censored. The time variable, in this case, would be either ‘time from discharge to return-to-work’ or ‘time from discharge to the survey date’.”\n\n\n\n\n\n\n\n\nEntering survival data\n\n\n\n\n\nBecause survival data consist of a pair of variables, you also need to specify them as a pair when you pass them to R functions. The survival package provides a dedicated input function Surv() for this purpose, which is used by functions such as survfit() and coxph(). The exact input format depends on the package. For example, the mets package defines a separate Event() function. The cifplot() function in the cifmodeling package accepts both Surv() and Event().\n\nlibrary(survival)\nlibrary(cifmodeling)\n\nsurvfit(Surv(time, status) ~ stoma,\n  data         = dat\n)\ncifplot(Surv(time, status) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\ncifplot(Event(time, status) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\n\n\n\n\n\n\nMe: “So if the event variable is binary, that means every patient is in exactly 1 of 2 states: either they returned to work or they were censored. Where do deaths go?”\n\n\nDad: “If you treat it the way I just described, patients who die are grouped under ‘censored’. But there is another way to handle it, called competing risks. Put simply, a competing risk is an event that prevents the event of interest (such as return-to-work) from being observed.”\n\n\nMe: “Ah, so in that sense death is a competing risk.”\n\n\nDad: “Exactly. Survival data are also called ‘time-to-event data’ in English. Events that occur over time aren’t limited to survival and death. Competing risk models were developed to analyze situations like this. In that case, the event variable becomes a three-category variable: event, competing risk, or censoring. The coding looks like this:”\n\n\nEvent variable = 0: censored before the event is observed\nEvent variable = 1: event observed\nEvent variable = 2: competing risk occurs before the event is observed\n\n\nMe: “I think I get it. I’m going to use this revised questionnaire, then.”\n\n\nDad: “Let’s test the idea with a small simulation in R—just enough to see why competing risks matter.”\n\n\n\n\nSurvival Analysis and Competing Risk Analysis\n\n\n\n\n\n\nGenerating simulation data (with relapse)\n\n\n\nLet us now move a little closer to a real clinical research in cancer and compare three outcomes in simulated data: overall survival (OS), relapse-free survival (RFS), and cumulative incidence of relapse (CIR). For CIR, some patients die before recurrence, and we have to decide how to treat those deaths. This is what we call a competing risk.\nThe code below defines a function, generate_data(), that generates three different survival outcomes in R, including both death and relapse. The event for OS is “death”, and the event for RFS is “death or relapse”. For CIR, the event is “relapse”, and death is treated as a competing risk. We will reuse generate_data() and the resulting simulated data in later explanations.\n\nStoma: binary data generated from a binomial distribution (rbinom)\nSurvival time: data generated from an exponential distribution (rexp) (computed from the random variables t_relapse, t_death, and t_censoring)\n\nIn the previous episode, we summarized survival data without competing risks using the Kaplan-Meier curves. In contrast, for competing risks analysis, the appropriate method is not the Kaplan-Meier curves but the Aalen-Johansen curves.\n\n\n\n\n\n\n\n\nR code for generate_data()\n\n\n\n\n\n\ngenerate_data &lt;- function(n = 200, hr1, hr2) {\n  # Stoma: 1 = with stoma, 0 = without stoma\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  # Sex: 0 = WOMAN, 1 = MAN\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  # Age: normal distribution (stoma group slightly older)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  \n  # Hazards for relapse and death (larger hazard implies earlier event)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1 * 0.10, 0.10)\n  hazard_death     &lt;- ifelse(stoma == 1, hr2 * 0.10, 0.10)\n  hazard_censoring &lt;- 0.05\n  \n  # Latent times to relapse, death, and censoring\n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)\n  t_death     &lt;- rexp(n, rate = hazard_death)\n  t_censoring &lt;- rexp(n, rate = hazard_censoring)\n  \n  # Overall survival (OS)\n  # status_os = 1 → death (event of interest)\n  # status_os = 0 → censored\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = death, 0 = censored\n  \n  # Relapse-free survival (RFS)\n  # status_rfs = 1 → relapse or death whichever comes first (event of interest)\n  # status_rfs = 0 → censored\n  time_rfs   &lt;- pmin(t_relapse, t_death, t_censoring)\n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1  # relapse\n  status_rfs[time_rfs == t_death   & time_rfs &lt; t_censoring] &lt;- 1  # death\n  \n  # Cumulative incidence of relapse (CIR)\n  # status_cir = 1 → relapse (event of interest)\n  # status_cir = 2 → death as competing risk\n  # status_cir = 0 → censored\n  \n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1\n  status_cir[time_cir == t_death   & time_cir &lt; t_censoring] &lt;- 2\n  \n  data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n}\n\n\n\n\n\n\n\n\n\n\nKaplan-Meier curve for OS\n\n\n\nOS and RFS are ordinary survival data, so as before we can use the cifplot() function from the cifmodeling package to draw Kaplan-Meier curves. Let us start with OS.\n\n\n\n\n\n\n\n\nR code and output\n\n\n\n\n\n\nset.seed(46)\ndat &lt;- generate_data(hr1 = 2, hr2 = 1.5)\n\n# devtools::install_github(\"gestimation/cifmodeling\") # if needed\nlibrary(cifmodeling)\ncifplot(\n  Event(time_os, status_os) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKaplan-Meier curve for RFS\n\n\n\nNext is RFS. Apart from the variables specified inside Event(), the code is unchanged.\n\n\n\n\n\n\n\n\nR code and output\n\n\n\n\n\n\ncifplot(\n  Event(time_rfs, status_rfs) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Relapse-free survival\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAalen-Johansen curve for CIR\n\n\n\nIn the code below, the competing risk is encoded via Event(time_cir, status_cir):\n\nstatus_cir = 1: event of interest (relapse)\nstatus_cir = 2: competing risk (death without prior relapse)\nstatus_cir = 0: censoring\n\nBy additionally specifying outcome.type = \"competing-risk\", we draw the Aalen-Johansen curves.\n\n\n\n\n\n\n\n\nR code and output\n\n\n\n\n\n\ncifplot(\n  Event(time_cir, status_cir) ~ stoma,\n  data         = dat,\n  outcome.type = \"competing-risk\",\n  label.y      = \"Cumulative incidence of relapse\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nMe: “Isn’t the Aalen-Johansen curve just the Kaplan-Meier curve flipped upside down on the y-axis?”\n\n\nDad: “On the graph they can look almost identical, so it’s natural to think that. But I’d still like you to keep them distinct in your mind.\n\nA survival curve (Kaplan-Meier) and a cumulative incidence curve (Aalen-Johansen) are different statistical procedures. When there are competing risks, you should use the Aalen-Johansen curve.\n\nBy the way, earlier you said you wanted to use ‘cumulative incidence of relapse’ rather than ‘relapse-free time’. That’s because, in technical terms, the cumulative incidence curve is synonymous with the Aalen-Johansen curve. In principle, you could analyze CIR with a Kaplan-Meier curve. In that case, deaths without relapse would be coded not as a competing risk (status_cir = 2) but as censoring (status_cir = 0). But in reality, death is a different outcome from end of follow-up or loss to follow-up. That’s why treating it as a competing risk is the appropriate approach.”\n\n\nMe: “Then is it wrong to analyze RFS where both death and recurrence are treated as events?”\n\n\nDad: “No, of course not. But remember that the difference between RFS curves reflects not only recurrence but also deaths from other causes. So, as we’ve just discussed, you need to use OS, RFS, and CIR in different ways, depending on what you want to learn.”\n\n\n\n\n\n\n\n\nA quiz related to this episode\n\n\n\nCDISC ADaM ADTTE (Analysis Data Model for Time-to-Event Endpoints) is a standard format for clinical trial data used by pharmaceutical companies. In this standard, the variable that indicates censoring is called CNSR. Which of the following codings represents censoring?\n\nCNSR = 0\nCNSR = 1\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 2.\n\nIn ADaM ADTTE, CNSR is the censoring indicator: 0 = event, 1 (or &gt;0) = censored. In many R workflows, including Event() and Surv(), the default convention is event = 1, censoring = 0. You therefore cannot use CNSR directly as an event indicator.\n\n\n\n\n\nEpisodes, glossary, and R-script\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\nStatistical Terms in Plain Language\nstudy-design.R"
  },
  {
    "objectID": "en/truth-2.html",
    "href": "en/truth-2.html",
    "title": "What Could Have Happened",
    "section": "",
    "text": "Truth II − What Could Have Happened\n\nKeywords: causal model, language & writing, probability model, research hypothesis\n\n\n\nWhat would have happened if we had chosen differently?\n\n\nDad: “Let me talk about a concept you need in order to understand what adjusting for confounding really means. Think back to the examples we’ve used so far—surgical procedures for gastric cancer, whether or not to create a stoma, even coffee consumption. What we actually want to know in all of these cases is the same, right? What would have happened if we had made a different choice? For example, would the patient have survived if a different surgical procedure had been chosen?”\n\n\nMe:“Yes, that’s true.”\n\n\nDad: “Unfortunately, you can’t get to that truth by staying on the rails of regression analysis alone. You have to start not from a probability model, but from the question: What would have happened if we had changed the cause? Causal inference is a framework designed to answer exactly that question.”\n\n\nMe:“Huh? Are you saying I need to redo the analysis using a completely different method?”\n\n\nDad: “No, no. I’m talking at an abstract level for now. Think about a randomized clinical trial comparing an active treatment with a placebo. What you want to know is the difference between the outcome if everyone received the active treatment and the outcome if everyone received the placebo, right? If the endpoint is overall survival, that difference shows up as a difference between survival curves. That difference is the causal effect.”\n\n\nMe: “Hmm…I see. In JCOG9502, for example, the question was whether to choose procedure TH or LTA for gastric cancer surgery. Once the standard treatment is decided, everyone would receive that procedure. So the difference between the survival curves shown in the paper corresponds to the causal effect. And now that you mention it, there’s no probability distribution or regression model explicitly appearing there.”\n\n\nDad: “Exactly. But your cancer survivor survey is an observational study—it’s not randomized. Even if you want to think about it the same way as JCOG9502, the outcome ‘what would have happened if a stoma had not been created’ doesn’t actually exist. It’s a hypothetical scenario. That’s why, in observational studies, the only option is to predict these unobserved outcomes using covariates and regression models. We distinguish these from observed outcomes and call them potential outcomes. They can’t be observed, but they can be defined medically and logically—as ‘another possible outcome.’”\n\n\nMe: “But what’s the point of defining something that doesn’t even exist?”\n\n\nDad: “That’s not the right way to think about it. First you define what causal effect you want to know, and then you collect data to estimate it. What you can see is just one face of a six-sided Rubik’s Cube. Even if a potential outcome is drawn on another face, you can’t observe it. But imagine preparing many Rubik’s Cubes with the same structure and placing them on a table in random orientations. You only see one face of each cube, but you can still infer what pictures might be on the other faces. That’s essentially what a randomized clinical trial does.”\n\n\nMe: “This is getting complicated. What exactly is different between JCOG9502 and my survey?”\n\n\nDad: “The biggest difference is obvious: randomization. Randomized clinical trials are designed from the start to answer the question, ‘What happens if we intervene?’ The target population is clearly defined, interventions are randomly assigned, and bias is minimized. In observational studies like your cancer survivor survey, no matter how carefully you think through the research hypothesis or the PECO, some ambiguity remains—especially about who exactly counts as Patients and Controls. You also can’t be sure whether you’ve measured enough confounders to adequately adjust for bias and ensure comparability.”\n\n\nMe: “I see.”\n\n\nDad: “Let’s get back to the main point. In the Rubin causal model, before thinking about analytic models or confounding adjustment, you first define the potential outcomes and then reason about the differences between them.”\n\n\nThe complementary roles of probability models and causal models\n\nMe: “I still don’t quite get it. What are we actually looking at when we interpret results from generalized linear models or Cox regression? Aren’t regression coefficients different from causal effects?”\n\n\nDad: “You could say that a single number carries two or even three layers of meaning. At the root of it, probability models and causal models form a kind of two-story structure.”\n\n\nProbability model: a structure that describes how the observed data are generated\nCausal model: a structure that represents what would have happened if the cause had been changed, both in the observed world and in unobserved worlds\n\n\nDad: “This is a creative hierarchical relationship: behind the generation of data lies a causal model. You could even say that data are measurements of phenomena that arise according to a causal structure. And as we said earlier, potential outcomes themselves can’t be observed.”\n\n\nMe: “Right.”\n\n\nDad: “So data are like shadows. What you really want to see is just a little beyond them.”\n\n\nMe: “When you put it that way, it does feel like the truth of causal relationships exists before the data are generated. I don’t quite feel it, but I think I understand. Still, if that’s the case, why didn’t you teach causal models from the beginning instead of logistic regression?”\n\n\nDad: “Hm. That needs a bit more explanation. It’s not that logistic regression or stratified analysis should never be used. They’re methods—like ways of solving a Rubik’s Cube. They’re not the same thing as the structure of the cube itself. What I wanted you to understand here is that, to interpret regression coefficients or odds ratios correctly as evidence about causal relationships, you need a causal model.”\n\n\nMe: “You’re a specialist, so you don’t notice this, but for me, both logistic regression and the Rubin causal model are completely new ideas. The Rubin causal model sounds like analyzing what would have happened to a given patient if we had treated them differently, right? That seems like something you could do by combining anatomy, pathophysiology, pharmacology, and clinical experience.”\n\n\nDad: “Essentially, yes. But that approach focuses on cause and effect for individual patients. Causation at the level of individual events is called token causation, and there’s still a gap between that and causation as a general law.”\n\n\nMe: “Token? That word doesn’t really click for me.”\n\n\nDad: “For example, asking ‘Did this drug save that particular patient?’ is close to token causation.”\n\n\nMe: “Ah, I see. I get that both individual events and general laws matter.”\n\n\nDad: “Clinical trials and surveys deal with populations, not individuals. By analyzing populations statistically, we try to uncover general regularities. Probability distributions and regression models provide the tools to do that—that’s what we talked about before. Probability models and causal models serve different roles.”\n\n\nMe: “And we’re back to the hard stuff again. Could I get another cup of coffee?”\n\n\n\n\n\nNext episodes\n\nWhat Data Cannot Tell Us\nWhat Could Have Happened\nWhat Is It That You Want to Know?"
  },
  {
    "objectID": "jp/causal-inference-1.html#ランダム化の下で第3の因子はどうする",
    "href": "jp/causal-inference-1.html#ランダム化の下で第3の因子はどうする",
    "title": "Three-Variable DAGs: The Smallest Building Blocks of Causal Structure",
    "section": "ランダム化の下で第3の因子はどうする？",
    "text": "ランダム化の下で第3の因子はどうする？\n\nお父さん「この考え方はランダム化臨床試験でも応用できる。JCOG9502っていう臨床試験の論文を読んだことがあったよね（Sasako, et al. 2006）。あれは、手術方法（TH群またはLTA群）を比較して全生存期間に差があるかを調べた研究だった」\n\n\n私「うん。だけど、ランダム化しているから第3の因子ってないんじゃない？だってTH群とLTA群をランダムに割付けてるもの」\n\n\nお父さん「正解。でも、この試験ではハザード比を求めるとき、いくつかの変数を調整している。使ったのはロジスティック回帰じゃなくてCox回帰だけどね。」\n\n\n私「そうなのか。じゃあ調整した方がいいのかな、さっきの”共通原因だけ調整”の話と矛盾するけど」\n\n\nお父さん「ここでもDAGを使って考えられる。Eを手術方法、Dを全生存期間、Cをステージとすると、図はこうなる。試験結果では有意な関連はなかったけど、わかりやすいようにE→Dの矢印は残したよ」\n\n\n\n私「やっぱり共通原因ではないね」\n\n\nお父さん「そう。ステージは交絡因子ではないから、調整する必要はなかった。でも、Cox回帰によって全生存期間をモデル化するとしたらどうかな。がんのステージはもちろん予後に関係するから、モデルに入れたくならない？」\n\n\n私「それは入れたくなる。ステージだけじゃなくてリンパ節転移とか、残存腫瘍の有無とかもモデル化したくなる」\n\n\nお父さん「この図の場合、Cは交絡因子じゃないから、調整しなくてもバイアスは生じない。でも、真に近いモデルを当てはめて、ハザード比の推定精度を高めるという観点からは、Cを調整してもいい」\n\n\n交絡因子を調整する目的: 因果効果推定におけるバイアス補正\n回帰モデルに共変量を加える目的: 確率モデルのデータへの当てはまりの改善（結果的にバイアス軽減につながる）\n\n\nお父さん「じゃあ、JCOG9502の論文を読んで、調整した変数をリストアップしてよ」\n\n\n私「ほい」\n\n\nステージ\nBorrman型\n残存腫瘍\nリンパ節転移（傍大動脈）\nリンパ節転移（縦隔）\nリンパ節転移（陽性数）\n洗浄細胞診\n\n\nお父さん「このうち術前に確定するものと術中・術後変数はどれなの？術中・術後変数の変数はさっきのDAGとは違い手術の影響を受けるから、E→Cの矢印が必要だよね」\n\n\n私「そうだね、残存腫瘍、リンパ節転移、洗浄細胞診あたりは手術の途中から後に決まるかな。特に残存腫瘍なんかは」\n\n\nお父さん「じゃあ残存腫瘍を考えよう。Eを手術方法、Dを全生存期間、Cを残存腫瘍とするとDAGはこうなる」\n\n\n\n私「中間媒介因子だね」\n\n\nお父さん「うん。DAGを用いて交絡因子を選ぶとしたら、残存腫瘍は交絡因子でないから、Cox回帰で調整しないことになる。この研究では、アウトカムを正しくモデル化するという観点から調整変数を選んだみたい。でも中間媒介因子は調整しない方が、純粋に術式の違いだけがもたらす因果効果が得られるから結果の解釈はしやすい」"
  },
  {
    "objectID": "jp/causal-inference-3.html",
    "href": "jp/causal-inference-3.html",
    "title": "DAGs and Conditional Distributions: Two Languages for the Same Structure",
    "section": "",
    "text": "Causal Inference III − DAGs and Conditional Distributions: Two Languages for the Same Structure\n\nKeywords: bias, causal model, confounding & collapsibility, probability model\n\n\n\n調整すべき因子かどうかってどうやって見分けるの？\n\n\nお父さん「まだ話は続くから、コーヒー淹れなおそうか。ここからの話題はDAGと確率変数の関係について。まず、確率の基本について思い出してみよう」\n\n\n\n\n\n\n\n\n確率の復習\n\n\n\n同時確率と条件付確率\n複数の事象を扱うとき、事象が同時に起こる確率（同時確率）と、順番に起こる確率（条件付確率）を区別することが大切です。たとえば2種類の事象AとBがあったとしましょう。「AまたはBが起きる」という事象は、和集合\\(A\\cup{B}\\)で表します。「AかつBが起きる」という事象は、積集合\\(A\\cap{B}\\)で表します。\n\n\n同時確率は、AとB両方が同時に起きる確率のことです。集合の記号を用いると、\\(\\mathrm{Pr}(A\\cap{B})\\)と書くことができます。\n条件付確率は、先にどちらかの事象が起きて、その結果を知った後に、別の事象が起きる確率のことです。事象Bが起きたことを条件付けた下で事象Aの起きる確率は、AとBの積事象の確率を、Bが起きる確率で割ったもので表すことができます。\n\\(\\mathrm{Pr}(A|B)=\\frac{\\mathrm{Pr}(A\\cap{B})}{\\mathrm{Pr}(B)}\\)\nベン図で表すなら、この確率の分母は集合Bに、分子は積集合\\(A\\cap{B}\\)に対応します。また、上の式を変形することで、同時確率と条件付確率に、\\(\\mathrm{Pr}(A\\cap{B})=\\mathrm{Pr}(A|B)\\mathrm{Pr}(B)\\)という関係があることがわかります。\n\n独立性と条件付き独立性\n定義をきちんと思い出してほしいことがもうひとつあります。それは独立性です。事象AとBが独立であるとは、積集合の確率が、それぞれの事象の確率の積と等しいことと定義されます。\n\\(\\mathrm{Pr}(A\\cap{B})=\\mathrm{Pr}(A)\\mathrm{Pr}(B)\\)\n事象AとBに加えて、第3の事象Cがあるとき、Cで条件付けたAとBの同時分布を考えることができますよね。この分布における独立性を、「Cで条件付けた独立性」や「条件付独立性」といいます。条件付独立性もまた、積集合の確率が、それぞれの事象の確率の積と等しいことと定義することができます。\n\\(\\mathrm{Pr}(A\\cap{B}|C)=\\mathrm{Pr}(A|C)\\mathrm{Pr}(B|C)\\)\n\n\n\n\nお父さん「準備が整ったので、DAGと確率変数の関係について説明しよう」\n\n\n私「ふむふむ」\n\n\nお父さん「Aの確率分布がBに依存することを、矢印で表すことにする。つまり、Bで条件付けたAの確率は、B→Aで表される。逆に、AとBが独立なら、矢印はない。このルールを使えば、DAGを条件付確率と対応付けることができそうでしょ。そうすると独立性や相関性について考えることができる」\n\n\n私「確率分布って正規分布とかそういうの？」\n\n\nお父さん「そうきたか。えっとね、正規分布は条件付確率じゃない。でも、たとえばロジスティック回帰だったら、条件付確率を表すから、それをイメージしてもいい。ここでは具体的な確率分布を意図しているわけじゃなくて、一般的な話をしてるんだけどね」\n\n\n私「ふーん」\n\n\nお父さん「確率変数によって別の確率変数が影響を受けるためには、なんらかの関連が必要だよね」\n\n\n私「そりゃそうだ」\n\n\nお父さん「統計学では、一般に、それは条件付確率だったり、相関だったりする。一方で、DAGではそれをグラフ上の有向パスで表している。胃がんの例で用いたDAGに、このルールを適用してみてよ。たとえばAからDに入る矢印はないでしょ。このことは、A以外の変数であるB、C、Eで条件付けると、DはAと独立という意味になる」\n\n\n私「えーっと、Aは性格、Dは胃がん発生だっけ。年齢も、体質も、ピロリ菌除菌の有無も同じだったら、性格に関係なく、胃がんリスクは等しいと仮定しているって意味なのかな？」\n\n\nお父さん「そういうこと。次に、DAG全体について考えてみてよ。さっきのグラフでは、AからB、BからA、AからD、BからEへの矢印はないよね。このことは、AはBに直接影響せず、BはAに直接影響せず、AはDに直接影響せず、BはEに直接影響しないという仮定を表している。もっといえば、これは、さらに、AがBを介して伝わるDへの効果はない、という意味にもなる。このような依存関係を条件付分布で表すと、以下の5つの式のようになる。これがさっきのDAGに対応する確率分布だよ」\n\n\\(\\mathrm{Pr}(A|B,C,D,E)=\\mathrm{Pr}(A)\\)\n\\(\\mathrm{Pr}(B|A,C,D,E)=\\mathrm{Pr}(B)\\)\n\\(\\mathrm{Pr}(C|A,B,D,E)=\\mathrm{Pr}(C|A,B)\\)\n\\(\\mathrm{Pr}(D|A,B,C,E)=\\mathrm{Pr}(D|B,C,E)\\)\n\\(\\mathrm{Pr}(E|A,B,C,D)=\\mathrm{Pr}(E|A,C)\\)\n\n私「…。すまん、気を失ってた。なんだか具体性がなくて、それでって思っちゃうよ。話の終着点がみえない」\n\n\nお父さん「そっか。ここまでの話ではね、DAGと条件付確率を対応付けるルールを説明したかったんだ。簡単にいうと、条件付けの方の変数から、条件を付けられる変数の方に、矢印が入るようなルールで、DAGと条件付確率を結びつけることができる。このルールを踏まえて、合流点の意味を考えてみてよ。この図でEとDに相関はある？相関はない？」\n\n\n\n私「じゃあもうちょっとだけ話に付き合ってあげる。うーんと。この図にはE→CとD→Cがある。これって、\\(\\mathrm{Pr}(C|D,E)\\)って意味だっけ？」\n\n\nお父さん「そうだったね」\n\n\n私「さらに、EとDに入る矢印はない。つまり、CとDとEの確率分布は、それぞれ\\(\\mathrm{Pr}(C|D,E)\\)と\\(\\mathrm{Pr}(D)\\)と\\(\\mathrm{Pr}(E)\\)ってことになる。でもここからがわかんないな」\n\n\nお父さん「確率の復習で述べた同時分布と条件付確率の関係を思い出してみて。同時確率は、\\(\\mathrm{Pr}(C,E,D)=\\mathrm{Pr}(C|D,E)\\mathrm{Pr}(D)\\mathrm{Pr}(E)\\)と表されるでしょ。この式がポイントなんだ。これって、EとDは独立という意味でしょ」\n\n\n私「うん。確率分布が積で書けてるからね」\n\n\nお父さん「さらに、この図は、最初に示した合流点の図とは違って、E→Dはない。つまり、曝露変数とアウトカムに因果関係はない状況を想定したものといえる。っていうことはさ。Cについてなにも操作しなくても、EとDに相関があれば因果関係があるし、相関がなければ因果関係はないってことになるでしょ。相関があるかどうかは、曝露変数EとアウトカムDのデータを集めれば、確認できるよね」\n\n\n私「なんとなくゴールが見えてきた。この図みたいにCが合流点だったら、調整なんかせずにEとDの相関を調べればいいってことね」\n\n\nお父さん「簡単にいうとそういうこと。合流点があると、変数間の相関関係がトリッキーになるんだ」\n\n\n\n\n\n\n\n\n合流点の性質\n\n\n\n合流点を含むパスは相関を生じさせない\n合流点という名前は、有向パスが合流するノードという意味に由来します。パスの上に合流点が1つ以上あるとき、合流点からの影響は別のノードへ伝わりません。このことを、合流点があるとそのパスはブロックされる、という言い方をします。逆に合流点が含まれないとパスはブロックされません。実際、合流点を含むパスが確率変数同士を結びつけても、それだけでは相関は生じません。\n合流点は調整すべきではない\n上で述べた性質を踏まえて、下に示すDAGについて考えてみてください。結論から先に言うと、この場合もEとDは独立ですが、条件付けによって相関が生じます。\nCで条件付けたとき、つまりCを特定の値に固定すると、なにが起きるでしょうか。Cの値が固定されると、A→Cのパスがあるため、Cの影響でAの分布が変化します。さらに、B→Cのパスがあるため、Bの分布も変化します。\n次に問題になるのは、このDAGにA→CとB→Dというパスがあることです。AとBの確率分布が変化すると、A→CとB→Dのパスによって、EとDに同時に影響します。そうすると、Cを固定することによって、E-A-C-B-Dというパスを通じて、EとDに相関が生じることになります。\nまとめると、以下のように、合流点を含むパスは、共通原因・中間媒介因子しか含まないパスとは逆の性質を持っています。\n\n合流点があるとそのパスはブロックされる。合流点を1つでも含むパスは相関を生じさせない\n合流点を交絡因子として調整すると、もともと相関がなかったとしても、相関が生じる\n\n\n\n\n\n\n\n\n\n\n合流点とブロックの関係\n\n\n\n\n\nこの表は、原因から結果までのパスを、有向か無向か、合流点をいくつ含んでいるかに従って、4分類して、パスの性質を整理したものです。すでに述べたように、調整するかどうか検討の候補になるのは、原因から結果までの無向パスです。もし、無向パスが合流点を含まないなら、パス上のどこかの変数を調整しない限り、そのパスはブロックされません。言い換えると、パス上の変数を調整し、このパスをブロックすることで、バイアスを防ぐことができるかもしれません。無向パスが合流点を1つ含むとき、調整しなくてもこのパスは合流点でブロックされますが、合流点のみを調整すると、ブロックが解けてしまいます。ただし、非合流点を調整すると、合流点を調整したとしても、そのパスはブロックされます。合流点を1つ以上含む場合も、考え方は同じです。調整していない合流点があるか、非合流点を調整すると、このパスはブロックされます。しかし、すべての合流点のみを調整すると、ブロックが解けてしまいます。\n\n\n\n\n\n\n\n\n\n調整しないとき\nパス上の変数を調整したとき\n\n\n\n\n原因から結果までの有向パス\nブロックされていない（定義から合流点を含まない）\n調整しなくてよい\n\n\n原因から結果までの無向パス（合流点を含まない）\nブロックされていない\n調整によりブロックされる\n\n\n原因から結果までの無向パス（合流点1つ含む）\n合流点でブロックされる\n(1)合流点のみ調整するとブロックが解けてしまうが、(2)非合流点を調整すると（合流点を調整したとしても）ブロックされる\n\n\n原因から結果までの無向パス（合流点1つ以上を含む）\n合流点でブロックされる\n(1)すべての合流点のみを調整するとブロックが解けてしまうが、(2)調整していない合流点があるとブロックされ、(3)非合流点を調整してもブロックされる\n\n\n\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nこのDAGの解釈として正しいのはどちらでしょうか。\n\nEとDに相関がある\nEとDは独立\n\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は1です。\n\nこのDAGは、\\(\\mathrm{Pr}(E|C)\\)と\\(\\mathrm{Pr}(D|C)\\)を意味しています。そのため、どう変形しても、EとDの同時確率を\\(\\mathrm{Pr}(E)\\mathrm{Pr}(D)\\)という積の形で表すことができません。つまり、EとDを結ぶ直接の矢印はないにもかかわらず、EとDは相関しています。\n別の回で扱ったコーヒーとすい臓がんの例で、喫煙によって見かけの相関が生じていたことを覚えていますか？喫煙は、上のDAGにおけるC（共通原因）に相当します。\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nピロリ菌と胃がんの因果関係を表すDAGをもう一度示します。このDAGにおいて、交絡因子として調整すべき変数の集合として正しいのは、次のうちどれでしょうか。\n\nB\nC\nAとB\nAとC\n\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は4です。\n\nこのDAGは、上のクイズで扱ったDAGにパスE→Dを加えたものなので、調整すべき交絡因子は同じです。そして、先ほど考えたように、Cは合流点でもあり、共通原因でもあります。したがって、Aだけ、Bだけ、AとBだけを調整すると、パスE←C→Dによる疑似相関が残ってしまいます。さらに、Cは合流点なので、調整するとパスE←A→C←B→Dによる相関が生じてしまいます。\n結論をいうと、パスE←A→C←B→Dをブロックするため、Cに加えて、AまたはBを調整する必要があります。\n\n\n\n\n\n文献\n\nGreenland S, Pearl J, Robins JM. Causal diagrams for epidemiologic research. Epidemiology 1999;10(1):37-48\n\n\n\n次のエピソード\n\nA Circle, an Equation, and a Cylinder\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nThree-Variable DAGs: The Smallest Building Blocks of Causal Structure\nA Subtle Distinction between Common Causes and Confounders\nDAGs and Conditional Distributions: Two Languages for the Same Structure\nA Circle, an Equation, and a Cylinder\nBackdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias\nVolatility, Uncertainty, Complexity, and Ambiguity in Causal Inference\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\nEffects and Time I\nAdjusting for Bias I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/causal-inference-5.html",
    "href": "jp/causal-inference-5.html",
    "title": "Backdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias",
    "section": "",
    "text": "Causal Inference V − Backdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias\n\nKeywords: bias, causal model, confounding & collapsibility, probability model\n\n\n\nブロックの意味\n\n\n私「この前の続きをやろうよ、お父さん。DAGを説明してくれたときにさ、ブロックって用語が出てきたでしょ。合流点がパスをブロックするとか」\n\n\nお父さん「出てきたね」\n\n\n私「あれって、因果の流れが止まるって意味だよね」\n\n\nお父さん「うーん、その言い回しは厳密じゃない気がするなあ。ブロックは、DAG上のパスの性質について述べたもので、因果関係とは直接関係ない。パスが合流点を含んでいたり、非合流点を交絡因子として調整したりすることを指すんだけど」\n\n\n私「合流点があると、そのパスはなにもしなくてもブロックされる。非合流点については、調整するとパスがブロックされるってことね」\n\n\nお父さん「うん。専門的には、パスをブロックすると、ノードとノードを”有向分離”できるっていうのがポイントなんだけどなあ。有向分離の定義にも触れておいた方が誤解がなさそうだね」\n\n\n\n\n\n\n\n\n有向分離\n\n\n\nDAG上に、異なるノードを要素とする3つの集合があるとし、それぞれをA、B、Cと表します。以下の2条件を満たすとき、CはAとBを分離できる構造になっています（Greenland 1999）。これを有向分離（d-separation）といいます。\n\nAとBを結ぶ合流点を含まないすべてのパスは、Cの要素を含んでいる\nCに、AとBを結ぶパス上の合流点が含まれているとする。このとき、合流点を調整することでAとBを結ぶパスが生じたとしても、そのパスはCの別の要素を調整することでブロックできる\n\n\n\n\n\n私「話がややこしくなってきた」\n\n\nお父さん「そうでしょ。ノードの数が増えると、ノードの集合を考えないといけなくなって、定義が複雑になっちゃう。だから単純なケースで意味を確かめよう。この3つのDAGで、CはEとDを有向分離すると思う？」\n\n\n\n私「まず、EとDを結ぶパスはどのDAGもひとつ。上の2つのDAGは合流点を含んでいないし、パス上にCがある。だから有向分離してるはず。一番下はどうだろう。Cは合流点だし、パスE-C-Dは、別の要素で遮断できないよね。だから有向分離の条件に当てはまらない」\n\n\nお父さん「その通り。共通原因や中間媒介因子で調整するとパスがブロックされるとか合流点で調整すると、パスがブロックされなくなるっていうことを正確に表現すると、上の定義になるってことがわかったでしょ。もう少しDAGが複雑になると、この定義のよさがわかると思う。このDAGで、EとDを有向分離するのは、どのノードの集合だろう」\n\n\n\n私「合流点はないよね。だから有向分離するのはAとC？」\n\n\nお父さん「それだけじゃないよね。Aだけ、またはCだけでも、有向分離の条件を満たすでしょ」\n\n\n私「確かにそうね。ということは、AとCのどちらかのデータを取っておけば、交絡を調整できるってこと？」\n\n\nお父さん「そういうこと。じゃあ次のDAGについて考えようか」\n\n\n\n私「まだやるの？こっちから話しかけといてわるいけど、これで最後ね、お父さん。えっと、この図を考えればいいのね。AとBはそれぞれ有向分離するんじゃない？Cは合流点だから、有向分離できない」\n\n\nお父さん「そこまでは正しい。だけど有向分離できるのはそれだけじゃない。AとC、またはBとCはどうだろう。Cは合流点だけど、AまたはBによってパスE←A→C←B→Dは遮断できるでしょ」\n\n\n私「なるほど、二つ目の条件を使ったわけだ。丁寧に説明してくれたおかげで、有向分離がブロックの進化系っていうのは分かったつもりだけど。どういう意味があるの、これ？」\n\n\nお父さん「今回の話は、ブロックをちゃんと説明するっていうのが目的だったんだけど、ぴんとこなかったかなあ。さっきのDAGについていえば、有向分離できる変数の集合を探すことで、バイアスを防げる交絡因子の組み合わせを見つけられるっていう話の流れだったんだけど」\n\n\n私「ふーん。どこが分かんないのかも分からない感じになっちゃった。ひとりで考えてみる」\n\n\n\n\n\n\n\n\n有向分離と条件付独立性\n\n\n\nDAGを用いて、CがAとBを有向分離することが確認できたとします。そのとき、確率変数Cを与えた下で、AとBが条件付独立ということもわかります（Pearl 1995）。\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nこのDAGの解釈として正しいのはどちらでしょうか。\n\nCを与えた下で、EとDは条件付独立である\nCを与えても、EとDの間には相関がある\n\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は2です。\n\nパスE←C→DはCで遮断できますが、パスE→Dは遮断できません。したがって、CではEとDを有向分離できません。ただし、この場合には、有向分離できない理由は、EとDを結ぶ直接の因果関係が残ってしまうことであるという点に注意してください。EのDへの効果を推定するときには、（パスE→Dがあるかどうかにかかわらず）Cを調整すべきです。\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nこのDAGの解釈として正しいのはどちらでしょうか。\n\nCで条件付けないとき、EとDは独立である。また、Cを与えた下でも、EとDは条件付独立である\nCで条件付けないとき、EとDには相関がある。一方で、Cを与えた下で、EとDは条件付独立である\nCで条件付けないとき、EとDは独立である。一方で、Cを与えると、EとDの間には相関がある\nCで条件付けないとき、EとDには相関がある。また、Cを与えても、EとDの間には相関がある\n\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は4です。\n\nこの場合、最初のクイズとは違って、EとDを結ぶ直接のパスはありませんが、Cは合流点という問題があります。そのためCで調整すると、E←A→C←B→Dというパスが生じてしまい、やはりCでEとDを有向分離することはできません。\n\n\n\n\n\n文献\n\nGreenland S, Pearl J, Robins JM. Causal diagrams for epidemiologic research. Epidemiology 1999;10(1):37-48\nPearl J. Causal diagrams for empirical research. Biometrika 1995; 82(4): 669-88\n\n\n\n次のエピソード\n\nVolatility, Uncertainty, Complexity, and Ambiguity in Causal Inference\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nThree-Variable DAGs: The Smallest Building Blocks of Causal Structure\nA Subtle Distinction between Common Causes and Confounders\nDAGs and Conditional Distributions: Two Languages for the Same Structure\nA Circle, an Equation, and a Cylinder\nBackdoor Paths, Block, and d-Separation: A Clue for Adjusting for Bias\nVolatility, Uncertainty, Complexity, and Ambiguity in Causal Inference\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\nEffects and Time I\nAdjusting for Bias I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/effects-1.html",
    "href": "jp/effects-1.html",
    "title": "Silent Confusions Hidden in Percentages",
    "section": "",
    "text": "Effects and Time I − Silent Confusions Hidden in Percentages\n\nKeywords: effect measure, language & writing, observational study\n\n\n\n\n\n\n\n\n前回までのあらすじ\n\n\n\n\n\nはじめて研究に取り組む娘と統計家の父。父に研究仮説は”PICO”を”PECO”で整理するといいとアドバイスされ、医師である娘は、がんサバイバーにおけるストーマ造設と復職状況の関係を調査することに決める。それからというもの、父は娘に統計の話をふるチャンスをうかがっていた。\n\n\n\n\n95%って聞いたら100人いたら95人に効くって思わない？\n\n\nお父さん「あれ、お風呂あがったの。コーヒーでも淹れようか」\n\n\n私「カフェラテ」\n\n\nお父さん「いつものやつ？あれはカフェラテじゃなくて、ただのコーヒーミルクだよ」\n\n\n私「いいのよ。そういえばこの前出たワクチンについてなんだけどね。外来で”有効率95%“って患者さんに聞かれたんだけど、こういう統計って私もちょっと混乱するんだよね」\n\n\nお父さん「うん、あれは話題になったよね。ワクチン有効率（vaccine efficacy）って意外と計算が難しいんだよ。まず”率”って用語には要注意だね」\n\n\n私「そう？罹患率とか死亡率とかよく使うけど」\n\n\nお父さん「それとは別。うん、そこは日本語特有の言い回しだから間違えやすいよね。この場合の率は百分率の意味で使っているんだけど、疫学でいう率（rate）とは計算が違うんだ。ややこしいのはそこだけじゃない。この場合の95%は、プラセボに比べて発症リスクが5%に下がるって意味だから」\n\n\nワクチン有効率は疫学一般で用いられる率ではない\nプラセボ効果との相対比較のための指標\n\n\n私「ん？100人いたら95人に効くって意味じゃないの？」\n\n\nお父さん「違う違う。プラセボの効果との相対比較。プラセボを打ったときに比べ、どのくらい感染を予防できるっていう意味のパーセントなんだ。論文ではともかく日常会話ではほとんど誤解されて伝わっちゃう。“リスク”までさかのぼらないと、わからないと思う。ちょっと、そこにある紙ナプキンとペンをとって。式で書いてあげるよ。いくつか疫学の指標を書くけど、“95%という数字はどのリスクとどのリスクをどう比べているのか”だけが、はっきりすればいい。そのために、こういう分割表で集計したデータを頭に浮かべよう」\n\n\n\n\n\n\n\n\nリスクを比較するための基本的な指標\n\n\n\n医学では分野によってさまざまな指標が用いられており、特に割合を比較する指標にはわかりにくいものが少なくありません。割合を理解するための最初のステップは分割表です。\n\n\n\n\n群1\n群2\n\n\n\n\n発症あり\nA人\nB人\n\n\n発症なし\nC人\nD人\n\n\n発症リスク\n\\(\\pi_1\\)\n\\(\\pi_2\\)\n\n\n\nこの表では人数や割合を、具体的な数字ではなく、A、B、C、Dや群1・群2の発症リスク\\(\\pi_1\\)と\\(\\pi_2\\)を使って表しています。2群ごとの割合\\(\\pi_1\\)と\\(\\pi_2\\)の比較では、以下のような指標が用いられます。\n\nリスク差（risk difference、絶対リスク減少）\n\n\\[\nRD={\\pi_1}-{\\pi_2}\n\\]\n\nリスク比（risk ratio）\n\n\\[\nRR=\\frac{\\pi_1}{\\pi_2}\n\\]\n\nオッズ比（odds ratio）\n\n\\[\nOR=\\frac{\\pi_1/(1-\\pi_1)}{\\pi_2/(1-\\pi_2)}\n\\]\nこれらの指標を使うときは、どちらの群を基準に比較しているかを意識することが大切です。上の式では群2を基準にとっています。\n\n\n\n\n\n\n\n\n治療の有効性を比較するための指標\n\n\n\n特に、2種類の治療のどちらが有効か調べるために比較するケースでは、以下の指標もよく用いられます。どちらの指標でも\\(\\pi_2&gt;\\pi_1\\)と想定されています。ワクチン有効率では、群2はプラセボを受けていると考えてください。\n\nNumber needed to treat（NNT）\n\n\\[\nNNT=\\frac{1}{\\pi_2-\\pi_1}=-\\frac{1}{RD}\n\\]\n\nワクチン有効率（相対リスク減少）\n\n\\[\nVE=\\frac{\\pi_2-\\pi_1}{\\pi_2}=1-RR\n\\]\n\n\n\n\n私「へー、ワクチン有効率はイメージしてたパーセントじゃないね。リスク比をちょっといじっただけの式じゃない。でも、“有効率”っていわれたり、パーセントが単位だと、いわゆる割合と思いがちだよね。お父さんって、頭の中にいつもこんな計算式があるの？いきなり式が出てくると違和感あるなあ。統計学と医学ってだいぶ雰囲気が違うね」\n\n\nお父さん「もう慣れちゃったのかもね。でも、式で書かないと、ワクチン有効率がなんなのか、わからないでしょ。それにね、この数字には数式よりずっとリアルな意味がある」\n\n\n私「なによ、持って回った言い方して、授業じゃないんだから」\n\n\nお父さん「いや、聞けばすぐわかるよ。ワクチン有効率の数字は、臨床データから推定されたものでしょ。たくさんの参加者を対象に臨床試験を行って、実際に観察されたという経験が、ぎゅっと要約された結果が、この数字なんだ。でも、データ上でどんな結果が観察されたか、ワクチン有効率だけでは伝わらないでしょ。こういうのを”数字が独り歩きする”っていうんだ」\n\n\n\n\n\n\n\n\nワクチンランダム化臨床試験の数値例\n\n\n\n次の表は、ワクチンとプラセボを比較した仮想的な臨床試験のデータです。表の人数からワクチン有効率を計算すると以下のような結果が得られます。\n\n\n\n\nワクチン群\nプラセボ群\n\n\n\n\n発症あり\n40\n800\n\n\n発症なし\n960\n200\n\n\n発症リスク\n4%\n80%\n\n\n\n\\(\\pi_1 = 40/1000 = 0.04\\)\n\\(\\pi_2 = 800/1000 = 0.8\\)\n\\(VE=\\frac{\\pi_2-\\pi_1}{\\pi_2}=95 \\%\\)\n\n\n\n\n私「確かにね。95%有効っていう数字だけみると、”ほぼ確実に救える”って意味に捉えがちだけど、よく考えたらワクチンにそこまでの効果はないよね。パーセントを使ったレトリックに騙されちゃいそう」\n\n\nお父さん「解析結果はね。解釈するときに言語そのもの以外の情報が不可欠なんだ。70%だろうが80%だろうが、同じ数字でも奏効率とワクチン有効率は別の計算だからね。でも日常会話でそんなこと気にしてられないでしょ。だから間違って使われることが多い。パーセント表記が逆に誤解を生んでる疫学の指標は、他にもあるよ」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n奏効率（response rate）とは、抗がん剤による治療を行った結果、何割の患者で腫瘍が縮小したか（完全奏効または部分奏効を達成したか）や血液から腫瘍細胞が消えたか（完全寛解）を表す指標です。この用語は広く用いられていますが、Japan Clinical Oncology Group（JCOG）という臨床試験グループでは奏効割合（response proportion）という表現を好んでいます（Japan Clinical Oncology Group 2025）。\nさて、次の指標のうち、率（rate）に該当するのはどれでしょうか。\n\n打率\n男女比率\n有病率\n死亡率\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は4です。\n\n割合、率、比の3つの違いについて説明しましょう。比とは、ある量を別の量で割ったもののことです。たとえば、BMIは体重を身長で割ったものですから比の一種で、単位はkg/m2です。割合は、一部の数を全体の数で割ったもの（言い換えると、分母が分子を含んでいるもの）です。割合は、もちろん2値データや分類データを要約するために用いられる指標ですよね。この指標は、言葉の定義からいって、比の一種です。しかし、割合は、100%を超えることはなく、そして人数を人数で割っているためキャンセルして単位がない（無単位）という特徴があります。割合と区別してほしいのが率です。たとえば胃がんの発生率（incidence rate of gastric cancer）というと、一定時間に胃がんが発生するスピードで、人年法（胃がんの発生数/観察人年）で計算されます。人数を人数×年で割っているため、単位は1/年（より一般には1/時間）です。\n「打率」は安打数÷打数であり、「割合」になります。\n「男女比率」は男性の人数÷女性の人数であり、「比」になります。\n「有病率」は疾患を有する人の人数÷全体の人数であり、「割合」になります。\n「死亡率」は死亡件数÷観察人年であり、「率」になります。\n\n\n\n\n\n文献\n\nJCOGプロトコールマニュアル version 3.8 [Internet]. 東京: Japan Clinical Oncology Group; 2025\n\n\n\n次のエピソードとRスクリプト\n\nWho Is This Percentage About? Target Populations and Attributable Fractions\neffects.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nA First Note on Cox Regression\nAfter Cox Regression: A Case Study and R Demonstration\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/effects-3.html",
    "href": "jp/effects-3.html",
    "title": "When Odds Ratios Approximate Risk Ratios—and When They Fail",
    "section": "",
    "text": "Effects and Time III − When Odds Ratios Approximate Risk Ratios—and When They Fail\n\nKeywords: bias, effect measure, observational study\n\n\n\nリスク比とオッズ比って、結局同じ？\n\n\n私「お父さんの話を聞いててね、国試の勉強してたときのことを思い出したよ。保健統計だったか、疫学だったかの問題で、オッズ比の計算問題を解いたことがあったなあ。リスク比とオッズ比って結局同じ使い方をするの？みたいな」\n\n\nお父さん「ああ、この前、膵がんの数値例で計算したとき、リスク比とオッズ比はどちらも3倍だったね。でも、これはたまたま。もっと正確にいうと、膵がんのように、リスクの値が低いときはリスク比とオッズ比は近い値になるんだ。ほら、リスク比とオッズ比の数式を見比べてよ。リスク比とオッズ比の違いって、式の分母に\\(1-\\pi_1\\)と\\(1-\\pi_2\\)があるかどうかでしょ。リスクが低いと、ここがほとんど1になるから、リスク比とオッズ比の差がなくなる」\n\n\n私「まあ、私も論文読むとき別に区別してないけど」\n\n\nお父さん「えーっと、状況によってはそれはよくない。疾患や対象集団によっては、リスクが低いときばかりじゃないからね。最近の論文だと、オッズ比をリスク比の代わりに使うなら、そのままの値じゃなくて、オッズ比の平方根を報告した方がいいっていう説もある（VanderWeele 2017）」\n\n\n私「なにそれ、またお作法が増えたの？」\n\n\nお父さん「お作法があるわけじゃないんだけど、オッズ比をリスク比の近似として使うことがあるからね。そういうときに限っては、オッズ比の代わりにオッズ比の平方根でもいいんじゃないっていう主張かな。どっちにしても近似バイアスはそれなりに残るんだけど。リスク比とオッズ比の使い分けの話をするときは、まずは具体的な計算結果をみた方がわかりやすいと思う」\n\n\n\n\n\n\n\n\nリスク比はオッズ比の近似か\n\n\n\n表1は、2群の疾患リスク\\(\\pi_1\\)と\\(\\pi_2\\)の数値を0.1から0.9まで動かして、リスク比、オッズ比、オッズ比の平方根（square root of OR）を計算したものです。\n\\(RR=\\frac{\\pi_1}{\\pi_2}\\)\n\\(OR=\\frac{\\pi_1/(1-\\pi_1)}{\\pi_2/(1-\\pi_2)}\\)\n\\(SOR=\\sqrt{\\frac{\\pi_1/(1-\\pi_1)}{\\pi_2/(1-\\pi_2)}}\\)\n\\(\\pi_1\\)と\\(\\pi_2\\)のどちらかが0.2を超えると、リスク比とオッズ比はまったく違う値になることがわかります。リスク比とオッズ比が1より小さいとき、オッズ比はリスク比より必ず小さくなります。また、\\(\\pi_1\\)と\\(\\pi_2\\)が0.2～0.7の範囲であれば、リスク比とオッズ比の平方根は、高々0.11しか違いません。\n\n\n\n疾患リスク0.1～0.4疾患リスク0.5～0.8\n\n\n表1. 2群の疾患リスクを0.1から0.9まで動かしたときのリスク比（RR）、オッズ比（OR）、オッズ比の平方根（SOR）\n\n\n\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n\n\n\n\n0.1\nRR=1\n0.50\n0.33\n0.25\n0.20\n0.17\n0.14\n0.13\n0.11\n\n\n\nOR=1\n0.44\n0.25\n0.17\n0.11\n0.07\n0.05\n0.03\n0.01\n\n\n\nSOR=1\n0.67\n0.51\n0.41\n0.33\n0.27\n0.22\n0.17\n0.11\n\n\n0.2\n\nRR=1\n0.67\n0.50\n0.40\n0.33\n0.29\n0.25\n0.22\n\n\n\n\nOR=1\n0.58\n0.38\n0.25\n0.17\n0.11\n0.06\n0.03\n\n\n\n\nSOR=1\n0.76\n0.61\n0.50\n0.41\n0.33\n0.25\n0.17\n\n\n0.3\n\n\nRR=1\n0.75\n0.60\n0.50\n0.43\n0.38\n0.33\n\n\n\n\n\nOR=1\n0.64\n0.43\n0.29\n0.18\n0.11\n0.05\n\n\n\n\n\nSOR=1\n0.80\n0.65\n0.53\n0.43\n0.33\n0.22\n\n\n0.4\n\n\n\nRR=1\n0.80\n0.67\n0.57\n0.50\n0.44\n\n\n\n\n\n\nOR=1\n0.67\n0.44\n0.29\n0.17\n0.07\n\n\n\n\n\n\nSOR=1\n0.82\n0.67\n0.53\n0.41\n0.27\n\n\n\n\n\n表1. 2群の疾患リスクを0.1から0.9まで動かしたときのリスク比（RR）、オッズ比（OR）、オッズ比の平方根（SOR）\n\n\n\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n\n\n\n\n0.5\n\n\n\n\nRR=1\n0.83\n0.71\n0.63\n0.56\n\n\n\n\n\n\n\nOR=1\n0.67\n0.43\n0.25\n0.11\n\n\n\n\n\n\n\nSOR=1\n0.82\n0.65\n0.50\n0.33\n\n\n0.6\n\n\n\n\n\nRR=1\n0.86\n0.75\n0.67\n\n\n\n\n\n\n\n\nOR=1\n0.64\n0.38\n0.17\n\n\n\n\n\n\n\n\nSOR=1\n0.80\n0.61\n0.41\n\n\n0.7\n\n\n\n\n\n\nRR=1\n0.88\n0.78\n\n\n\n\n\n\n\n\n\nOR=1\n0.58\n0.26\n\n\n\n\n\n\n\n\n\nSOR=1\n0.76\n0.51\n\n\n0.8\n\n\n\n\n\n\n\nRR=1\n0.89\n\n\n\n\n\n\n\n\n\n\nOR=1\n0.44\n\n\n\n\n\n\n\n\n\n\nSOR=1\n0.67\n\n\n\n\n\n\n\n\n私「この表、いっぱい数字があって見方がわからないな。対角のところがRR=OR=SOR=1になるのは、\\(\\pi_1\\)と\\(\\pi_2\\)が同じ値だからだよね」\n\n\nお父さん「ごめんごめん、説明が必要だよね。RRに近いのは、ORとSORのどっちかをみてほしいんだ。さっき話した通り、古い教科書ではオッズ比はリスク比の近似だって教えるけど、実際にいろんな組み合わせで計算すると、そうならないことがある。っていうか、表をみるとRRとOR、結構ずれてない？むしろオッズ比の平方根をとった方がいいんじゃないかって話」\n\n\n私「平方根なんて論文書くとき勝手に計算していいのかね」\n\n\nお父さん「リスク比を推定することが目的なら、オッズ比の平方根を論文で示してもいいかもって気はする。推定方法の一種として、論文のMethodsで説明していればね。でも、よっぽど特殊な状況じゃなければ、リスク比を計算するのが素直だと思うけど」\n\n\n私「そう？私の周りではオッズ比の方がよく聞くけど？まあ胃がんや大腸がんの研究だと、ハザード比をダントツよく使うけど」\n\n\nお父さん「オッズ比が出てくるのは疫学の教科書とか国試対策でしょ。あれはケース・コントロール研究を教える都合ってだけだよ。リスクって疾患や死亡が起きる確率そのものでしょ。その差や比を直接とったリスク差・リスク比が基本だって理解しとかないと、単なる暗記になっちゃう。ハザード比は、ハザード関数っていう時間の関数の理解がないと取扱注意だし、前回話したように、層別などの調整を行うとき、リスク比はとても扱いやすい指標だからね」\n\n\n\n\n\n\n\n\nケース・コントロール研究とオッズ比\n\n\n\n\n\n古典的なケース・コントロール研究は、コホートの中から疾患を発生したケースを特定し、疾患を発生しなかったものの中からコントロールを選択し、ケースとコントロールの曝露状況を比較する研究です。言い換えると、この研究デザインでは、一部の集団のみ（ケースとコントロールのみ）について、過去の曝露状況を調査します。そうすると、コホートの一部しか曝露状況がわからないから、曝露群・非曝露群のリスクの分母がわかりませんよね。そこで、リスク比の代わりに「曝露オッズ比」を求める、と疫学の教科書には書かれています。ただし、古典的なケース・コントロール研究とは違い、最近ではデータベースが利用できたり、研究デザインを工夫していたりするため、ケース・コントロール研究といってもリスク比を計算できる状況も増えてきています。\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nリスク比とオッズ比が1より小さいとき、オッズ比はリスク比より必ず小さくなるといいました。それでは、2群をオッズ比で比較するときのp値は、リスク比で比較するときのp値より、小さくなる（つまり有意になりやすく、検出力が向上する）のでしょうか。ただし、実際にデータから計算されたp値だと、検定の種類の選び方に影響されるし、偶然性も入ります。理論上の期待値がどうなるか考えてみてください。\n\nオッズ比のp値は、リスク比のp値より、期待値の上で小さい\nオッズ比のp値は、リスク比のp値より、期待値の上で大きい\nオッズ比のp値は、リスク比のp値と、期待値の上で等しい\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です\n\nリスク比やオッズ比は最尤法で推定することが普通です。最尤法を用いるとき、検定の性能（検出力など）は、指標の選び方によらず一定、ということが統計学で知られています。直感的な説明をすると、“同じデータから同じ情報を引き出している”から、どの指標を使って差を推定しても、検定としての力は変わらないのです。\n\n\n\n\n\n文献\n\nVanderWeele T. On a square-root transformation of the odds ratio for a common outcome. Epidemiology 2017;28(6):e58–e60\n\n\n\n次のエピソードとRスクリプト\n\nFrom Risk and Rate to Survival and Hazard\neffects.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nA First Note on Cox Regression\nAfter Cox Regression: A Case Study and R Demonstration\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/effects-5.html",
    "href": "jp/effects-5.html",
    "title": "A First Note on Cox Regression",
    "section": "",
    "text": "Effects and Time V − A First Note on Cox Regression\n\nKeywords: effect measure, probability model, survival & competing risks\n\n\n\nCox回帰はハザード比ではなく比例ハザード性のモデル\n\n\n私「お父さん、正直にいうと生存曲線とかの数式はわからなかったんだけど、ひとつだけすごく気になったことがあって。それが。ハザード\\(\\lambda_1\\)と\\(\\lambda_2\\)の比をとったこの式なの。\\(HR\\)はハザード比（hazard ratio）だよね」\n\n\n\n指数分布のハザード比 \\[\nHR=\\frac{\\lambda_1}{\\lambda_2}\n\\]\n\n\n\n私「この式はCox回帰（Cox regression）でもおなじ？ちがう？」\n\n\nお父さん「ごめん、これはCox回帰の式じゃないね。Cox回帰のハザード比はこういう式で表す」\n\n\n\nCox回帰のハザード比 \\[\nHR=\\frac{\\lambda_1(x)}{\\lambda_2(x)}\n\\]\n\n\n\n私「うん、こんな感じの式になるって思ったんだ。さっき生存関数を教えてくれたのと同じで\\(x\\)は時間だよね。ハザード関数は時間とともに変化できて、\\(\\lambda_1(x)\\)と\\(\\lambda_2(x)\\)は2群それぞれのハザード関数だっていうことはわかるよ。指数分布ではハザードは定数だった。でも、不思議なのは、どうみても上も下も同じ計算じゃない？割り算しただけ」\n\n\nお父さん「ああ、文脈がないとそう読むのが普通かもね。指数分布の式の方はね、この式以前に、もともとハザードが一定なんだ。下のCox回帰をみると、\\(\\lambda_1(x)\\)と\\(\\lambda_2(x)\\)は時間\\(x\\)の関数で、ハザード比だけが一定っていうある種の制約を表している」\n\n\n私「つまり？」\n\n\nお父さん「つまりこの式が出た時点で、はじめて比例ハザード性が仮定された、あるいは構造が決まったっていうような文脈でとらえてほしいんだ」\n\n\n私「やっぱり違うのか。まってね、ということは、この式はcoxph()の中で\\(\\lambda_1(x)\\)と\\(\\lambda_2(x)\\)の比をとっているっていう意味じゃないよね。仮定を置いたってことは、それが成り立たないと困るわけだ。ハザード比の定義でもなさそうな口ぶりだよね」\n\n\nお父さん「その通り。比例ハザード性は成り立たないと困るし、この式はハザード比の定義ではない。この式は、単純に2群比較するときのCox回帰のモデルそのものを表している」\n\n\n私「これがCox回帰の式ね。ロジスティック回帰の式に比べてシンプルすぎて見てて不安になるな。比例ハザード性っていう聞き覚えのある単語で説明されてやっと安心する」\n\n\nお父さん「この式は本質的なところしか書いてないからね。でも、教科書に書いてあるCox回帰の式と、比例ハザード性というエッセンスは同じ。教科書は対数ハザード比を回帰係数ベクトル\\(\\beta\\)に置き換えて、ベクトル表記してあるだけだ」\n\n\n\\[\n\\lambda(x)=\\lambda_0(x)\\exp(Z \\beta)\n\\]\n\n\nお父さん「Cox回帰のよさはいくつもあるけど、\\(\\lambda_1(x)\\)と\\(\\lambda_2(x)\\)はどんな関数でもいいという点が、とても実用的なんだ。比例ハザード性という仮定はあるけどね。その点、指数分布はハザードが定数だから、ずっと融通が利かない。データへの当てはまりが悪いんだ」\n\n\n\n\n\n\n\n\n補2重対数変換: ハザード比を抽出する変換\n\n\n\nあまり知られていませんが、Cox回帰に代えて一般化線型モデルでも（離散時間の枠組みで）ハザード比を推定できます。リンク関数として補2重対数変換（glmでいえば binomial(link = \"cloglog\")）を選びます。Cox回帰の構造を深堀するために、指数分布のもとで「生存関数に log(-log) を当てる」と何が起きるかを見てみましょう。指数分布のハザード比と回帰係数を\\(\\beta=\\log(HR)\\)と表すことにします。\n2群の生存関数を、ハザード\\(\\lambda_1\\)と\\(\\lambda_2\\)を使って\n\\(S_1(x)=\\exp(-\\lambda_1 x)\\)\n\\(S_2(x)=\\exp(-\\lambda_2 x)\\)\nとします。それぞれ対数をとって符号を変えます。\n\\(-\\log\\{S_1(x)\\}=\\lambda_1 x\\)\n\\(-\\log\\{S_2(x)\\}=\\lambda_2 x\\)\nもう一度対数をとり、さらに差をとってみます。\n\\(\\log[-\\log\\{S_1(x)\\}]-\\log[-\\log\\{S_2(x)\\}]=\\log(\\lambda_1 x)-\\log(\\lambda_2 x)=\\log(HR)=\\beta\\)\nこの結果は、比例ハザード性の下では常に成り立ちます。つまり、同じ時点\\(x\\)の下で2群の差をとると、時間\\(x\\)がキャンセルして回帰係数\\(\\beta\\)だけが残ります。生存時間解析の裏では、生存関数から回帰係数（対数ハザード比）を抽出するために、この変換が使われています。その一例は、比例ハザード性の図示（いわゆるログログプロット）です。Kaplan–Meier曲線の補2重対数変換をとると、曲線間の比例ハザード性が、曲線の平行移動に置き換わるのです。\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n\nこの人は誰でしょう。\n\nKaplan\nMeier\nCox\nWilcoxon\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です\n\nこの方がCox先生です。\nDavid Cox (statistician)\n\n\n\n\n\n次のエピソードとRスクリプト\n\nAfter Cox Regression: A Case Study and R Demonstration\neffects.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nA First Note on Cox Regression\nAfter Cox Regression: A Case Study and R Demonstration\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/frequentist-1.html",
    "href": "jp/frequentist-1.html",
    "title": "Reading a Paper over a Cup of Coffee",
    "section": "",
    "text": "Frequentist Thinking I − Reading a Paper over a Cup of Coffee\n\nKeywords: clinical trial, language & writing, p-value, survival & competing risks\n\n\n\n\n\n\n\n\n前回までのあらすじ\n\n\n\n\n\nはじめて研究に取り組む娘と統計家の父。父に研究仮説は”PICO”を”PECO”で整理するといいとアドバイスされ、医師である娘は、がんサバイバーにおけるストーマ造設と復職状況の関係を調査することに決める。おなじ復職状況でも、2値データと生存時間データの2通り解析の仕方があると教えられた娘。上司に読むことを勧められた論文で、OS・DFSという用語が出てきたことを思い出すのだった。\n\n\n\n\n生存曲線まわりの数値を読み解く\n\n\n父「ん？寒くなってきたのに、遅くまでなに読んでるの？コーヒーでも淹れようか」\n\n\n私「あ、お父さん、ありがと。ミルクもお願い。いまね、胃がん手術の論文読んでるんだ。そうだ、前に全生存期間（OS）と無病生存期間（DFS）の違いについて教えてくれたでしょ」\n\n\nお父さん「そんなこともあったね」\n\n\n私「お父さんも臨床論文読んだりする？仕事で」\n\n\nお父さん「臨床試験の統計家やってるから、たまにね。どっちかっていうと、論文を書くことの方が多いけど。臨床の最新知識はそこまで仕事でいらないし」\n\n\n私「よかった。この論文、細かいところがよくわかんないんだ。特に統計っぽい言葉の意味がね。ちょっとこの図を見てよ。JCOG9502っていう胃がん手術の術式を比べた臨床試験の論文なの（Sasako, et al. 2006）。TH群は開腹創から下縦隔へアプローチする標準的な手術を受けた患者、LTA群は左開胸開腹連続切開によって下縦隔郭清も行った患者のことね」\n\n\n\nお父さん「この図は、いわゆるKaplan-Meier曲線だよ。図AがOS、図BがDFSだね。どちらの図でも、TH群（青の曲線）よりLTA群（赤の曲線）の方が下にある。つまりTH群の方が、治療成績がいい」\n\n\n私「そこまではわかるの。知りたいのは細かいところなんだってば。最初につまずいたのが、生存曲線の下に書いてあるアットリスク数 （number at risk）でね。これって時点ごとの人数のことでしょ。図Aと図Bの手術時点の人数を見てよ。図Aは82人と85人、図Bは76人と75人で、左右で解析された人数が違うの。理由はわかる？」\n\n\nお父さん「これは結構難しいな。臨床試験で解析対象から除外されるって、プロトコール逸脱とかよっぽどのことだと思うけど。コーヒーおかわりくれる？ふむ。DFSの解析を行うには再発したかどうかを評価しないといけないよね。そのあたり、なにか理由はありそう？」\n\n\n私「そっか、腫瘍組織が完全に切除できなかったら、再発とみなしていないのかもしれない。えーっと、論文を読むと、確かにR0切除ができたのは151人って書いてある。そのせいだな多分。それとね、7年目あたりから人数が数人しかいなくなってるの。これってどう思う？」\n\n\nお父さん「この試験って登録何年で、追跡何年なの？それによるでしょ」\n\n\n私「登録期間は1995年から2003年だから、8年。生存時間データは2006年までのものを解析したって書いてあるな。そうすると追跡期間は最短で3年かな」\n\n\nお父さん「そうすると、必ずしも術後3年以上追跡されるわけじゃないよね。以前、打ち切りについて話したことがあったよね。生存時間データは、イベントと打ち切りから構成される。3年以内に打ち切りが多いのは不自然だけど、3年以降に追跡が打ち切られるのは計画通りのことだよ」\n\n\n私「打ち切りがいつ起きたかなんて、論文を読んでも書いてないよね？」\n\n\nお父さん「そんなことはない。生存曲線にひげが立ってるでしょ」\n\n\n私「このぴょこぴょこしたやつ？」\n\n\nお父さん「そうそう。それが打ち切りのシンボル。時間原点の直後にひげがたくさん立ってたら、なにが起きてると思う？研究を始めたらすぐ、患者さんが追跡できなくなって、打ち切りになったってこと。そんな変な研究にはバイアスがあるかもしれないよね」\n\n\n私「図では、3年以内のひげは数えるほどしかない。じゃあほとんどの患者は3年以上追跡できたんだ。いい研究なんだね。今までの話をまとめると、こういうことか」\n\n\nアットリスク数は時点ごとの人数を表す\nひげは打ち切りを表す\n図に示されない情報だが登録期間・追跡期間も要確認\n\n\n私「でもそういうのって統計の教科書に書いてないよね。平均とか回帰係数ばっかり」\n\n\nお父さん「生存時間解析は教科書では後回しになりがちだからね。がんの臨床試験データの解析を勉強するなら、統計学一般の教科書より、米国の臨床試験グループ（SWOG）の統計家が書いた臨床試験の教科書がいいよ（Green, et al. 2013）」\n\n\n私「よく考えたら10年以上かかったんだ、この図を描くのに。スタッフは大変だっただろうな。そういえばさ、臨床試験の研究計画書の話がでたでしょ、この前。計画書って参加施設の倫理委員会に出すじゃない。そうしたら基本的に変更しないよね、手続きもいるし」\n\n\nお父さん「そうだね」\n\n\n私「10年後の先を見越して、しかも誰が読むかもわからないのに、計画を文章にするって怖いよね。100人以上の患者さんも関わってくるし。そりゃあ、アウトカムひとつとっても言葉の意味を固めときたくもなるわ。あ、あとさ、生存曲線まわりの英語についてなんだけど、”hazard ratio”、”95% CI”、”one-sided p”、”two-sided p”は日本語でなんていうか教えてよ」\n\n\nお父さん「ハザード比、95%信頼区間、片側p値、両側p値かな。このあたりの指標は、生存時間解析の定番だよ。ハザード比とかp値は、Cox回帰で計算するんだけど、本格的な話は、また今度ゆっくりやろうか」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n予後がどのくらいかを説明するために、がん患者の余命を用いることがあります。胃がん手術後の余命をJCOG9502の図から読み取ることができるでしょうか。\n\n図A（OSのKaplan-Meier曲線）から読み取ることができる\n図B（DFSのKaplan-Meier曲線）から読み取ることができる\n図AとBどちらからも読み取ることができない\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は1です\n\n胃がん手術後の余命を表す指標として、生存期間の平均値または中央値がありますが、図から読み取りやすいのは生存期間中央値です。\n生存期間は、日数や年数のような数値データですから、連続データに近い特徴を持っています。連続データでは、中央値（median）は上位50%に相当する値のことですよね。半数以上の対象者がイベントを起こして、生存期間が確定すれば、たとえ打ち切りがあっても、生存期間中央値を求めることができます。\n具体的には、生存期間中央値は、50%が生存している時点、すなわち図AのSurvivalが50%になる時点に対応しています。つまりKaplan-Meier曲線が50%まで下がった時点を読み取ればよいのです。\n\n\n\n\n\n文献\n\nGreen J, Benedetti J, Smith A, Crowley J. 米国SWOGに学ぶがん臨床試験の実践 第2版（原書第3版）. 東京: 医学書院; 2013\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\n\n\n\n次のエピソードとRスクリプト\n\nP-Value Explanations That Seem Plausible at First Glance\nfrequentist.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nReading a Paper over a Cup of Coffee\nP-Value Explanations That Seem Plausible at First Glance\nBeyond 0.05: Interpreting P-Values in a Clinical Trial\n\n過去のシリーズ\n\nStudy Design I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/frequentist-3.html",
    "href": "jp/frequentist-3.html",
    "title": "Beyond 0.05: Interpreting P-Values in a Clinical Trial",
    "section": "",
    "text": "Frequentist Thinking III − Beyond 0.05: Interpreting P-Values in a Clinical Trial\n\nKeywords: clinical trial, p-value, research hypothesis, survival & competing risks\n\n\n\n正しくp値を解釈するための考え方\n\n\n私「ただいま、お父さん。そろそろダウン出さなきゃだめだね。あ、ホットコーヒーもらっていい？」\n\n\nお父さん「そろそろ帰る時間だと思って、たっぷり淹れてた。そうそう、JCOG9502の論文で生存曲線とp値の話をしたことがあったよね（Sasako, et al. 2006）。そのとき気になったんだけどさ。どうしてp値が0.05より小さいと統計学的に有意っていったの？」\n\n\n私「それがルールなんじゃないの？」\n\n\nお父さん「そこはね、論文の読み方を間違えてる。質問していい？論文に目を通すとき、最初にAbstract（抄録）を読むでしょ。次にどこを読む？」\n\n\n私「Results（結果）。だってどういう結果だったかはやく知りたいもん」\n\n\nお父さん「うんうん、その気持ちはすごくわかる。でも、p値を見るときに限っては、正しく解釈するために、事前にMethods（方法）を読んでおく必要がある。科学コミュニティのなかで、p値について誤解が多いことが問題視されていて、アメリカ統計協会（ASA）が、統計を専門としない研究者、実務家、サイエンスライター向けの声明を出したことがある。そのきっかけは、2014年2月のASAフォーラムにこんな投稿がなされたことだった」\n\n\n私「なんだこの禅問答」\n\nQ. Why do so many colleges and grad schools teach p ≤ 0.05?（なぜ多くの大学、大学院で「p ≤ 0.05」と教えているのか？）\nA. Because that’s what the scientific community and journal editors use（なぜなら科学コミュニティと雑誌編集者が依然として0.05を使っているからである）\nQ. Why do so many people still use p ≤ 0.05?（なぜ多くの人々が「p ≤ 0.05」を依然として使うのか？）\nA. Because that’s what they were taught in college or grad school（なぜなら彼らが大学、大学院でそう教わったからである）\n\nお父さん「そして、ASAはp値の使い方について6つの原則を出した」\n\n\np値はデータと特定の統計モデル（訳注:仮説も統計モデルの要素の1つ）が矛盾する程度を示す指標の1つである\np値は、調べている仮説が正しい確率や、データが偶然のみで得られた確率を測るものではない\n科学的な結論や、ビジネス、政策における決定は、p値がある値（訳注:有意水準）を超えたかどうかにもとづくべきではない\n適正な推測のためには、すべてを報告する透明性が必要である\np値や統計的有意性は、効果の大きさや結果の重要性を意味しない\np値は、それだけでは統計モデルや仮説に関するエビデンスの、よい指標とはならない\n\n\n私「さっきのやり取りがきっかけで、学会でp値批判があったってわけね。でもまあ6つとも抽象的でぴんとこないな」\n\n\nお父さん「そう？“科学的な結論は、有意水準を超えたかどうかにもとづくべきではない”なんてのは、かなり明確に書いてあると思うけど。JCOG9502論文でいえば、原則3や原則5は、p値だけ見るんじゃなくて、生存曲線をじっくり観察してから結論を出そうっていってるんだ。もちろん専門知識がないと、原則がなにを意図しているかはわかりにくい。原則4は、たとえば多重性の問題（multiplicity）に関係している」\n\n\n私「多重性？」\n\n\nお父さん「最近の臨床試験では、多重性っていう統計的な問題が潜んでいることが多い。JCOG9502論文を例にもう少し説明しようか。Statistical Analysis（統計解析）のところを読み返してみて。alpha error（αエラー）っていうのは、有意水準ともいうけど、どちらもp値と比べる水準のこと」\n\nAfter 8 years of slow accrual, the JCOG data and safety monitoring committee approved an amendment to the sample size and analysis plan. The amended sample size was 250, with one-sided alpha error of 0.1 and beta error of 0.2, with a 12-year accrual period (in total) and 8-year follow-up.（JCOG9502論文[Sasako, et al. 2006]の”Statistical Analysis”から抜粋）\n\n私「p値を0.1と比べるってこと？0.05じゃないの？」\n\n\nお父さん「うん、αエラーの理想は教科書通りの0.05。試験途中にαエラーは変えるべきではない。そんなことはみんなわかってるんだ。でも、現実に登録が難航すると、軌道修正が必要になることもある。この試験もそう。苦肉の策でαエラーを0.1に緩めたみたい」\n\n\n私「読み飛ばしてた。自由すぎるなJCOG」\n\n\nお父さん「あとさ、ASA声明の原則4とその解説を念頭に置いて、JCOG9502の図Aと図Bを見てみてよ。生存曲線が2本、p値が4つ示されているよね。この複数のp値は、どう読み解けばいいかわかる？」\n\n\n\n私「もともとそれが知りたくて、お父さんに質問したんだけど、わかってる？図Aのp値と図Bのp値については、私もちゃんと考えてたよ。図Aの方を見ればいいんでしょ。JCOG9502の主要エンドポイントはOSで、図Aが全生存曲線だもの。でも図Aだけでも片側と両側があるじゃない。ここが意味不明で、考えこんじゃった」\n\n\nお父さん「それはそんなに難しくない。臨床試験で、試験治療群と標準治療群の成績を比べるとするでしょ。試験治療群が勝ったときだけ、有意差があったって宣言するのが、片側p値。どちらの群が勝っていても、統計的に有意かどうか判定するのが、両側p値だよ」\n\n\n私「論文を読むと、JCOG9502のプロトコール上、LTAが試験治療、THが標準治療とされてたんだよな。LTAの方が、侵襲性が高いからかな。だからLTA群の予後がいいっていう結果でないと、有意差ありって宣言しないわけだ。これって普通？」\n\n\nお父さん「いや？両側p値を使うのが普通。でもJCOGが行っている臨床試験では、試験治療群の成績が、標準治療群よりいいかどうかに興味があり、しかも毒性や侵襲の異なる治療同士を比べることが多いので、片側仮説の方が自然なんだ。そのためこのグループでは、片側p値の採用を許容している（Japan Clinical Oncology Group 2025）。片側p値で有意じゃなかったら、標準治療を使い続けるから、それでいいんだって。この論文の両側p値は参考値みたいだね。つまり、有効性の主たる判断には、図Aの片側p値だけが用いられることになる」\n\n\n私「ストーマ造設あり・なしと復職状況を調べる私の調査だったら、仮説の意味から考えても両側p値がおすすめってことね。よくわかりました」\n\n\n\n\n\n\n\n\n統計的有意性とp値に関するASA声明\n\n\n\n\n\nあらゆる科学論文でp値が用いられていますが、p値が誤用されたり、研究結果の解釈に悪い影響を与えたりする弊害が指摘されています。典型的なものを挙げると、研究で小さいp値が得られると、それだけで重要な知見が得られたとみなされたり、機械的にp値が0.05より小さいというだけで意思決定がなされたりするケースは、皆さんもよく目にするのではないでしょうか。\nASAは2016年に、定量的研究の実施とその解釈を改善するため、p値の適正な使用と解釈に関する6つの原則をまとめました（Wasserstein and Lazar 2016）。以下に引用します。\n\np値はデータと特定の統計モデル（訳注:仮説も統計モデルの要素の1つ）が矛盾する程度を示す指標の1つである\np値は、調べている仮説が正しい確率や、データが偶然のみで得られた確率を測るものではない\n科学的な結論や、ビジネス、政策における決定は、p値がある値（訳注:有意水準）を超えたかどうかにもとづくべきではない\n適正な推測のためには、すべてを報告する透明性が必要である\np値や統計的有意性は、効果の大きさや結果の重要性を意味しない\np値は、それだけでは統計モデルや仮説に関するエビデンスの、よい指標とはならない\n\n統計学の教科書では、p値と帰無仮説の関係を中心に説明しています。しかしp値を解釈するとき大切なのは、帰無仮説だけではありません。ASA声明の趣旨は、研究計画やデータの収集から結果の報告に至るまで、統計解析の背景にあるあらゆる情報を利用しなければ、p値は正しく解釈できないということです。\n原則4に注目してみましょう。ASA声明では、原則4の解説として「複数のデータ解析を実施して、そのうち特定のp値のみを報告することは、報告されたp値を根本的に解釈不能としてしまう」と述べています。かみ砕いて言うと、たくさんp値があると、そのなかで都合のいいp値を採用してしまいますよね。このような、いいとこどりの解析は、科学者の間で意識的にも無意識にも広く行われていて、偽陽性（false positive）の研究結果 ばかりが報告される一因ではないか、という問題意識を統計学者はもっています。この問題は、統計学で多重性（multiplicity）や選択的推論（selective inference）と呼ばれています。\n\n\n\n\n\n\n\n\n\n片側p値と両側p値\n\n\n\n\n\np値と仮説検定（hypothesis test）は、研究仮説が正しいかどうかについて、二者択一の判断をするための統計手法です。なんだか難しそうなので、例え話で説明しましょう。\nコイン投げをして、6回連続で表が出たとします。このコインは、イカサマコイン（表が出る確率が1/2でない）でしょうか？p値では以下のように考えます。表が出る確率は1/2という仮説の下で、6回連続で表の確率は(1/2)の6乗で0.0156ですよね。6回連続で裏の確率は同じく0.0156です。すなわち、このような極端なデータが得られる確率は、足してp=0.0312と極めて低いことがわかります。このような極端なデータが得られるのはおかしくはありませんか？従って、このコインにはイカサマがある、というのが、p値を用いて仮説（表が出る確率は1/2）を否定するときのロジックです。\n片側（one-sided）p値と両側（two-sided）p値は、コインの片側（表だけ）をみるか、両側（表と裏）をみるかに、それぞれ対応しています。コイン投げの例え話でいえば、片側p値はp=0.0156、両側p値はp=0.0312です。\n\nJCOG9502に戻って考えてみましょう。仮説検定では3段階の手続きを行います。まず、仮説を設定します。JCOG9502では、真実は「LTA群はTH群に比べ全生存期間を延長する効果がある」と「効果がない」の2通りがあり得ます。仮説検定では、「効果がない」という仮説に注目して、帰無仮説（null hypothesis）と呼びます（こちらが、表が出る確率が1/2に対応します）。\n次に、帰無仮説の下でデータがどのように分布するかを調べます。仮に、同じ対象者167人の試験を1000回繰り返したと想像してみてください。これが頻度論の思考様式です。仮に効果がなかったとしても、ランダム誤差のため、LTA群の生存曲線の方がよい場合もあれば、TH群の方がよい場合もあるでしょう。しかし1000回繰り返した結果は、差がないという結果を中心に分布するはずです。そこで、この1000回の分布と、実際に観察されたデータとを比べp値を計算します。\np値とは、帰無仮説が正しい、つまり生存曲線に差がない、という仮定の下で、実際に観察された2本の生存曲線の差よりも、極端な差が観察される確率のことです。もしp値が小さければ、こんなに確率の低いことが起きるわけがない、だから生存曲線に差がないというそもそもの前提条件が間違いだ、という判断になるわけです。逆に、p値が大きければ、当たり前のことが起きたという意味になります。\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n非劣性試験や同等性試験を除くほとんどのランダム化臨床試験で、両側p値が標準とされている理由として正しいものは、次のうちどれでしょうか。\n\n試験治療が優れていたとしても、劣っていたとしても、差があるなら結論を出したいから\n統計学者の間の決まりごと\n世界中の臨床試験で統一した方が、混乱が少ないから\nランダム誤差は、平均の上方向と下方向の両方のばらつきを生じるから\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です\n\nこれは歴史的経緯によるものです。1998年にICH E9ガイドラインが策定されたとき、米国、欧州、日本の規制当局で、両側p値を基本にすることが合意されました（吉村2003）。\n\n\n\n\n\n文献\n\nJCOGプロトコールマニュアル version 3.8 [Internet]. 東京: Japan Clinical Oncology Group; 2025\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\nWasserstein R and Lazar NI. The ASA’s statement on p-values: Context, process, and purpose. Am Statistician 2016; 70: 129-33\n吉村功. 検証的臨床試験における有意水準と試験の数－「臨床試験のための統計的原則」との関連で－. 計量生物学 2003; 24: S3-9\n\n\n\nThis concludes the Frequentist Thinking series. If you’d like to keep reading over your next cup of coffee, the following episodes are waiting:\n\nR Demonstration of Bias in Kaplan-Meier Under Competing Risks\nUnderstanding Confidence Intervals via Hypothetical Replications in R\nAlpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size\nfrequentist.R"
  },
  {
    "objectID": "jp/frequentist-5.html",
    "href": "jp/frequentist-5.html",
    "title": "Understanding Confidence Intervals via Hypothetical Replications in R",
    "section": "",
    "text": "Frequentist Experiments II − Understanding Confidence Intervals via Hypothetical Replications in R\n\nKeywords: probability model, simulation, study design, survival & competing risks\n\n\n\nお父さん、その95%信頼区間って本当に95%なの？\n\n\n私「あのさ、もうひとつ聞きたいと思っていたことがあって。95%信頼区間（confidence interval）って、みんな当たり前のようにいうけど、ほんとに95%も当たってるの？」\n\n\nお父さん「ん？そりゃ当たってるよ。仮定した確率モデルが正しければね」\n\n\n私「ふーん。シミュレーションもできる？」\n\n\nお父さん「ああ、そういうこと。じゃあ続けてハザード比の95%信頼区間の被覆確率（coverage）を出してみようか。Rでね」\n\n\n私「coverage？つまり、本当に100回に95回当たるかどうか？」\n\n\nお父さん「そう。信頼区間が真値を当てる頻度を、シミュレーションデータで数えるんだ。頻度論の約束が、どの程度守られているかを確かめる仮想実験だよ。前提条件を整理しよう。2群比較の生存曲線を比べたいんだよね」\n\n\n私「ストーマあり群とストーマなし群ね」\n\n\nお父さん「そうだね、ストーマあり群とストーマなし群のOSを比べよう。真のハザード比は1.5、つまりストーマあり群の方が寿命が1.5倍短い。ハザード比の95%信頼区間は、1000回シミュレーションしたら、1.5を約950回は含んでいるはず」\n\n\n私「ん？私、調査は1回しかしないつもりだけど」\n\n\nお父さん「あのね、聞いて。統計家が話している確率モデルは、実際にこれから行われる研究そのものじゃないと思った方がいい。たとえるなら”こういう集団から、こういうルールでデータを発生させて”と別世界に指示を出す手紙なんだ。現実と別世界はデータとRとシミュレーションでつながっている。その手紙に書かれたルールに従って別世界の誰かが研究を1000回繰り返す」\n\n\n私「ふーん。そこで当たりがでた割合がcoverageね」\n\n\nお父さん「そう。以前JCOG9502の話をしたとき、“p値が0.05だったら100回に5回は正しい”っていってたよ。自分の経験だと違って見えるものだけど同じこと。それでね、生存曲線の形は指数分布で決める。途中で追跡できなかった患者は打ち切り扱いになるけど、それも指数分布で発生させる。この設定だと、Cox回帰の仮定はすべて正しい。だから理論的にcoverageは95%になるはず」\n\n\n私「じゃあ、その通りになるかどうか、Rで確かめればいいんだね」\n\n\n\n\n\n\n\n\ncoxph()を用いた95%信頼区間のシミュレーション\n\n\n\nハザード比を推定する方法はいくつかありますが、もっともポピュラーなのはsurvivalパッケージのcoxph()です。以前のデモで、generate_data(hr1, hr2)を用いて、ストーマの有無やOSのデータを生成しました。今回は同じデータにCox回帰を当てはめ、ストーマあり群とストーマなし群のハザード比を計算してみます。この関数では、死亡ハザード比の真値はhr2という引数で指定できます。\n\n\n\n\n\n\n\n\ngenerate_data()のコードはこちら（データ生成に使用）\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # 再発のハザード（大きいほど早く起こる）\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # 死亡のハザード（大きいほど早く起こる）\n  hazard_censoring &lt;- 0.05                               # 打ち切りハザード（群に依存しない）\n  \n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)   # 再発までの潜在時間\n  t_death     &lt;- rexp(n, rate = hazard_death)     # 死亡までの潜在時間\n  t_censoring &lt;- rexp(n, rate = hazard_censoring) # 打ち切りまでの潜在時間\n  \n  ## --- 全生存期間（OS） ----------------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = 死亡, 0 = 打ち切り\n  \n  ## --- 無再発生存期間（RFS） -----------------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # 再発\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # 死亡\n  \n  ## --- 累積再発率（CIR） + 競合リスク --------------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # イベント1: 再発\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # イベント2: 競合リスクとしての死亡\n  \n  ## --- データフレームにまとめる --------------------------------\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n}\n\n\n\n\n\n\n\n\n\n\ncalculate_coverage()のコードはこちら（generate_data()とcoxph()を呼んでシミュレーションを実行）\n\n\n\n\n\n\ncalculate_coverage &lt;- function(model=c(\"coxph\",\"finegray\"), n, hr1, hr2, hr_true) {\n  replications=1000\n  covered &lt;- numeric(replications)\n\n  for (r in seq_len(replications)) {\n    dat &lt;- generate_data(n, hr1, hr2)\n    if (identical(model, \"coxph\")) {\n      fit &lt;- coxph(Surv(time_os, status_os) ~ stoma, data = dat)\n    } else if (identical(model, \"finegray\")) {\n      dat$fstatus_cir &lt;- factor(dat$status_cir,\n                                levels = 0:2,\n                                labels = c(\"censor\",\n                                           \"relapse\",\n                                           \"death\"))\n      fgdat &lt;- finegray(Surv(time_cir, fstatus_cir) ~ ., data=dat)\n      fit &lt;- coxph(Surv(fgstart, fgstop, fgstatus) ~ stoma, weight=fgwt, cluster=id, data=fgdat)\n    }\n    confidence_interval &lt;- confint(fit)\n    covered[r] &lt;- as.integer(confidence_interval[1] &lt;= log(hr_true) && log(hr_true) &lt;= confidence_interval[2])\n  }\n  coverage &lt;- mean(covered)\n  return(coverage)\n}\n\n\n\n\n\n\n\n\n\n\ncalculate_coverage()を実行するRコードと結果はこちら\n\n\n\n\n\n\n# install.packages(\"survival\") #インストールが必要なら実行\nlibrary(survival)\ncoverage_200 &lt;- calculate_coverage(model=\"coxph\", n=200, hr1=2, hr2=1.5, hr_true=1.5)\nprint(coverage_200)\n\n[1] 0.953\n\n\n\n\n\n\n\n私「だいたいcoverageが95%になるっていうのは確認した。でも結局、95%信頼区間ってどう理解すればいいの？」\n\n\nお父さん「教科書的にいうとね。同じようなデータを何度も集めて、毎回95%信頼区間を作ったとき、“真の値を含む区間”の割合が0.95になるように設計された指標なんだ。これを”in the long run”の性能って言ったりする。でも、概念的に理解するよりも、シミュレーションを行った方がわかりやすいと思って」\n\n\n私「いやわかりにくいだろ。1回の研究で”この区間が当たっている確率が95%“って意味じゃないんだね」\n\n\nお父さん「そうだね」\n\n\n私「じゃあ、人数が100人だったらどうなるの？人数が減ったら当たりにくくはならないの？」\n\n\nお父さん「設計上は当たりにくくなったりはしないよ。95%信頼区間のcoverageはサンプルサイズによらず95%になるように作ってある。n=100、200、400、800のシミュレーション結果をみてみようか」\n\n\n\n\n\n\n\n\ncalculate_coverage()を実行するRコードと結果はこちら\n\n\n\n\n\n\ncoverage_100 &lt;- calculate_coverage(model=\"coxph\", n=100, hr1=2, hr2=1.5, hr_true=1.5)\ncoverage_400 &lt;- calculate_coverage(model=\"coxph\", n=400, hr1=2, hr2=1.5, hr_true=1.5)\ncoverage_800 &lt;- calculate_coverage(model=\"coxph\", n=800, hr1=2, hr2=1.5, hr_true=1.5)\nprint(coverage_100)\n\n[1] 0.94\n\nprint(coverage_200)\n\n[1] 0.953\n\nprint(coverage_400)\n\n[1] 0.954\n\nprint(coverage_800)\n\n[1] 0.948\n\n\n\n\n\n\n\n信頼区間アプローチによるサンプルサイズ設計\n\n\n私「ほんとだ、だいたい95%。じゃあ調査人数は何人でもいいってことだ」\n\n\nお父さん「ん？どういう意味？」\n\n\n私「がんサバイバー何人に調査票を送るかってこと。だって信頼区間の性能は人数によらないんでしょ」\n\n\nお父さん「あ、ごめん、誤解があったね。サンプルサイズが小さくなると、coverageは同じでも、信頼区間幅が広くなる。つまり、同じ95%でも、どれくらい曖昧な推定値で我慢しないといけないかが変わるんだ。今のところ、何人に調査するつもりだった？」\n\n\n私「100人から調査票戻ってきたら上出来かなって思ってるけど」\n\n\nお父さん「やっぱり必要サンプルサイズは計算してなかったか。がんを手術した後の復職率を推定したいってことでいいの？それなら100人でギリギリだと思う」\n\n\n私「いや？前にお父さんにPECOを教えてもらったよね。あれから上司と相談して、ストーマを造設した患者の復職状況を造設しなかった患者と比べることにしたの」\n\n\nお父さん「そうなんだ。そうすると計算が違ってくる。100人だと足りないはず」\n\n\n私「へ？なんでそんなことわかるのよ。100人に協力してもらうのってたいへんなのよ」\n\n\nお父さん「どれだけサンプルサイズが必要なのかについて、統計学的な根拠に基づいて見積もる方法があるんだよ。この表をみてみて。ある書籍から借りてきたものなんだけど（Machin, et al. 2022）」\n\n\n割合0.01～0.15割合0.16～0.50\n\n\n表1. 割合の推定において指定した 95%信頼区間幅のため必要なサンプルサイズ\n\n\n\n割合 \\(\\pi\\)\n0.05\n0.10\n0.15\n0.20\n\n\n\n\n0.01\n108\n43\n25\n17\n\n\n0.02\n152\n52\n29\n19\n\n\n0.03\n201\n61\n33\n21\n\n\n0.04\n252\n72\n37\n23\n\n\n0.05\n304\n83\n41\n25\n\n\n0.06\n356\n95\n46\n28\n\n\n0.07\n407\n107\n50\n30\n\n\n0.08\n458\n118\n55\n32\n\n\n0.09\n508\n130\n60\n35\n\n\n0.10\n554\n139\n62\n35\n\n\n0.11\n604\n153\n69\n40\n\n\n0.12\n651\n164\n74\n42\n\n\n0.13\n696\n175\n78\n44\n\n\n0.14\n741\n186\n83\n47\n\n\n0.15\n784\n196\n87\n49\n\n\n\n\n\n表1. 割合の推定において指定した 95%信頼区間幅のため必要なサンプルサイズ\n\n\n\n割合 \\(\\pi\\)\n0.05\n0.10\n0.15\n0.20\n\n\n\n\n0.16\n826\n206\n92\n51\n\n\n0.17\n867\n216\n96\n54\n\n\n0.18\n907\n226\n100\n56\n\n\n0.19\n945\n236\n104\n58\n\n\n0.20\n982\n245\n108\n60\n\n\n0.25\n1150\n286\n126\n70\n\n\n0.30\n1288\n320\n141\n78\n\n\n0.35\n1395\n347\n152\n84\n\n\n0.40\n1472\n366\n161\n89\n\n\n0.45\n1518\n377\n166\n92\n\n\n0.50\n1533\n381\n167\n93\n\n\n\n\n\n\n\nお父さん「たとえばなんだけどね。復職率を調べたいとするでしょ。そうすると復職率をどれくらい精確に推定できたかを表す指標が、95%信頼区間だよね。仮に復職率が50%だったとしてみよう。そうすると、50%±10%程度の推定精度がほしいよね。ここでいう±の後の数字が、95%信頼区間の幅になるんだ」\n\n\n私「ああ、”50%（95%CI 40～60%）”みたいな感じで論文に書くことになるわけだ。40〜60%の場合、95%信頼区間幅は20%ってことね」\n\n\nお父さん「そういうこと。表では復職率を\\(\\pi\\)という変数で表しているんだけど、”\\(\\pi=0.5\\)”と”信頼区間幅0.2”に対応する数字をみて。93って書いてあるでしょ。これが必要サンプルサイズ」\n\n\n私「どうだろう。復職率ってもっと高くない？手術したときの年齢にもよるけど、たとえば患者さんが50歳前後だったら、80%はいってほしいなあ」\n\n\nお父さん「そうなんだ。そうすると復職率80%は非復職率20%と同じことだから、”\\(\\pi=0.2\\)”と”信頼区間幅0.2”のところをみればいい。サンプルサイズは60人」\n\n\n私「100人で足りてるじゃん」\n\n\nお父さん「いやいやいや、これは復職率の信頼区間からサンプルサイズを計算したからこうなったんだ。“信頼区間アプローチ”といって、主に探索的研究で使うものなんだよ。別の計算の仕方もある。ストーマ造設ありとなしの復職率を比べるような仮説検証を目指した研究なら、“仮説検定アプローチ”といって、仮説検定の考え方にそってサンプルサイズを計算しないといけない」\n\n\n私「そっか、だいたいわかった。私、午後から出かけるから。また今度教えてよ、じゃあね」\n\n\n\n\n\n\n\n\nサンプルサイズ設計の2つのアプローチ\n\n\n\n研究計画を立てるときには、サンプルサイズを見積もる必要があります。サンプルサイズの計算は大まかにいえば2種類あって、信頼区間アプローチ（たとえば表1）と仮説検定アプローチ（次回）を用いることができます。\n信頼区間アプローチは、調査や探索的研究で用いられます。このアプローチによって割合を推定するために必要なサンプルサイズを求めるとき、次の数値を設定する必要があります。\n\n割合の真値（復職率など）\n信頼区間幅\n\nもうひとつの仮説検定アプローチは、臨床試験や仮説検証型の研究に適しています。このアプローチでは、以下の3つの要素が最低でも必要です。\n\n有意水準（通常5%）\n検出力（通常80～90%）\n検出したい効果サイズ（2群間の生存確率の差やハザード比など）\n\nサンプルサイズ設計は、βエラーを制御するという意味で、p値と対になる統計手法といえます。\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n臨床検査の正常範囲の意味として正しいのはどれでしょうか。\n\nある集団からのランダムサンプルにおいて検査値の平均±1.96×標準偏差\n健常人集団における検査値の95%が含まれる範囲\n健常人集団における検査値の平均±1.96×標準誤差\nある集団からのランダムサンプルにおいて検査値の95%が含まれる範囲\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は2です\n\n標準偏差（SD）と標準誤差（SE）の区別が重要です。前者は「検査値自体が個人間でどのくらいばらつくか」を、後者は「平均の推定がどのくらい精確か」を表しています。そして、「平均±1.96×標準偏差」は、正規分布における「95%が含まれる範囲」に相当しています。\nなお、似て非なる範囲に「平均±1.96×標準誤差」があります。これは「仮想的反復の下で真の平均を95%の割合で包む区間」、すなわち頻度論統計学でいう95%信頼区間に対応します。\n\n\n\n\n\n文献\n\nMachin D, Campbell MJ, Tan SB, Tan SH. 医学のためのサンプルサイズ設計（原著第4版）. 京都: 京都大学学術出版会; 2022\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\nGreen J, Benedetti J, Smith A, Crowley J. 米国SWOGに学ぶがん臨床試験の実践 第2版（原書第3版）. 東京: 医学書院; 2013\n\n\n\n次のエピソードとRスクリプト\n\nAlpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size\nfrequentist.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nR Demonstration of Bias in Kaplan-Meier Under Competing Risks\nUnderstanding Confidence Intervals via Hypothetical Replications in R\nAlpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/glossary.html",
    "href": "jp/glossary.html",
    "title": "Statistical Terms in Plain Language",
    "section": "",
    "text": "Glossary − Statistical Terms in Plain Language\n\nKeywords: causal model, language & writing, probability model, survival & competing risks\n\n\n\n統計学のことば\n\n\n私「お父さん、いま診療科で輪読してる論文があるんだけど、言葉のニュアンスがつかめなくて。お父さんの話って、統計用語がいろいろ出てくるでしょ。正直いって実感がわかないのもあったんだ。よければ統計用語を日常用語で言い換えてみてくれないかな」\n\n\nお父さん「今日は時間があるからいいよ、いくつかやってみようか。五十音順に並べるね」\n\n\nAalen-Johansen法　Aalen-Johansen method\n競合リスク解析において、累積発生曲線を推定する方法\nαエラー　alpha error\n治療が本当は効かないのに有効と考えたり、関連がないのにあると判断してしまったりする類の誤り。偽陽性といってもよい。p値などを用いて5%以下に抑えることが、医学研究の慣習になっている\n一般化線型モデル　generalized linear model\n「回帰モデル」の一種で、回帰分析、分散分析、ロジスティック回帰などの統計手法の総称。統計ソフトウェアでは”GLM”という略称がよく用いられる\n打ち切り　censoring\n生存時間データを測定するとき、ある特定の時点で観察が妨げられ、その時点以降に関心のあるイベントが発生したであろうことしかわからなくなること\n回帰モデル　regression model\nある変数が他の変数とどのような関連にあるのかを調べるための統計手法。回帰分析と同義だが、「分析」は統計手法を指すニュアンスがあるのに対して、「モデル」というとなんらかの数式や確率分布を意味することが多い。\n確率モデル　probability model\n抽象的なデータの見方を「モデル」とこの作品では呼んでいる。確率モデルは、データがどのような確率分布から発生するかを仮定したモデルのこと。\n片側p値　one-sided p-value\n相関には、正の相関と負の相関があるが、そのうちのどちらかにしか関心がないとき用いられるp値のこと。片側ではなく両側p値を用いることが一般的\nKaplan-Meier法　Kaplan-Meier method\n生存時間解析において、生存曲線を推定する方法\n競合リスク　competing risk\nがんの原病死を追跡するときの事故死のように、それが起こると関心のあるイベントが観察されなくなる、競合するイベントのこと\n寄与割合　attributable fraction\nリスクや発生率の数値を変換して、特定の集団におけるリスク因子への曝露が、どのくらい疾患発症に寄与するかを割合で表したもの。いくつも定義がある\n効果サイズ　effect size\n治療の効果の大きさや、治療を比較したときの差のこと。サンプルサイズ設計では、効果サイズの値を設定しなければならないが、そもそもそれを知りたいから研究をするのだから悩ましい。このジレンマを皮肉って、「サンプルサイズから逆算して出した集積可能な差のこと」といった人もいる\n交絡　confounding\n集団を比較するとき気をつけるべきバイアス\nCox回帰　Cox regression\n1972年にCox教授が発明し、大流行した統計手法。回帰モデルの一種だが、一般化線型モデルではない。生存時間をアウトカムとして扱い、生存曲線の差をハザード比として要約したり、様々な因子が生存時間と関連があるかどうか検討するために利用される\nサンプルサイズ設計　sample size calculation\n対象者数などの研究の規模を決めること。たとえば、効果サイズ、αエラー、βエラー（または検出力）を設定することで、研究に必要な対象者数を計算できる\n情報バイアス　information bias\n情報を集めるとき気をつけるべきバイアス\n推定目標（エスティマンド）　estimand\n臨床試験で治療を始めた後に、有害事象が生じたり、治療を中止したりすると、その試験でどのような治療効果を調べたいのか曖昧になる。推定目標とは、その研究でなにを推定したいのかを意味する統計用語。臨床試験では、計画段階で推定目標を決めておくことが、ICH E9ガイドラインにより求められている\n生物統計家　biostatistician\n医学・生命科学における統計専門家のことだが、バイオインフォマティシャン、データサイエンティスト、疫学者とは、所属学会やコミュニティーが異なる。狭い意味では、臨床試験を専門とする統計プロフェッショナルのことを指し、そのための資格（試験統計家認定制度）もあるくらいだが、生物（bio）という接頭辞がついているためわかりにくい\n生存曲線　survival curve\n横軸に時間を、縦軸にその時点で生存している割合を図示したグラフのこと。がんや循環器疾患など多くの疾患領域で、研究結果が生存曲線として示されることが多い\n選択バイアス　selection bias\n研究の対象となる集団を選ぶとき気をつけるべきバイアス\n代替エンドポイント　surrogate endpoint\n治療が患者の予後に与える効果を調べるとき、臨床的に意味のある指標が得られないことがある。そのような状況で代わりに用いられるエンドポイントやアウトカムのこと。たとえばがん臨床試験では、奏効率が全生存期間の代替エンドポイントとして用いられてきたが、延命効果があるかどうかを必ずしも反映しないという批判も多い\nDAG（有効非循環グラフ）　directed acyclic graph\n抽象的なデータの見方を「モデル」とこの作品では呼んでいる。DAGは、変数間の因果関係を矢印で表した構造的な因果モデルの一種。\nデザイン　design\n統計学では昔から実験計画のことを”design”と呼んできたが、それが転じて、研究立案やその際に決めるべき要素を意味するようになった。ランダム化臨床試験、調査、コホート研究などは、デザインの一種\nバイアス　bias\n一般的には偏った見方や行動を指す言葉だが、統計学では、推定値が真値（推定目標）からずれる傾向やその程度の意味で用いられる。データを集めた後にバイアスがあることがわかったとしても、対処は難しい\nハザード比　hazard ratio\nCox回帰から計算される指標で、生存曲線を比較するために用いられる\n比　ratio\nある量を別の量で割ることで求められる指標。割合と率は比の一種\n比例ハザード性　proportional hazards assumption\n死亡や増悪のようなイベントが生じるスピードが、群の間で定数倍になっていて、その関係が時間を通じて変わらないという仮定のこと\np値　p-value\n研究結果をみるとき、真っ先に見てしまいがちな数字。統計学的有意（statistical significance）、つまり誤差を越えた関連があるか見分けるときに用いられる\nFine-Grayモデル　Fine-Gray model\n1999年にFine教授が発明した、Cox回帰を拡張した統計手法。競合リスクを含む生存時間データがアウトカムのときの回帰モデルの一種\nβエラー　beta error\nサンプルサイズ設計の鍵になる数字。せっかく臨床試験を行ったのに、真に効く治療を有効性がないと判断してしまう確率のこと。データをたくさん集めることができ、βエラーが低いことを、「検出力が高い」という\nランダム化　randomization\n新規治療と標準治療のように、介入の効果を比べたいとき、どの介入を受けるかをランダム（無作為）に決める操作のこと。バイアスが生じないようにする工夫のひとつ\n率　rate\n一定時間に事象が生じるスピードを表す指標。疫学では、人年法（発生数/観察人年）で計算される。人数を人数×年で割っているため、単位は1/年（より一般には1/時間）\nリスク　risk\n疾患が生じる確率のこと。ただし、どの集団を対象に推定したかによって疾患リスクは当然異なるから、リスクの数字だけを使うのはやめたほうがよい\n両側p値　two-sided p-value\n相関には、正の相関と負の相関があるが、両方に関心があるとき用いられるp値のこと。片側ではなく両側p値を用いることが一般的\nRubin因果モデル　Rubin causal model\n抽象的なデータの見方を「モデル」とこの作品では呼んでいる。Rubin因果モデルは、同じ解析単位において原因が別の値をとっていたとき、アウトカムがどうなっていたか（潜在結果変数）を用いて、因果効果を定義したモデルのこと。割付アルゴリズムや確率分布を含めた枠組みを指すこともあるが、因果効果の定義に関わる部分に焦点を当てるため、それらは明示的には扱わない。\nロジスティック回帰　logistic regression\nある事象が生じる確率と、他の変数との関連を調べるための統計手法。2値データがアウトカムのときの回帰モデルの一種。回帰係数の指数（exponential）をとることでオッズ比を計算できる\n割合　proportion\n全体に対してそれが占める分量を表す指標。2値データや分類データを要約するために用いられる。人数を人数で割っているため、単位がキャンセルして単位を持たない（無単位）\n\n\n私「こうして一覧で見ると、論文ででてきた呪詛もちょっとは人間の言葉に見えてきたかも」\n\n\nお父さん「そうそう。用語がわかると、あとは臨床やデータ自体の話に集中できるからね」\n\n\n\n\n\n\n\n\n統計用語の違い\n\n\n\n生存曲線は英語ではsurvival curveですが、同じまたは似た意味で用いられる用語は、survival function、survival rate、overall survival curve、Kaplan-Meier curveなど無数にあります。実はそれぞれ細かい意味が違うのです。\n\n生存曲線（survival curve）とほぼ同義\nSurvival function\nほぼ同義だが、曲線というよりある時点の値を意図した用語\nSurvival rate, survival probability, survival proportion\n生存曲線をどの統計手法で推定したのかを特定する用語\nKaplan-Meier curve, Kaplan-Meier estimator, Kaplan-Meier estimate, Kaplan-Meier method\nエンドポイントの種類を特定する用語\nOverall survival curve, disease-free survival curve, 5-year OS, 3-year DFS\n\n統計学では、推定方法を推定量（estimator）、推定した結果を推定値（estimate）、推定しようとしている対象を推定目標（estimand）といいます。ここは論文を書くとき注意が必要なところで、MethodsではKaplan-Meier estimatorと書くのが自然ですし、ResultsではKaplan-Meier estimateを用いることが多いでしょう。「人名+estimator」の代わりに「人名+method」という表記もできて、Kaplan-Meier methodの方がより広い意味で用いることができます。\n最後に注意してほしいのが、累積発生曲線（cumulative incidence curve）や累積発生関数（cumulative incidence function）です。論文の図の縦軸のラベルに用いられることが多い表現ですが、生存曲線と本質的に違いはないと思いがちですよね。しかしこれらは、競合リスクがあるときにだけ用いられる、統計家が意識して区別している用語です。専門的には、統計家の名前を用いてAalen-Johansen曲線とも呼びます。生存曲線の上下を反転したグラフを”cumulative”と呼ぶことがありますが、これは統計用語ではなく慣習的な表現です。累積発生曲線と区別しないと誤解が生じます。\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n以下の4つの単語は、正式な統計用語ではありませんが、しばしば臨床試験の文献で目にするものです。このうち、誤りとはいえないものはどれでしょう。\n\nサンプル数\nCOX回帰\nOS曲線\nT検定\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です。\n\nサンプルサイズのことをサンプル数と表記している文献がありますが、サンプル数は臨床試験でいえば群の数に相当するので、用法として誤りです。Coxは人名なので、1文字目以外は大文字ではありません。OS曲線は、overall-survival curveの意味ととれなくはないので、誤りとはいえないでしょう。t検定のことをT検定と表記するケースも目にします。T検定は、t検定とは別の統計手法として存在するのですが、臨床試験では使われないため誤記でしょう。"
  },
  {
    "objectID": "jp/logistic-regression-1.html",
    "href": "jp/logistic-regression-1.html",
    "title": "Understanding Collapsibility of Effect Measures: Marginal vs Stratified",
    "section": "",
    "text": "Adjusting for Bias I − Understanding Collapsibility of Effect Measures: Marginal vs Stratified\n\nKeywords: clinical trial, confounding & collapsibility, effect measure, R simulation\n\n\n\n効果の指標\n\n\n私「お父さん、なにか甘いものない？お腹すいちゃって」\n\n\nお父さん「大福だったら買い置きがあるよ。コーヒーとお茶、どっちにする？」\n\n\n私「コーヒー。ミルクも入れて。お茶もいいけど、統計の話を聞きたいときはコーヒーの気分なんだ。このあいだも、疫学で使う統計の話をしてくれたでしょ。でも、医学部で講義を受けたのが昔すぎてさ。疫学ってなにか忘れちゃったな」\n\n\nお父さん「疫学か。疫学は、集団における病気について調べる分野だよね。病気の原因を調べたり、予防方法や公衆衛生対策を立てたりする。がん、循環器、感染症など扱う病気によってだいぶ違うよね。まあ、疫学の基本はなにかっていったら、コホート研究とリスクかな」\n\n\n私「そうだったね、この前のワクチン有効率のやつは、リスクもワクチン有効率もパーセンテージ表記だからまぎらわしいって話だった。効果の指標（effect measure）もいろいろあったな。リスク比、オッズ比、ハザード比だっけ？」\n\n\n\n\nリスク比とオッズ比、どっちを使う？\n\n\nお父さん「じゃあ、リスク比とオッズ比の話をしようか。コーヒー飲みながら気楽に聞いてね。統計学が気にするのは、それぞれの指標の意味・解釈の違いもあるけど、それ以上に数学的な性質を考えているんだよね。オッズ比は数学的にいい面と悪い面がある。いいところは、”リスクの数値”と”1からリスクを引いた数値”が対称に出てくるような数式をしていること。生存確率と死亡確率をひっくり返しても同じっていったらいいかな」\n\n\n私「ふーんそうなんだ」\n\n\nお父さん「後は、ケース・コントロール研究のような、コホートの一部の情報しかない状況でも計算できるし、ロジスティック回帰のようなモデリングするとき利用しやすいのがいいところかな。悪い面はね、層別解析をしたとき、ちょっと不自然な計算結果になる」\n\n\n私「ケース・コントロール研究って、データベースとかを使って後ろ向きに調査するやつね。これも疫学。そうねえ、不自然な数字になるのは困るんじゃない？層別なんてしたこと私はないけど」\n\n\nお父さん「そうだね、次の2つの表は層別する前とする後の結果なんだけど、比べてみてよ」\n\n\n\n\n\n\n\n\n層別した指標の併合可能性\n\n\n\n表1と表2は、がん患者100人のランダム化臨床試験を想定して作った数値例です。表1では100人全体における死亡リスクを、表2はステージIIIの50人とステージIVの50人に層別した死亡リスクを示しています。\nまず、抗がん剤投与群の死亡リスクをみてください。ステージIIIでは死亡リスクは20%と低く、ステージIVでは40%と高いことがわかります。そして全体の死亡リスクは、ステージIIIとステージIVの平均（30%）です。このように、リスクには、層別する前の値が、層別した後の平均になるという性質があります。\nこれを踏まえて、リスク比、リスク差、オッズ比の性質を考えてみましょう。表1と表2を比べると、リスク比はすべて0.50倍です。このように、層別する前後でリスク比が変化しないことは、治療効果を測るために好ましい性質です。なぜなら、ステージIIIでリスクが半分になり、ステージIVでも半分になるなら、2つの層を合計してもリスクが半分になってほしいからです。リスク差は、2つのリスクの差をとったものです。したがって、リスクと同じように層別する前の値が、層別した後の平均になります。層ごとのリスク差が等しければ（この数値例ではそうなっていませんが）、層別前のリスク差も、層別後のリスク差と同じ値になるはずです。リスク差とリスク比の持つこの性質を、併合可能性（collapsibility）と呼んでいます。\n一方で、オッズ比は層の併合可能性を持たないことが知られています。表1と表2において、オッズ比は0.29倍、0.38倍、0.17倍と変化していますよね。\n\n\n\nステージによる層別前ステージによる層別後\n\n\n表1. 仮想的ながんランダム化臨床試験におけるリスク差・リスク比・オッズ比\n\n\n\n\n緩和療法群\n抗がん剤投与群\n効果の指標\n\n\n\n\n合計（100人）\n\n\n\n\n\n　死亡\n30\n15\n\n\n\n　生存\n20\n35\n\n\n\n　死亡リスク\n60%\n30%\n\n\n\n　リスク差\n\n\n-30%\n\n\n　リスク比\n\n\n0.50倍\n\n\n　オッズ比\n\n\n0.29倍\n\n\n\n\n\n表2. 層別後の死亡リスクとリスク差・リスク比・オッズ比\n\n\n\n\n緩和療法群\n抗がん剤投与群\n効果の指標\n\n\n\n\nステージIII（50人）\n\n\n\n\n\n　死亡\n10\n5\n\n\n\n　生存\n15\n20\n\n\n\n　死亡リスク\n40%\n20%\n\n\n\n　リスク差\n\n\n-20%\n\n\n　リスク比\n\n\n0.50倍\n\n\n　オッズ比\n\n\n0.38倍\n\n\nステージIV（50人）\n\n\n\n\n\n　死亡\n20\n10\n\n\n\n　生存\n5\n15\n\n\n\n　死亡リスク\n80%\n40%\n\n\n\n　リスク差\n\n\n-40%\n\n\n　リスク比\n\n\n0.50倍\n\n\n　オッズ比\n\n\n0.17倍\n\n\n\n\n\n\n\n\n私「なるほどね、リスク比を計算すると同じ0.5なのに、オッズ比の値はばらばらなんだ。オッズ比は層別すると同じ効果としては扱いにくいから注意しなさいってことね」\n\n\nお父さん「そうだね、研究者としては、ステージ別でも層別しなくても、リスクが半分になる治療なら、半分ってことが読み取れる値になってほしいよね。そういう感覚でしょ」\n\n\n私「うん」\n\n\nお父さん「そこまではいいんだ。でも誤解してほしくないのは、リスク比は併合可能で、オッズ比は併合可能ではない、だからオッズ比が悪いっていいたいわけじゃないよ。結果の読み取り方と相性があるってこと。オッズ比はオッズ比で、ロジスティック回帰と対応しているっていうのは別のメリットがある」\n\n\n私「ふーん。お父さんって数学的性質を整理するときめっちゃ早口」\n\n\n\n\nリスク差、リスク比、オッズ比、どれを使う？\n\n\n私「ごめん、そもそも論なんだけど。どうせ割合同士を比べるんだから、わざわざ比をとらなくてもいいんじゃない？パーセントの差でよくない？+10%とか-10%とか。リスクの違いはこれでじゅうぶん伝わるでしょ」\n\n\nお父さん「うん、リスク差はもっと使われていいと思う。でも、リスク差にも欠点がある。複数の研究を集めてメタアナリシスをするとき、それぞれの研究から得られたリスク差やリスク比をひとつの値に要約するでしょ」\n\n\n私「ああ、みたことある」\n\n\nお父さん「このとき問題になるのが、コントロール群（プラセボ群や緩和療法群）で観察されたリスクが、研究によって低かったり高かったりすることなんだ。同じ疾患や治療を扱っていても、予後のいい患者ばかり集めた研究もあれば、予後の悪い患者を対象にした研究もあるでしょ」\n\n\n私「そりゃあるよね」\n\n\nお父さん「リスク差、リスク比、オッズ比で、どれがコントロール群のリスクの影響を受けやすいかを、55件のメタアナリシスのデータを使って調べた研究がある（Furukawa, Guyatt, Griffith 2002）。その結果、以下のようなことがわかった」\n\n\n\nリスク差は、研究ごとにリスクが変動すると、その影響にともなうばらつきが大きい\nリスク比やオッズ比は、研究間を通じて数値が安定していた\n\n\n\nお父さん「つまりね、指標によって解釈のしやすさや統計的な特徴が違うっていうこと。リスク差だけでも、リスク比やオッズ比のような比の指標だけでも、論文で示す情報としては不足があるっていうのが、おそらく結論」\n\n\n私「じゃあどうしたらいいのよ」\n\n\nお父さん「結局、臨床研究で観察された差って、リスク差やワクチン有効率のようなひとつの数字で要約できないんだと思う。結果を報告するときは、絶対指標（リスク差）と相対指標（リスク比やハザード比）の両方を示したり、Kaplan-Meier曲線やAalen-Johansen曲線をグラフにするのが正解なんじゃないかな。数字しか出せないなら、いちばんバランスがいいのは、リスク差+リスク比かもね」\n\n\n\n\n\n\n\n\nglm()を用いたリスク差、リスク比、オッズ比の計算\n\n\n\nリスク差、リスク比、オッズ比はいろいろな手段で計算できますが、汎用性が高いのは一般化線型モデル（glm）を用いる方法です。リンク関数を選ぶことで、リスク差（link=\"identity\"）、リスク比（link=\"log\"）、オッズ比（link=\"logit\"）を選択することができ、交絡因子の調整もしやすいのが便利なところです。ただし、リスク比とオッズ比では、回帰係数の指数をとるひと手間が必要です。表1のリスク差、リスク比、オッズ比を再現するコードを示しておきますので、参考まで。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\ndat &lt;- data.frame(\n  treat = factor(c(\"palliative\", \"palliative\", \"chemotherapy\", \"chemotherapy\"), levels = c(\"palliative\", \"chemotherapy\")),\n  death = c(1, 0, 1, 0),\n  n     = c(30, 20, 15, 35)\n)\ndat\n\n         treat death  n\n1   palliative     1 30\n2   palliative     0 20\n3 chemotherapy     1 15\n4 chemotherapy     0 35\n\nfit_identity &lt;- glm(\n  death ~ treat,\n  family  = binomial(link = \"identity\"),\n  weights = n,\n  data    = dat\n)\nrisk_difference &lt;- coef(fit_identity)[[\"treatchemotherapy\"]]\nprint(risk_difference)\n\n[1] -0.3\n\nfit_log &lt;- glm(\n  death ~ treat,\n  family  = binomial(link = \"log\"),\n  weights = n,\n  data    = dat\n)\nrisk_ratio &lt;- exp(coef(fit_log)[[\"treatchemotherapy\"]])\nprint(risk_ratio)\n\n[1] 0.5\n\nfit_logit &lt;- glm(\n  death ~ treat,\n  family  = binomial(link = \"logit\"),\n  weights = n,\n  data    = dat\n)\nodds_ratio &lt;- exp(coef(fit_logit)[[\"treatchemotherapy\"]])\nprint(odds_ratio)\n\n[1] 0.2857143\n\n\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n一般化線型モデルの一種であるロジスティック回帰は、「確率」ではなく「オッズ」をモデル化しており、オッズ比を求めるためによく用いられます（田中2022）。さて、ロジスティック回帰を用いて、リスク比を計算することができるでしょうか。\n\nロジスティック回帰を用いてリスク比を計算できる\nロジスティック回帰を用いてリスク比を計算できない\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は1です\n\nロジスティック回帰の共変量に、数値を代入することで、確率を計算することができます。共変量として、2群（たとえば抗がん剤投与群と緩和療法群）を指定すれば、それぞれの群の確率が求まりますよね。その比をとれば、リスク比が計算できます。\n\n\n\n\n\n文献\n\nFurukawa TA, Guyatt GH, Griffith LE. Can we individualize the ‘number needed to treat’? An empirical study of summary effect measures in meta-analysis. Int J Epidemiol 2002; 31: 72-6\n田中司朗. 医学研究のための因果推論I. 一般化線型モデル. 東京: 朝倉書店; 2022\n\n\n\n次のエピソードとRスクリプト\n\nFrom Risk to Logistic Regression\nlogistic-regression.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nUnderstanding Collapsibility of Effect Measures: Marginal vs Stratified\nFrom Risk to Logistic Regression\nLogit: How a Transformation Shapes an Effect\nWhere My Logistic Regression Went Wrong\nWhy Logistic Regression Fails in Small Samples\nUnderstanding Confounding in Effect Measures: Marginal vs Stratified\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\nEffects and Time I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/logistic-regression-3.html",
    "href": "jp/logistic-regression-3.html",
    "title": "Logit: How a Transformation Shapes an Effect",
    "section": "",
    "text": "Adjusting for Bias III− Logit: How a Transformation Shapes an Effect\n\nKeywords: effect measure, generalized linear model\n\n\n\n数式を使ってロジスティック回帰を教えてよ\n\n\nお父さん「ああ、ここにいたんだ。コーヒーと大福？」\n\n\n私「うんうまいよ」\n\n\nお父さん「食べながらでいいから聞いてよ。ロジスティック回帰はね、医学研究でよく使うから知っておいた方がいいと思って。簡単にいうと、2値データのための回帰モデルの一種。ストーマ造設、年齢、性別、年収といった共変量が、復職の有無のような2通りの値をとるアウトカムとどの程度相関するかを、調べることができる」\n\n\n私「もうちょっと統計っぽく教えてよ」\n\n\nお父さん「ん？統計手法には、パラメトリック法とノンパラメトリック法があるけど、ロジスティック回帰はパラメトリックモデルの一種として位置づけられる。最近の教科書では、一般化線型モデルのひとつとして扱われることが多いかな」\n\n\n私「そういうんじゃなくてさ。ほら、リンク関数とか出てきたでしょ。ああいうのがでてくると消化不良でさ」\n\n\nお父さん「数式使っていいの？」\n\n\n私「うん。数式でてくると、ところどころわからないんだけど。ごまかされるのもいや。ほら、このペン使っていいよ」\n\n\nお父さん「じゃあ、個人のリスクと共変量の関係から話せばいいのかな」\n\n\n\n\n\n\n\n\nロジスティック回帰\n\n\n\n\\(N\\)人の対象者に番号をつけて\\(i=1,...,N\\)で表すことにします。個人\\(i\\)のリスクを\\(\\pi_i\\)で表します。\\(\\pi_i\\)は、個人レベルの\\(N\\)個のパラメータですが、そのすべてを別々に推定したいわけではありません。\\(\\pi_i\\)に関連する\\(p-1\\)個の共変量\\(X_{i,1},X_{i,2},...,X_{i,p-1}\\)が測定されており、両者の関連の強さに関心があるとします。このとき\n\\(\\log(\\frac{\\pi_i}{1-\\pi_i})=\\beta_0+\\beta_1X_{i,1}+...+\\beta_{p-1}X_{i,p-1}\\)\nという関係が成り立つ確率分布をロジスティック回帰といいます。\nこの式の係数\\(\\beta_0,\\beta_1,...,\\beta_{p-1}\\)を回帰係数（regression coefficients）、特に\\(\\beta_0\\)を切片項（intercept）といいます。正規分布は平均と分散というパラメータで形状が決まりますよね。それと同じように、ロジスティック回帰の確率分布は、回帰係数\\(\\beta_0,\\beta_1,...,\\beta_{p-1}\\)で規定されます。\\(\\pi_i\\)は、\\(\\beta_0,\\beta_1,...,\\beta_{p-1}\\)が与えられれば計算できますが、直接推定するわけではありません。\n\n\n\n\n私「ふむふむ。ひとりひとりに\\(\\pi_i\\)と\\(X_{i,1},X_{i,2},...,X_{i,p-1}\\)がある。そしてロジスティック回帰の式で結びついているわけね。そして、その式の係数が回帰係数」\n\n\nお父さん「そう。ロジスティック回帰の裏には2項分布があって、実は\\(\\pi_i\\)は2項分布の確率に対応している。2項確率の式に、共変量\\(X_{i,1},X_{i,2},...,X_{i,p-1}\\)が含まれていて、アウトカムと共変量の関連の強さを、回帰係数が決めるんだ」\n\n\n私「この式まではわかったよ」\n\n\nお父さん「よかった。ちょっと補足するとね、確率分布に含まれる未知数のことを、統計学ではパラメータと呼んでいる。そしてパラメータの関数として、確率分布を書くことができるものを、パラメトリックモデルっていうんだ。こういう風に考えると、パラメータを推定したり、推定値に信頼区間をつけたりすることが、統計解析の目標になるよね。もうひとつ知っておいてほしいのが、ロジスティック回帰では、アウトカムと共変量の関係がロジット関数（logit function）で結びつくと仮定していること。glm()について話したの覚えてる？」\n\n\n私「うん。リンク関数をlinkで指定することは理解したよ。それがこの式？」\n\n\nお父さん「そうだよ。glm()の引数は、family、y ~ x1 + x2、linkなんだけどfamily=binomial()のように 2項分布を選ぶと自動的にロジット関数が使われる。ロジスティック回帰の左辺をみてよ」\n\n\n\n\n\n\n\n\nリンク関数とロジット関数\n\n\n\n個人のパラメータと共変量との関係を結びつける1対1の単調な変換\n\\(g(\\pi_i)=\\beta_0+\\beta_1X_{i,1}+...+\\beta_{p-1}X_{i,p-1}\\)\nのことを、一般にリンク関数（link function）といいます。ロジスティック回帰のリンク関数は\n\\(g(\\pi_i)=\\log(\\frac{\\pi_i}{1-\\pi_i})\\)\nです。この関数はロジット関数と呼ばれ、ロジスティック回帰を特徴付けています。\n\n\n\n\nロジット関数の特徴\n\n\n私「単に関数に名前をつけただけでしょ。もうちょっと解説が欲しいなあ」\n\n\nお父さん「そうだよね。ロジット関数も関数の一種だから、グラフにした方が特徴がつかみやすい。次の説明だとどうかな」\n\n\n\n\n\n\n\n\nロジット関数の形状\n\n\n\n仮に共変量が1個で、連続データだったとしましょう。確率\\(\\pi_i\\)と共変量\\(X_i\\)の関係は、ロジット関数を通じて\n\\(\\log(\\frac{\\pi_i}{1-\\pi_i})=\\beta_0+\\beta_1X_{i}\\)\nという式で表されることになります。\n図は、このロジット関数の\\(\\exp(\\beta_1)\\)の値を5、10、20、200と設定して、\\(X_i\\)を0から1までの範囲で変化させた、ロジット関数の逆関数のプロットです。\\(\\exp(\\beta_1)\\)は、\\(X_i\\)が1SD変化したときのオッズ比に相当します。つまり、図でもっとも傾きの小さい黒い曲線は、オッズ比5のときのものです。この曲線はそれほど変化が急にはみえませんが、医学研究ではオッズ比5でもかなり強い関連です。\nこのように、ロジット関数の逆関数はS字型の曲線を表しています。X軸方向にどんな値をとったとしても、Y軸方向の変化は0から1の範囲に収まることが、特徴のひとつです。そして、曲線の傾きは回帰係数\\(\\beta_1\\)によって決まります。\n\n\n\n\n\n私「やっとイメージがわいた。ロジット関数って、確率と共変量との関係を表してるんだ。どれくらい年齢が上がると、復職できる確率が下がるか、みたいなことね」\n\n\nお父さん「さらに、ロジスティック回帰は、がんサバイバー調査のように群を比較するときにも使われる。シンプルに2人の対象者を比べるとどうなるかって話をするね」\n\n\n\n\n\n\n\n\nロジット関数とオッズ比の関係\n\n\n\n共変量が1個のとき、ロジスティック回帰は\n\\(\\log \\left(\\frac{\\pi_i}{1-\\pi_i}\\right)=\\beta_0+\\beta_1X_{i}\\)\nと表すことができます。そして、対象者\\(i=1\\)では\\(X_{1}=0\\)、対象者\\(i=2\\)では\\(X_{2}=1\\)という値をとる状況を考えてみましょう。それぞれの対象者の共変量の値を、上の式に代入すると、以下のようになります。\n\\(\\log\\left(\\frac{\\pi_1}{1-\\pi_1}\\right)=\\beta_0\\)\n\\(\\log\\left(\\frac{\\pi_2}{1-\\pi_2}\\right)=\\beta_0+\\beta_1\\)\nここで、\\(\\pi_1\\)は対象者1の確率パラメータ、\\(\\pi_2\\)は対象者2の確率パラメータです。これらの確率パラメータから、オッズ比を求めるとどうなるでしょうか。それは、以下の式で計算されます。\n\\(\\left(\\frac{\\pi_2}{1-\\pi_2}\\right)\\div\\left(\\frac{\\pi_1}{1-\\pi_1}\\right)=\\exp(\\beta_0+\\beta_1)\\div \\exp(\\beta_0)=\\exp(\\beta_1)\\)\nこの結果は、回帰係数\\(\\beta_1\\)の指数をとるとオッズ比が得られることを意味しています。\n\n\n\n\n私「なるほど、回帰係数からオッズ比を計算できるってこういうことなのね」\n\n\nお父さん「このオッズ比の計算ができるのは、ロジット関数の特徴によるものでしょ。だから、ロジスティック回帰はオッズ比のモデルともいえるんだ。リスク比にはリスク比のモデルがあるし、リスク差にはリスク差のモデルがある。大事なのはfamily、y ~ x1 + x2、linkを選ぶことで、データの型にあった回帰モデルを指定できるってこと。yとxにそれぞれ連続変数を指定すると、散布図に回帰直線を掛くことができるし、計数データにPoisson回帰を当てはめたりもできる。一般化線型モデルは、生存時間データや経時データ以外ならほとんど対応できる汎用的な統計手法なんだ」\n\n\n\n\nロジスティック回帰の可逆性\n\n\n私「でもね、その説明だとみんなロジスティック回帰を使ってる理由にはなってないよね。link=\"logit\"よりlink=\"identity\"、つまり変換しなくたっていいじゃない」\n\n\nお父さん「それはリスク差のモデルだね。そのモデルが悪いわけじゃないけど、ロジット関数が選ばれた理由はちゃんとある。この話はちょっと抽象的かもしれない。たとえるならね、ロジスティック回帰はルービックキューブのように構造が安定しているんだ」\n\n\n私「どういう意味？」\n\n\nお父さん「操作を加えても構造が維持されるっていうこと。どんな方向で、どんな順序で面を回しても、ルービックキューブは元に戻せる。解けば絵の向きもきちんと揃う。観測できるのは、ただの1面しかないんだけどね」\n\n\n私「ロジスティック回帰とルービックキューブねえ」\n\n\nお父さん「統計解析に話を戻そうか。人工的にデータに変換を加えることがあるよね。たとえば死亡じゃなくて生存をアウトカムにしたり、LDLコレステロールの単位をmg/dLからmmol/Lに変えたり。これは共変量\\(X_i\\)のスケール変換のことだよ」\n\n\n私「うんうん。それはよくやることだよね」\n\n\nお父さん「統計学者は、いろいろな回帰モデルのうち、変換に対して不変な構造はなにかって考えた。ここでいう変換は、数学では群作用（group action）っていうんだけど、ある変換を加えても意味が変わらない操作のこと」\n\n\n私「出た。抽象。なんだそれ」\n\n\nお父さん「ほら、コインの表裏を入れ替えてもコイン投げの確率は変わらない。ルービックキューブを回転しても構造は変わらない。考えた結果、2値アウトカムのモデルでは以下のパーツを使うしかないってことがわかった」\n\n\n確率分布: 2項分布（指数型分布族）\n回帰係数×共変量（線型結合）\nリンク関数: ロジット関数\n\n\nお父さん「ここで出てくるロジット関数は、変換しても可逆性（invertibility）を保つ唯一の関数なんだ。たとえば死亡確率を\\(\\pi=0.2\\)とするよ。このとき生存確率は？\\(1-\\pi=0.8\\)だよね」\n\n\n私「うん。当たり前」\n\n\nお父さん「この”死亡と生存を入れ替える”という操作が群作用に相当する。ここで問題にしているのはリンク関数\\(g\\)だったよね。確率\\(\\pi\\)を、リンク関数で別のスケール\\(g(\\pi)\\)に変換したとする。このとき、死亡と生存を入れ替えても、値が反転するだけで構造が維持されるには\\(g\\)はどんな性質を持つべき？」\n\n\n私「なるほどね、そういう意味で可逆性っていってるのね。でも値が反転するってのがわかんないな。どういうこと？」\n\n\nお父さん「つまりこういうこと」\n\n\\[g(1−\\pi)=−g(\\pi)\\]\n\n私「へ？やっぱ意味わかんない」\n\n\nお父さん「さっき、対象者1の\\(\\pi_1\\)と対象者2の\\(\\pi_2\\)を比べるとオッズ比が出てきたのを思い出して。あのとき、\\(g(\\pi_1)\\)と\\(g(\\pi_2)\\)の差をとっていた。\\(g\\)じゃなくてロジット関数そのものを使ったけどね。つまり、\\(g(\\pi)\\)は差のスケールで死亡リスクがどれくらい高いかを表す尺度なんだ。死亡と生存を入れ替えたらどうなる？\\(g(1-\\pi)\\)は死亡リスクの低さを意味するよね。つまり、死亡と生存の入れ替えによって、符号は反転するはず」\n\n\n私「なるほど。\\(g(1−\\pi)=−g(\\pi)\\)という関係が成り立つのはなにか探せばいいのね？」\n\n\nお父さん「もう少し条件がある。さっきいった共変量の変換でも関係性は維持されるっていう条件がそのひとつ。また、\\(g(\\pi)\\)という尺度に、上限と下限があったら不便だし、ゼロという基準が必要だよね。だからさらに条件を追加する」\n\n\n\\(g(1−\\pi)=−g(\\pi)\\)\n\\(\\pi\\)が0に近づけば\\(g(\\pi)\\)は−∞に向かう\n\\(\\pi\\)が1に近づけば\\(g(\\pi)\\)は∞に向かう\n\\(\\pi=1/2\\)を基準にとって\\(g(1/2)=0\\)\n\n\nお父さん「この4つの条件を満たす滑らかな関数は、実はほとんどひとつしかない」\n\n\\[g(\\pi)=\\log \\left(\\frac{\\pi}{1-\\pi}\\right)\\]\n\n私「それがロジット関数ってことか。データを人工的に変換しても解析結果が変わらないってこと？」\n\n\nお父さん「あれ、そこまでは説明しなかったけど、その通り。可逆性があるモデルでは、データを変換しても構造もそれに合わせて変わってくれて、本質的に同じ解析結果が得られる。みんなが使っている統計手法はね、大半が人間が選んだだけじゃないんだ。数学的な法則がそっと姿を現しているんだよ」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n脳卒中発症の有無をアウトカム、LDLコレステロールを共変量としてロジスティック回帰を当てはめたとします。LDLコレステロールの単位をmg/dLからmmol/Lに変換したとき、オッズ比は何倍になるでしょうか。ただし\nLDLコレステロール(mmol/L) =LDL コレステロール(mg/dL) ×0.02586\nという関係が成り立ちます。\n\n0.02586倍\n1/0.02586倍\n変化しない\n1、2、3すべて誤り\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n正解は4です。\nこれは単位を換算するにはどうすればよいかという問題です。ある共変量Xの効果は、回帰係数βとの積（βX）で表され、それは共変量の単位によらず一定ですよね。このことに気づくと、答えに近づきます。Xの単位を定数倍すると、βは定数分の一に換算されます。ただし、ロジスティック回帰では、回帰係数からロジット関数を経由してオッズ比を求めるため、単位を換算するには、1/0.02586乗のようにべき乗の操作をすることになります。\n\n\n\n\n\n文献\n\n田中司朗. 医学研究のための因果推論II. Rubin因果モデル. 東京: 朝倉書店; 2022\n\n\n\n次のエピソードとRスクリプト\n\nWhere My Logistic Regression Went Wrong\nlogistic-regression.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nUnderstanding Collapsibility of Effect Measures: Marginal vs Stratified\nFrom Risk to Logistic Regression\nLogit: How a Transformation Shapes an Effect\nWhere My Logistic Regression Went Wrong\nWhy Logistic Regression Fails in Small Samples\nUnderstanding Confounding in Effect Measures: Marginal vs Stratified\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\nEffects and Time I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/logistic-regression-5.html",
    "href": "jp/logistic-regression-5.html",
    "title": "Why Logistic Regression Fails in Small Samples",
    "section": "",
    "text": "Adjusting for Bias V − Why Logistic Regression Fails in Small Samples\n\nKeywords: bias, effect measure, generalized linear model\n\n\n\nなぜロジスティック回帰の計算ができなかったのか\n\n\n私「お父さん、コーヒー飲んで寛いでいるところわるいんだけど、時間あるかな。ロジスティック回帰についてなんだけど。説明してくれたのはありがたいんだけどね、群作用とか完全分離とか、途中でわかんなくなっちゃってさ。気になって、先に進めないわけよ」\n\n\nお父さん「そうだったのか。Rコードを見せてもらったけど、解析自体は間違ってなさそうだよ」\n\n\n私「いや、私自身の問題だよね。納得感というか自信というか。だからさ、完全分離について説明してくれない？この前の解析で、なにが起きたのか知りたいんだよね。あの解が出なかったていう結果しかないと、なんだかね」\n\n\n\n\n\n\n\n\nロジスティック回帰の推定\n\n\n\n尤度関数による推定\n以前、ロジスティック回帰の\\(\\pi_i\\)は2項分布の確率に対応しているといいました。2項分布の確率関数にはデータと\\(\\pi_i\\)が含まれていますが、この式にデータを代入すると、\\(\\pi_i\\)の式が得られます。さらに、\\(\\pi_i\\)は\\(\\beta_0,\\beta_1,...,\\beta_{p-1}\\)の関数です。したがって、確率関数の式は、\\(L(\\beta_0,\\beta_1,...,\\beta_{p-1})\\)というように、\\(\\beta_0,\\beta_1,...,\\beta_{p-1}\\)の関数とみなすことができます。この関数を尤度関数といいます。\nロジスティック回帰の回帰係数は、この尤度関数を最大化する値として計算されます。ただし、データから必ずしも解が求まるわけではありません。計算が収束しなかったり、不安定になったりする理由は、主に2通り考えられます。\n完全分離\n一つ目は、完全分離（complete separation）や擬似完全分離（quasi-complete separation）です。完全分離とは、\n\\(\\log(\\frac{\\hat\\pi_i}{1-\\hat\\pi_i})=\\hat\\beta_0+\\hat\\beta_1X_{i,1}+...+\\hat\\beta_{p-1}X_{i,p-1}\\)\nを計算したとき、その値によって、アウトカムを100%の精度で0または1に判別できてしまう状況のことをいいます。擬似完全分離は、100%ではないものの、共変量からアウトカムがほぼ判別できてしまう状況です。別の言葉でいえば、共変量の情報に比べて、データに含まれる情報が不足していて、実質的にランダム性がないということを意味します。つまり、完全分離や擬似完全分離は、サンプルサイズに比べ、共変量の数が多すぎるときによく生じる問題です。\n多重共線性\n二つ目は、多重共線性（multicollinearity）です。これは、共変量同士の相関が強すぎることを意味します。仮に、年収が年齢に完全に比例する状況（つまり相関が1）を考えてみてください。このとき、ロジスティック回帰を用いて年収と年齢の影響を分離することはできません。これが多重共線性の一例です。言い換えると、相関の高い共変量は、推定が不安定になるため、同時にロジスティック回帰に含めない方がよい場合が多いです。\n\n\n\n\nお父さん「つまり、完全分離が生じるデータは、若い人は全員復職、高齢者は全員非復職っていう調査結果みたいなもの。年齢だけで復職できるかどうか100%当てられてしまう。まさにこれが完全分離で、尤度関数から解が求まらない状況だよ」\n\n\n私「あれ？回帰分析って最小2乗法を使うんじゃないの？尤度関数？」\n\n\nお父さん「大学の教科書ではそう教わるけどね。最小2乗法を使うのは連続データのときだけかな。別の推定方法もいろいろある」\n\n\n私「ふーん。新しい方法がいろいろありそうってのは知ってるよ。AIとか機械学習とか」\n\n\nお父さん「まあね。はやりだよね」\n\n\n私「統計学と機械学習ってどう違うの？同じ？」\n\n\nお父さん「お隣さんって感じかな。データを解析するって意味では同じことをしているわけだし、機械学習の教科書でも、ロジスティック回帰とかロジスティック判別とかは扱うもの。統計学で習うROC曲線なんかは、機械学習の範疇な気がするし。重なる部分は多いよ。まあ、機械学習の方がたくさんのパラメータを推定する傾向にあるとはいえるかな。ロジスティック回帰よりニューラルネットワークの方が、モデルも複雑だし、パラメータの数も多い。さっき共変量の数を減らそうっていったでしょ。機械学習では、ああいうパラメータの数を減らすって発想はしない」\n\n\n私「パラメータの数が少ないのが統計学の特徴ってわけ？」\n\n\nお父さん「うーん、でもそれは程度問題かもしれない。一番の違いはなんだろうね。統計学は確率モデルが必ず基礎にあるってことかな。そして、標本から母集団を調べるっていう考え方をする。手法でいうと、p値とか信頼区間とか、ああいうやつね」\n\n\n統計手法を選ぶ理由\n\n私「はやりだから使っていいのかな。ほら、ニューラルネットワークとかこの前の群作用とか、知らなくてもみんな使ってるよね。問題ないのかな」\n\n\nお父さん「でもね、2項分布とロジット関数のところまでは理解できなかった？」\n\n\n私「そこまではできた」\n\n\nお父さん「なら合格点だと思う。数理的な手法って奥が深いでしょ。だから、仮に数学的な真実があったとして、究極的には部分的な理解しかできないかもしれない。専門家とユーザーで程度は違うけどね。だから、みんな使ってるっていうのは、使ってもいい理由のひとつにはなる。医療でも、添付文書で有効性が確立していないって書かれた薬が、第一選択だったりするでしょ」\n\n\n私「ああ、コミュニティスタンダードのことね。そういうこともあるのが現実だけど、すっきりはしてないよね、医師はみんな。それにさ、コミュニティスタンダードの薬は、単にみんな使っているから選んでるんじゃないよ。難病で他に候補がなかったり、エビデンスが足りなくても経験上は効果があるから、その薬を使って治療してるの」\n\n\nお父さん「それって、医療上の目的に対してじゅうぶん役に立ってるってことでしょ。ロジスティック回帰も同じじゃない？用途に見合った性能があるって自信を持っていえれば、ところどころ理解が追い付かなくても、使用していいと思う。そう、まさに完璧に解明された技術なんてないのが現実だからね。世の中ではいろんな技術が使われてる。でも、すべて3つの理由で正当化されるんだよ」\n\n\n数学と自然科学が支えている\nコミュニティが支えている\n使用する目的が支えている\n\n\nお父さん「それぞれが100%じゃなくても、この3つが支えあえれば使う意味があるんだ」\n\n\n私「そういうもんかな。納得したような、まだ霧が残っているような気もする。まあいいや、疲れてきたし。性別のオッズ比が無限大になった理由はわかったよ。尤度関数にデータを代入したら、回帰係数の解が変になるような式になったってわけね」\n\n\n\n\n\n\n\n\n\nデータの型と統計手法\n\n\n\n\n\nアウトカムはデータの型によって4種類に分類されます。\n\n連続データ （例：血圧やQOL）\n分類データ （例：有害事象の有無）\n計数データ （例：有害事象の発生件数）\n生存時間データ （例：全生存期間）\n\nさらに、分類データはいくつかの種類があり、カテゴリが2通りのものを2値データ、カテゴリに順序があるものを順序データと呼んでいます。生存時間データの一種には、競合リスクを考慮した競合リスクデータがあります。データの型によって、正規分布や2項分布など確率分布が異なりますよね。そのため、それぞれ異なる統計手法が用いられます。詳しくは表をみてください。\n仮に、ストーマ造設あり・なしと復職状況の関係を調べたいとすると、2つの変数をモデルに当てはめることになるため、回帰モデルを用いて調べたいとします。このときアウトカムを復職の有無（2値データ）とするなら、ロジスティック回帰を選ぶべきです。もし復職までの期間（生存時間データ）とするなら、Cox回帰の方が適切です。\n個人内で反復測定があるか\n同一個人にくり返し臨床検査やアンケートを行うと、似たような検査結果になりますよね。たとえば、朝と晩に血圧を測ると、2つの測定値に相関が生じます。治療前と治療後に、QOL質問票に回答してもらう場合も、その測定値は独立ではありません。このように1人の患者に複数回の測定値があるデータを反復測定データといいます。反復測定データでは、個人内の測定値は独立ではありません。したがって、独立性を仮定している統計手法（たとえば対応のないt検定や\\(\\chi^2\\)検定）は不適切です。反復測定データの解析では、変量効果モデル（random-effects model）や一般化推定方程式（generalized estimating equation）と呼ばれるやや高度な手法が用いられます。この場合の変量効果は、「ひとりひとりの個人の効果」を表しています。これらの方法は、個人内でデータが独立ではないこと（データの相関）を考慮するものです。\n交絡の調整が必要かどうか\n交絡因子（confounder）とは、治療とアウトカムとの関係を歪める第三の因子のことです。仮に、ストーマ造設あり・なしと復職状況の関係に、年齢が強くかかわっているとしましょう。そして、ストーマ保有者と非保有者で、平均年齢が異なっているとします。このような場合、2群間の年齢の違いを無視するとバイアスが生じます。これを補正するために、ロジスティック回帰がよく用いられます。 ランダム化臨床試験では、比較する群間で実験条件が揃っているため、交絡の調整は不要です。一方、観察研究（コホート研究やケース・コントロール研究）では交絡の調整は必須です。今回題材にした復職率の調査も観察研究の一種ですから、統計解析ではロジスティック回帰やCox回帰が主に用いられるでしょう。最近では交絡を調整して、正しく因果関係を調べるために、因果推論の手法（プロペンシティスコアなど）を用いることが増えてきました（田中2022）。\n\n\n\n\n\n\n\n\n\n\nデータの型\n反復測定\n交絡調整\n統計手法\n備考\n\n\n\n\n連続データ\nなし\nなし\n対応のないt検定、Wilcoxon順位和検定\n平均の比較\n\n\n\n個人内で2回測定\nなし\n対応のあるt検定、Wilcoxon符号付順位検定\n対応のあるデータ\n\n\n\nなし\nなし\n正規線型モデル\n回帰モデルの一種\n\n\n\nあり\nあり\n変量効果モデル、一般化推定方程式\n回帰モデルの一種\n\n\n2値データ\nなし\nなし\n\\(\\chi^2\\)検定\n割合の比較\n\n\n\n個人内で2回測定\nあり\nMcNemar検定\n対応のあるデータ\n\n\n\nなし\nあり\nロジスティック回帰\n回帰モデルの一種\n\n\n\nあり\nあり\n変量効果モデル、一般化推定方程式\n回帰モデルの一種\n\n\n計数データ\nなし\nなし\n\\(\\chi^2\\)検定\n発生率の比較\n\n\n\nなし\nあり\nPoisson回帰\n回帰モデルの一種\n\n\n\nあり\nあり\n変量効果モデル、一般化推定方程式\n回帰モデルの一種\n\n\n生存時間データ\nなし\nなし\nKaplan-Meier曲線\n生存曲線の記述\n\n\n\nなし\nあり\nCox回帰\n回帰モデルの一種\n\n\n競合リスクデータ\nなし\nなし\nAalen-Johansen曲線\n累積発生率曲線の記述\n\n\n\nなし\nあり\nFine-Grayモデル\n回帰モデルの一種\n\n\n\n\n\n\n\n\n次のエピソードとRスクリプト\n\nUnderstanding Confounding in Effect Measures: Marginal vs Stratified\nlogistic-regression.R\n\n\n\n\n\n\n\n他のエピソードはこちら\n\n\n\n\n\nこのシリーズのエピソード\n\nUnderstanding Collapsibility of Effect Measures: Marginal vs Stratified\nFrom Risk to Logistic Regression\nLogit: How a Transformation Shapes an Effect\nWhere My Logistic Regression Went Wrong\nWhy Logistic Regression Fails in Small Samples\nUnderstanding Confounding in Effect Measures: Marginal vs Stratified\n\n過去のシリーズ\n\nStudy Design I\nFrequentist Thinking I\nFrequentist Experiments I\nEffects and Time I\n\n用語集\n\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/publish-a-paper-1.html",
    "href": "jp/publish-a-paper-1.html",
    "title": "A Subtle Distinction Between Editors and Reviewers",
    "section": "",
    "text": "Publish a Paper I − A Subtle Distinction Between Editors and Reviewers\n\nKeywords: bias, language & writing, research hypothesis\n\n\n\n\n\n\n\n\n前回までのあらすじ\n\n\n\n\n\nはじめて研究に取り組む娘と統計家の父。父に研究仮説は”PICO”を”PECO”で整理するといいとアドバイスされ、医師である娘は、がんサバイバーにおけるストーマ造設と復職状況の関係を調査することに決める。調査は終ったが、いざ論文を書くとなると腰が重くなり、パソコンを閉じて父に話しかけるのだった。\n\n\n\n\nEditorとReviewerってちがう人なんだ\n\n\n私「がんサバイバー調査についてなんだけどね。調査結果がまとまったから、論文を書かなきゃって思ってるんだけど…。お父さんって、どこかのジャーナルで統計エディターしてたよね？論文って、どんな感じで書くと採択されやすいのかな」\n\n\nお父さん「どんな感じねえ。医学が専門ってわけじゃないから話しにくいな。自分ではどう思ってる？」\n\n\n私「はやってる研究テーマは通りやすそう。免疫チェックポイント阻害薬みたいな新薬とか、新しい診断基準とか。あ、ランダム化臨床試験は、調査より注目されるし、きっと有利ね」\n\n\nお父さん「そのイメージはまずまずあってると思うよ。エディターをやってて感じるのはね、採択するときの基準は、突き詰めると2つしかない」\n\n\nその研究から得られた結論の価値（value）は高いか\n結論は妥当な方法論（methodology）で導かれているか\n\n\nお父さん「ランダム化臨床試験が絶対に正しい方法っていってるわけじゃないよ。臨床試験でも、観察研究でも、それぞれの分野で認められている方法論に従って行われているかを、エディターやレビュワーはチェックしてるんだ」\n\n\n私「あれ？エディターとレビュワーって違う人？」\n\n\nお父さん「もちろん。採択されるかどうかは、ピアレビュー（査読）の結果で決まるでしょ。レビュワーの役割は、論文や学会抄録を読んで、採点したり、修正（revise）を求めるときはどこを直してほしいかコメントしたりすること。エディターの役割は、一言でいうとジャーナルを編集すること。編集事務局を運営したり、編集方針を決めたり、レビュワーを割り当てたりする。採択するかどうかはエディターが判断するし、査読コメントを著者に送ることもある。たとえばね、カバーレターってあるでしょ。論文につける手紙」\n\n\n私「聞いたことないよ。そんなのあるんだ」\n\n\nお父さん「そっか。カバーレターの宛先は、レビュワーじゃなくてエディターだよっていおうとしたんだけど。カバーレターは、たいてい編集委員長（Editor-In-Chief）宛に書くんだ」\n\n\n私「ふーん。カバーレターって大切？」\n\n\nお父さん「どうだろうね。お父さんは、カバーレターで研究の価値をアピールする方だけど、定型文で十分っていう人もいる。周りの研究者に聞いても、どれくらい重視するかはまちまち。ろくに読まないエディターもいるのは事実」\n\n\n私「そういうもんか。ピアレビューが何かはどこかで聞いたことあるよ。ジャーナルからコメントがきて、著者がそれに回答するんだよね。でも、裏側では、エディターじゃなくてレビュワーが採点してるんだ」\n\n\nお父さん「ジャーナルによって、多段階評価だったり数字をつけたりするけどね。エディターがレビュワーから集めた採点結果とコメントをとりまとめて、著者にどういう判断になったかを伝える」\n\n\n採択（accept）\n大修正（major revision）\n小修正（minor revision）\n不採択（reject）\n\n\nお父さん「ピアレビューを経ないと、論文が粗製乱造されてしまう。だから、研究者はみんなピアレビューという仕組みを大切にしている」\n\n\n私「ちなみにお父さんお金もらってる？」\n\n\nお父さん「いや？ボランティア。利益相反とかいわれるとややこしいから、むしろどこからもお金を受け取りたくない。2019年にレビュワーの利益相反が問題になったことがあってね。それ以来、そのジャーナル（BMJ）は、査読コメントや著者の回答をサイトで公開するようになった。ピアレビューのプロセスが知りたければ、そのサイトをみてみたらいいよ。論文投稿するときは、論文を書くだけじゃなくて、英語でやり取りしなきゃいけないことが案外多いから、参考になるかもしれない」\n\n\n\n\n価値と方法論\n\n\n私「ふむふむ。話を戻すとさ。採択される基準は、価値と方法論っていってたよね。具体的にはどうすればいいの？」\n\n\nお父さん「エディターはたくさんの論文をさばかなきゃいけないから、ざっとタイトルと抄録だけ目を通すことが多い」\n\n\n私「ふむふむ」\n\n\nお父さん「たいていの臨床医学系のジャーナルでは、構造化抄録を採用しているから、なにをどこに書けばいいかはわかりやすい。JAMAの抄録がどんな要素から構成されてるかみてみようか」\n\n\nImportance（研究の重要性）\nObjective（目的）\nDesign, setting and participants（デザイン、状況設定、参加者）\nExposures（曝露）\nMain outcomes and measures（主要アウトカムとその測定方法）\nResults（結果）\nConclusions and relevance（結論と意義）\n\n\n私「JAMAの抄録はこうなのね。研究の価値は、”Importance”と”Conclusions and relevance”に書けばいい。研究方法も、どんな要素が求められるか、デザインから測定方法まで指定されてる。確かにわかりやすい。参加者、曝露、主要アウトカムは、PECOの通りに書けばいいよね」\n\n\nお父さん「それでいいと思う。がんサバイバーの調査の”価値”はなにって聞かれたらなんて答える？」\n\n\n私「まず、がん手術後に仕事に就けるかどうかは、生活に関わる大きな問題だっていうのが前提かな。その上で、どんな患者が苦労していて、就労支援を求めているのかを調べて、ストーマ造設が関連することがわかった。それが研究をやった意義だと思う」\n\n\nお父さん「うんうん。それが抄録を読んだ人に伝わるように書こう。たとえばこんな感じでどうだろう」\n\n\nImportance: Although prognosis of early rectal cancer has been improved, little is known about employment problems after surgery.\nObjective: To compare employment status between patients with and without stoma\nDesign, setting and participants: A mail survey was conducted at 3 hospitals in Japan. Participants were 20-to-80-year-old patients with clinical stage I–III rectal cancer who were employed at diagnosis and received curative surgery from 2010 to 2020. Participants were followed up using self-administered questionnaires for 12 months.\nExposures: Stoma creation\nMain outcomes and measures: Return-to-work at 12 months after surgery\nResults: Responses were obtained from AAA patients and the response rate was BB%. The median time to return-to-work was CC months and the proportion of working patients at 12 months after surgery was DD%. The odds ratio for delayed return-to-work was EEE (95% confidence interval FFF to GGG, p = HHH) after adjustment for age, sex and income.\n\nConclusions and relevance: Stoma creation in rectal cancer is associated with difficulty in returning to work. Further employment support may be necessary.\n\n\nお父さん「この文章で工夫した点は4つある。まず、今回みたいに日本で調査を行う場合、海外の研究者は日本の事情を知らないでしょ。だからどんな方法で参加者が選ばれたをきちんと書く。単に直腸がん患者って書くんじゃなくて”patients with clinical stage I–III rectal cancer who were employed at the time of diagnosis and received curative surgery from 20XX to 20YY”とかね」\n\n\n私「ふんふん」\n\n\nお父さん「2つ目の工夫は、回答率（response rate）を示すこと。回答率が低いと、選択バイアスがあるかもしれないからね」\n\n\n私「その次はなに？」\n\n\nお父さん「3つ目はさっき話した交絡調整だね。観察研究の査読では必ず確認されるポイントになってる。本文に書いてあれば十分だけど、抄録でも、オッズ比を示すときに”after adjustment for age, sex and income”のような説明があると、ちゃんとしてるなって思ってもらえるかもしれない」\n\n\n私「なるほどね。2つ目と3つ目は、バイアスがどれくらいあるかについて書いたんだね。最後のひとつは？」\n\n\nお父さん「つまらないテクニックなんだけど。“Return-to-work”や “20-to-80-year-old patients”のように、単語をハイフンでつなぐと、文字数を節約できる。普通に”patients aged 20 to 80 years”って書くと6文字も使っちゃうでしょ。抄録には文字数の制限があるからね」\n\n\n私「じゃあさ、少し話がそれるんだけど、主語と時制について聞いていい？”A mail survey was conducted at 3 hospitals in Japan.”っていう一文があるけど、受動態にするのが普通なの？それに、調査はすでに行われたから、時制は過去形なんだよね。IntroductionとConclusionsは現在形だけど」\n\n\nお父さん「論文を書くときは、Weを主語にしない方が、客観的だからいいっていう考え方がある。でも最近は、主語をはっきりさせたほうが、かえって正確だという意見もある。たとえば別の表現をとって”Study design was a mail survey at 3 hospitals in Japan”というように、研究方法を説明する文体にしてもいい。情報が増えたぶん、より正確で、かしこまったニュアンスになる。この場合は、受動態でも能動態でも、不自然ってことはないよ」\n\n\n私「時制については？」\n\n\nお父さん「普遍的な現象や法則性を表すときは現在形を使う。結論を現在形で書くと、「ストーマ造設は職場復帰の難しさに関わることが明らかになった」っていうニュアンスになる。過去形を使って、“Stoma creation in rectal cancer was associated with a difficulty in return-to-work.”と書くと、「今回の調査では」関連があったという限定的な意味になる」\n\n\n私「じゃあ主語と時制はいま教えられた通りで書いてみる」\n\n\nお父さん「うんうん。ちなみにね、凝った英語を使う必要はないよ。論文は、“concise”つまり簡潔な表現が好ましいとされる。接続詞や関係代名詞を多用しちゃって、一文が長くなりがちな人もいるけど、最初はそうしない方がいい。短い文章が続いていてもぜんぜん変じゃないからね」\n\n\n\n\n次のエピソード\n\nThree Tips for Writing a Paper"
  },
  {
    "objectID": "jp/publish-a-paper-3.html",
    "href": "jp/publish-a-paper-3.html",
    "title": "Communicating with Care",
    "section": "",
    "text": "Publish a Paper III − Communicating with Care\n\nKeywords: language & writing\n\n\n\n言葉を整える時間\n\n\nお父さん「論文は書けた？」\n\n\n私「Resultsの途中まではね。診療しながらだと、まとまった時間がなかなか取れなくて」\n\n\nお父さん「そうだよね。論文って、書くときはそれだけに集中しないと進まないものだから」\n\n\n私「わかるー。このあたりの英語表現なんだけど、少し見てくれる？」\n\n\nお父さん「文章を見直してるところなんだね。あれ、画面のまま？」\n\n\n私「だめかな」\n\n\nお父さん「だめじゃないけど。落ち着いて推敲するときは、紙に出して読むのも悪くないよ。画面と紙じゃ、同じ文章でも印象が変わるから」\n\n\n私「はい、プリントアウトしましたー」\n\n\nお父さん「まず気になったのは、この一文かな」\n\n\nOverall survival curves and disease-free survival curves were estimated by the kaplan-meier method and tested with p-value less than 0.05 as significant.\n\n\n私「どこが変？」\n\n\nお父さん「意味は伝わる。でも、専門用語の並び方が少しちぐはぐに見える」\n\n\n私「kaplan-meierもp-valueも、統計のことばでしょ？」\n\n\nお父さん「そうなんだけど、役割が違う。Kaplan–Meierは“方法”で、p値は“指標”だよね。同じ列に並べるなら、レベルをそろえた方がいい」\n\n\nOverall survival curves and disease-free survival curves were estimated using the Kaplan–Meier method and compared by the stratified log-rank test. The significance level was set at 0.05.\n\n\n私「細かいけど、たしかに」\n\n\nお父さん「推敲ってそういうものだよ。論文の文章を見直すとき、いつも気にしてほしいことがある」\n\n\n私「なに？」\n\n\nお父さん「この3つを頭に置いておくといいよ」\n\n\n専門用語は、正確に使われているか\n情報は、第三者が読み返して再現できるだけ書かれているか\n主張の強さは、結果に見合っているか\n\n\nお父さん「どれも特別なことじゃない。でも、これが崩れると、文章全体の信頼感が落ちる」\n\n\n私「たとえば、この文章はどう？」\n\n\nThe return-to-work rate was defined as the proportion of return-to-work divided by the number of patients.\n\n\nお父さん「悪くはないけど、少し情報が足りないかな。いつ時点の話？分母は誰？」\n\n\n私「あ、たしかに。もともと働いていた人だけだ」\n\n\nお父さん「じゃあ、そこは書いた方がいい。結果が正しいかどうか以前に、“何を数えたのか”が伝わらないと、読者は判断できないから」\n\n\nThe return-to-work proportion was defined as the number of patients employed 12 months after surgery divided by the number of patients who were employed at diagnosis.\n\n\n私「ちょっと冗長じゃない？」\n\n\nお父さん「うん。でも、親切ではある。論文では、親切さが勝つことも多いよ」\n\n\n私「ここは強調したかったんだけど」\n\n\nStoma creation was strongly associated with a difficulty in return-to-work.\n\n\nお父さん「気持ちはわかる。でも、少し強いかもしれないね」\n\n\n私「結論なんだから、強くいってもいいかなと思って」\n\n\nお父さん「強調したい結果ほど、淡々と書いた方が伝わることもある。特にConclusionではね。それに、“strongly”とか“significantly”って言葉は、読み手によって受け取り方が変わる。表現を変えた方がいい。2つ例を挙げる」\n\n\nStoma creation was significantly associated with a difficulty in return-to-work (p=AAA)\n\n\nThe odds ratio for delayed return-to-work was BBB (95% confidence interval CCC to DDD, p=EEE)\n\n\n私「significantって書くと、自動的に統計学的に有意って意味になっちゃうんだっけ」\n\n\nお父さん「そう。使うならp値を示すし、Methodsに解釈も書く。効果指標と信頼区間も忘れない。推敲は、言葉を整える作業に見えるけど、実際は”読者がどの世界を読むか”を整える作業なんだ」\n\n\n私「全部一気に直そうとすると、頭が追いつかないよ」\n\n\nお父さん「それでいい。一度に全部整えようとしなくていい。今日は専門用語、次は情報量、その次はトーン。そうやって何度も読み返す」\n\n\n私「地味だね」\n\n\nお父さん「うん。でも、そうやって時間を掛けて整えていくものだよ。推敲は、すればするほどいい文章になる」\n\n\n私「うん。だから、急がない」\n\n\n\n\n最後のエピソード\n\nA Morning Just Before Submission"
  },
  {
    "objectID": "jp/study-design-1.html",
    "href": "jp/study-design-1.html",
    "title": "A Story of Coffee Chat and Research Hypothesis",
    "section": "",
    "text": "Study Design I − A Story of Coffee Chat and Research Hypothesis\n\nKeywords: language & writing, observational study, research hypothesis, study design\n\n\n\nはじめて研究に取り組む娘と統計家の父\n\n\n私「お父さんってさ、大学で統計学を教えてるんでしょ」\n\n\nお父さん「そうだよ」\n\n\n私「診療科の上司に、そろそろ研究して学会発表でもしてみないかって言われてさ。その先生、2016年がん対策基本法が改正されてからずっと、がん患者さんの就労支援に興味があるの。要するに、私にその調査をやらせたいみたい。まあやってみたくなくはないけどね。これって統計じゃない？」\n\n\nお父さん「まあね。なにか臨床的に知りたいことや仮説はあるの？」\n\n\n私「ないよ」\n\n\nお父さん「仮説がないと調査がデザインできないよ」\n\n\n私「まじか。データをとってから考えればいいと思ってた。うーん、やっぱり仕事を続けにくいのはどんな患者さんなのかが知りたいかな」\n\n\nお父さん「女性より男性の方が、復職率が高いとか？」\n\n\n私「性別にも興味あるけど、やっぱり知りたいのはがんのステージとか合併症とかかな。私が勤めているのは消化管外科なんだけど、ストーマをつけている患者さんは、手術前と同じ仕事を続けられているのだろうか、とか。うん、調査票つくってみる。ありがとう！」\n\n\nお父さん「待ちなさい。調査対象は決まってるの？」\n\n\n私「ん？うちの病院で手術したがん患者さん」\n\n\nお父さん「胃がんでストーマを造設することってあるの？」\n\n\n私「ゼロじゃないけど、みたことない」\n\n\nお父さん「でしょ。ストーマに興味があるなら、胃がんは外した方がいいんじゃない？」\n\n\n私「そうかなあ」\n\n\nお父さん「デザイン段階で、どのような対象に調査すべきか考えておくことは大切だよ。一般論だけど、対象集団を狭く限定した方が、質問項目を詳細にできるから。それに比較可能性（comparability）も高まる。ストーマ保有者と非保有者を比べるなら、がん種は統一したいよね」\n\n\n私「比較可能性とかお硬い言い方するね。でも、患者さんの背景がばらけるとやりにくいよね。なるべく揃っている方が比較しやすい、ってことはわかるよ」\n\n\nお父さん「比較可能性を高めるための統計手法やRパッケージもある。回帰調整のためのglm()やプロペンシティスコア調整のためのCBPS()とかね。一方で、対象集団は広い方が、一般化可能性（generalizability）が高い。がんサバイバーの復職率を推定したいんだったら、がん種を限定する必要はないし、できれば複数の施設で調査したいよね」\n\n\n私「確かに、うちの病院だけだと実態調査っていいにくい気もしてきた。一般化可能性が高い研究をしなさいっていうのは、ほかの施設の参考になるデータをとれって意味だよね」\n\n\nお父さん「うんうん。大学の授業だとね、こんな風に教えてるよ。\n\n研究で調べたい疑問がはっきりしないなら、“PICO”と”PECO”という要素を使って 研究をデザインしなさい\n\n研究の要素をひとつひとつ決めていく計画の立て方を、研究の構造化っていったりする」\n\n\n私「構造化？実際怪しいな、そこ。いや、聞いたことはある」\n\n\nお父さん「じゃあ軽く整理しよう。たとえばPICO/PECOのPは、患者（Patients）または集団（Population）の頭文字をとっている。どのような患者が対象かが、研究デザインの大切な1要素だってこと」\n\n\n\nどのような患者が対象か（Patients/Population）\nどのような要因に注目するか（Intervention/Exposure）\nそれを何と比較するのか（Comparison）\n患者にどのようなアウトカムが生じたのか（Outcome）\n\n\n\n私「ExposureとComparisonははじめて聞いたけど、私の場合はストーマ保有者と非保有者ってことだよね。Outcomeってなに？」\n\n\nお父さん「PICO/PECOのOはアウトカムっていって、治療結果や、転帰、予後のこと。統計解析ではアウトカムのデータがいちばん重要。だから、計画でここを固めるのがポイントになる」\n\n\n私「データが集まる前に固められなくない？」\n\n\nお父さん「いや、データが集まっちゃったら変更が効かないでしょ。調査票を確定する前には決めておきたいよね。ああ。そうだね、アウトカムのイメージがまだないんだ。アウトカムはね、どんなデータをどうやって解析するかに関わってくる。解析結果を左右するからきちんと考えておいた方がいいんだ。データが集まった後は、どの統計ソフトを使うつもり？」\n\n\n私「R。診療科の先輩が使ってるから」\n\n\nお父さん「Rは得意？」\n\n\n私「学部の頃、授業あったけどもうわすれたな」\n\n\nお父さん「じゃあRの使い方も身につけなきゃだね。どの関数を使うかも、アウトカムによって違うんだよ」\n\n\n\n\n\n\n\n\n臨床疑問と研究仮説\n\n\n\n日常診療をしていると、さまざまな疑問や知りたいことが生じることがあります。診療現場から生まれたありのままの疑問のことを、臨床疑問（clinical question）といいます。臨床研究をスタートするとき、意識してほしいのは、臨床疑問を研究仮説（research hypothesis）として表現することです。研究仮説は、研究デザインに最低限必要な要素で構成されます。たとえば典型的な臨床研究では、以下のような要素が含まれることが多いでしょう。\n\nPatients/Population\nIntervention/Exposure\nComparison\nOutcome\n\n上の会話で出てきた”PICO”や”PECO”は、この頭文字をとったものです。I（Intervention＝介入）かE（Exposure＝曝露）かは、その研究が薬の臨床試験のような介入研究か、今回のがんサバイバー調査のような観察研究かによって変わります。観察研究には患者さん一人ひとりを追跡するコホート研究、ある時点からさかのぼって調査するケースコントロール研究、ある1時点における要因とアウトカムを調査する横断研究がありますが、いずれもPECOで構造化が可能です。\nがんサバイバー調査を題材にして、研究仮説の例を3つ考えてみました。\n\n\n\n\n\n\n\n\n研究仮説1\n\n\n\n\n\nP: 根治切除後の直腸がん患者\n\nE: ストーマ造設あり\n\nC: ストーマ造設なし\n\nO: 手術後1年以内の復職の有無\nストーマ保有者と非保有者の復職率を比較する研究を想定してみました。この場合Cをどうするかは悩ましい問題ですが、復職率の数字が得られただけでは、それが高いかどうか判断が難しいので、なんらかの比較対照を設定した方がよいでしょう。なお、比較可能性とは、この場合EとCを正しく比べられるということを意味します。\n\n\n\n\n\n\n\n\n\n研究仮説2\n\n\n\n\n\nP: 根治切除後のがん患者\n\nE: 「仕事とがん治療の両立お役立ちノート」の配布あり\n\nC: 「仕事とがん治療の両立お役立ちノート」の配布なし\n\nO: 手術後1年以内の復職の有無\n就労支援の一環として作成された「仕事とがん治療の両立お役立ちノート」の効果を調べようという研究です。患者Pは、直腸がんに限定せず、アウトカムOは、手術後の復職の有無としました。こうした方が、幅広い患者に当てはまる調査結果が得られますよね。これが一般化可能性の一例です。アウトカムについては、別の例として、患者満足度や患者の経済状態なども考えられるでしょう。\n\n\n\n\n\n\n\n\n\n研究仮説3\n\n\n\n\n\n「性・年齢、ステージ、術後補助化学療法、パフォーマンスステータス、合併症、ストーマ、手術前の就労状況、家計収入額、がん保険、就労支援サービスの利用などの因子は、1年以内の復職率と関連するか」\nPECOになりにくい研究仮説もあります。たとえば、疾患発生と関連のあるリスク因子を探す、いわゆる探索的研究では、EとCははっきり決まっていません。構造化といっても、臨床疑問をかならずPECOの形式にしなければならないわけではありません。研究デザインに最低限必要な要素を特定することが大切です。\n\n\n\n\n\n私「なるほどね、オリジナル仮説を立てろっていわれたら困るけど、研究の要素を洗い出して、ひとつひとつ決めていく作業はきらいじゃないわ。いつかは必要なことだし」\n\n\nお父さん「そうでしょ。それに研究者の思考を、早い段階で専門的な表現に置き換えておくと、コミュニケーションもうまくなる。疾患やアウトカムの定義、治療や曝露内容は、医師や施設によって微妙な違いがあるものだからね。言葉をおろそかにすると混乱の種になる」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n研究計画を立てるとき、しばしば”ceteris paribus”というラテン語表現が登場します。この言葉の意味にいちばん近いのはどれでしょう。\n\n因果関係があるなら必ず起こる\n普遍的に一般化できる法則\n他の条件が同じである\nじゅうぶん多くのデータを観察する\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です\n\n“ceteris paribus”という概念は、比較可能性（comparability）を保つための条件と考えて問題ありません。\n\n\n\n\n\nエピソードとRスクリプト\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\nstudy-design.R"
  },
  {
    "objectID": "jp/study-design-3.html",
    "href": "jp/study-design-3.html",
    "title": "Outcomes: The Bridge from Data Collection to Analysis",
    "section": "",
    "text": "Study Design III − Outcomes: The Bridge from Data Collection to Analysis\n\nKeywords: clinical trial, language & writing, research hypothesis, survival & competing risks\n\n\n\nアウトカムってなに？\n\n\n私「さっきのアウトカムについてなんだけどね。診療科内で臨床試験の論文を読むんだけど、そこで出てくる”DFS”とか”RFS”とかの略語もアウトカムだよね？実はよくわからないんだけど、当たり前のように使われているから質問しにくいんだ。DFSとRFS、どっちもがんの再発を調べてるみたいなんだけど。お父さん詳しい？」\n\n\nお父さん「もちろん統計解析でDFSを扱うことはあるよ。一番よく出てくるOSは全生存期間（overall survival）だよね。DFSは無病生存期間（disease-free survival）、RFSは無再発生存期間（relapse-free survival）のこと」\n\n\n私「無再発生存期間って再発までの日数のこと？」\n\n\nお父さん「再発までの日数だったら無再発期間(relapse-free time)とかって言葉を選ぶかなあ。累積再発率（cumulative incidence of relapse）やCIRって呼ぶことの方が多いけど」\n\n\n私「よけいにわからん。ぜんぶ同じじゃないの？」\n\n\nお父さん「生存時間解析ではね、細かいけど違うんだ。再発を経験せずに、死亡することもあるでしょ。無病生存期間のポイントは、再発・2次がん・死亡のうち、どれか最初のイベントまでの時間を扱うこと。だから、再発だけでなく、死亡したり別のがんを発症したりしたときも、イベントとして扱われるんだ」\n\n\n私「イベント扱いって？」\n\n\nお父さん「生存時間データは、一般に特定のイベントまでの経過時間なんだ。端的にいうとね、無病生存期間のデータから“3年無病生存確率”を計算するとするでしょ。それは“イベントが起こらない確率”に相当するんだけど、意味合いとしては3年時点で、再発も2次がんも経験せず、生存できる確率を求めることになる」\n\n\n私「そういうことか」\n\n\nお父さん「RFSでは、イベントは死亡と再発にするのが普通。つまり二次がんはイベントに含めない。無再発期間だったらイベントは再発だけ。図をみたら、イメージしやすくなるかな」\n\n\n\n私「ふんふん。私はね、無病生存期間の結果が重要だと思うな。再発と2次がん、どっちも起きない方がいい。無再発期間はあまり解析する意味を感じないな。死亡は一番重要なイベントじゃない？なんで省いちゃうのよ」\n\n\nお父さん「そうだね。でも、がんが再発した後に死亡した患者は、無再発期間だったとしてもイベント扱いになるよね」\n\n\n私「確かにね。よく考えたら、再発前に亡くなるケースって、感染症とか、交通事故とかだね。がん治療や原病とは関係ないかもしれない」\n\n\nお父さん「臨床試験で用いられるアウトカムは、”エンドポイント”とよばれることもあるよね。研究によって研究仮説が違うから、それにあわせて様々なエンドポイントが選ばれる。進行がんではがんの増悪に注目した無増悪生存期間、根治切除後の研究では無再発生存期間とかね。表に、がん臨床試験の主な生存時間エンドポイントを整理してあげるよ（Japan Clinical Oncology Group 2021）」\n\n\n\n\n\n\n\n\n\n\n\n\nエンドポイント\nイベント1\nイベント2\nイベント3\nイベント4\n打ち切り日\n\n\n\n\n全生存期間\n死亡\n\n\n\n最終生存確認日\n\n\n無増悪生存期間\n死亡\n増悪/再発\n\n\n最終無増悪確認日\n\n\n無再発生存期間\n死亡\n再発\n\n\n最終生存確認日\n\n\n無再発期間\n再発\n\n\n\n最終生存確認日\n\n\n無病生存期間\n死亡\n再発\n2次がん\n\n最終生存確認日\n\n\n無イベント生存期間\n死亡\n寛解導入失敗\n再発\n2次がん\n最終生存確認日\n\n\n治療成功期間\n死亡\n治療中止（治療中の増悪/再発を含む）\nプロトコール治療完了後の増悪/再発\n\n最終治療継続確認日または最終無増悪確認日\n\n\n\n\n私「でかした！」\n\n\nお父さん「この表は、臨床試験グループが研究計画書を作るときのものなんだ。研究計画書は、医師や統計家がチームになって書くからね。定義を決めておかないと混乱する。このグループでは”one word one meaning”がモットーなんだ」\n\n\n私「だよね、私もこんがらがり中だわ」\n\n\nお父さん「OSは、生存時間の原点（time origin）から死亡するまでの期間のこと。DFSは、時間原点から再発、2次がん、死亡のうち、最初のイベントまでの期間のこと。でも、さっき言ったみたいに、3年OSとか3年DFSという言い方をすることもある。この場合は期間じゃなくて確率の意味になる。OSとDFSの違いは、再発と2次がんが含まれること。そうすると、3年OSより3年DFSの方が、確率は小さくなるよね」\n\n\n私「時間原点ってはじめて聞いた。もう少し説明してよ」\n\n\nお父さん「じゃあ、どの時点から生存時間をスタートするか、典型的な決め方をいくつか紹介しようか。まず、DFSは根治手術後の再発状況を調べるため用いられるアウトカムだよね。だから、”手術日”がこの場合の時間原点の候補になる。手術日のように治療の起点がはっきりしている状況だと決めやすいよね」\n\n\n私「あーよくみるやつだわ」\n\n\nお父さん「でしょ。一方で、もし”退院日”を時間原点にすると、手術直後の死亡が評価対象にならなくなっちゃうから、研究によってはそこを批判されるかもしれない。もうひとつ典型的な決め方を挙げると、臨床試験の登録日があるかな。ランダム化臨床試験だと、登録日に治療をランダムに割付けるから、それを原点にして生存曲線を描くのが自然だよね」\n\n\n私「なるほどね、研究によって微妙に定義が違うもんね。実は今、調査票作っててね。お父さんがアウトカムにうるさいって周りに話したら、みんな意外とちゃんと区別してて。DFSとかOSを正確に知りたかったんだ。聞いてよかった、また相談するね」\n\n\n\n\n\n\n\n\n臨床エンドポイントと代替エンドポイント\n\n\n\n\n\nOS、DFS、RFSは、特に術後補助化学療法の有効性を評価するときに用いられるアウトカム（エンドポイントともいいます）です。それでは両者は、どのような考え方で使い分けられているのでしょうか。指針の1つになっているのが、医薬品の承認審査の考え方です。たとえば抗悪性腫瘍薬の臨床評価方法に関するガイドライン（厚生労働省2021）では、抗がん剤を承認するためには、生存期間の延長などにもとづき、確実な有効性を示す必要があると述べています。そのため、具体的な指標として、OSが臨床エンドポイント（clinical endpoint）とみなされ、こちらが重視されています（Biomarkers Definitions Working Group 2001）。\nその一方で、術後補助化学療法としての抗がん剤の有効性を評価する臨床試験では、代替エンドポイント（surrogate endpoint）として採用することがあります。代替エンドポイントとは、臨床エンドポイントの代わりになることが意図されたもので、臨床上の便益・害の有無を予測することが期待されるものと定義されます。DFSのような代替エンドポイントを用いる最大のメリットは、試験期間が短くなることです。ただし、過去の承認審査では、代替エンドポイントの利用が誤った医薬品評価につながったケースが数多く報告されています（Fleming and DeMets 1996）。たとえば、進行大腸がんにおける5FU+ロイコボリン併用療法は、臨床試験で腫瘍縮小がみられたにもかかわらず、臨床エンドポイントであるOSを評価すると、ほとんど延命効果がないことが明らかになりました（Fleming and DeMets 1996）。\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nがん臨床研究で用いられるアウトカムのひとつに無増悪生存期間（progression-free survival）があります。このアウトカムを測定するには、画像による腫瘍増悪の判定が必要になります。このとき、客観性を高めるため、第三者が画像をみて増悪を判定すると、主治医による増悪の判定と一致しないことがあり得ます。この問題は、中央判定と施設判定の不一致と呼ばれます。以下の選択肢のうち、対処法として適切でないものを選びなさい。\n\n統計解析では、客観性が高い中央判定の結果を採用する\n統計解析では、中央判定と施設判定のうち、先に起きたものを採用する\n症例検討会を開き、中央判定と施設判定の結果が一致しない患者の扱いを医学的に決定する\n中央判定を採用した解析と、施設判定を採用した解析の、2通りを行う\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は2です\n\n中央判定と施設判定のうち、先に起きたものを採用すると、無増悪生存期間が短くなる方向にバイアスが生じるため、適切ではありません。\nひとつだけ注意があります。施設判定ではなく中央判定を必ず採用すべき、というわけではありません。施設で増悪になった後、それが追跡状況や画像検査の頻度に影響したり、施設の担当医の治療方針が変化したりすることがあります。このような状況では、施設判定を用いることが適切かもしれません。\n\n\n\n\n\n文献\n\nBiomarkers Definitions Working Group. Biomarkers and surrogate endpoints: preferred definitions and conceptual framework. Clin Pharmacol Ther 2001;69(3):89-95\nFleming TR and DeMets DL. Surrogate end points in clinical trials: are we being misled? Ann Intern Med 1996;125(7):605-13\nJCOGプロトコールマニュアル version 3.8 [Internet]. 東京: Japan Clinical Oncology Group; 2025\n薬生薬審発0331第1号. 抗悪性腫瘍薬の臨床評価方法に関するガイドライン [Internet]. 東京: 厚生労働省医薬・生活衛生局医薬品審査管理課長; 2021\n\n\n\nエピソード、用語集、Rスクリプト\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\nStatistical Terms in Plain Language\nstudy-design.R"
  },
  {
    "objectID": "jp/study-design-5.html",
    "href": "jp/study-design-5.html",
    "title": "When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys",
    "section": "",
    "text": "Study Design V − When Bias Creeps In\n\nKeywords: bias, language & writing, observational study, study design\n\n\n\n調査で気をつけておくべきバイアス\n\n\n私「ただいまーつかれたー。お父さん、甘いものない？」\n\n\nお父さん「いちご大福ならあるよ。コーヒーもちょうど淹れたところだ」\n\n\n私「ああ助かる。この時間帯に仕事が終わるとちょうど満員電車でさ、きついんだよね。診療時間の間もハードだったし」\n\n\nお父さん「おつかれさま。コーヒーはいったよ」\n\n\n私「ありがとう。あのさ、ハードなエンドポイントとソフトなエンドポイントって言い回しがあるじゃない？」\n\n\nお父さん「あるね」\n\n\n私「臨床試験にあこがれてる先輩がいてね、復職状況はソフトなエンドポイントだからだめだ、全生存期間（OS）はハードなエンドポイントだからいいんだ、みたいな言い方をするのよ。私の調査が否定されてるみたいなんだけど、どういうことなのか、よくわかんなくて」\n\n\nお父さん「確かにがん臨床試験はOSをエンドポイントにすることが多いけど、それを基準にダメ出しするのもどうかと思うけどね。それに、慣用的にハード・ソフトっていう表現が用いられるけど、その意味を正確に伝えるなら、客観的・主観的って言った方がいいんじゃないかな」\n\n\n私「客観的？主観的？」\n\n\nお父さん「よくある議論を挙げると、OSはハード、無増悪生存期間（PFS）はソフトというのがある。OSは死亡日と最終生存確認日だけで決まるから、ハードなエンドポイント。PFSでは、死亡とがんの増悪がイベントとして定義されるんだけど、そうするとデータを集めるために増悪日の情報が必要になる。ところが臨床的には増悪がいつ起きたかは、主観的に判断されるケースがあるよね。全身状態や腫瘍マーカーが悪化したりするケースだね。臨床試験で、こういうケースをイベントとみなすかは議論がわかれるけど、意見がわかれること自体でPFSはソフトなエンドポイントっていう人もいるね」\n\n\n私「なるほど、ハード=客観的、ソフト=主観的ってことね。たしかに、私の調査票はソフトなエンドポイントっていわれるわけだ。そもそも患者さんの主観を尋ねるための調査だもんね」\n\n\nお父さん「まあ、その先輩が伝えたかったのは、復職状況を調べるうえで、できるだけあいまいな部分を排除して、客観的に測定しなさいってことじゃない？調査対象者が、退院後の就労日を正確に回答してくれるなら、十分に客観的な測定ができていると思うけどね」\n\n\n私「じゃあさ、ハードなエンドポイントにはバイアスがない、ソフトなエンドポイントにはバイアスがあるって考えていい？」\n\n\nお父さん「主観が入るとバイアスが生じやすいとはいえるけど、そんなに単純じゃないかな。調査がいい加減だったら、死亡が完全に特定できず、死亡率を過小評価することだってあるもの。ちょっとたばこを吸っていい？」\n\n\n私「どうぞご自由に。死亡調査って大変だよね」\n\n\nお父さん「そうそう。もっと細かいことをいうとね、死亡に至るまで100%の情報を集める必要はないんだ。でも、それは死亡情報の収集に偏りがないときだけ。死亡情報が集まるかどうかが、患者の健康状態に依存してしまうと、バイアスの原因になる。これは生存時間データの打ち切りが、ランダムでなくなるからなんだ。この前、RのKaplan-Meier曲線とAalen-Johansen曲線をみせたよね。あの曲線は、打ち切りがあっても描ける。でもバイアスがなく正確であるためには、打ち切りが、病状や予後とは関係なくランダムに起きていることが前提になってる。たとえば追跡期間が1年って決まっていて、全員1年で打ち切りになるとか、外的要因のため一部の患者で観察が続けられなくなるとかね。結局、情報が偏るとバイアスが生じるのは、ハードなエンドポイントでもソフトなエンドポイントでも同じこと」\n\n\n\n\n\n\n\nランダム誤差とバイアス\n\n\n\n統計学は誤差を扱う学問ですが、臨床研究ではランダム誤差（random error）とバイアス（bias）を区別することが大切です。ランダム誤差は、基本的にはゼロを中心としたばらつきを想定しています。一方で、得られた推定値が真の値から系統的にずれていることを、バイアスといいます。臨床研究における統計学の目標は、ランダム誤差を制御し、バイアスを可能な限りゼロに近づけることです。\nたとえるなら、ランダム誤差は的の中心を狙って矢を放つときのばらつき、バイアスは狙いが中心からずれている状態といえます。競合リスクの扱いを間違ったとき生じるKaplan-Meier曲線のバイアスは、ランダム誤差ではありませんよね。ランダム誤差はサンプルサイズを大きくすることで減少させることができますが、バイアスは研究デザインやデータ収集方法を工夫しないと、解消できません。\n\n\n\n\nバイアスの分類\n\n私「そりゃあ、データが偏ったらバイアスっていうのは私にもわかるけど。死亡情報が集められないのはどうしようもないときだもの。ベストを尽くすしかないよね。じゃあさ、私の調査で、それ以外に気をつけておいた方がいいバイアスってある？」\n\n\nお父さん「そうだね。調査票を郵送するんでしょ。そういうとき、回答してくれない患者が多いと偏りが生じやすいから、回答率を上げるように工夫するといい。たとえば、調査票で年収って聞いてる？」\n\n\n私「聞くかもしれない」\n\n\nお父さん「経済状況のようなナイーブな質問内容には十分配慮した方がいいよ。それが理由で回答してくれないと、解析対象集団が調査対象全体を代表しているといえなくなってしまう」\n\n\n私「他には？」\n\n\nお父さん「他にはね、ストーマ非保有者よりストーマ保有者の方が、調査票への回答率が高くなっちゃうとか。そもそもストーマ非保有者とストーマ保有者の回答率に差があると、これらの集団を比較してもバイアスがあるって批判されるかもしれない」\n\n\n私「それって交絡のこと？」\n\n\nお父さん「交絡ってどこで聞いたの？よく知ってるね。あれもバイアスの一種だけど、今回のとは違う。回答率の差やなにか理由があって回答してくれない場合は、母集団からのサンプル抽出に影響する選択バイアスといって、区別されるんだ。それに、年収って尋ねられると、過大申告してしまいがちだよね。このように集めた情報自体に偏りがあることを、情報バイアスと呼んでいる。調査や観察研究の計画に関する授業では、バイアスを3種類に大別して考えるといいって教えている。\n\n\n選択バイアス（selection bias）\n情報バイアス（information bias）\n交絡（confounding）\n\n\n実際に研究を行うといろいろな理由でバイアスが生じるけど、研究デザインの段階では、この3つに分けて考えると対策を立てやすい。一部の対象者ばかり選ばれないようにしなさい、情報を集めるときはバイアスが入らないように配慮しなさい、集団を比較するときは、比較したい要因以外の特徴を揃えるようにしなさいってね」\n\n\n私「ふーん？選択バイアス、情報バイアスねえ？やっぱり臨床研究って言葉遣いがよくわかんないな」\n\n\n\n\n\nUp to this point, we have been talking about the essence of research — how we frame research questions and plan to obtain unbiased answers. The following episodes step away from study design and begin to reflect on observed effects and their uncertainty, how we reason about causes, and what ultimately becomes publishable.\n\nReading a Paper over a Cup of Coffee\nP-Value Explanations That Seem Plausible at First Glance\nBeyond 0.05: Interpreting P-Values in a Clinical Trial\n\n\n\n過去のエピソード\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\nStatistical Terms in Plain Language\nstudy-design.R"
  },
  {
    "objectID": "jp/truth-2.html",
    "href": "jp/truth-2.html",
    "title": "What Could Have Happened",
    "section": "",
    "text": "Truth II − What Could Have Happened\n\nKeywords: causal model, language & writing, probability model, research hypothesis\n\n\n\n原因を変えたら結果はどうなっていたか\n\n\nお父さん「今から、“交絡調整”の意味を知るために必要な概念について話すね」\n\n\n私「うん。コーヒーお代わり」\n\n\nお父さん「これまでの例を思い出してごらん。胃がん手術の術式、ストーマ造設、コーヒー摂取、どれも知りたいのは別の選択をしていたら結果はどうなっていたかってことじゃない？別の術式だったら助かっていたか、とか」\n\n\n私「そうだね、それはその通り」\n\n\nお父さん「正直にいうと回帰分析のレールに乗ったままでは、その真実にはたどり着けない。出発点を変える。確率モデルではなく原因を変えたら結果はどうなっていたかという疑問からスタートすること。因果推論はその問いに答えるための方法論なんだ」\n\n\n私「げ。別の方法で解析をやり直せっていいたいの？」\n\n\nお父さん「ちがうちがう、今してるのは抽象的な話なんだ。たとえば実薬とプラセボを比較するランダム化臨床試験だったらどう？全員に実薬を投与した結果とプラセボを投与した結果の差が知りたいんじゃない？それがOSなら生存曲線の差になる。この差こそが因果効果なんだ」\n\n\n私「うーん。そうか。JCOG9502だったら、胃がん手術で術式THを選ぶか、術式LTAを選ぶかを決めたいんだものね。標準治療が決まったら全員その術式になるはずだもの、その話は納得だわ。論文に出ていた生存曲線の差が因果効果にあたるわけか。確かに、そこに確率分布も回帰モデルも出てこないね」\n\n\nお父さん「そう。でも、がんサバイバー調査は観察研究で、ランダム化されていない。JCOG9502と同じように考えたくても、“仮にストーマを造設しなかった場合のアウトカム”は実在しない。仮定の話だからね。だからこの観察研究では、観測できないアウトカムを、共変量や回帰モデルで予測するしかない。これはデータ上のアウトカムとは区別して、潜在結果変数（potential outcome）と呼ばれている。観測はできないけれど、医学的・論理的に定義できる”もうひとつの結果”というわけだね」\n\n\n私「実在しないものを定義しても仕方ないじゃない」\n\n\nお父さん「そうじゃない。どんな因果効果が知りたいかを定義して、それを推定するためにデータを集める」\n\n\n私「そうじゃないのか」\n\n\nお父さん「たとえるなら、6つあるルービックキューブの面の1つしか見えないようなもの。別の面に別の結果が描かれていたとしても観測できないんだ。でも同じ構造をもつルービックキューブをたくさん用意して、それぞれをランダムな向きで机の上に並べてごらん。どのキューブも一面しか見えないけれど、どんな絵が描かれているかを推し量ることはできる。ランダム化臨床試験がやっているのはこれに似ている」\n\n\n私「ややこしい話になってきた。JCOG9502と私の調査のどこが違うんだろう」\n\n\nお父さん「一番の違いはひとつ。ランダム化しているかどうか。そもそもランダム化臨床試験は、“介入したら結果はどうなるか”を調べるためにデザインされているからね。ターゲット集団も明確に定義されているし、介入もランダムに割付けられていてバイアスもない。がんサバイバー調査のような観察研究では、研究仮説やPECOをどんなに慎重に考えても、曖昧なところは残る。特にPatientsとControlsがね。比較可能性についても、交絡因子のデータがバイアスを調整するためじゅうぶんかどうかわからない」\n\n\n私「ふむ」\n\n\nお父さん「話を戻そう。Rubin因果モデルは、解析するモデルや交絡調整について考える前に、潜在結果変数を定義し、その差について推測するんだ」\n\n\n\n\n確率モデルと因果モデルの補完関係\n\n\n私「やっぱりわからないな。一般化線型モデルやCox回帰の結果って、なにを見てるの？回帰係数は因果効果とは違うの？」\n\n\nお父さん「ひとつの数字が二重、三重の意味を持っているっていったらいいかな。根っこをたどると、確率モデルと因果モデルは二階建てなんだ」\n\n\n確率モデル: 観測されたデータがどう生じるかを記述する構造\n因果モデル: 観測された世界と、観測されなかった世界の両方で、原因を変えたら結果はどうなっていたかを表す構造\n\n\nお父さん「これはちょうど、データが発生する背後に因果モデルがあるという創造的な階層関係なんだ。因果的な構造に従って生じた現象を測定したものがデータだといってもいい。ほら、さっきいったように潜在結果変数は観測できないでしょ」\n\n\n私「うん」\n\n\nお父さん「だからね、データは影みたいなものなんだ。見たいものは、その少し向こう側にいる」\n\n\n私「そういわれると確かに因果関係の真実は、データの発生する前から存在するのかもね。実感はないけど理解はした。でも、それならどうして最初からロジスティック回帰じゃなくて因果モデルを教えなかったの？」\n\n\nお父さん「ふむ。もう少し説明が必要だね。ロジスティック回帰や層別解析を使っちゃいけないわけじゃない。それは方法なんだ。ルービックキューブの解き方みたいなもの。ルービックキューブの構造とは別物」\n\n\n私「べつもの」\n\n\nお父さん「ここで知ってほしかったのは、回帰係数やオッズ比を、因果関係を考えるための証拠として正しく解釈するためには、因果モデルが必要だってこと」\n\n\n私「お父さんは専門だからわかってないけど、私にとってはロジスティック回帰もRubin因果モデルも初めて聞く概念なんだよ。絶賛こんがらがり中だわ。Rubin因果モデルって、ある患者に別の方法で治療したら結果はどうなっていたかを分析すればいいんでしょ？それって解剖・病態生理・薬理に関する基礎知識と臨床経験を組み合わせればできそうなことじゃない？」\n\n\nお父さん「本質的にはその通り。でも、それはあくまで患者ひとりひとりにとっての原因と結果を分析するアプローチになっている。個々の事象に関する因果を単一因果（token causation）っていうんだけど、それと一般法則としての因果には、まだギャップがあるよね」\n\n\n私「トークン？ぴんとこない言葉だけど」\n\n\nお父さん「たとえば”あの患者さんが助かったのはこの薬のおかげか？“というレベルの話がtoken causationに近い」\n\n\n私「ああ、そういうこと。有害事象と薬の因果関係を判定をする、みたいなことね。そういわれたら、個々の出来事と一般法則どっちも因果っていうね」\n\n\nお父さん「臨床試験や調査は集団を対象にしているよね。集団を統計的に分析することで法則性を見出そうとしているんだ。そのための道具を用意するためのベースになっているのが、確率分布や回帰モデルだっていう話だったでしょ。確率モデルと因果モデルは役割が違う」\n\n\n私「また、難しい話に戻ってきたね。コーヒーもう一杯くれる？」\n\n\n\n\n次のエピソード\n\nWhat Is It That You Want to Know?"
  },
  {
    "objectID": "kanji_en/index.html",
    "href": "kanji_en/index.html",
    "title": "Coffee and Research",
    "section": "",
    "text": "One intriguing property of kanji characters—the logographic characters used in Japanese and Chinese—is that traces of their ancient meanings remain embedded in their internal structure. When we analyze the characters corresponding to causal inference, a small but revealing discovery emerges.\nThe first character is in. Imagine a large square. Originally, this square represented a mat or a surface, but it was also used as a motif for space, or even the universe itself. Within this square lies a single human figure, arms and legs outstretched. This image retains a sense of a human being entrusting themselves to the universe or the world around them.\nThe second character, ga (or ka), is more concrete. It is composed of two vertical parts. The lower part represents a tree. Above it is a shape that depicts fruit growing on the branches—fruit that has reached full maturity. Here, ga signifies not a process in progress, but something that has fully developed and come to completion.\nThe third character, sui, also splits in two—this time left and right: a hand on the left, a bird on the right. Originally, this likely evoked a concrete action, such as attempting to grasp or push something forward. Over time, that literal image faded, and the character took on a more abstract meaning. From a modern perspective, it is more natural to read these components broadly as action and object.\nThe final character, ron, is the most abstract. Let us begin with its right-hand component. This element conveys the idea of arranging multiple elements in an orderly and structured way. On the left is a component that, even in modern form, directly signifies language. Together, ron represents the act of giving structure and order to ideas through words.\nTaken together, causal inference—when expressed in Japanese—can be seen as composed of eight elements:\n\nthe universe,\nthe human being,\nthe tree,\nthe fruit,\naction,\nobject,\nlanguage,\nand order.\n\nCausality, in this reading, is both a law of nature and a human-centered way of understanding the world. It is also an activity in which the order inherent in those laws is articulated and made explicit through language.\nDoesn’t it feel as though all the essential components of what contemporary researchers and philosophers now call causal inference are already present here? And aren’t you tempted to see the kanji we’ve been analyzing?\n\n\n\n\n\n\nkanji characters representing causal inference\n\n\n\n\n\n Calligraphy by Eiji Sakurai."
  },
  {
    "objectID": "kanji_en/index.html#eight-elements-of-causal-inference-preserved-in-japanese",
    "href": "kanji_en/index.html#eight-elements-of-causal-inference-preserved-in-japanese",
    "title": "Coffee and Research",
    "section": "",
    "text": "One intriguing property of kanji characters—the logographic characters used in Japanese and Chinese—is that traces of their ancient meanings remain embedded in their internal structure. When we analyze the characters corresponding to causal inference, a small but revealing discovery emerges.\nThe first character is in. Imagine a large square. Originally, this square represented a mat or a surface, but it was also used as a motif for space, or even the universe itself. Within this square lies a single human figure, arms and legs outstretched. This image retains a sense of a human being entrusting themselves to the universe or the world around them.\nThe second character, ga (or ka), is more concrete. It is composed of two vertical parts. The lower part represents a tree. Above it is a shape that depicts fruit growing on the branches—fruit that has reached full maturity. Here, ga signifies not a process in progress, but something that has fully developed and come to completion.\nThe third character, sui, also splits in two—this time left and right: a hand on the left, a bird on the right. Originally, this likely evoked a concrete action, such as attempting to grasp or push something forward. Over time, that literal image faded, and the character took on a more abstract meaning. From a modern perspective, it is more natural to read these components broadly as action and object.\nThe final character, ron, is the most abstract. Let us begin with its right-hand component. This element conveys the idea of arranging multiple elements in an orderly and structured way. On the left is a component that, even in modern form, directly signifies language. Together, ron represents the act of giving structure and order to ideas through words.\nTaken together, causal inference—when expressed in Japanese—can be seen as composed of eight elements:\n\nthe universe,\nthe human being,\nthe tree,\nthe fruit,\naction,\nobject,\nlanguage,\nand order.\n\nCausality, in this reading, is both a law of nature and a human-centered way of understanding the world. It is also an activity in which the order inherent in those laws is articulated and made explicit through language.\nDoesn’t it feel as though all the essential components of what contemporary researchers and philosophers now call causal inference are already present here? And aren’t you tempted to see the kanji we’ve been analyzing?\n\n\n\n\n\n\nkanji characters representing causal inference\n\n\n\n\n\n Calligraphy by Eiji Sakurai."
  }
]