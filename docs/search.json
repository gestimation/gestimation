[
  {
    "objectID": "jp/truth-3.html",
    "href": "jp/truth-3.html",
    "title": "What Is It That You Want to Know?",
    "section": "",
    "text": "Truth III − What Is It That You Want to Know?\n\nKeywords: bias, causal model, confounding/collapsibility, hypothesis/outcome, language/writing, probability model\n\n\n\n研究仮説を言葉にするということ\n\n\nお父さん「はい、コーヒーのおかわり。ミルクはいる？」\n\n\n私「いる。お父さんのいいたいことがわかってきたよ。データを集めてロジスティック回帰をすると、自動的に結論が出るわけじゃないんだ。それは、うちの診療科だけのデータでRを試してたときから気づいてたよ。有意だったら因果関係あり、有意じゃなかったら因果関係なしみたいに、白黒はっきりしてないんだなって。でも、どんな集団が解析対象なのかや、ストーマ保有者をどんな集団と比べているのか、足りない交絡因子はなにかなど、どの部分の詰めが甘いのかがだんだん見えてきた」\n\n\nお父さん「それはよかった。最近は昔よりもデータ駆動型の統計手法を使うことが増えたから、時代のせいもある。AIとかね。でも、どんな真実を知りたいのか言葉にしないと、正しい解析も存在しない。ランダム化臨床試験のように研究仮説を立てて、それにあわせて研究計画書を書けば、比較にならないくらい研究結果の質も高くなる。ランダム誤差とバイアスをコントロールできるように研究をデザインできるからね」\n\n\n私「確かに、的の中心が決まらないと、矢の狙いが偏っているか調整もできないな。逆算すると、研究仮説の形で真値を固めておかないと、オッズ比が正しいかどうか判断できないんだ」\n\n\nお父さん「そう。研究仮説や因果モデルは、調査票やデータよりずっと抽象的に見えるよね。どちらかというと確率モデル寄りに見える。だけどこれは医療者の疑問そのもの。治療効果や予防方法に関する仮説は、自然の摂理ではなく、よりよい医療技術はどれかという人間側の問いなんだ」\n\n\n私「…じゃあ、真値ってよく聞く言葉だけど、自然のどこかに転がっている数字じゃないんだね」\n\n\n\n\nThis concludes the Truth series. If you’d like to keep reading over your next cup of coffee, further episodes are waiting:\n\nThree-Variable DAGs: The Smallest Building Blocks of Causal Structure\nCommon Causes and Confounders\nDAGs and Conditional Distributions: Two Languages for the Same Structure\nBackdoor Paths and Confounders\n\n\n\nTo clarify which conceptual layers the issues in the series belong to, it may help to revisit the previous series:\n1. Study design — 研究の出発点\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\nWhen Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys\n\n2. Glossary — 統計学のことば\n\nStatistical Terms in Plain Language\n\n3. Frequentist thinking — 統計学の思考\n\nReading a Paper over a Cup of Coffee\nP-Value Explanations That Seem Plausible at First Glance\nBeyond 0.05: Interpreting P-Values in a Clinical Trial\n\n4. Frequentist Experiments — 統計学の実証\n\nR Demonstration of Bias in Kaplan-Meier Under Competing Risks\nUnderstanding Confidence Intervals via Hypothetical Replications in R\nAlpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size\n\n5. Effects and time — 効果は時間とともに\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nUnderstanding Collapsibility of Effect Measures in Marginal and Stratified Analyses with R\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nDistinguishing Time-Point, Time-Constant, and Time-Varying Effects: An R Example\n\n6. Adjusting for bias — 回帰モデリングの風景\n\nFrom Risk to Logistic Regression\nLogit: How a Transformation Shapes an Effect\nWhere My Logistic Regression Went Wrong\nWhy Logistic Regression Fails in Small Samples\nSimpson’s paradox\n\n7. Truth — 真実\n\nWhat Data Cannot Tell Us\nWhat Could Have Happened\nWhat Is It That You Want to Know?"
  },
  {
    "objectID": "jp/truth-1.html",
    "href": "jp/truth-1.html",
    "title": "What Data Cannot Tell Us",
    "section": "",
    "text": "Truth I − What Data Cannot Tell Us\n\nKeywords: bias, causal model, confounding/collapsibility, hypothesis/outcome, language/writing, probability model\n\n\n\nロジスティック回帰の限界\n\n\nお父さん「熱いコーヒー淹れてくれる？」\n\n\n私「いいよ。いっしょに大福もどうぞ」\n\n\nお父さん「ありがとう。この前の”コーヒーと膵がん”の話、覚えてる？層別解析やロジスティック回帰で交絡を調整したときのこと」\n\n\n私「その節はどうも」\n\n\n\n\n\n\n\n\nSimpsonのパラドックス\n\n\n\n\n\n前回のテーマであるSimpsonのパラドックスは、調整前後で関連の程度が変わる現象のことです。詳しい中身は覚えていなくてもかまいません。ここでは「調整前と調整後で話が変わりうる」という点だけ思い出してください。\n表1は、コーヒーと膵がんを想定した仮想データです。コーヒー摂取群とコーヒー非摂取群で、それぞれ膵がん発生ありとなしが調べられています。膵がんを発生したのはそれぞれの群で15人と12人、膵がんがなかったのは365人と868人です。オッズ比を計算してみましょう。コーヒー摂取群では膵がんリスクは3.9%で、コーヒーを摂取しない群の1.4%に比べて、オッズ比は3倍です。これは、コーヒーを摂取すると、膵がんリスクが高くなることを意味しています。\n表2には、交絡因子（喫煙）によって対象者を層別した結果が示されています。ここから膵がんのオッズ比を求めるとどうなるでしょうか。コーヒー摂取でも非摂取でもリスクは同じですよね。つまりオッズ比は1倍です。\n表1. 層別前の膵がんリスクとオッズ比\n\n\n\n\nコーヒー摂取\nコーヒー非摂取\nオッズ比\n\n\n\n\n合計\n\n\n\n\n\n　膵がんあり\n15\n12\n\n\n\n　膵がんなし\n365\n868\n\n\n\n　リスク\n3.9%\n1.4%\n3倍\n\n\n\n表2. 層別後の膵がんリスクとオッズ比\n\n\n\n\nコーヒー摂取\nコーヒー非摂取\nオッズ比\n\n\n\n\n喫煙\n\n\n\n\n\n　膵がんあり\n14\n4\n\n\n\n　膵がんなし\n266\n76\n\n\n\n　リスク\n5.0%\n5.0%\n1倍\n\n\n非喫煙\n\n\n\n\n\n　膵がんあり\n1\n8\n\n\n\n　膵がんなし\n99\n792\n\n\n\n　リスク\n1.0%\n1.0%\n1倍\n\n\n\n\n\n\n\n\nお父さん「じゃあ、振り返って考えてみようか。喫煙が交絡因子だったよね。喫煙を調整した結果と調整しない結果がある。どっちを報告する？」\n\n\n私「ん？そりゃ調整した方でしょ」\n\n\nお父さん「だよね。でも交絡因子がAとBの2つあって、ともに曝露とアウトカムの関係をゆがめているとする。AとBの両方を調整したときのオッズ比を、仮に3だとしよう。Aだけ調整したらオッズ比は2、どちらも調整しなかったらオッズ比は3。さあ、Aだけ調整した結果とどちらも調整しない結果、どちらが正しいと思う？」\n\n\n私「えーっと、真値が3なんだから調整しない方かな」\n\n\nお父さん「ところがね、Bのデータはそもそも集めていなかったら？“AとBを調整したときオッズ比は3”なんてわからないよね。これでも”調整しない方が正しい”？」\n\n\n私「なにがいいたいの？私、ロジスティック回帰は苦手なんだよ」\n\n\nお父さん「真値が見えない状況では、ただのオッズ比とロジスティック回帰で調整したオッズ比のどちらが真実に近いかなんていえないってことだよ。データとは別に、手がかりになるような知識や概念が必要だって思わない？」\n\n\n私「そんなこといわれてもね。知識を得るために調査してるわけだし。Rに四苦八苦している私にとっては、がんばって調整した結果が正しいって信じるしかないよね」\n\n\nお父さん「気持ちはわかるけど、もうちょっとつきあって。このSimpsonのパラドックスは、交絡という現象と同じものだと思ってない？」\n\n\n私「え？調整したらバイアスが消えるんだよね？そうじゃないの？」\n\n\nお父さん「いや、数学的には異なる現象なんだ。交絡はそんなに単純な問題じゃない。直感的な説明をするとね。層別前の解析は集団全体のオッズ比でしょ」\n\n\n私「そうだね」\n\n\nお父さん「当たり前だけど、層別後のオッズ比は、喫煙集団のオッズ比と非喫煙集団のオッズ比だよね。どっちが真値なんだろう？ターゲット集団によって真値が変わっていいの？」\n\n\n私「ん？えっと、そうだね、コーヒーが健康に悪いかどうかは個人差ないと思う」\n\n\nお父さん「うん。この事例でいえば喫煙が交絡因子なのは間違いないんだよ。でも一般には、層別前と層別後のどっちのオッズ比が真値なのか、統計学の枠組みで決めるロジックはないんだ。もちろん、Simpsonのパラドックスは数字のパズルではないし、どっちの解析が正しいかという命題も言葉遊びじゃない。データと真値の関係をどう認識するかに関わる問題なんだ。専門家以外のほとんどが、両者の関係性を真逆にとらえている。そろそろ本当のことを話そう」\n\n\n\n\nエピソード\n\nWhat Data Cannot Tell Us\nWhat Could Have Happened\nWhat Is It That You Want to Know?"
  },
  {
    "objectID": "jp/study-design-4.html",
    "href": "jp/study-design-4.html",
    "title": "A First Step into Survival and Competing Risks Analysis with R",
    "section": "",
    "text": "Study Design IV − A First Step into Survival and Competing Risks Analysis with R\n\nKeywords: bias, observational study, hypothesis/outcome/population, simulation, survival/competing-risk\n\n\n\n調査項目とデータの型\n\n\n私「あれ、懐かしい。私が小学生の頃に買ったルービックキューブじゃない、そんなのやってるの。時間があるならちょっといい？がんサバイバーの復職率を調査する話があったでしょ。患者さんに送る調査票をつくってみたんだけど、見てくれる？あ、この前のRも参考になったよ、調査結果が想像できた」\n\n\nお父さん「どれどれ」\n\n\n\nお父さん「復職率の定義はなに？」\n\n\n私「どういうこと？」\n\n\nお父さん「調査票を見ただけじゃ、この質問項目で十分かどうかわからないってこと。手術日から調査日の間に、復職を希望した患者さんが、希望どおり復職できたかどうかを調べたいのかな？」\n\n\n私「それもいいんだけど、復職を希望してないって回答した患者さんのなかに、会社の方針などの理由で復職をあきらめた患者さんも含まれるかもしれない。だから、復職率を計算するとき、分母は、復職を希望した患者さんじゃなくて、手術を受けた患者さん全員にしたいわ。そうした方が、就労実態がわかりやすそうだもの」\n\n\nお父さん「手術日から調査日の間の復職を調べたいかどうかについては？」\n\n\n私「えーっと。調査票に回答してもらうタイミングは患者さんによってまちまちになりそうだから、調査日は使いたくない。1年以内に復職できるかを定義にするのはどうかな？あ！ 復職日を答えてもらえばいいのかも！」\n\n\nお父さん「復職日はあった方がいいよね。そうすると、復職状況から解析用の“変数”をつくるには、分類データと生存時間データの2通りが考えられる。それはさておき、手術後に亡くなった場合はどうするの？」\n\n\n私「入院中に亡くなった場合は、調査対象に含めない。でも、術後再発による死亡を分母から除外するのは変な気がする」\n\n\nお父さん「そうだね。除外するとバイアスが生じると思う。ターゲットにしている集団からずれちゃうからね。がん患者を追跡するような研究をするとき、大切なことが3つある。1つ、どのタイミングを時間原点にするかを決める必要があるよね。この場合、時間原点は退院日にするといい。2つ、追跡期間の目標を設定して、その時点までは、可能な限り情報を収集すること。情報が取れないとバイアスが生じる原因になる。3つ、時間原点後に生じたイベントは除外してはならない」\n\n\n\n時間原点を定義する\n追跡期間の目標を設定し、その時点までは可能な限り情報を収集する\n時間原点後に生じたイベントは除外したり、層別に用いたりしない\n\n\n\n私「後からバイアスがあるとか言われたくないもんね。ふむふむ」\n\n\nお父さん「以前、“PECO”という要素を使って臨床疑問を構造化したらってアドバイスしたよね。Pが根治切除後の直腸がん患者さんだったら、その集団をもれなく調査しないといけない」\n\n\n私「分類データと生存時間データってなに？」\n\n\nお父さん「これもこの前話したでしょ。統計解析を行ううえで基本になるのが“データの型”で、分類データと生存時間データはその種類だよ」\n\n\n私「いや、先週の話だし、私忙しいし」\n\n\nお父さん「調査票を少し手直ししたから、これを使ってもう一度話すよ」\n\n\n\nお父さん「分類データは、この場合、患者のアウトカムを分類したものだよ。1年以内に復職したかどうかをアウトカムにしたらどうかなっていってたよね」\n\n\n私「うん」\n\n\nお父さん「たとえば、“1年以内に復職あり”を分類1、“1年以内に復職なし”を分類2にしたら、2値データと呼ばれる分類データの一種になる。これは調査票から調べられるし、復職率も計算できるよね」\n\n\n私「うん。1年以内の死亡を復職なしって扱えばね」\n\n\nお父さん「でも就労状況を集計するときは2値データではなく、3カテゴリの分類データの方がいい。“1年以内に復職あり”を分類1、“1年以内に復職なし（死亡以外の理由のため）”を分類2、“1年以内に復職なし（死亡のため）”を分類3にしたらどう？もっと詳細にアウトカムが把握できるでしょ」\n\n\n私「うんうん。じゃあ生存時間データはなんだっけ？OSってこと？」\n\n\nお父さん「たしかに全生存期間（OS）は生存時間データの一種だよ。名前から誤解されがちだけど、それ以外にもあるんだ。生存時間データがどういうものかっていうと、時間原点から“イベント”までにかかった時間を表す変数のこと」\n\n\n私「復職状況も生存時間データになるの？」\n\n\nお父さん「そうすることもできる。この場合は、“退院日から復職日までの期間”を考えればいい。たとえばね、4月1日に退院して、4月30日に復職したとしたら、この患者の生存時間データは30-1+1=30日になる。これだとただの日数だから、連続データとの違いがはっきりしないけど、生存時間データの本質は、打ち切り （censoring）があることなんだ。調査日までに復職しなかった場合、退院日から復職日までの期間は存在しないでしょ」\n\n\n私「まあそうだけど、それでいいんじゃないの？」\n\n\nお父さん「統計解析のソフトウェアを使うとき一工夫が必要で、調査日の時点で復職しなかった、つまり復職の追跡が打ち切られたという情報を、入力してあげなければならない。だから生存時間データは、2つの変数が組になっているんだ。\n\n\n\n時間変数\nイベント変数とと\n\n\n\nお父さん「イベント変数は、いわゆる生存時間データの場合は、イベントが観察されたか、打ち切りになったかを表す2値データ。時間変数は、この場合は“退院日から復職日までの期間”か“退院日から調査日までの期間”のどちらかになる」\n\n\n\n\n\n\n\n生存時間データの入力\n\n\n\n生存時間データは2つの変数の組であるため、Rの関数に入力するときもペアで指定する必要があります。survivalパッケージのsurvfit()やcoxph()では、実は入力専用の関数Surv()を用意しています。入力の仕様はパッケージによってまちまちで、たとえばmetsパッケージではEvent()を別に定義して用いています。cifmodelingパッケージのcifplot()は、Surv()とEvent()の両方に対応しています。\n\nlibrary(survival)\nlibrary(cifmodeling)\n\nsurvfit(Surv(time, status) ~ stoma,\n  data         = dat\n)\ncifplot(Surv(time, status) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\ncifplot(Event(time, status) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\n\n\n\n\n私「えーっと、イベント変数は2値データってことは、すべての患者さんで復職か、打ち切りかの2択しかないってこと？死亡はどうなるの？」\n\n\nお父さん「いま話したような扱いをするなら、死亡した患者さんは、打ち切りという分類に含まれることになる。ただし、競合リスク （competing risk）という別の扱い方もある。簡単にいうと、それが起こると研究で調べたいイベント（たとえば死亡や復職）が観察されなくなる、競合するイベントのことだよ」\n\n\n私「ああ、死亡が競合リスクってことね」\n\n\nお父さん「生存時間データは、英語ではsurvival data以外にtime-to-event dataっていったりもするんだけどね。時間とともに起きるイベントって、生存か死亡かだけじゃないでしょ。競合リスクを解析できるようにしたのが競合リスクモデルなんだ。この場合、さっきのイベント変数は、イベント、競合リスク、打ち切りという3カテゴリを表す変数になる。イベント変数はこんな感じでコーディングされる」\n\n\nイベント変数=0: イベントが観察される前に打ち切りになった\nイベント変数=1: イベントが観察された\nイベント変数=2: イベントが観察される前に競合リスクが生じた\n\n\n私「だいたいわかった。この調査票、使わせてもらうね」\n\n\n\n\n生存時間解析と競合リスク解析\n\n\n\n\n\n\nシミュレーションデータ（再発あり）の生成\n\n\n\n前回より少しだけがんの臨床研究を意識して、シミュレーションデータにおける、全生存期間（OS）・無再発生存期間（RFS）・累積再発率（CIR）の違いをみてみましょう。CIRの解析では、再発の前に死亡した患者が存在するため、その扱いを決める必要があります。これを競合リスク（competing risk）といいます。\n以下のコードでは、死亡だけではなく再発を伴った生存時間アウトカム3種類をRで生成する「関数」generate_data()を定義しています。OSのイベントは「死亡」、RFSのイベントは「死亡と再発」です。CIRのイベントは「再発」ですが、死亡を競合リスクとして扱います。なお、generate_data()やこのシミュレーションデータは、今後の解説でも再利用する予定です。\n\nストーマ保有：2項分布（rbinom）から生成した2値データ\n生存時間：指数分布（rexp）から生成した生存時間データ（t_relapse, t_death, t_censoringの乱数から計算）\n\n前回、競合リスクのない生存時間データを要約しましたが、そこで用いたのはKaplan-Meier曲線でしたよね。それに対して、競合リスク解析では、Kaplan-Meier曲線ではなく、Aalen-Johansen曲線を用いるのが正式です。\n\n\n\n\n\n\n\n\ngenerate_data()のコードはこちら（データ生成に使用）\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # 再発のハザード（大きいほど早く起こる）\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # 死亡のハザード（大きいほど早く起こる）\n  hazard_censoring &lt;- 0.05                               # 打ち切りハザード（群に依存しない）\n  \n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)   # 再発までの潜在時間\n  t_death     &lt;- rexp(n, rate = hazard_death)     # 死亡までの潜在時間\n  t_censoring &lt;- rexp(n, rate = hazard_censoring) # 打ち切りまでの潜在時間\n  \n  ## --- 全生存期間（OS） ----------------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = 死亡, 0 = 打ち切り\n  \n  ## --- 無再発存期間（RFS） -------------------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # 再発\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # 死亡\n  \n  ## --- 累積再発率（CIR） + 競合リスク --------------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # イベント1: 再発\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # イベント2: 競合リスクとしての死亡\n  \n  ## --- データフレームにまとめる --------------------------------\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n  return(dat)\n}\n\n\n\n\n\n\n\n\n\n\n全生存期間（OS）のKaplan–Meier曲線\n\n\n\nOSとRFSは通常の生存時間データですから、前回と同様にcifmodelingパッケージのcifplot()を使って、Kaplan–Meier曲線で記述します。まずはOS。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\n# devtools::install_github(\"gestimation/cifmodeling\") #インストールが必要なら実行 \nlibrary(cifmodeling)\nset.seed(46)\ndat &lt;- generate_data(hr1=2, hr2=1.5) #再発ハザード比2, 死亡ハザード比1.5のデータ生成\n\ncifplot(Event(time_os, status_os) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n無再発生存期間（RFS）のKaplan–Meier曲線\n\n\n\n次にRFSです。Event()で指定する変数以外は変わりません。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\ncifplot(Event(time_rfs, status_rfs) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Relapse-free survival\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積再発率（CIR）のAalen-Johansen曲線\n\n\n\n以下のコードでは、Event(time_cir, status_cir)のコーディングによって競合リスクを入力しています。\n\nstatus_cir=1 : 関心のあるイベント（再発）\nstatus_cir=2 : 競合リスク（再発を経験しない死亡）\nstatus_cir=0 : 打ち切り\n\nさらにoutcome.type = \"competing-risk\"を指定することで、Aalen-Johansen曲線を描いています。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\ncifplot(Event(time_cir, status_cir) ~ stoma,\n  data         = dat,\n  outcome.type = \"competing-risk\",\n  label.y      = \"Cumulative incidence of relapse\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n私「Aalen-Johansen曲線って、Kaplan–Meier曲線のY軸を逆さにしただけじゃないの」\n\n\nお父さん「グラフ上は見分けられないからそう思っても仕方ないよね。でもこのふたつは区別してほしい。\n\n生存曲線（Kaplan–Meier曲線）と累積発生曲線（Aalen-Johansen曲線）は別の統計手法なので 競合リスクがあるときはAalen-Johansen曲線を用いる。\n\nちなみに、relapse-free timeじゃなくてcumulative incidence of relapseを使いたいっていったけど、それは累積発生曲線（cumulative incidence curve）が、専門的にはAalen-Johansen曲線と同じ意味だからなんだよね。やろうと思えばCIRを解析するとき、Kaplan–Meier曲線を計算することもできるよ。このとき、再発を経験しない死亡は、競合リスク（status_cir=2）ではなく打ち切り（status_cir=0）として入力することになる。でも本来なら、死亡は、追跡期間終了や追跡不能による打ち切りとは、違う転帰だよね。だから競合リスクとして扱うのが正しい。\n\n\n私「じゃあ死亡と再発を両方イベントにしたRFSを解析するのは間違い？」\n\n\nお父さん「もちろん間違いじゃないよ。でも、RFS曲線の差は、再発だけでなく他因死の影響も反映しているよね。だから、さっきいったみたいに、OS、RFS、CIRは使い分けが必要になる」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nCDISC ADaM ADTTE（Analysis Data Model for Time-to-Event Endpoints）は、製薬企業が行う臨床試験データの標準規格です。この規格では、打ち切りにはCNSRという変数名の変数を用いることになっています。打ち切りを表すコーディングのは、次のうちどちらでしょう。\n\nCNSR=0\nCNSR=1\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は2です\n\nCDISC ADaM ADTTEでは、1がTRUEを表しています。Event()やSurv()など多くの統計パッケージのデフォルトでは、イベント=1、打ち切り=0というコーディングを想定しています。CNSRをそのまま用いることはできません。\n\n\n\n\n\nエピソードとRスクリプト\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\nA First Step into Survival and Competing Risks Analysis with R\n[When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys]\nstudy-design.R"
  },
  {
    "objectID": "jp/study-design-2.html",
    "href": "jp/study-design-2.html",
    "title": "Data Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes",
    "section": "",
    "text": "Study Design II − Data Have Types\n\nprobability model, simulation, survival/competing-risk, language/writing\n\n\n\nデータには型がある\n\n\n私「コーヒー淹れたから、もう少し相談させてよ。さっきRの話がでたでしょ。そのとき、どの関数を使うかもアウトカムによって違うんだよっていってたじゃない？あれ、いまいちピンとこないんだけど。データなんて、全部数字じゃないの？」\n\n\nお父さん「いいね、最近秋めいてきたからコーヒーがあるとありがたい。数字には違いないんだけどね。統計解析では、データの型がとても大事なんだ。代表的なのはこの4つ」\n\n\n\n連続データ\n2値データなどの分類データ\n計数データ\n生存時間データ\n\n\n\n私「連続データって、年齢とか血圧みたいな測るやつでしょ？2値データもわかるよ。私の調査で比較したいストーマ保有あり・なしとか」\n\n\nお父さん「ご名答。で、計数データは、交通事故の発生件数のような、数をカウントしたデータのこと。生存時間データは、たとえば寿命とかだね。死亡など特定のイベントが起こるまでの時間を扱うデータだよ。今回のがんサバイバー調査でいえば、手術から復職までの時間とか、再発までの時間とかね」\n\n\n私「いわれてみれば、たしかに種類が違うね。でも、昔受けたRの授業では、言われた通りにコード打ってただけだったなあ。glm()とかsurvfit()とか、なんか呪文みたいなのを」\n\n\nお父さん「そうだね。パソコンある？」\n\n\n私「へ」\n\n\nお父さん「パソコン。あるでしょ。RStudioインストールしよう」\n\n\n私「はあ、まあ声を掛けたのはこっちだからいいけど」\n\n\nお父さん「Rではね、連続データを解析するなら、mean()、t.test() なんかがよく使われる」\n\n\n私「はあ」\n\n\nお父さん「2値データを集計するときはtable()。p値を計算するときはfisher.test()。複雑な解析はglm(family = binomial) みたいな回帰モデル。生存時間データだと、survfit()、coxph()、それからcifplot()みたいな関数が出てくる」\n\n\n私「そんなにいっぱい覚えられるわけないでしょ。Rの授業でも思ってたけど、そんなのあたかも呪文なんだって」\n\n\nお父さん「覚えなくていいよ」\n\n\n私「え、いいの？」\n\n\nお父さん「大事なのは、どの型のデータに、どんな関数をあてるのかをイメージできること。もっといえば、どんな確率分布を仮定しているかを、なんとなくでいいから思い浮かべてほしいんだ」\n\n\n私「確率分布？」\n\n\nお父さん「学部でやったでしょ。正規分布（normal distribution）は聞いたことある？」\n\n\n私「それくらいはね」\n\n\nお父さん「単なるデータの記述より高度な統計手法では、裏でなんらかの確率モデル（probability model）を考えてる。連続データの正規分布とか、2値データの2項分布（binomial distribution）とか、計数データのPoisson分布とかね。生存時間データだと、標準的に使われるモデルってわけじゃないんだけど、一番シンプルな分布は指数分布（exponential distribution）っていうんだ」\n\n\n私「はあ。それとRが関係するわけ？」\n\n\nお父さん「うん。たとえばさ、これは覚えてほしいんだけど、割合（proportion）と率（rate）っていう指標のがある。日常生活でもよく使うでしょ？交通事故の発生率とか。でも、日常では、割合と率の違いを意識しないよね。でも、統計の世界では、割合は2項分布のパラメータ、率はPoisson分布のパラメータなんだ」\n\n\n私「割合と率なんて同じ意味でしょ？」\n\n\nお父さん「違う違う。割合ってパーセントで表すでしょ、女性割合が60%とか。でも、“東京都の1年あたりの交通事故の発生率”を例に考えてみてよ。パーセントにならなくない？交通事故が何回、起きたかを年で割ってるだけだから」\n\n\n私「ふーん。続けたまえ」\n\n\nお父さん「教科書どおりじゃなくていいんだ。“あ、これは正規分布っぽい連続データだから、このあたりの関数かな”とか、0/1のデータだから、このへんの関数かなって、感覚で結びつけられるといいよ。そうするとRの関数もずっと覚えやすくなる」\n\n\n私「なるほどね。データの型と分布をイメージできれば、R関数丸暗記不要ってことね。そいつははかどるわ」\n\n\nお父さん「そうそう。イメージがあれば、あとでマニュアルや本を見たときに、ああ、これのことかってつながるからね。じゃあ、Rでちょっとだけデモを見せてみようか。年齢（連続）、性別とストーマ（2値）、生存時間（生存時間データ）をシミュレーションして、簡単な解析をやってみるよ」\n\n\n私「また呪詛が出てくるんでしょ？」\n\n\nお父さん「そうだね。とりあえずlibrary(ggplot2)、library(cifmodeling)って打って。ヒストグラムとKaplan-Meier曲線を教えるよ」\n\n\n私「とりあえず思考停止で打つわ」\n\n\nお父さん「教えてあげてるんだから思考停止しない。Rの機能を追加するとき、install.packages()とlibrary()を使う。ざっくりいうとね、それぞれ、“Rパッケージをパソコンにインストールする”コマンドと、“インストール済みのパッケージを使えるようにする”コマンドなんだ」\n\n\n私「ふむふむ。じゃあインストールの方は、一度やったら、それで終わり？」\n\n\nお父さん「基本的にはそう。同じパソコンなら、インストールは原則1回でOK。たとえば、install.packages(\"ggplot2\")は、CRANっていうパッケージの倉庫から、自分のパソコンにダウンロードする。library(ggplot2)は、ggplot2を取り出して、“これからグラフを描くからこの道具を使います”ってRに宣言する」\n\n\n私「なるほど。ちょっとスッキリした。今まで毎回インストールしなきゃいけないのかなって思ってた」\n\n\nお父さん「毎回インストールすると、“コーヒー淹れるたびに豆を買いに行く”ようなものだからね。豆はまとめて買っておいて、飲むときに挽けばいい。パッケージも同じだよ」\n\n\n\n\n\n\n\n\nシミュレーションデータの生成\n\n\n\nここでは、Rを使って簡単なシミュレーションデータを作り、連続データ・2値データ・生存時間データそれぞれについて、代表的な統計解析のデモをします。題材は「ストーマ保有者と非保有者の2群比較」です。\n\n年齢：正規分布rnorm()から生成した連続データ\n性別・ストーマ保有：2項分布rbinom()から生成した2値データ\n生存時間：指数分布rexp()から生成した生存時間データ\n\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\nset.seed(46)\n\n# ストーマ保有あり(1)/なし(0)\nstoma &lt;- rbinom(200, size = 1, prob = 0.4)\n\n# 性別 0 = 女性, 1 = 男性\nsex &lt;- rbinom(200, size = 1, prob = 0.5)\n\n# 年齢：正規分布から生成（ストーマあり群を少し高齢に）\nage &lt;- rnorm(200, mean = 65 + 3 * stoma, sd = 8)\n\n# 生存時間：指数分布（ストーマあり群の予後の期待値10年、ストーマなし群の予後の期待値15年）\nhazard &lt;- ifelse(stoma == 1, 1 / 10, 1 / 15)\ntime   &lt;- rexp(200, rate = hazard)\n\n# ランダムな打ち切り（0 = 打ち切り, 1 = イベント）\nstatus &lt;- rbinom(200, size = 1, prob = 0.9)\n\ndat &lt;- data.frame(\n  age    = age,\n  sex    = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n  stoma  = factor(stoma, levels = c(0, 1), labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n  time   = time,\n  status = status\n)\nhead(dat)\n\n       age   sex         stoma      time status\n1 59.19077 WOMAN WITHOUT STOMA 17.939751      1\n2 59.46486   MAN WITHOUT STOMA 18.189251      1\n3 55.34491   MAN WITHOUT STOMA  2.445121      1\n4 60.68207   MAN WITHOUT STOMA 46.737429      1\n5 61.79577   MAN WITHOUT STOMA  0.149128      1\n6 62.84530 WOMAN    WITH STOMA  0.298167      1\n\n\n\n\n\n\n\n\n\n\n\n連続データと2値データの要約\n\n\n\nまず、ggplot2パッケージのggplot()と、table()を使って、ストーマあり群とストーマなし群のデータをヒストグラムと分割表で記述しています。データを生成したときの設定を踏まえると、ヒストグラムでは、ストーマありとなしの間で、年齢の分布がずれているはずです。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\n# install.packages(\"ggplot2\") #インストールが必要なら実行\nlibrary(ggplot2)\n\nggplot(dat, aes(x = age, fill = stoma)) +\ngeom_histogram(alpha = 0.5, position = \"identity\", bins = 10) +\nlabs(x = \"AGE\", y = \"FREQUENCY\", fill = \"STOMA\") +\ntheme_minimal()\n\n\n\n\n\n\n\ntable(STOMA = dat$stoma, SEX = dat$sex)\n\n               SEX\nSTOMA           WOMAN MAN\n  WITHOUT STOMA    43  76\n  WITH STOMA       44  37\n\n\n\n\n\n\n\n\n\n\n\n生存曲線による生存時間データの要約\n\n\n\n次の生存時間データでは、cifmodelingパッケージのcifplot()を使って、Kaplan–Meier曲線を描いてみます。ストーマ保有者より、非保有者の方が、生存曲線が高くなる（生存期間が長くなる）はずです。生存時間データとその扱いについては、次とその次のエピソードでお話しします。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\n# install.packages(\"cifmodeling\") #インストールが必要なら実行\nlibrary(cifmodeling)\ncifplot(Event(time, status) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n2009～2014年にFDAによって承認されたがん領域の医薬品は、83品目あったそうです。奏効率（腫瘍縮小や完全寛解）がエンドポイントの臨床試験を根拠として承認されたのは、83品目のうち何割だったか、正しいものを選びなさい。\n\n0～24%\n25～49%\n50～74%\n75～100%\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は2です\n\nKim and Prasad（2016）の総説論文によると、奏効率の結果に基づいて承認されたのは83品目のうち31品目と報告されています。また、エンドポイントの内訳は通常承認と加速承認では異なります。通常承認では、品目55品目のうち48品目が全生存期間、無増悪生存期間、無病生存期間で評価されたのに対し、加速承認では、奏効率を主要エンドポイントとする第II相試験の結果を根拠にした品目が大多数でした。\n\n\n\n\n\n文献\n\nKim C and Prasad V. Strength of validation for surrogate end points used in the US Food and Drug Administration’s approval of oncology drugs. Mayo Clin Proc 2016; S0025-6196(16)00125-7\n\n\n\nエピソードとRスクリプト\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\n[A First Step into Survival and Competing Risks Analysis with R]\n[When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys]\nstudy-design.R"
  },
  {
    "objectID": "jp/publish-a-paper-4.html",
    "href": "jp/publish-a-paper-4.html",
    "title": "Story and Quiz − Publishing a paper IV",
    "section": "",
    "text": "Story and Quiz − Publishing a paper IV\n\n　　　　　　　　　　　　　　　　　　　　Keywords: survival/competing-risk, paper writing\n\n\n\n推敲のコツ\nお父さん「論文は書けた？」\n私「Resultsの途中まではね。まとまった時間がとれなくて」\nお父さん「診療しながら時間を確保するのは大変だよね。論文ってそれだけに集中しないと書けないものだから」\n私「このあたりの英語表現なんだけどさ、みてくれる？」\nお父さん「文章を見直してるところだったんだね。あれ？画面上で？」\n私「だめかな」\nお父さん「画面と紙じゃ読んだときの印象が違うよ。落ち着いて文章を見直したいときは、手間を惜しまずプリントアウトしよう」\n\n画面と紙の両方を使って推敲する\n\nお父さん「一通り読んだよ。まず気になったのはこの一文かな」\n（例1）Overall survival curves and disease-free survival curves were estimated by the kaplan-meier method and tested with p-value less than 0.05 as significant.\nお父さん「論文を書くとき気を使ってほしいことはいくつかある。そのひとつが専門用語を正しく扱うっていうことで、これは医学用語でも統計用語でも同じだけどね。ここで使っているkaplan-meier methodとp-valueは、専門用語でしょ。だから正確に。人名に由来する統計手法は、大文字からはじめてKaplan-Meier methodと書かなきゃいけない。それに、専門的にみると、用語のレベル感が違う」\n私「レベル感ってどういうこと？どっちも統計の言葉って感覚しかないよ」\nお父さん「そうだとは思うけど気になっちゃう。Kaplan-Meier methodは統計手法のひとつだよね。でも、p-valueは特定の手法ではなくて、指標の種類を表している。並列するならレベル感を合わせて、ログランク検定とかFisher正確検定とか、どの検定を使ったのかを書いてほしくなる。文章の意味でいっても、”tested with p-value less than 0.05 as significant”には、有意水準をいくつに設定したかっていう情報しかないからね」\n私「じゃあ直してみる。これでどう？層別ログランク検定を使ったんだ」\n（改善案1-1）Overall survival curves and disease-free survival curves were estimated by the Kaplan-Meier method and compared by the log-rank test, stratified by factors shown in Table 1. The significance level was set at 0.05. （レベル感をそろえた）\nお父さん「いいね、違和感はなくなった。でも、ちょっと気になるのは、意味があいまいなところかな。生存曲線もTable 1の因子で層別したの？」\n私「してない。でもそこは読んでもよくわかんないね、この英文。”stratified by”がどこまでかかってるかはっきりしないもの」\nお父さん「接続詞や関係代名詞を使って、長い文をつくるとそうなりがちだよね。対策のひとつとしては、コンマの位置を変えると、意味をとりやすくなる」\n（改善案1-2）Overall survival curves and disease-free survival curves were estimated by the Kaplan-Meier method, and were compared by the log-rank test stratified by factors shown in Table 1. The significance level was set at 0.05.（コンマの位置を変えた）\nお父さん「これでもいいけど、長い文は短い文に分けるのが一番いい。以下の英文が、”concise”でいちばん読みやすいんじゃないかな」\n（改善案1-3）Overall survival curves and disease-free survival curves were estimated by the Kaplan-Meier method and compared by the stratified log-rank test.\nThe factors shown in Table 1 were used for stratification. The significance level was set at 0.05. （短い文に分けた）\nお父さん「専門用語で気をつけてほしいのは、正確性だけじゃない。単語と意味を1対1に対応させないといけない。統計用語って、別表現があるのがやっかいなんだよね。たとえば生存曲線だけでも、同じ意味で用いられる表現は無数にある。だから、文章を書いているうちに別表現が混在してしまって、それぞれ別の意味と思った読者は混乱しちゃうかもしれない。特定の意味を示す単語はひとつだけにするように気をつけてほしい」\n私「改善案1-3でも混在してるじゃない」\nお父さん「この文章の場合、全生存期間・無病生存期間の生存曲線を表すグラフを、Kaplan-Meier法で推定した、という意味だから、混在ではないよ。用語を使い分けているんだ。じゃあ一旦ここでまとめようか。文章を推敲するときのコツを3つ話したよ」\n\n専門用語の表現は正確か\n長すぎて意味をとりにくい文はないか\n専門用語とその意味は1対1に対応しているか\n\n\n\n\n\n\n\nNote\n\n\n\n 統計用語の意味\n生存曲線は英語ではsurvival curveですが、同じまたは似た意味で用いられる用語は、survival function、survival rate、overall survival curve、Kaplan-Meier curveなど無数にあります。実はそれぞれ細かい意味が違うのです。\n\n生存曲線（survival curve）とほぼ同義\nSurvival function\nほぼ同義だが、曲線というよりある時点の値を意図した用語\nSurvival rate, survival probability, survival proportion\n生存曲線をどの統計手法で推定したのかを特定する用語\nKaplan-Meier curve, Kaplan-Meier estimator, Kaplan-Meier estimate, Kaplan-Meier method\nエンドポイントの種類を特定する用語\nOverall survival curve, disease-free survival curve, 5-year OS, 3-year DFS\n\n統計学では、推定方法を推定量（estimator）、推定した結果を推定値（estimate）、推定しようとしている対象を推定目標（estimand）といいます。ここは論文を書くとき注意が必要なところで、MethodsではKaplan-Meier estimatorと書くのが自然ですし、ResultsではKaplan-Meier estimateを用いることが多いでしょう。「人名+estimator」の代わりに「人名+method」という表記もできて、Kaplan-Meier methodの方がより広い意味で用いることができます。\n最後に注意してほしいのが、累積発生率曲線（cumulative incidence curve）や累積発生率関数（cumulative incidence function）です。生存曲線と同じだと思いがちですよね。しかしこれらは、競合リスクがあるときにだけ用いられる、統計家が意識して区別している用語です。生存曲線の上下を反転したグラフを”cumulative”と呼ぶことがありますが、これは統計用語ではなく慣習的な表現です。累積発生率曲線と区別しないと誤解が生じます。\n\n\nお父さん「次はこの一文について考えてみてよ。なにか足りない情報はない？」\n（例2）The return-to-work rate was defined as the proportion of return-to-work divided by the number of patients.\n私「えーっと。そうか、いつまでに仕事に就けたかが書いてないんだ。術後12ヶ月とか書いた方がよかった」\nお父さん「そう。さらに気になるのは、”return-to-work rate”が割合ってことは文脈から明らかってこと。追加の情報があまりないんだ。たとえば割合を計算するときの分母は、調査した患者全員なの？」\n私「ううん、もともと仕事をしていた人だけ」\nお父さん「じゃあその情報があった方がいいよね。それに、”return-to-work”が2回使われていて冗長だよね。こういう風に直そう」\n（改善案2-1）The return-to-work proportion was defined as the number of patients employed 12 months after surgery divided by the number of patients who were employed at diagnosis.\n私「分子と分母を具体的に書いたわけだ」\nお父さん「そう。無回答や欠測データがあって、分母の数があわないことが意外と多い。この場合も、もともと就職してない人はどうなったのか気になる読者もいるでしょ。だから、スマートじゃないけど丁寧に書いた方が親切。別の文章でも似たようなことは起きる。意外と難しいのが、増減を表す英語表現なんだ。この文章を読んでみて」\n（例3）The return-to-work proportion increased from 2010 to 2020 with a rate of AA%.\nお父さん「増加率がAA%だったっていいたいんだろうけど、この情報だけじゃどれくらい増えたのかわからなくない？もしかしたら1年あたりの変化率かもしれないし。これも情報不足の例で、数値を補う必要がある」\n（改善案3-1）The return-to-work proportion increased from BB% in 2010 to CC% in 2020, with an annual increase of DD%.\n私「いいじゃん。ほかによくあるパターンってないの？」\nお父さん「ほかに足りない情報が目につくのは、サンプルサイズについての説明かな。ちょっと専門的になるけどね。たとえばこの箇所」\n（例4）We planned to recruit 160 patients, with a significance level of 5% and statistical power of 80% to detect a difference of 10% between patients with and without stroma.\n私「ここか。この前教えられた通り書いたんだが」\nお父さん「えっと、よく思い出してよ。p値には両側と片側があるっていったじゃない。その情報がこの文章にないよね。こんな感じで書かなきゃ、サンプルサイズの計算が再現できない」\n（改善案4-1）We planned to recruit 160 patients, with a significance level of 5% and statistical power of 80% to detect a difference of 10% between patients with and without stroma.\nお父さん「ただし、まだ気になるところが残っている。それはこの文章に引用文献がついていなくて、10%の差の根拠がわからないこと。人によっては、不足している情報があると感じる読者もいると思う。それと、細かいけど、例1では有意水準を0.05っていってたのに、例4でパーセントを使うのは統一性がない。この手の問題は、専門用語のチェックに加えて、以下の3点に注意すると、見つけられるはず」\n\n不足している情報はないか\n冗長な情報はないか\nどの時点のことを指しているか読み取れるか\n\nお父さん「あと気になったのは、文章のトーンや論調で、たとえばここの表現なんだけど。強調したいから”strongly”っていってるんだよね。でも、これじゃ強すぎない？」\n（例5）Stoma creation was strongly associated with a difficulty in return-to-work.\n私「そうかな。いちばん重要な結果だからこう書いたんだけど。どういう英文がいいと思うの？」\nお父さん「一般論なんだけど、論文の結果のうち、強調したいものとそうじゃないものがあるよね。適切に強調した方が、メリハリがついて読みやすくなるけど、どのくらい強い表現にするかは考えなくちゃ。改善案を7つ考えてみたんだ。いちばん簡単なのは、強調表現をやめたり、別の表現にしたりするだけでも、調整はできる」\n（改善案5-1）Stoma creation was associated with a difficulty in return-to-work（強調表現を削除した）\n（改善案5-2）Stoma creation was highly associated with a difficulty in return-to-work（強調表現を弱めた）\n（改善案5-3）Stoma creation was substantially associated with a difficulty in return-to-work（やや遠回しな強調表現にした）\n私「これくらいなら私も思いつくんだけど」\nお父さん「うん。でも、文章の推敲って結局表現を選ぶことだから、ぴったりした形容詞や副詞はなにかもチェックポイントだよ。注意してほしいのはsignificantを使うとき。これは論文でよく目にするけど、統計学的に有意という意味になってしまう。この表現を選ぶときは、p値を示さないといけない」\n（改善案5-4）Stoma creation was significantly associated with a difficulty in return-to-work (p=AAA)（統計学的に有意という意味を加えた）\nお父さん「単に副詞や形容詞を加える以外の表現方法もある。いくつか例を挙げるけど、次第に客観的なニュアンスが強くなるよね」\n私「いわれてみるとそうね。論文書いてると、関連があったかどうか説明する文の繰り返しになっちゃうから、いろんなパターンがあると助かる」\n（改善案5-5）The return-to-work proportion of patients with stoma was lower than that of patients without stoma（比較対照を示した）\n（改善案5-6）The return-to-work proportion in patients with stoma was BB%, being much lower than that in patients without stoma（定量的に表現した）\n（改善案5-7）The odds ratio for delayed return-to-work was CCC (95% confidence interval DDD to EEE, p=FFF)（直接的に結果を述べた）\nお父さん「重要な結果や論文の結論は、強調したくなるのが人情だけど、エディターやレビュワーが読むと、強すぎる表現は不適切と感じちゃう。特にConclusionには気を遣う」\n私「不適切って思われるのはわかるわ。実際、論文読んでるとき著者の偏った意見って気になるもの。単に表現の問題じゃなくて、内容が偏ってることもあるんじゃない？」\nお父さん「それもある。論文を推敲するときは、主張が偏っているところも直したいよね。まずは、パラグラフ全体で強調しすぎていないかをみて、次に、それぞれの文で強すぎる表現になっていないかチェックするといい。それに、以前話したように、賛成・反対の両方の視点で読むっていうのもよくやる。どちらかに肩入れしていると感じたら、トーンを落としたり、両論併記したりすると、バランスがとれる。次のこの文は、逆に主張を弱めたかったんでしょ」\n（例6）It is considered that the unexpectedly high rate of return-to-work is attributable to the Guideline for Support for Therapy and Work Life published by MHLW.\n私「うん、厚労省のガイドラインが効いたかどうか自信がなくて」\nお父さん「この文の主語は誰？」\n私「え？私かな」\nお父さん「でも英文には主語がないでしょ。”It is considered that”や”It is thought that”は一般的にこう考えられているっていう意味になる」\n私「なるほど、日本語だと、主張を和らげるために、”と思う”や”と考えられる”っていいがちだけど、英語では使えないんだ」\nお父さん「そう。英語論文で確信の度合いを表すときは、probablyやpresumablyなどの副詞や、mustやmayなどの助動詞を使うといい。いくつか文案をみせるね。順に主張が弱くなる」\n（改善案6-1）The unexpectedly high rate of return-to-work is presumably attributable to the Guideline for Support for Therapy and Work Life published by MHLW.（かなり確信がある）\n（改善案6-2）It is likely that the unexpectedly high rate of return-to-work is attributable to the Guideline for Support for Therapy and Work Life published by MHLW.（可能性が高い）\n（改善案6-3）The unexpectedly high rate of return-to-work is possibly attributable to the Guideline for Support for Therapy and Work Life published by MHLW.（可能性がある）\n（改善案6-4）It seems that the unexpectedly high rate of return-to-work is attributable to the Guideline for Support for Therapy and Work Life published by MHLW.（そのようにみえる）\n（改善案6-5）The unexpectedly high rate of return-to-work may be attributable to the Guideline for Support for Therapy and Work Life published by MHLW.（可能性のひとつ）\nお父さん「付け加えるとね、あまり強調したり弱めたりしないことも大切だよ。たとえば、possiblyやmayばかり使って論文を書くと、読者は根拠が弱いんじゃないか、論理があいまいなんじゃないかって不安になる。事実を淡々と述べるだけでふつうは問題ない。まとめるとポイントはこの3つかな」\n\n個々のパラグラフをみて、強調の程度は適切か\n個々の文をみて、適切な強調表現を選んでいるか\n賛成・反対の両方の視点で読んだとき、偏った主張はないか\n\nお父さん「さて、専門用語の扱い、情報の過不足、表現の強弱を中心に話してきたけど、文章の推敲って奥が深いし、一度にすべてをチェックすることは難しい。だから、何度も原稿を読み返すといい」\n\n推敲は、すればするほど、いい文章になる\n\n私「そろそろ覚えきれなくなってきたよ」\nお父さん「うん、それじゃあ最後に復習を兼ねてひとつ課題をやってみてよ。以下の文章は、JCOG9502（Sasako, et al. 2006）のDiscussionの冒頭部分を改変したもの。Discussionの第一パラグラフでは、結果を簡潔にまとめることが多い。これをもっといい英文にしてみて」\n（例7）It was shown that LTA does not provide a survival advantage compared with TH in the treatment of curable gastric cancers, although the study was stopped after the interim analysis, because patients assigned LTA were unlikely to have an improved overall survival compared with those assigned TH for Siewert type 2 or 3 tumours.\n私「わかった。長い」\nお父さん「そう、長すぎて、文章の意味がすぐ頭に入ってこないよね。特に”because”以降がどこにかかっているのかはっきりしない。どうしたらいいかな」\n私「えーっと。短く分けるんだっけ。これでどう？」\n（改善案7-1）It was shown that LTA does not provide a survival advantage compared with TH in the treatment of curable gastric cancers.\nThe study was stopped after the interim analysis, because patients assigned LTA were unlikely to have an improved overall survival compared with those assigned TH for Siewert type 2 or 3 tumours.\nお父さん「うん、ずっと読みやすくなったよね。”It was shown”を使うより、主語をはっきりさせると、より英語らしくなる。また、別のやり方として、後半を簡潔にすることもできる。たとえば、これ以上試験を続けても有効性を示せないことを意味する無益性（futility）という専門用語を使うとこうなる。こっちの方がスマートだけど、専門性が高すぎる文章かもしれない」\n（改善案7-2）This study showed that LTA does not provide a survival advantage compared with TH in the treatment of curable gastric cancers, although the study was stopped after the interim analysis because of futility.\nお父さん「もうひとつポイントがあるんだ。改善案7-1をみて。一つ目の文に書かれていることが、Discussionで読者が最初に受け取る情報になるよね。そこで考えてほしいのは、二つ目の文でどんな情報が加わるかっていうこと。答えをいっちゃうと、それは”for Siewert type 2 or 3 tumours”なんだけど」\n私「確かに。その説明はDiscussionの最初に欲しいね。対象疾患がわからないと、その先が読めないもの」\nお父さん「つまり、疾患の定義のような論文のキーになる情報は、リマインドしてもいいってこと。JCOG9502の論文でも、Discussionの冒頭でそうしている。採用されたのは以下の英文だよ。この臨床試験がどんな疾患を対象にしていて、どんな結果だったか、改めて整理したいっていう意図が感じられる。こういうパラグラフが最初にあると、読者と共通の材料をもって、Discussionを始められるよね」\n（論文で採用された表現）This study shows that LTA does not provide a survival advantage compared with TH in the treatment of curable gastric cancers with an oesophageal invasion of 3 cm or less, which corresponds mainly to tumours classified as Siewert type 2 or 3.\nThe study was stopped after the interim analysis, because patients assigned LTA were unlikely to have an improved overall survival compared with those assigned TH for Siewert type 2 or 3 tumours.\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n“Statistics”は、日本でも中国でも韓国でも「統計」という漢字を当てます。それでは「統計」という言葉が生まれた国はどれでしょう。\n\n日本\n中国\n韓国\nそれ以外の国\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は1の日本です\n\n明治時代、伊藤博文がアメリカに視察に行ったとき、同じ大蔵省にいて語学が堪能だった福地源一郎を同行して、英語の翻訳をさせたそうです。統計という言葉もこのとき生まれたといわれています。\n福地源一郎 - Wikipedia\n\n\n\n\n\n文献\n\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\n\n\n\nContinuation of their story\nStudy design I\nStudy design II\nStudy design III\nStudy design IV\nStudy design V\nClinical trial I\nClinical trial II\nClinical trial III\nEpidemiology I\nEpidemiology II\nEpidemiology III\nEpidemiology IV\nRegression I\nRegression II\nRegression III\nRegression IV\nCausal inference I\nCausal inference II\nCausal inference III\nCausal inference IV\nPublish a paper I\nPublish a paper II\nPublish a paper III\nPublish a paper IV"
  },
  {
    "objectID": "jp/publish-a-paper-2.html",
    "href": "jp/publish-a-paper-2.html",
    "title": "Story and Quiz − Publishing a paper II",
    "section": "",
    "text": "Story and Quiz − Publishing a paper II\n\n　　　　　　　　　　　　　　　　　　　　Keywords: paper writing\n\n\n\n論文を書くときの3つのアドバイス\n私「この前はピアレビューの仕組みについて話してくれたけど、次は論文の書き方を教えてよ」\nお父さん「いいよ。じゃあ最初のアドバイスはこれ」\n\n図表を作ってメッセージを決める\n\nお父さん「この前みせた抄録を、もう一度通して読んでみてよ。冒頭から結論まで、余計なことを書かず、ひとつのテーマに沿って書かれてない？」\n私「ほんとだ」\nお父さん「これは論文全体を書くときのコツでもある。読者になにを伝えたいかをひとつに絞っておくってこと」\n私「そうね。”Further support for employment is necessary”、つまりストーマ保有者は再就職が難しいから、さらなる就労支援が求められることを伝えてる文章になってる。ってことは、テーマっていうか、読者へのメッセージをひとつ決めなさいっていいたいのね」\nお父さん「うん、メッセージっていってもいい。でもね、論文なんだから、データに基づくことしか主張できないでしょ。だから、論文を書き始めるときは、論文に載せる図表を作ることから手をつけるといいよ。データからどこまでのことがいえるか、図表をみながらメッセージを決めると、文章を書くときの目標がはっきりするんじゃないかな」\n私「図表ねえ。まだ2個しかないよ。背景因子と復職率の表しか」\nお父さん「一部じゃなくて、すべての図表をセットで作っておいた方がいい。どうしてかっていうと、解析結果のバージョン管理がしやすくなるから」\n私「どういうこと？必要になったらそのときに図表を作るのじゃだめなの？」\nお父さん「図表を固定できるなら困らないんだけどね。データの扱いや統計手法の細かい違いで、同じような図表を作ることになりがちで、なかなか固定できないものなんだ。もちろん、いい結果が出るようにいろんな解析を試すっていう意味じゃないよ。載せる図表をひとまとめにしてセットにした方が、どのデータセットでいつ作ったかとか、管理しやすいでしょ。そういうこと」\n私「じゃあ、とりあえず図表作成から始めるか」\nお父さん「投稿規定にいくつ図表を載せられるか書いてあるから、確認してね。きっと図表を作る過程で、足りない図表を追加したり、図表を取捨選択したりすると思うんだ。そうしていくうちにメッセージも洗練されていくはず」\n私「図表を作ってメッセージを決めるっていうけど、いうほど簡単じゃなくない？私に説得力のあるメッセージが書けるかな」\nお父さん「説得力か。それはメッセージだけの問題じゃないよね。主張の裏付けは確かかどうかだもの。二つ目にこんなアドバイスをしようと思ってた」\n\n研究の限界を考察して説得力を高める\n\nお父さん「メッセージを考えるときに、批判的な視点を取り入れてみたらどうかな」\n私「批判的っていうのは、エディターとかレビュワーの視点っていう意味？批判的吟味って言葉は聞いたことあるけど」\nお父さん「そんな感じ。査読でどんなコメントがきそうか、予想することはよくあるよ。データの欠点についてどんな指摘がきそうか、統計手法につっこみはこないか、結果からロジカルに主張を導けてるか、とかね。思考の積み重ねが説得力を高めるんじゃないかな」\n私「じゃあさ、どの程度の欠点だったら許される？どのくらいのクオリティが要求されてるかわかんないんだよね」\nお父さん「それは一概にはいえない。たとえば結論の価値が高いなら、多少の欠点があっても採択したくなる。別の研究の二番煎じだったり、新規性が感じられなかったりする論文は、載せる価値がないって思っちゃう。そうだなあ。データがらみで一発リジェクトにしそうな理由って、診断方法が不正確なケースや、測定しておくべきデータがとられていないケースくらいじゃない？それ以外には、統計解析が間違っていたり、解析結果に明らかにバイアスが生じていたり、著者の論理が一貫しないってケースもあるかな」\n私「一発リジェクトじゃないってことは、メジャーリビジョンってこと？」\nお父さん「そういうこと。研究の弱みについて、著者はどう考えているか確認する必要があるし、バイアスがあっても、統計解析を工夫したり感度解析で対処できることも多い。でも、その結果が論文に示されていないだけかもしれないからね」\n私「ふーん。それって臨床試験でも同じなの？臨床試験は、どんな解析をするか、がちがちに決まっているんじゃなかったっけ。統計解析計画書っていう文書をつくるって聞いたことがあるよ。感度解析を追加しても許されるのかな」\nお父さん「そこは柔軟に考えないといけない。計画外の解析結果を、論文に載せることができなかったとしても、査読コメントへの回答で示すことはできるでしょ。レビュワーの方が間違っていて、論文で出したくないような結果を要求されることもゼロではないけど、そういうときには、レビュワーにだけ見せるっていう手を使うこともある。やっぱり困るのはデータがとられてないケースだよね。データがないと、解析結果を示してレビュワーを説得することもできない」\n私「なんとか対処できるような査読コメントしかこなかったらいいんだけど。でもさ、考えてみたら欠点なんていくらでもあるよね」\nお父さん「そう思うのは研究者あるあるだね。対処のしようのない欠点はどの研究にもある。じゃあみんなどうしてるかっていうと、Discussionの研究の限界（study limitations）っていうパラグラフに書くっていうのが、ひとつのやり方だね。たとえば、ストーマ保有者と非保有者を正しく比較できているのかっていう問題があるでしょ。どんな批判がくるか予想するうちに、調整できてない交絡因子を思いついちゃうかもしれない。もしデータをとっているなら、ロジスティック回帰の共変量に入れた方がいいよね。データがないならDiscussionで言い訳しないといけない」\n私「縁起でもないこといわないでよ」\nお父さん「まあ研究の限界ってネガティブな話題ではあるけど、きちんと研究の限界について考察しておくと、論文全体の説得力は増すよね」\n私「そうかもしれないけど」\nお父さん「それにぜったい批判的じゃなきゃだめってこともないと思う。書いているときとは別の視点で、原稿を見直すのは、いい論文を書くために効果的だよ。別人になったつもりで文章を推敲するっていうか」\n私「別の視点って誰目線よ」\nお父さん「たとえば、読者目線でパラグラフをひとつひとつ読む。きっと、読者がもっと説明してほしいところ、逆に冗長で読みにくいところ、そのパラグラフで言いたいことがはっきりしないところがあるはず」\n私「それはあるかもね。冷静に文章を読み直したら、自分でもなにいってるかわからんってなることあるよね」\nお父さん「そうそう、視点を変えるとクールダウンできるって面もあるね。論文の結論についていうと、賛成・反対の読者がそれぞれどう読むか想像してみるっていうのもいい。たとえば外科医にも、開腹手術派と内視鏡手術派がいるっていうじゃない。開腹手術と内視鏡手術を比較するランダム化臨床試験の論文を読んだとき、それぞれの派閥で、読み方が違いそうじゃない？侵襲性のことばかり考察に書いてあると、開腹手術派はいやな顔をしたり。そんなバランスを欠いた議論にならないように、賛成・反対の両方の視点で、原稿を見直すっていうのも、やり方のひとつ。結論が白黒はっきりするような論文では特に有効じゃないかな」\n私「それもいいかもね。あえて偏った主張をしたいわけじゃないもの」\nお父さん「じゃあ三つ目のアドバイス。論文本文の書き方について。本文の方が抄録よりずっと長い。本文を一気に書くのは無理だから、小分けにした方がいい。どのくらい小分けにして書くかっていうと、セクション（節）とパラグラフ（段落）を単位にするのがひとつの基準だよ」\n\nセクションとパラグラフごとに書く\n\n私「パラグラフは英語の授業で習ったやつだよね。セクションはそれをまとめたもの？」\nお父さん「うん。論文の章立てには、Introduction、Methods、Results、Discussion、Conclusionsというセクションを使うよね。たとえばIntroductionというセクションを書くことを想像してみて。Introductionには、いくつくらいのパラグラフがありそう？」\n私「え？えーっと、まず直腸がんについて書くでしょ。就労問題について書いて、ストーマについて説明して、先行研究を挙げて、って考えると、4～5パラグラフくらい？」\nお父さん「それは平均より多いっていわれてる。論文1本あたりの、セクションごとのパラグラフ数の平均（SD）を調べた調査がある。次の表は、1997年1月1日から連続で掲載された50論文を集計したものだよ。ちなみに、この集計が載ってる論文執筆のテキストは、実践的ないい本だよ（Albert 2016）」\n\n\n\n\nIntroduction\nMethods\nResults\nDiscussion\n\n\n\n\nN Engl J Med\n2.6（1.1）\n9.2（3.3）\n8.9（3.8）\n6.9（1.8）\n\n\nLancet\n2.6（1.3）\n7.6（3.6）\n6.1（2.9）\n7.0（2.6）\n\n\nBMJ\n2.3（0.9）\n6.0（3.7）\n5.9（3.1）\n7.4（2.8）\n\n\nJ Pediatr\n2.6（1.1）\n6.7（3.4）\n7.0（3.9）\n7.3（2.8）\n\n\nPediatr Res\n2.6（1.3）\n9.6（3.8）\n6.3（2.9）\n8.5（3.4）\n\n\nArch Dis Child\n2.6（1.3）\n6.5（4.0）\n6.1（4.0）\n6.9（2.8）\n\n\n\nお父さん「臨床系のジャーナルに投稿するなら、Introductionは3パラグラフ、MethodsからDiscussionまではそれぞれ7パラグラフが目安かな。もちろん論文の内容にもよるけどね。もし、がんや消化管外科の専門誌に出すなら、直腸がんの細かい説明を省略すれば、Introductionのパラグラフを減らせるかもしれない。たとえば、”Employment of cancer survivors is an emergent problem”っていうような一文から始まって、就労問題について議論していっても不自然ではないでしょ」\n私「そっちの出だしの方がこなれてる感じがする」\nお父さん「こんな経験ない？どんな内容にするか考えながら文章を書くと、知らず知らずのうちに無駄に長くなっちゃうこと。そうならないように、パラグラフごとにトピックを明確にしておくといいよ。調査方法とか研究の限界とか、いろいろなトピックがあるけど、それぞれ読者に伝えないといけない情報があるでしょ」\n私「うん、パラグラフライティングを意識すると、必要十分な情報が把握しやすくなりそう」\nお父さん「最後に、論文の構成について話そう。一般的にいうとね。Introductionでは、どのような科学的な背景があってその研究が行われたのか、研究に関わる様々な論拠、研究仮説や研究目的を書く。Methodsは研究方法を、Resultsは結果を書く。Discussionは、研究の意義を説明したり、他の研究と比べたり、研究の限界について述べたりする」\n私「なんとなくはわかるけどね」\nお父さん「ピアレビューを意識するなら、Methodsで必要な情報を漏らさず丁寧に説明するように、気をつけなさい。さっきいったように、正しい方法論で研究したんだって、わかってもらうことがポイントだからね」\n私「漏らさず丁寧に？たった7パラグラフしかないのに？」\nお父さん「そういうことになっちゃう。それに、論文の文字数には投稿規定による上限がある。だから工夫が必要だよね。よくやる手は、ジャーナルのサイトからダウンロードできる付録（supplementary material）に書くってこと。方法や結果の細かい部分は、MethodsやResultsの本文に入らないことがあるからね。あとは、引用文献をうまく利用すると、説明を省略できるかもしれない。引用文献のスタイルは、間違えてると印象が悪いから注意してね」\n私「なるほど、論文のボリューム感がわかってきた。思ったより、簡潔に、しかも情報を詰め込むように書くんだね。付録とかにできるんなら、どっちかっていうと、ボリュームの制限より、書き忘れがないことに注意しないと」\nお父さん「そうだね。書き忘れ対策としては、医学雑誌編集者国際委員会（ICMJE）という団体が、なにを書かなきゃいけないかリストを用意してくれている（EQUATOR Network 2007）。調査や観察研究の論文を書くときは、観察研究用のSTROBEチェックリストを参考にするといい」\n私「へー。論文に書くことリストだね。項目をひとつひとつパラグラフにしていけばいいって考えると、気が楽になった。論文書いてみるね」\nTitle and abstract | （a）タイトルまたは抄録のなかで、試験デザインを一般に用いられる用語で明示する\n\n\n\n\n\n\n\n（b）抄録では、研究で行われたことと明らかにされたことについて、十分な情報を含み、かつバランスのよい要約を記載する\n\n\n\n\n\nIntroduction\n\n\n\n　背景と論拠\n\n\n\n研究の科学的な背景と論拠を説明する\n\n\n\n　目的\n特定の仮説を含む目的を明記する\n\n\nMethods\n\n\n\n　研究デザイン\n\n\n\n研究デザインの重要な要素を、論文のはじめの部分で示す\n\n\n\n　セッティング\nセッティング、実施場所のほか、基準となる日付については、登録、曝露、追跡、データ収集の期間を含めて明記する\n\n\n　参加者\n（a）適格基準、参加者の母集団、選定方法を明記する。追跡の方法についても記述する\n\n\n（b）マッチング研究の場合、マッチングの基準、曝露群と非曝露群の各人数を記載する\n\n\n\n　変数\nすべてのアウトカム、曝露、予測因子、潜在的交絡因子、潜在的な効果修飾因子を明確に定義する。該当する場合は、診断方法を示す\n\n\n　データ源と測定方法\n関連する各因子に対して、データ源、測定・評価方法の詳細を示す。2つ以上の群がある場合は、測定方法の比較可能性を明記する\n\n\n　バイアス\n潜在的なバイアス源に対応するためにとられた措置があればすべて示す\n\n\n　サンプルサイズ\nサンプルサイズがどのように算出されたかを説明する\n\n\n　量的変数\n量的変数の分析方法を説明する。該当する場合は、どのグルーピングがなぜ選ばれたかを記載する\n\n\n　統計手法\n（a）交絡因子の調整に用いた方法を含め、すべての統計学的方法を示す\n\n\n\n（b）サブグループと交互作用の検証に用いたすべての方法を示す （c）欠測データをどのように扱ったかを説明する （d）該当する場合は、脱落例をどのように扱ったかを説明する （e）あらゆる感度分析の方法を示す | | Results 　参加者 | （a）研究の各段階における人数を示す（例：潜在的な適格者数、適格性が調査された数、適格と確認された数、研究に組入れられた数、フォローアップを完了した数、分析された数）。 （b）各段階での非参加者の理由を示す （c）フローチャートによる記載を考慮する | | 　記述的データ | （a）参加者の特徴（例：人口統計学的、臨床的、社会学的特徴）と曝露や潜在的交絡因子の情報を示す （b）それぞれの変数について、データが欠測した参加者数を記載する （c）追跡期間を平均および合計で要約する | | 　アウトカムデータ | アウトカムのイベント発生数や要約指標の数値を経時的に示す | | 　主な結果 | （a）調整前の推定値と、該当する場合は交絡因子での調整後の推定値、そしてそれらの精度（例：95％信頼区間）を記述する。どの交絡因子が、なぜ調整されたかを明確にする （b）連続変数がカテゴリー化されているときは、カテゴリー境界を報告する （c）意味のある場合は、相対リスクを、意味をもつ期間の絶対リスクに換算することを考慮する | | 　他の解析 | その他に行われたすべての分析（例：サブグループと交互作用の解析や感度分析）の結果を報告する | | Discussion 　鍵となる結果 | 研究目的に関しての鍵となる結果を要約する | | 　限界 | 潜在的なバイアスや精度の問題を考慮して、研究の限界を議論する。潜在的バイアスの方向性と大きさを議論する | | 　解釈 | 目的、限界、解析の多重性、同様の研究で得られた結果やその他の関連するエビデンスを考慮し、慎重で総合的な結果の解釈を記載する | | 　一般化可能性 | 研究結果の一般化可能性（外的妥当性）を議論する | | Other information 　研究の財源 | 潜在的なバイアスや精度の問題を考慮して、研究の限界を議論する。潜在的バイアスの方向性と大きさを議論する |\n\n\n\n\n\n\nNote\n\n\n\n 因果関係に基づく変数の分類\nSTROBE声明の「変数」というセクションでは、これまで説明してこなかった用語がいくつか用いられています。簡単に定義を述べておきます。\n\nアウトカム（outcome）\n因果関係における結果に対応する変数。臨床試験ではエンドポイントという用語を用いる\n曝露（exposure）\n因果関係における原因に対応する変数。治療（treatment）のこともある\n予測因子（predictive factor）\nアウトカムの予測に用いられる共変量のこと。または、アウトカムと相関する共変量のことで、この場合は予後因子（prognostic factor）と同じ意味になる\n交絡因子（confounder）\n因果効果の推定においてバイアスを排除できるような共変量の集合\n効果修飾因子（effect modifier）\n因果効果の大きさや方向の違いをもたらす共変量のこと。または、曝露との交互作用がある共変量のこと\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nバンクーバースタイルには、インターネット上の記事を引用するための形式もあります。\n「人を対象とする生命科学 医学系研究に関する倫理指針」を、バンクーバースタイルで表すと、以下のようになります。さて、□に入るテキストとして正しいものは、次のうちどれでしょうか。\nMinistry of Education, Ministry of Health, Labour and Welfare, Ministry of Economy, Trade and Industry. Ethical Guidelines for Life Science and Medical Research Involving Human Subjects. [□]. 2022 [Accessed October 1, 2022] Available from: https://www.mhlw.go.jp/stf/seisakunitsuite/bunya/hokabunya/kenkyujigyou/i-kenkyu/index.html\n\nInternet\nPDF file\nCopyright preserved\nIn Japanese\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n正解は1です。\nバンクーバースタイルでは、インターネットなど論文以外のメディアに公表された記事を引用するとき、文献リストを以下のように書きます。\n[著者名（苗字+名前のイニシャル）]. [記事名]. [メディアの種類]. [発行年] [アクセスした日] Available from: [URL]\n\n\n\n\n\nContinuation of their story\nStudy design I\nStudy design II\nStudy design III\nStudy design IV\nStudy design V\nClinical trial I\nClinical trial II\nClinical trial III\nEpidemiology I\nEpidemiology II\nEpidemiology III\nEpidemiology IV\nRegression I\nRegression II\nRegression III\nRegression IV\nCausal inference I\nCausal inference II\nCausal inference III\nCausal inference IV\nPublish a paper I\nPublish a paper II\nPublish a paper III\nPublish a paper IV"
  },
  {
    "objectID": "jp/logistic-regression-5.html",
    "href": "jp/logistic-regression-5.html",
    "title": "Simpson’s paradox",
    "section": "",
    "text": "Adjusting for Bias V − Simpson’s paradox\n\nKeywords: confounding/collapsibility, effect measure, generalized linear model, observational study, simulation\n\n\n\nロジスティック回帰で「調整する」ってどういうこと？\n\n\n私「お父さん、ロジスティック回帰でわからないことがあるんだけど。観察研究では交絡因子（confounder）を調整しないといけないって前にいってたよね」\n\n\nお父さん「ああ、そんな話もあったね」\n\n\n私「でも統計学の本を読んでも、なにをどう調整するのか書いてないんだよ」\n\n\nお父さん「いいよ。でも少し長くなる。コーヒーでも飲みながらでいい？」\n\n\n私「賛成。いちご大福あるから持ってくる」\n\n\nお父さん「疫学では有名な話なんだけどね。40年前に、“コーヒーを飲むと膵がんリスクが上がる”という論文がでたことがあった」\n\n\n私「いかにもありそうな話だね」\n\n\nお父さん「そうでしょ。でも、観察研究では、コーヒーを飲む習慣のある集団と、きちんと比較できるようなコントロールを選ぶことは難しい。だから疫学の教科書では、集団同士を比較するときには、第3の因子が隠れていないか注意せよと、必ず書いてある」\n\n\n私「ふんふん」\n\n\nお父さん「それでは問題です。このコーヒー論争で、実際に問題になった第3の因子はなんでしょう？」\n\n\n私「え？えーっと」\n\n\n\nお父さん「答えはこれ」\n\n\n\n\n\n\n\n\nお父さんの答えは？\n\n\n\n\n\nそれは喫煙です。当時は今より喫煙率が高くて、ほとんどの方がコーヒーと一緒にたばこを吸っていたそうです。\n\n\n\n\n\n\n私「へえ、そんな話があったんだ」\n\n\nお父さん「じゃあさ、こういう第3の因子を無視して解析するとどうなる？」\n\n\n私「それくらいわかるよ。バイアスが入るんでしょ」\n\n\nお父さん「そういうこと。これが疫学でいう交絡因子。交絡調整の意味は数字で示すと一番早い。Simpsonのパラドックスっていう現象を使って説明しよう」\n\n\n\n\n\n\n\n\nSimpsonのパラドックス\n\n\n\nコーヒーと膵がんの数値例を用いて、統計学でいう調整とはどういう操作のことなのか、一番シンプルな層別解析でみてみましょう。表1は、コーヒーと膵がんを想定した仮想データです。コーヒー摂取群とコーヒー非摂取群で、それぞれ膵がん発生ありとなしが調べられています。膵がんを発生したのはそれぞれの群で15人と12人、膵がんがなかったのは365人と868人です。オッズ比を計算してみましょう。コーヒー摂取群では膵がんリスクは3.9%で、コーヒーを摂取しない群の1.4%に比べて、オッズ比は3倍です。これは、コーヒーを摂取すると、膵がんリスクが高くなることを意味しています。\n表2には、交絡因子（喫煙）によって対象者を層別した結果が示されています。ここから膵がんのオッズ比を求めるとどうなるでしょうか。コーヒー摂取でも非摂取でもリスクは同じですよね。つまりオッズ比は1倍です。\nこのように、調整前後で、関連の程度が変わる現象を、Simpsonのパラドックスといいます（Simpson 1951）。\n表1. 層別前の膵がんリスクとオッズ比\n\n\n\n\nコーヒー摂取\nコーヒー非摂取\nオッズ比\n\n\n\n\n合計\n\n\n\n\n\n　膵がんあり\n15\n12\n\n\n\n　膵がんなし\n365\n868\n\n\n\n　リスク\n3.9%\n1.4%\n3倍\n\n\n\n表2. 層別後の膵がんリスクとオッズ比\n\n\n\n\nコーヒー摂取\nコーヒー非摂取\nオッズ比\n\n\n\n\n喫煙\n\n\n\n\n\n　膵がんあり\n14\n4\n\n\n\n　膵がんなし\n266\n76\n\n\n\n　リスク\n5.0%\n5.0%\n1倍\n\n\n非喫煙\n\n\n\n\n\n　膵がんあり\n1\n8\n\n\n\n　膵がんなし\n99\n792\n\n\n\n　リスク\n1.0%\n1.0%\n1倍\n\n\n\n\n\n\n\n私「単純な解析ではリスク因子だったのに、層別しただけで関連が消えた。でもこれは“計算上のトリック”じゃないよね？以前こうやって雑談してたとき、オッズ比は層別すると数値が安定しないっていってたのは関係ある？」\n\n\nお父さん「部分的に関係はある。オッズ比は層別したら値が変わりやすい、併合可能ではない（non-collapsible）指標だからね。でも、それより重要なことは、ほとんどの観察研究で、交絡の影響は、効果の指標の違いよりずっと大きいということ。層別で関連が消える現象は、一般化線型モデルでも再現できるよ」\n\n\n\n\n\n\n\n\nglm()を用いた膵がんデータの解析\n\n\n\n交絡調整のための統計手法として、層別解析以外に一般化線型モデルもよく用いられます。オッズ比のモデルであるロジスティック回帰は、link=\"logit\"を用いたglm()に、リスク比はlink=\"log\"に対応していましたね。以下のコードでは調整前のオッズ比・リスク比はsmokeを入れないモデルで、調整後のオッズ比・リスク比はsmokeを入れたモデルで推定しています。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\ndat &lt;- data.frame(\n  cancer = c(1, 0, 1, 0,   1, 0, 1, 0),\n  coffee = c(1, 1, 0, 0,   1, 1, 0, 0),\n  smoke  = c(1, 1, 1, 1,   0, 0, 0, 0),\n  n      = c(14, 266, 4, 76,  1, 99, 8, 792)\n)\nfit_logit1 &lt;- glm(\n  cancer ~ coffee,\n  family  = binomial(link = \"logit\"),\n  weights = n,\n  data    = dat\n)\nodds_ratio1 &lt;- exp(coef(fit_logit1)[[\"coffee\"]])\nprint(odds_ratio1)\n\n[1] 2.972603\n\nfit_logit2 &lt;- glm(\n  cancer ~ coffee+smoke,\n  family  = binomial(link = \"logit\"),\n  weights = n,\n  data    = dat\n)\nodds_ratio2 &lt;- exp(coef(fit_logit2)[[\"coffee\"]])\nprint(odds_ratio2)\n\n[1] 1\n\nfit_log1 &lt;- glm(\n  cancer ~ coffee,\n  family  = binomial(link = \"log\"),\n  weights = n,\n  data    = dat\n)\nrisk_ratio1 &lt;- exp(coef(fit_log1)[[\"coffee\"]])\nprint(risk_ratio1)\n\n[1] 2.894737\n\nfit_log2 &lt;- glm(\n  cancer ~ coffee+smoke,\n  family  = binomial(link = \"log\"),\n  weights = n,\n  data    = dat\n)\nrisk_ratio2 &lt;- exp(coef(fit_log2)[[\"coffee\"]])\nprint(risk_ratio2)\n\n[1] 1\n\n\n\n\n\n\n\nSimpsonのパラドックスが起きる条件\n\n\n私「やっぱりトリックに見えちゃうな、何が起きてるのやら。とりあえず調整しとけっていいたいの？」\n\n\nお父さん「えっとね、いちばん伝えたいことから話すね。研究の原則としてときどき使う”ceteris paribus”というラテン語があってね。“All other things being equal”くらいの意味なんだけど、比較する集団で条件をそろえたら、交絡によるバイアスは生じない。たとえばランダム化臨床試験とかね」\n\n\n私「うん、その説明はわかりやすい」\n\n\nお父さん「じゃあ、その次になにが起きたか整理しよう。まず前提になるのが、喫煙が膵がんのリスク因子だってこと。これはいいよね」\n\n\n私「うん」\n\n\nお父さん「次に注目してほしいのが、喫煙とコーヒーの関連なんだ。喫煙状況ごとにコーヒー摂取割合を計算してみてよ」\n\n\n私「コーヒー摂取割合ね。層別前は30%。喫煙集団では78%、非喫煙集団では11%だよ」\n\n\nお父さん「喫煙群と非喫煙群でコーヒー摂取割合に大きな差があるでしょ。この現象が起きた理由は、コーヒー摂取と喫煙に強い関連があったため、ということ。これは、当時、たばこを吸いながらコーヒーを飲んでいたことを表している」\n\n\n私「時代を感じるね、仕事の合間に寛ぎたい気持ちはめっちゃわかる」\n\n\nお父さん「Simpsonのパラドックスのポイントは、3つの変数の相関関係なんだ。2つの条件が揃うとSimpsonのパラドックスが起きる。正確にいうと、これは十分条件で必要条件じゃないんだけどね（田中2022）」\n\n\n第3の因子と曝露の間に相関がある\n第3の因子とアウトカムの間に相関がある\n\n\n私「曝露とアウトカムと第3の変数の関係性ねえ。ちょっと確認させて。コーヒー摂取群とコーヒー非摂取群で、喫煙率が違う。さらに喫煙は膵がんリスクも上げる。そうすると層別したらオッズ比の値が変わった。ああ、もともとバイアスが入ってたんだから、調整して値が変わるのは当然か。確かにそうなる。交絡の話ってまあまあややこしいね」\n\n\n\n\n文献\n\nSimpson EH. The interpretation of interaction in contingency tables. J Royal Stat Soc B 1951;13:238-41\n田中司朗. 医学研究のための因果推論II. Rubin因果モデル. 東京: 朝倉書店; 2022\n\n\n\nThis concludes the Adjusting for Bias series. If you’d like to keep reading over your next cup of coffee, the following episode is waiting:\n\n[Truth: What Is It That You Want to Know?]"
  },
  {
    "objectID": "jp/logistic-regression-3.html",
    "href": "jp/logistic-regression-3.html",
    "title": "Where My Logistic Regression Went Wrong",
    "section": "",
    "text": "Adjusting for Bias III − Where My Logistic Regression Went Wrong\n\nKeywords: confounding/collapsibility, effect measure, hypothesis/outcome/population, generalized linear model, language/writing\n\n\n\nどうしてオッズ比が無限大になっちゃったの？\n\n\nお父さん「あのさ、昨日のロジスティック回帰の表の続きをしない？コーヒー淹れたから」\n\n\n私「えーお手やらわかに。コーヒーもありがとう。この表の話だよね」\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nパラメータ\n自由度\n推定値\n標準誤差\n95%信頼区間\n\\(\\chi^2\\)\np値\n\n\n\n\nIntercept\n1\n-27.25\n3.03\n-33.20～-21.30\n80.55\n&lt;0.01\n\n\nSTOMA\n1\n1.41\n1.54\n-16.1～4.45\n0.84\n0.3588\n\n\nAGE\n1\n1.47\n1.48\n-1.42～4.36\n0.99\n0.3197\n\n\nSEX\n1\n25.72\n0.00\n25.72～25.72\n\n\n\n\nINCOME\n1\n-0.00\n0.00\n-0.00～0.00\n0.58\n0.4481\n\n\n\n\n\nお父さん「そう、これね、間違いではないんだけど、まだよくできる。表を作成するときには、情報が自然に入ってくるように、読者の立場で考えなくちゃ。具体的な注意点はこんなところかな」\n\n\n\n読者の立場で考える\n表のフォーマットに従う\n単位・表示桁数に気を配る\n表タイトル・脚注を利用して補足情報を伝える\n数え尽くしの原則を守る\n\n\n\nお父さん「ロジスティック回帰からいろんな指標が出せるけど、表にはオッズ比、95%信頼区間、p値だけあれば普通はじゅうぶんだよ」\n\n\n私「それはこの表にも載ってるよね」\n\n\nお父さん「載っていません。この表の”推定値”は、みたところ回帰係数の値でしょ。それを換算してオッズ比のスケールに直さないといけない。換算するには、回帰係数\\(\\beta\\)の指数をとって、\\(OR=\\exp(\\beta)\\)を求めればいい」\n\n\n私「そうなのか。ストーマのオッズ比は\\(\\exp(1.41)=4.1\\)ってことね。あれ？\\(\\exp(25.72)\\)を計算してみると、パソコンに表示できないくらいに大きい数字になったんだけど。ほとんど無限大に近い数字だ。性別の影響が強いのかな。年収は\\(\\exp(-0.00)\\)？なんか変だな」\n\n\nお父さん「これはよくあるトラブルだよ」\n\n\n私「そうなの？」\n\n\nお父さん「復職しなかった患者さんはほとんど女性だったんじゃない？擬似完全分離（quasi-complete separation）っていうデータの配置上の問題が起きちゃってて、性別の回帰係数を、うまく推定できていないんだ。この先は少し長くなりそうだから、ちょっとたばこ吸わせてもらうね」\n\n\n\n\n\n\n\n\n完全分離\n\n\n\nロジスティック回帰の回帰係数は、最尤法（maximum likelihood）という汎用的な推定方法によって計算されます。これはある種の方程式を解くことに対応していますが、データから必ずしも解が求まるわけではありません。これが完全分離（complete separation）や擬似完全分離（quasi-complete separation）という問題です。これらの問題が起きると、回帰係数が求まらなかったり、不安定だったりするため、共変量の数の削減や、最尤法以外の推定方法の利用など、なんらかの根本的な対処が必要になります。\n\n\n\n\nお父さん「（灰皿にたばこを押しつけながら）正しい計算ができていないわけだから、ロジスティック回帰の結果を示すのはやめた方がいい。性別だけじゃなくて年収も問題だね。単位が円のまま扱うと、桁が大きすぎて数字が読めない。単位を万円にして、年収が1万円増えたら復職率がどう変化するかを示すといいんじゃないかな。性別と年収の扱いは気になると思うけど、今はこれくらいにしよう。表の体裁を直してあげるよ」\n\n\n\n\n\n\nオッズ比\n95%信頼区間\np値\n\n\n\n\nストーマなし\n（基準）\n\n\n\n\nストーマあり\n4.13\n0.20～85.23\n0.36\n\n\n65歳未満\n（基準）\n\n\n\n\n65歳以上\n4.35\n0.24～78.60\n0.32\n\n\n女性\n（基準）\n\n\n\n\n男性\n∞\n∞～∞\n\n\n\n年収（万円）\n1.00\n0.98～1.01\n0.45\n\n\n\n*手術後1年以内の復職をアウトカムとした多変量ロジスティック回帰\n\n\n私「あれ？オッズ比4.13倍ってことは、復職率がだいたい4倍になったってこと？そんなことある？」\n\n\nお父さん「違う違う。あのね、オッズ比はオッズの比をとったもの。オッズっていうのは、復職率を\\(\\pi\\)で表すと、それを\\(\\pi/(1-\\pi)\\)と変換したものなんだ。\\(\\pi\\)が0に近いときは、オッズ比は\\(\\pi\\)の比に近い値になるんだけど、比の分子と分母の取り方で、向きが変わることに注意しないといけない。今回は、モデルの定義上、ストーマありの方が”復職できない”オッズが約4倍という意味だよ。ただし、2値アウトカムを”復職できない”に取ると、向きは逆になる」\n\n\n私「わかりにくいのう」\n\n\nお父さん「じゃあ、どこに気を付けて手直ししたか説明するね。ロジスティック回帰では、共変量はなにで、どう扱ったかを正確に伝えることが大切なんだ。データをみると、年齢は65歳未満か以上かで分類した2値データみたいだね。そういうときは、何歳で分類したか、どの分類を基準にしたかわからないと、結果を読み取れない。また、連続データでは、忘れがちだけど単位が必要。年収の単位を円から万円にして、表に追記しておいたよ」\n\n\n\n\n\n\n\n\n注意事項1. フォーマット\n\n\n\n論文で示される表には、決められたフォーマットがあります。表は、行（row）と列（column）から構成され、行と列は概念的には対称ですが、視覚的には役割が異なります。英語圏では、表は左から右に、行ごとに読むことが慣習になっています。そのため、このサイトに示されている表のように、縦線で区切ることはしません。\n数字の意味をわかりやすく伝えるためには、どこにどのような情報を配置するかに気を配るべきです。さきほどの表では、列が指標の種類を表すというシンプルな方針を採用しています。そのため、数字がオッズ比、95%信頼区間、p値に対応することが一目でわかります。また、必要な情報から順に読み取れるように、各行または各列の順序にも気を配りたいところです。\nある程度大きな表であれば、情報はグループにわけられることが普通です。表のフォーマットも、グループが視覚的にわかりやすいように工夫できます。たとえば後に出てくる表1では、行と列でそれぞれグループ化がなされています。行をグループ化するときには字下げ（indent）を用います。性別の内訳を示すために字下げがなされていますよね。また、列をグループ化するときにはスパナ（spanner）を用います。“ストーマ保有者”、“ストーマ非保有者”といった列の見出しを、スパナヘッド（spanner head）といいます。\n\n\n\n\n\n\n\n\n注意事項2. 単位・表示桁数\n\n\n\n表では測定単位（unit）を明らかにすることが重要です。臨床検査値を扱う論文を投稿するときは、その雑誌の編集方針をみて、どのような単位系を採用しているか確認しましょう。\n数字の表示桁数は、ある程度桁数やルールが統一されていなければ、印象を悪くします。統計ソフトウェアが出力する数字は桁数が大きいことがありますが、そのまま表に示す必要はありません。有効数字2桁または3桁か、もともとの測定値より桁数を1桁大きく示すのが基本です。\n日本工業規格（Z 9041-1:1999）によると、平均の有効数字は、測定値より1～2桁大きく、標準偏差の有効数字は、最大でも3桁程度といわれています。つまり、むやみに数字の表示桁数を増やしても精確性が増すわけではないのです。年齢を例に挙げると、測定単位は「歳」なので、小数点1桁まで示すとよいでしょう。表1の年齢の平均・標準偏差では、そのようになっています。p値については、小数点以下2桁か3桁まで報告すれば、有意水準（0.05が多い）との大小関係が読み取ることができるので、必要十分でしょう。\n\n\n\n\n私「表の作り方をご助言いただけるのはありがたいんだけどさ、肝心のロジスティック回帰はどうすればいいんだろ」\n\n\nお父さん「擬似完全分離を避けるには、共変量の数を削るのがわかりやすい。今回はサンプルサイズが不足しているみたいだから、他の共変量はすべて使わないで、単にストーマ造設と復職率だけの関連を調べたらどうかな？1パラメータあたり5〜10イベント程度は欲しいといわれるからね。その場合も、通常の\\(\\chi^2\\)検定は使わない方がいいよ。Fisherの正確検定とClopper-Pearson信頼区間っていう方法が推奨されている」\n\n\n\n\n\n\n\n\n2値データの解析においてサンプルサイズが不足したときの指針\n\n\n\n\nロジスティック回帰の共変量の数を減らす（目安としてパラメータの数のおよそ5倍のイベント数が必要）\n\\(\\chi^2\\)検定ではなくFisher正確検定を用いる\n2項分布に基づく信頼区間（Clopper-Pearson信頼区間）を用いる（田中2022）\n\n\n\n\n\n足りなかったたくさんの情報\n\n私「でも、ロジスティック回帰で交絡因子を調整しなさいっていったのはお父さんなんだよ」\n\n\nお父さん「そうだね、それは重要な問題だよね。じゃあ、ストーマ保有者と非保有者で、年齢、性別、年収の分布がどれくらい違うかをまず確認しようか。前にも話したとおり、年収を尋ねたことでバイアスが生じていないかとか、年収を尋ねて欠測が多いんじゃないかとか、いろいろ気になるし。もし分布が揃ってたら、調整しなくても影響は小さいかもしれない」\n\n\n私「あ、その表なら資料にあるよ」\n\n\nお父さん「じゃあ、あとはストーマ造設と復職率の関連を表にするだけだね。資料には、以下の表1と表2を載せればいいよ」\n\n\n表1. 20XX～20YY年にZZ病院で手術を受け、がんサバイバー復職率調査に回答した直腸がん患者80人の背景因子の記述\n\n\n\n\nストーマ保有者（N=20）\nストーマ非保有者（N=60）\n\n\n\n\n年齢（歳）\n57.0 (8.6)\n65.5 (10.4)\n\n\n65歳以上\n10.0%\n51.7%\n\n\n性別\n\n\n\n\n　男性\n35.0%\n53.3%\n\n\n　女性\n60.0%\n46.7%\n\n\n　不明\n5.0%\n0.0%\n\n\n年収（万円）\n508 (77)\n514 (101)\n\n\n\n*平均（SD）または%\n表2. 直腸がん患者のうちストーマ保有者20人と非保有者60人の復職率の比較\n\n\n\n\n\n\n\n\n\n\n\n\nN\n1年以内に復職せず\n復職率\n95%信頼区間*\np値†\n\n\n\n\nストーマあり\n20\n1\n95.0%\n75.1～99.9%\n\n\n\nストーマなし\n60\n2\n96.7%\n88.5～99.6%\n1.00\n\n\n\n*Clopper-Pearson法\n†Fisher正確検定\n\n\nお父さん「集団のアウトカムを比較したいときは、その前に表1のようにそれぞれの集団の背景因子を記述するべきだよ。ストーマ保有者は20人しかいなくて、非保有者に比べて、平均年齢が低くて、女性が多いわけだ。やっぱり最終的にはロジスティック回帰で、背景因子の違いを調整しないといけないかもね。現時点での調査の回答率はどうだった？」\n\n\n私「調査票は100人に送って、80人から回収できたから、回答率は80%かな」\n\n\nお父さん「項目ごとの無回答（item non-response）についてはどう？」\n\n\n私「そっか、調査票を回収できたかと、項目ごとの回答があったかは別だもんね。年齢は全員回答してくれたよ。性別は1人記入していなかった。項目ごとの回答数まで、表に示した方がよかった？」\n\n\nお父さん「ううん、論文ではそこまで細かい数字は示さないことが多い。重要な変数が欠測してたりするなら別だけどね。たとえばさ、ロジスティック回帰を行うとき、性別不明はどう扱ったの？」\n\n\n私「統計ソフトウェアのマニュアル調べたら、欠測は自動的に除外されるんだって」\n\n\nお父さん「そうすると解析対象の人数が80人じゃなくて79人に減るんだから、表を作るときにそこを説明しておかないといけないんじゃない？一般に、ロジスティック回帰の結果を示す表だけだと、どんなデータかわかりにくいっていう問題がある。復職できなかったのは3人しかいないって、表2をみるまで気づかなかったよ？まだ1施設からのデータしか集まってないからでしょ。それじゃあロジスティック回帰はしたくてもできないよね」\n\n\n私「確かにね。そのあたりの状況を、読者に伝えなきゃって気持ちが足りなかったみたい」\n\n\n\n\n\n\n\n\n注意事項3. 表タイトル・脚注\n\n\n\n読者が表を読むときのことを想像してみてください。最初に目にするのは、表に示された結果自体ではなく、表タイトルの情報です。簡潔な表タイトルをよく目にしますが、これはもったいないことです。表1、表2の表タイトルには、調査が行われた状況、対象疾患、人数、統計解析の目的などが含まれています。表タイトルを決めるときは、可能な限り多くの情報を伝えるように工夫しましょう。\n表には様々な数字が示されますから、どういった指標かわかりにくいときがしばしばあります。もしかしたら、複雑な統計手法から計算されたものかもしれません。データを解析するために用いた統計手法は、方法のセクションで説明することが基本ですが、読者への配慮として、表の脚注（footnote）を利用することもあります。表1でいえば、括弧内の数字の意味は自明ではないので、“平均（SD）または%”と脚注がついていますよね。表2の脚注には、どの統計手法を用いて信頼区間とp値を計算したかが説明されています。このように読者にとってなじみのない指標や表現には、補足説明が必要です。\n脚注を参照するための記号には、a、b、cまたは*、†、‡、§、¶を用いるのが正式です。\n\n\n\n\n\n\n\n\n注意事項4. 数え尽くしの原則\n\n\n\n統計解析の経験があるものなら誰でも、様々な理由で対象者が除外されるため、個々の解析で、人数が必ずしも同じにならないことを知っているものです。透明性を高めるために、統計解析ごとに、何人が対象となったか報告するべきです。\n統計家の間では、数え尽くしの原則（principle of exhaustion）という言葉があります。分類変数の分類が複雑だったり、欠測データがあったりするときには、分類ひとつひとつの人数を合計し、それが全体の人数に合うかどうかを確認せよ、というのがこの原則の教えです。最初に作成した表では人数が示されておらず、どのようなデータが解析されたのかわかりません。一方、表1・表2では、何人が解析対象で、何人が復職したのかが記述されています。さらに、数え尽くすと全体80人や100%に一致することから、正しく集計されたことが読み取れます。\n\n\n\n\n私「ちなみにお父さん、もし”臨床疑問と研究仮説”で例を挙げてくれたときの研究仮説3みたいに、研究の目的が復職率と関連する因子の探索だとしたら、何か変わることはある？」\n\n\nお父さん「どんな特徴を持った患者が、復職が難しいのか、予測因子をみつけたいってことかな。予測因子の候補となるデータがあるなら、それをロジスティック回帰の共変量に入れることで、予測因子の探索を行うことができるよね」\n\n\n私「うんうん」\n\n\nお父さん「こういった探索的検討では、特定の因子に関心がないってことが第一の違いだよ。ストーマと復職率の関連を調べるときは、ストーマのオッズ比やp値を求めることがゴールでしょ。予測因子の探索では、予測因子の候補をできるだけたくさん集めて、どの因子をモデルに入れたら予測精度が高いか、逆にどの因子は要らないかを調べることがゴールになる。これを変数選択っていうんだ」\n\n\n私「ゴールは違ってもさ、p値を使えばよくない？有意な因子をモデルに入れたらいいんでしょ」\n\n\nお父さん「そういうやり方もあるけどね。予測2乗誤差、ROC曲線、AICといった予測精度専用の指標を使うことも多い。大事なのはね。予測因子の候補や変数選択の基準を、研究計画書などに書いておくこと。事前に決めておかないと、どうしても研究者の主観が入っているんじゃないかって批判されるからね」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nロジスティック回帰の起源として正しいのは、次の時代のうちどれでしょうか。\n\n1900年以前\n1900～30年\n1931～60年\n1961年以降\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は1です\n\n少なくとも、ベルギーの数学者Queteletが1838年に出版した書籍に、ロジット関数の式が示されています。ロジスティックという単語は、同じくベルギーの数学者Verhulstが1845年にProceeding of Belgian Royal Academyで、初めて用いられたとされています。\n\n\n\n\n文献\n\n田中司朗. 医学研究のための因果推論I. 一般化線型モデル. 東京: 朝倉書店; 2022\n\n\n\nエピソード、用語集、Rスクリプト\n\nFrom Risk to Logistic Regression\nLogit: How a Transformation Shapes an Effect\nWhere My Logistic Regression Went Wrong\nWhy Logistic Regression Fails in Small Samples\nSimpson’s paradox\nStatistical Terms in Plain Language\nlogistic-regression.R"
  },
  {
    "objectID": "jp/logistic-regression-1.html",
    "href": "jp/logistic-regression-1.html",
    "title": "From Risk to Logistic Regression",
    "section": "",
    "text": "Adjusting for Bias I − From Risk to Logistic Regression\n\nKeywords: confounding/collapsibility, effect measure, generalized linear model, language/writing\n\n\n\nロジスティック回帰をしてみたんだけど\n\n\n\n\n\n\n前回までのあらすじ\n\n\n\n\n\nはじめて研究に取り組む娘と統計家の父。父に研究仮説は”PICO”を”PECO”で整理するといいとアドバイスされ、女医である娘は、がんサバイバーにおけるストーマ造設と復職状況の関係を調査することに決める。その後いくつか質問するうちに、父のことを「こいつ使える」と思い始めたのだった。\n\n\n\n\n\n私「これみてよ、お父さん」\n\n\nお父さん「ん？どうしたの、この資料」\n\n\n私「前に相談したがんサバイバーの復職状況を調べる研究についてなんだけどね、うちの診療科だけだけど調査票が集まったから、解析してみたの。その結果をまとめた資料よ」\n\n\nお父さん「ああ、あれね。ストーマ造設と復職率の関連を調べることにしたんだっけ。資料のどこをみればいいの？」\n\n\n私「この表なんだけど。ロジスティック回帰（logistic regression）をしてみたんだ。その結果をまとめたよ。どうかな」\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nパラメータ\n自由度\n推定値\n標準誤差\n95%信頼区間\n\\(\\chi^2\\)\np値\n\n\n\n\nIntercept\n1\n-27.25\n3.03\n-33.20～-21.30\n80.55\n&lt;0.01\n\n\nSTOMA\n1\n1.41\n1.54\n-16.1～4.45\n0.84\n0.3588\n\n\nAGE\n1\n1.47\n1.48\n-1.42～4.36\n0.99\n0.3197\n\n\nSEX\n1\n25.72\n0.00\n25.72～25.72\n\n\n\n\nINCOME\n1\n-0.00\n0.00\n-0.00～0.00\n0.58\n0.4481\n\n\n\n\n\nお父さん「ふむふむ。よくある回帰分析の結果だね。この表、上司にみせるんでしょ。その前にちょっと手直しした方がいいかもね」\n\n\n私「やっぱり？そんな気がしてみてもらおうと思ったんだ」\n\n\nお父さん「まず、Intercept、STOMA、AGE、SEX、INCOMEっていうのがわからないよ。Intercept以外は共変量（covariates）のことだよね」\n\n\n私「共変量って？」\n\n\nお父さん「共変量っていうのは、ロジスティック回帰に入れる説明変数のこと。復職率を規定する要因っていえばいいかな。それと、Interceptは回帰式でいう切片項のこと。統計ソフトウェアのアウトプットをそのまま表にしたんでしょ？きっとストーマ、年齢、性別、年収という変数を使ったんだと思うんだけど、データ上の変数名がそのままになっている。それに、出てきた数字をぜんぶ載せると、表がうるさくない？」\n\n\n私「めっちゃしゃべるな。そうね、実はRのglm()を使ったんだけど、そこもよくわからなかったんだよね。そこから聞こうかな」\n\n\nお父さん「どのあたり？」\n\n\n私「glm()の指定の仕方。引数っていうの？」\n\n\n\nglm(y ~ x1 + x2, family = binomial(), data = dat)\n\n\n\n私「以前、連続データは正規分布、2値データは2項分布ってイメージが大事みたいなこといってたでしょ？glm()もその延長だと思うんだけど、familyとかlinkとか謎で、ロジスティック回帰になってるか自信ない」\n\n\nお父さん「そこはね、単変量分布を一般化線型モデルに広げないと説明できないよ。つまりね、glm()はgeneralized linear modelの略なんだけど、ただの確率分布ってわけじゃなくて、3つのパーツから成り立っているんだ。ざっくりいうとこの3つだよ」\n\n\n確率分布（データの型はなにか）\n回帰係数×共変量\nリンク関数（平均をどう変換して共変量と結びつけるか）\n\n\n私「で、それがfamily、y ~ x1 + x2、linkなの？」\n\n\nお父さん「そう。glm()は、確率分布+回帰係数×共変量+リンクを指定してるだけなんだ」\n\n\n私「y ~ x1 + x2は私もわかるよ。調べたい変数をいれるんでしょ」\n\n\nお父さん「そうだね。Rの中では、この式がデザイン行列\\(X\\)に変換されてる」\n\n\n\nX &lt;- model.matrix(~ x1 + x2, data = dat)\n\n\n\nお父さん「ちょっとマニアックだけど、Rの内部では、model.matrix()っていう関数で、デザイン行列\\(X\\)を作っている。\\(X\\)の最初の列はすべて1になる。これは回帰直線でいう切片に対応している。次の列以降はx1とx2に対応する値が計算される。こうしておくと、たとえばx1が文字列でも数値に置き換えて計算できたり、回帰係数との掛け算が行列として計算できたり、なにかと都合がいい。ここまで覚えなくていいけど、仕組みを知っておくと理解が進むでしょ」\n\n\n私「なるほどね、じゃあfamilyってなに？データの型？」\n\n\nお父さん「そう。familyは日本語では分布族の意味だね。正確には指数型分布族（exponential family）。前にいったみたいに、データの型にあわせて確率分布を選ぶ」\n\n\n\n連続データ: gaussian()\n2値データ: binomial()\n計数データ: poisson()\n\n\nglm(y ~ x1 + x2, family = gaussian(), data = dat)\nglm(y ~ x1 + x2, family = binomial(), data = dat)\nglm(y ~ x1 + x2, family = poisson(), data = dat)\n\n\n\nお父さん「ただしね、一般化線型モデルではデフォルト仕様みたいなものがあって、familyを指定すると以下の3つが一度に決まるっていう特徴がある」\n\n\nyの確率分布\nyの分散\nその確率分布にあったリンク関数\n\n\n私「リンク関数ってなんだ？」\n\n\nお父さん「リンク関数（link function）は、平均をどう変換して回帰係数×共変量にあわせるかだよ。family = binomial()は、デフォルトでロジット関数（logit function）というリンク関数を使っている。ロジット関数が、2項分布の構造にあった”自然な”リンク関数なんだ。これがロジスティック回帰だよ」\n\n\n私「そっか、よかった。うん、けっこうわかったから今日はもういい」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nロジスティック回帰のリンク関数は、ロジット関数以外のものを代わりに使うことができます。リンク関数をうまく指定してリスク\\(\\pi\\)を変換することで、オッズ比以外の関連の指標を求められることが知られています。次の指標のうち、対応するリンク関数がなく、求められないものはどれでしょうか。\n\nリスク差\nリスク比\nハザード比\n1、2、3すべて求めることができる\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は4です\n\n一般化線型モデルはロジスティック回帰を一般化したもので、「リンク関数」を変えることで、さまざまな指標を計算できます（田中2022）。詳しくはのちのエピソードで述べますが、リンク関数は、ロジスティック回帰でいえば、リスク\\(\\pi\\)を関数\\(g(\\pi)\\)を用いて変換しています。\nリスク差を求めるには、\\(g(\\pi)=\\pi\\)つまり恒等関数を指定します。\nリスク比を求めるには、\\(g(\\pi)=\\log(\\pi)\\) つまり対数関数を指定します。\nハザード比を求めるには、\\(g(\\pi)=\\log\\{-\\log⁡(1-\\pi)\\}\\)つまり補二重対数（complementary log-log）関数を指定します。\n\n\n\n\n\n文献\n\n田中司朗. 医学研究のための因果推論I. 一般化線型モデル. 東京: 朝倉書店; 2022\n\n\n\nエピソード、用語集、Rスクリプト\n\nFrom Risk to Logistic Regression\nLogit: How a Transformation Shapes an Effect\nWhere My Logistic Regression Went Wrong\nWhy Logistic Regression Fails in Small Samples\nSimpson’s paradox\nStatistical Terms in Plain Language\nlogistic-regression.R"
  },
  {
    "objectID": "jp/glossary.html",
    "href": "jp/glossary.html",
    "title": "Statistical Terms in Plain Language",
    "section": "",
    "text": "Glossary − Statistical Terms in Plain Language\n\nKeywords: effect-measures, generalized linear model, p-value, scientific writing, study design. survival/competing-risk\n\n\n\n統計学のことば\n\n\n私「お父さん、いま診療科で輪読してる論文があるんだけど、言葉のニュアンスがつかめなくて。お父さんの話って、統計用語がいろいろ出てくるでしょ。正直いって実感がわかないのもあったんだ。よければ統計用語を日常用語で言い換えてみてくれないかな」\n\n\nお父さん「今日は時間があるからいいよ、いくつかやってみようか。五十音順に並べるね」\n\n\nαエラー　alpha error\n治療が本当は効かないのに有効と考えたり、関連がないのにあると判断してしまったりする類の誤り。偽陽性といってもよい。p値などを用いて5%以下に抑えることが、医学研究の慣習になっている\n一般化線型モデル　generalized linear model\n「回帰モデル」の一種で、回帰分析、分散分析、ロジスティック回帰などの統計手法の総称。統計ソフトウェアでは”GLM”という略称がよく用いられる\n打ち切り　censoring\n生存時間データを測定するとき、ある特定の時点で観察が妨げられ、その時点以降に関心のあるイベントが発生したであろうことしかわからなくなること\n回帰モデル　regression model\nある変数が他の変数とどのような関連にあるのかを調べるための統計手法。回帰分析と同義だが、「分析」は統計手法を指すニュアンスがあるのに対して、「モデル」というとなんらかの数式や確率分布を意味することが多い。\n片側p値　one-sided p-value\n相関には、正の相関と負の相関があるが、そのうちのどちらかにしか関心がないとき用いられるp値のこと。片側ではなく両側p値を用いることが一般的\n競合リスク　competing risk\nがんの原病死を追跡するときの事故死のように、それが起こると関心のあるイベントが観察されなくなる、競合するイベントのこと\n寄与割合　attributable fraction\nリスクや発生率の数値を変換して、特定の集団におけるリスク因子への曝露が、どのくらい疾患発症に寄与するかを割合で表したもの。いくつも定義がある\n効果サイズ　effect size\n治療の効果の大きさや、治療を比較したときの差のこと。サンプルサイズ設計では、効果サイズの値を設定しなければならないが、そもそもそれを知りたいから研究をするのだから悩ましい。このジレンマを皮肉って、「サンプルサイズから逆算して出した集積可能な差のこと」といった人もいる\n交絡　confounding\n集団を比較するとき気をつけるべきバイアス\nCox回帰　Cox regression\n1972年にCox教授が発明し、大流行した統計手法。回帰モデルの一種だが、一般化線型モデルではない。生存時間をアウトカムとして扱い、生存曲線の差をハザード比として要約したり、様々な因子が生存時間と関連があるかどうか検討するために利用される\nサンプルサイズ設計　sample size calculation\n対象者数などの研究の規模を決めること。たとえば、効果サイズ、αエラー、βエラー（または検出力）を設定することで、研究に必要な対象者数を計算できる\n情報バイアス　information bias\n情報を集めるとき気をつけるべきバイアス\n推定目標（エスティマンド）　estimand\n臨床試験で治療を始めた後に、有害事象が生じたり、治療を中止したりすると、その試験でどのような治療効果を調べたいのか曖昧になる。推定目標とは、その研究でなにを推定したいのかを意味する統計用語。臨床試験では、計画段階で推定目標を決めておくことが、ICH E9ガイドラインにより求められている\n生物統計家　biostatistician\n医学・生命科学における統計専門家のことだが、バイオインフォマティシャン、データサイエンティスト、疫学者とは、所属学会やコミュニティーが異なる。狭い意味では、臨床試験を専門とする統計プロフェッショナルのことを指し、そのための資格（試験統計家認定制度）もあるくらいだが、生物（bio）という接頭辞がついているためわかりにくい\n生存曲線　survival curve\n横軸に時間を、縦軸にその時点で生存している割合を図示したグラフのこと。がんや循環器疾患など多くの疾患領域で、研究結果が生存曲線として示されることが多い\n選択バイアス　selection bias\n研究の対象となる集団を選ぶとき気をつけるべきバイアス\n代替エンドポイント　surrogate endpoint\n治療が患者の予後に与える効果を調べるとき、臨床的に意味のある指標が得られないことがある。そのような状況で代わりに用いられるエンドポイントやアウトカムのこと。たとえばがん臨床試験では、奏効率が全生存期間の代替エンドポイントとして用いられてきたが、延命効果があるかどうかを必ずしも反映しないという批判も多い\nデザイン　design\n統計学では昔から実験計画のことを”design”と呼んできたが、それが転じて、研究立案やその際に決めるべき要素を意味するようになった。ランダム化臨床試験、調査、コホート研究などは、デザインの一種\nバイアス　bias\n一般的には偏った見方や行動を指す言葉だが、統計学では、推定値が真値（推定目標）からずれる傾向やその程度の意味で用いられる。データを集めた後にバイアスがあることがわかったとしても、対処は難しい\nハザード比　hazard ratio\nCox回帰から計算される指標で、生存曲線を比較するために用いられる\n比　ratio\nある量を別の量で割ることで求められる指標。割合と率は比の一種\n比例ハザード性　proportional hazards assumption\n死亡や増悪のようなイベントが生じるスピードが、群の間で定数倍になっていて、その関係が時間を通じて変わらないという仮定のこと\np値　p-value\n研究結果をみるとき、真っ先に見てしまいがちな数字。統計学的有意（statistical significance）、つまり誤差を越えた関連があるか見分けるときに用いられる\nFine-Grayモデル　Fine-Gray model\n1999年にFine教授が発明した、Cox回帰を拡張した統計手法。競合リスクを含む生存時間データがアウトカムのときの回帰モデルの一種\nβエラー　beta error\nサンプルサイズ設計の鍵になる数字。せっかく臨床試験を行ったのに、真に効く治療を有効性がないと判断してしまう確率のこと。データをたくさん集めることができ、βエラーが低いことを、「検出力が高い」という\nランダム化　randomization\n新規治療と標準治療のように、介入の効果を比べたいとき、どの介入を受けるかをランダム（無作為）に決める操作のこと。バイアスが生じないようにする工夫のひとつ\n率　rate\n一定時間に事象が生じるスピードを表す指標。疫学では、人年法（発生数/観察人年）で計算される。人数を人数×年で割っているため、単位は1/年（より一般には1/時間）\nリスク　risk\n疾患が生じる確率のこと。ただし、どの集団を対象に推定したかによって疾患リスクは当然異なるから、リスクの数字だけを使うのはやめたほうがよい\n両側p値　two-sided p-value\n相関には、正の相関と負の相関があるが、両方に関心があるとき用いられるp値のこと。片側ではなく両側p値を用いることが一般的\nロジスティック回帰　logistic regression\nある事象が生じる確率と、他の変数との関連を調べるための統計手法。2値データがアウトカムのときの回帰モデルの一種。回帰係数の指数（exponential）をとることでオッズ比を計算できる\n割合　proportion\n全体に対してそれが占める分量を表す指標。2値データや分類データを要約するために用いられる。人数を人数で割っているため、単位がキャンセルして単位を持たない（無単位）\n\n\n私「こうして一覧で見ると、論文ででてきた呪詛もちょっとは人間の言葉に見えてきたかも」\n\n\nお父さん「そうそう。用語がわかると、あとは臨床やデータ自体の話に集中できるからね」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n以下の4つの単語は、正式な統計用語ではありませんが、しばしば臨床試験の文献で目にするものです。このうち、誤りとはいえないものはどれでしょう。\n\nサンプル数\nCOX回帰\nOS曲線\nT検定\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です。\n\nサンプルサイズのことをサンプル数と表記している文献がありますが、サンプル数は臨床試験でいえば群の数に相当するので、用法として誤りです。Coxは人名なので、1文字目以外は大文字ではありません。OS曲線は、overall-survival curveの意味ととれなくはないので、誤りとはいえないでしょう。t検定のことをT検定と表記するケースも目にします。T検定は、t検定とは別の統計手法として存在するのですが、臨床試験では使われないため誤記でしょう。"
  },
  {
    "objectID": "jp/frequentist-5.html",
    "href": "jp/frequentist-5.html",
    "title": "Understanding Confidence Intervals via Hypothetical Replications in R",
    "section": "",
    "text": "Frequentist Experiments II − Understanding Confidence Intervals via Hypothetical Replications in R\n\nKeywords: probability model, simulation, study design, survival/competing-risk\n\n\n\nお父さん、その95%信頼区間って本当に95%なの？\n\n\n私「あのさ、もうひとつ聞きたいと思っていたことがあって。95%信頼区間（confidence interval）って、みんな当たり前のようにいうけど、ほんとに95%も当たってるの？」\n\n\nお父さん「ん？そりゃ当たってるよ。仮定した確率モデルが正しければね」\n\n\n私「ふーん。シミュレーションもできる？」\n\n\nお父さん「ああ、そういうこと。じゃあ続けてハザード比の95%信頼区間の被覆確率（coverage）を出してみようか。Rでね」\n\n\n私「coverage？つまり、本当に100回に95回当たるかどうか？」\n\n\nお父さん「そう。信頼区間が真値を当てる頻度を、シミュレーションデータで数えるんだ。頻度論の約束が、どの程度守られているかを確かめる仮想実験だよ。前提条件を整理しよう。2群比較の生存曲線を比べたいんだよね」\n\n\n私「ストーマあり群とストーマなし群ね」\n\n\nお父さん「そうだね、ストーマあり群とストーマなし群のOSを比べよう。真のハザード比は1.5、つまりストーマあり群の方が寿命が1.5倍短い。ハザード比の95%信頼区間は、1000回シミュレーションしたら、1.5を約950回は含んでいるはず」\n\n\n私「ん？私、調査は1回しかしないつもりだけど」\n\n\nお父さん「あのね、聞いて。統計家が話している確率モデルは、実際にこれから行われる研究そのものじゃないと思った方がいい。たとえるなら”こういう集団から、こういうルールでデータを発生させて”と別世界に指示を出す手紙なんだ。現実と別世界はデータとRとシミュレーションでつながっている。その手紙に書かれたルールに従って別世界の誰かが研究を1000回繰り返す」\n\n\n私「ふーん。そこで当たりがでた割合がcoverageね」\n\n\nお父さん「そう。以前JCOG9502の話をしたとき、“p値が0.05だったら100回に5回は正しい”っていってたよ。自分の経験だと違って見えるものだけど同じこと。それでね、生存曲線の形は指数分布で決める。途中で追跡できなかった患者は打ち切り扱いになるけど、それも指数分布で発生させる。この設定だと、Cox回帰の仮定はすべて正しい。だから理論的にcoverageは95%になるはず」\n\n\n私「じゃあ、その通りになるかどうか、Rで確かめればいいんだね」\n\n\n\n\n\n\n\n\ncoxph()を用いた95%信頼区間のシミュレーション\n\n\n\nハザード比を推定する方法はいくつかありますが、もっともポピュラーなのはsurvivalパッケージのcoxph()です。以前のデモで、generate_data(hr1, hr2)を用いて、ストーマの有無やOSのデータを生成しました。今回は同じデータにCox回帰を当てはめ、ストーマあり群とストーマなし群のハザード比を計算してみます。この関数では、死亡ハザード比の真値はhr2という引数で指定できます。\n\n\n\n\n\n\n\n\ngenerate_data()のコードはこちら（データ生成に使用）\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # 再発のハザード（大きいほど早く起こる）\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # 死亡のハザード（大きいほど早く起こる）\n  hazard_censoring &lt;- 0.05                               # 打ち切りハザード（群に依存しない）\n  \n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)   # 再発までの潜在時間\n  t_death     &lt;- rexp(n, rate = hazard_death)     # 死亡までの潜在時間\n  t_censoring &lt;- rexp(n, rate = hazard_censoring) # 打ち切りまでの潜在時間\n  \n  ## --- 全生存期間（OS） ----------------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = 死亡, 0 = 打ち切り\n  \n  ## --- 無再発存期間（RFS） -------------------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # 再発\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # 死亡\n  \n  ## --- 累積再発率（CIR） + 競合リスク --------------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # イベント1: 再発\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # イベント2: 競合リスクとしての死亡\n  \n  ## --- データフレームにまとめる --------------------------------\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n}\n\n\n\n\n\n\n\n\n\n\ncalculate_coverage()のコードはこちら（generate_data()とcoxph()を呼んでシミュレーションを実行）\n\n\n\n\n\n\ncalculate_coverage &lt;- function(model=c(\"coxph\",\"finegray\"), n, hr1, hr2, hr_true) {\n  set.seed(46)\n  replications=1000\n  covered &lt;- numeric(replications)\n\n  for (r in seq_len(replications)) {\n    dat &lt;- generate_data(n, hr1, hr2)\n    if (identical(model, \"coxph\")) {\n      fit &lt;- coxph(Surv(time_os, status_os) ~ stoma, data = dat)\n    } else if (identical(model, \"finegray\")) {\n      dat$fstatus_cir &lt;- factor(dat$status_cir,\n                                levels = 0:2,\n                                labels = c(\"censor\",\n                                           \"relapse\",\n                                           \"death\"))\n      fgdat &lt;- finegray(Surv(time_cir, fstatus_cir) ~ ., data=dat)\n      fit &lt;- coxph(Surv(fgstart, fgstop, fgstatus) ~ stoma, weight=fgwt, cluster=id, data=fgdat)\n    }\n    confidence_interval &lt;- confint(fit)\n    covered[r] &lt;- as.integer(confidence_interval[1] &lt;= log(hr_true) && log(hr_true) &lt;= confidence_interval[2])\n  }\n  coverage &lt;- mean(covered)\n  return(coverage)\n}\n\n\n\n\n\n\n\n\n\n\ncalculate_coverage()を実行するRコードと結果はこちら\n\n\n\n\n\n\n# install.packages(\"survival\") #インストールが必要なら実行\nlibrary(survival)\ncoverage_200 &lt;- calculate_coverage(model=\"coxph\", n=200, hr1=2, hr2=1.5, hr_true=1.5)\nprint(coverage_200)\n\n[1] 0.955\n\n\n\n\n\n\n\n私「だいたいcoverageが95%になるっていうのは確認した。でも結局、95%信頼区間ってどう理解すればいいの？」\n\n\nお父さん「教科書的にいうとね。同じようなデータを何度も集めて、毎回95%信頼区間を作ったとき、“真の値を含む区間”の割合が0.95になるように設計された指標なんだ。これを”in the long run”の性能って言ったりする。でも、概念的に理解するよりも、シミュレーションを行った方がわかりやすいと思って」\n\n\n私「いやわかりにくいだろ。1回の研究で”この区間が当たっている確率が95%“って意味じゃないんだね」\n\n\nお父さん「そうだね」\n\n\n私「じゃあ、人数が100人だったどうなるの？人数が減ったら当たりにくくはならないの？」\n\n\nお父さん「設計上は当たりにくくなったりはしないよ。95%信頼区間のcoverageはサンプルサイズによらず95%になるように作ってある。n=100、200、400、800のシミュレーション結果をみてみようか」\n\n\n\n\n\n\n\n\ncalculate_coverage()を実行するRコードと結果はこちら\n\n\n\n\n\n\ncoverage_100 &lt;- calculate_coverage(model=\"coxph\", n=100, hr1=2, hr2=1.5, hr_true=1.5)\ncoverage_400 &lt;- calculate_coverage(model=\"coxph\", n=400, hr1=2, hr2=1.5, hr_true=1.5)\ncoverage_800 &lt;- calculate_coverage(model=\"coxph\", n=800, hr1=2, hr2=1.5, hr_true=1.5)\nprint(coverage_100)\n\n[1] 0.956\n\nprint(coverage_200)\n\n[1] 0.955\n\nprint(coverage_400)\n\n[1] 0.968\n\nprint(coverage_800)\n\n[1] 0.953\n\n\n\n\n\n\n\n信頼区間アプローチによるサンプルサイズ設計\n\n\n私「ほんとだ、だいたい95%。じゃあ調査人数は何人でもいいってことだ」\n\n\nお父さん「ん？どういう意味？」\n\n\n私「がんサバイバー何人に調査票を送るかってこと。だって信頼区間の性能は人数によらないんでしょ」\n\n\nお父さん「あ、ごめん、誤解があったね。サンプルサイズが小さくなると、coverageは同じでも、信頼区間幅が広くなる。つまり、同じ95%でも、どれくらい曖昧な推定値で我慢しないといけないかが変わるんだ。今のところ、何人に調査するつもりだった？」\n\n\n私「100人から調査票戻ってきたら上出来かなって思ってるけど」\n\n\nお父さん「やっぱり必要サンプルサイズは計算してなかったか。がんを手術した後の復職率を推定したいってことでいいの？それなら100人でギリギリだと思う」\n\n\n私「いや？前にお父さんにPECOを教えてもらったよね。あれから上司と相談して、ストーマを造設した患者の復職状況を造設しなかった患者と比べることにしたの」\n\n\nお父さん「そうなんだ。そうすると計算が違ってくる。100人だと足りないはず」\n\n\n私「へ？なんでそんなことわかるのよ。100人に協力してもらうのってたいへんなのよ」\n\n\nお父さん「どれだけサンプルサイズが必要なのかについて、統計学的な根拠に基づいて見積もる方法があるんだよ。この表をみてみて。ある書籍から借りてきたものなんだけど（Machin, et al. 2022）」\n\n\n割合0.01～0.15割合0.16～0.50\n\n\n表1. 割合の推定において指定した 95%信頼区間幅のため必要なサンプルサイズ\n\n\n\n割合 \\(\\pi\\)\n0.05\n0.10\n0.15\n0.20\n\n\n\n\n0.01\n108\n43\n25\n17\n\n\n0.02\n152\n52\n29\n19\n\n\n0.03\n201\n61\n33\n21\n\n\n0.04\n252\n72\n37\n23\n\n\n0.05\n304\n83\n41\n25\n\n\n0.06\n356\n95\n46\n28\n\n\n0.07\n407\n107\n50\n30\n\n\n0.08\n458\n118\n55\n32\n\n\n0.09\n508\n130\n60\n35\n\n\n0.10\n554\n139\n62\n35\n\n\n0.11\n604\n153\n69\n40\n\n\n0.12\n651\n164\n74\n42\n\n\n0.13\n696\n175\n78\n44\n\n\n0.14\n741\n186\n83\n47\n\n\n0.15\n784\n196\n87\n49\n\n\n\n\n\n表1. 割合の推定において指定した 95%信頼区間幅のため必要なサンプルサイズ\n\n\n\n割合 \\(\\pi\\)\n0.05\n0.10\n0.15\n0.20\n\n\n\n\n0.16\n826\n206\n92\n51\n\n\n0.17\n867\n216\n96\n54\n\n\n0.18\n907\n226\n100\n56\n\n\n0.19\n945\n236\n104\n58\n\n\n0.20\n982\n245\n108\n60\n\n\n0.25\n1150\n286\n126\n70\n\n\n0.30\n1288\n320\n141\n78\n\n\n0.35\n1395\n347\n152\n84\n\n\n0.40\n1472\n366\n161\n89\n\n\n0.45\n1518\n377\n166\n92\n\n\n0.50\n1533\n381\n167\n93\n\n\n\n\n\n\n\nお父さん「たとえばなんだけどね。復職率を調べたいとするでしょ。そうすると復職率をどれくらい精確に推定できたかを表す指標が、95%信頼区間だよね。仮に復職率が50%だったとしてみよう。そうすると、50%±10%程度の推定精度がほしいよね。ここでいう±の後の数字が、95%信頼区間の幅になるんだ」\n\n\n私「ああ、”50%（95%CI 40～60%）”みたいな感じで論文に書くことになるわけだ。40〜60%の場合、95%信頼区間幅は20%ってことね」\n\n\nお父さん「そういうこと。表では復職率を\\(\\pi\\)という変数で表しているんだけど、”\\(\\pi=0.5\\)”と”信頼区間幅0.2”に対応する数字をみて。93って書いてあるでしょ。これが必要サンプルサイズ」\n\n\n私「どうだろう。復職率ってもっと高くない？手術したときの年齢にもよるけど、たとえば患者さんが50歳前後だったら、80%はいってほしいなあ」\n\n\nお父さん「そうなんだ。そうすると復職率80%は非復職率20%と同じことだから、”\\(\\pi=0.2\\)”と”信頼区間幅0.2”のところをみればいい。サンプルサイズは60人」\n\n\n私「100人で足りてるじゃん」\n\n\nお父さん「いやいやいや、これは復職率の信頼区間からサンプルサイズを計算したからこうなったんだ。“信頼区間アプローチ”といって、主に探索的研究で使うものなんだよ。別の計算の仕方もある。ストーマ造設ありとなしの復職率を比べるような仮説検証を目指した研究なら、“仮説検定アプローチ”といって、仮説検定の考え方にそってサンプルサイズを計算しないといけない」\n\n\n私「そっか、だいたいわかった。私、午後から出かけるから。また今度教えてよ、じゃあね」\n\n\n\n\n\n\n\n\nサンプルサイズ設計の2つのアプローチ\n\n\n\n研究計画を立てるときには、サンプルサイズを見積もる必要があります。サンプルサイズの計算は大まかにいえば2種類あって、信頼区間アプローチ（たとえば表1）と仮説検定アプローチ（次回）を用いることができます。\n信頼区間アプローチは、調査や探索的研究で用いられます。このアプローチによって割合を推定するために必要なサンプルサイズを求めるとき、次の数値を設定する必要があります。\n\n割合の真値（復職率など）\n信頼区間幅\n\nもうひとつの仮説検定アプローチは、臨床試験や仮説検証型の研究に適しています。このアプローチでは、以下の3つの要素が最低でも必要です。\n\n有意水準（通常5%）\n検出力（通常80～90%）\n検出したい効果サイズ（2群間の生存確率の差やハザード比など）\n\nサンプルサイズ設計は、βエラーを制御するという意味で、p値と対になる統計手法といえます。\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n臨床検査の正常範囲の意味として正しいのはどれでしょうか。\n\nある集団からのランダムサンプルにおいて検査値の平均±1.96×標準偏差\n健常人集団における検査値の95%が含まれる範囲\n健常人集団における検査値の平均±1.96×標準誤差\nある集団からのランダムサンプルにおいて検査値の95%が含まれる範囲\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は2です\n\n標準偏差（SD）と標準誤差（SE）の区別が重要です。前者は「検査値自体が個人間でどのくらいばらつくか」を、後者は「平均の推定がどのくらい精確か」を表しています。そして、「平均±1.96×標準偏差」は、正規分布における「95%が含まれる範囲」に相当しています。\nなお、似て非なる範囲に「平均±1.96×標準誤差」があります。これは「仮想的反復の下で真の平均を95%の割合で包む区間」、すなわち頻度論統計学でいう95%信頼区間に対応します。\n\n\n\n\n\n文献\n\nMachin D, Campbell MJ, Tan SB, Tan SH. 医学のためのサンプルサイズ設計（原著第4版）. 京都: 京都大学学術出版会; 2022\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\nGreen J, Benedetti J, Smith A, Crowley J. 米国SWOGに学ぶがん臨床試験の実践 第2版（原書第3版）. 東京: 医学書院; 2013\n\n\n\nエピソード、用語集、Rスクリプト\n\nReading a Paper over a Cup of Coffee\n[P-Value Explanations That Seem Plausible at First Glance]\n[Beyond 0.05: Interpreting P-Values in a Clinical Trial]\n[R Demonstration of Bias in Kaplan-Meier Under Competing Risks]\n[Understanding Confidence Intervals via Hypothetical Replications in R]\n[Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size]\nStatistical Terms in Plain Language\nfrequentist.R"
  },
  {
    "objectID": "jp/frequentist-3.html",
    "href": "jp/frequentist-3.html",
    "title": "Beyond 0.05: Interpreting P-Values in a Clinical Trial",
    "section": "",
    "text": "Frequentist Thinking III − Beyond 0.05: Interpreting P-Values in a Clinical Trial\n\nKeywords: clinical trial, hypothesis/outcome/population, p-value, language/writing\n\n\n\n正しくp値を解釈するための考え方\n\n\n私「ただいま、お父さん。そろそろダウン出さなきゃだめだね。あ、ホットコーヒーもらっていい？」\n\n\nお父さん「そろそろ帰る時間だと思って、たっぷり淹れてた。そうそう、JCOG9502の論文で生存曲線とp値の話をしたことがあったよね（Sasako, et al. 2006）。そのとき気になったんだけどさ。どうしてp値が0.05より小さいと統計学的に有意っていったの？」\n\n\n私「それがルールなんじゃないの？」\n\n\nお父さん「そこはね、論文の読み方を間違えてる。質問していい？論文に目を通すとき、最初にAbstract（抄録）を読むでしょ。次にどこを読む？」\n\n\n私「Results（結果）。だってどういう結果だったかはやく知りたいもん」\n\n\nお父さん「うんうん、その気持ちはすごくわかる。でも、p値を見るときに限っては、正しく解釈するために、事前にMethods（方法）を読んでおく必要がある。科学コミュニティのなかで、p値について誤解が多いことが問題視されていて、アメリカ統計協会（ASA）が、統計を専門としない研究者、実務家、サイエンスライター向けの声明を出したことがある。そのきっかけは、2014年2月のASAフォーラムにこんな投稿がなされたことだった」\n\n\n私「なんだこの禅問答」\n\n\nQ. Why do so many colleges and grad schools teach p ≤ 0.05?（なぜ多くの大学、大学院で「p ≤ 0.05」と教えているのか？）\nA. Because that’s what the scientific community and journal editors use（なぜなら科学コミュニティと雑誌編集者が依然として0.05を使っているからである）\nQ. Why do so many people still use p ≤ 0.05?（なぜ多くの人々が「p ≤ 0.05」を依然として使うのか？）\nA. Because that’s what they were taught in college or grad school（なぜなら彼らが大学、大学院でそう教わったからである）\n\n\n\n\n\n\n統計的有意性とp値に関するASA声明\n\n\n\nあらゆる科学論文でp値が用いられていますが、p値が誤用されたり、研究結果の解釈に悪い影響を与えたりする弊害が指摘されています。典型的なものを挙げると、研究で小さいp値が得られると、それだけで重要な知見が得られたとみなされたり、機械的にp値が0.05より小さいというだけで意思決定がなされたりするケースは、皆さんもよく目にするのではないでしょうか。\nASAは2016年に、定量的研究の実施とその解釈を改善するため、p値の適正な使用と解釈に関する6つの原則をまとめました（Wasserstein and Lazar 2016）。以下に引用します。\n\np値はデータと特定の統計モデル（訳注:仮説も統計モデルの要素の1つ）が矛盾する程度を示す指標の1つである\np値は、調べている仮説が正しい確率や、データが偶然のみで得られた確率を測るものではない\n科学的な結論や、ビジネス、政策における決定は、p値がある値（訳注:有意水準）を超えたかどうかにもとづくべきではない\n適正な推測のためには、すべてを報告する透明性が必要である\np値や統計的有意性は、効果の大きさや結果の重要性を意味しない\np値は、それだけでは統計モデルや仮説に関するエビデンスの、よい指標とはならない\n\n統計学の教科書では、p値と帰無仮説の関係を中心に説明しています。しかしp値を解釈するとき大切なのは、帰無仮説だけではありません。ASA声明の趣旨は、研究計画やデータの収集から結果の報告に至るまで、統計解析の背景にあるあらゆる情報を利用しなければ、p値は正しく解釈できないということです。\n原則4に注目してみましょう。ASA声明では、原則4の解説として「複数のデータ解析を実施して、そのうち特定のp値のみを報告することは、報告されたp値を根本的に解釈不能としてしまう」と述べています。かみ砕いて言うと、たくさんp値があると、そのなかで都合のいいp値を採用してしまいますよね。このような、いいとこどりの解析は、科学者の間で意識的にも無意識にも広く行われていて、偽陽性（false positive）の研究結果 ばかりが報告される一因ではないか、という問題意識を統計学者はもっています。この問題は、統計学で多重性（multiplicity）や選択的推論（selective inference）と呼ばれています。\n\n\n\n\n私「さっきのやり取りがきっかけで、p値の使い方について学会の議論があったってわけね。でもまあ抽象的でぴんとこないな」\n\n\nお父さん「そう？“科学的な結論は、有意水準を超えたかどうかにもとづくべきではない”なんてのは、かなり明確に書いてあると思うけど。JCOG9502論文でいえば、原則3や原則5は、p値だけ見るんじゃなくて、生存曲線をじっくり観察してから結論を出そうっていってるんだ。もちろん専門知識がないと、原則がなにを意図しているかはわかりにくい。原則4は、たとえば多重性の問題（multiplicity）に関係している」\n\n\n私「多重性？」\n\n\nお父さん「最近の臨床試験では、多重性っていう統計的な問題が潜んでいることが多い。JCOG9502論文を例にもう少し説明しようか。Statistical Analysis（統計解析）のところを読み返してみて。alpha error（αエラー）っていうのは、有意水準ともいうけど、どちらもp値と比べる水準のこと」\n\nAfter 8 years of slow accrual, the JCOG data and safety monitoring committee approved an amendment to the sample size and analysis plan. The amended sample size was 250, with one-sided alpha error of 0.1 and beta error of 0.2, with a 12-year accrual period (in total) and 8-year follow-up.（JCOG9502論文[Sasako, et al. 2016]の”Statistical Analysis”から抜粋）\n\n私「p値を0.1と比べるってこと？0.05じゃないの？」\n\n\nお父さん「登録が難航したため、苦肉の策でαエラーを0.1に緩めたみたい。本当は試験途中にαエラーは変えるべきではないんだけど、それでも重要な知見だから、こうして論文として多くの人に読まれているわけだよね」\n\n\n私「読み飛ばしてた。自由すぎるなJCOG」\n\n\nお父さん「あとさ、ASA声明の原則4とその解説を念頭に置いて、JCOG9502の図Aと図Bを見てみてよ。生存曲線が2本、p値が4つ示されているよね。この複数のp値は、どう読み解けばいいかわかる？」\n\n\n\n私「もともとそれが知りたくて、お父さんに質問したんだけど、わかってる？図Aのp値と図Bのp値については、私もちゃんと考えてたよ。図Aの方を見ればいいんでしょ。JCOG9502の主要エンドポイントはOSで、図Aが全生存曲線だもの。でも図Aだけでも片側と両側があるじゃない。ここが意味不明で、考えこんじゃった」\n\n\nお父さん「それはそんなに難しくない。臨床試験で、試験治療群と標準治療群の成績を比べるとするでしょ。試験治療群が勝ったときだけ、有意差があったって宣言するのが、片側p値。どちらの群が勝っていても、統計的に有意かどうか判定するのが、両側p値だよ」\n\n\n私「論文を読むと、JCOG9502のプロトコール上、LTAが試験治療、THが標準治療とされてたんだよな。LTAの方が、侵襲性が高いからかな。だからLTA群の予後がいいっていう結果でないと、有意差ありって宣言しないわけだ。これって普通？」\n\n\nお父さん「いや？両側p値を使うのが普通。でもJCOGが行っている臨床試験では、試験治療群の成績が、標準治療群よりいいかどうかに興味があり、しかも毒性や侵襲の異なる治療同士を比べることが多いので、片側仮説の方が自然なんだ。そのためこのグループでは、片側p値の採用を許容している（Japan Clinical Oncology Group 2025）。片側p値で有意じゃなかったら、標準治療を使い続けるから、それでいいんだって。この論文の両側p値は参考値みたいだね。つまり、有効性の主たる判断には、図Aの片側p値だけが用いられることになる」\n\n\n私「ストーマ造設あり・なしと復職状況を調べる私の調査だったら、仮説の意味から考えても両側p値がおすすめってことね。よくわかりました」\n\n\n\n\n\n\n\n\n片側p値と両側p値\n\n\n\np値と仮説検定（hypothesis test）は、研究仮説が正しいかどうかについて、二者択一の判断をするための統計手法です。なんだか難しそうなので、例え話で説明しましょう。\nコイン投げをして、6回連続で表が出たとします。このコインは、イカサマコイン（表が出る確率が1/2でない）でしょうか？p値では以下のように考えます。表が出る確率は1/2という仮説の下で、6回連続で表の確率は(1/2)の6乗で0.0156ですよね。6回連続で裏の確率は同じく0.0156です。すなわち、このような極端なデータが得られる確率は、足してp=0.0312と極めて低いことがわかります。このような極端なデータが得られるのはおかしくはありませんか？従って、このコインにはイカサマがある、というのが、p値を用いて仮説（表が出る確率は1/2）を否定するときのロジックです。\n片側（one-sided）p値と両側（two-sided）p値は、コインの片側（表だけ）をみるか、両側（表と裏）をみるかに、それぞれ対応しています。コイン投げの例え話でいえば、片側p値はp=0.0156、両側p値はp=0.0312です。\n\nJCOG9502に戻って考えてみましょう。仮説検定では3段階の手続きを行います。まず、仮説を設定します。JCOG9502では、真実は「LTA群はTH群に比べ全生存期間を延長する効果がある」と「効果がない」の2通りがあり得ます。仮説検定では、「効果がない」という仮説に注目して、帰無仮説（null hypothesis）と呼びます（こちらが、表が出る確率が1/2に対応します）。\n次に、帰無仮説の下でデータがどのように分布するかを調べます。仮に、同じ対象者167人の試験を1000回繰り返したと想像してみてください。これが頻度論の思考様式です。仮に効果がなかったとしても、ランダム誤差のため、LTA群の生存曲線の方がよい場合もあれば、TH群の方がよい場合もあるでしょう。しかし1000回繰り返した結果は、差がないという結果を中心に分布するはずです。そこで、この1000回の分布と、実際に観察されたデータとを比べp値を計算します。\np値とは、帰無仮説が正しい、つまり生存曲線に差がない、という仮定の下で、実際に観察された2本の生存曲線の差よりも、極端な差が観察される確率のことです。もしp値が小さければ、こんなに確率の低いことが起きるわけがない、だから生存曲線に差がないというそもそもの前提条件が間違いだ、という判断になるわけです。逆に、p値が大きければ、当たり前のことが起きたという意味になります。\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n非劣性試験や同等性試験を除くほとんどのランダム化臨床試験で、両側p値が用いられている理由として正しいものは、次のうちどれでしょうか。\n\n試験治療が優れていたとしても、劣っていたとしても、差があるなら結論を出したいから\n統計学者の間の決まりごと\n世界中の臨床試験で統一した方が、混乱が少ないから\nランダム誤差は、平均の上方向と下方向の両方のばらつきを生じるから\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です\n\nこれは歴史的経緯によるものです。1998年にICH E9ガイドラインが策定されたとき、米国、欧州、日本の規制当局で、両側p値を基本にすることが合意されました（吉村2003）。\n\n\n\n\n\n文献\n\nJCOGプロトコールマニュアル version 3.8 [Internet]. 東京: Japan Clinical Oncology Group; 2025\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\nWasserstein R and Lazar NI. The ASA’s statement on p-values: Context, process, and purpose. Am Statistician 2016; 70: 129-33\n吉村功. 検証的臨床試験における有意水準と試験の数－「臨床試験のための統計的原則」との関連で－. 計量生物学 2003; 24: S3-9\n\n\n\nエピソード、用語集、Rスクリプト\n\nReading a Paper over a Cup of Coffee\n[P-Value Explanations That Seem Plausible at First Glance]\n[Beyond 0.05: Interpreting P-Values in a Clinical Trial]\n[R Demonstration of Bias in Kaplan-Meier Under Competing Risks]\n[Understanding Confidence Intervals via Hypothetical Replications in R]\n[Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size]\nStatistical Terms in Plain Language\nfrequentist.R"
  },
  {
    "objectID": "jp/frequentist-1.html",
    "href": "jp/frequentist-1.html",
    "title": "Reading a Paper over a Cup of Coffee",
    "section": "",
    "text": "Frequentist Thinking I − Reading a Paper over a Cup of Coffee\n\nclinical trial, p-value, survival/competing-risk, language/writing\n\n\n\n生存曲線まわりの数値を読み解く\n\n\n\n\n\n\n前回までのあらすじ\n\n\n\n\n\nはじめて研究に取り組む娘と統計家の父。父に研究仮説は”PICO”を”PECO”で整理するといいとアドバイスされ、医師である娘は、がんサバイバーにおけるストーマ造設と復職状況の関係を調査することに決める。おなじ復職状況でも、2値データと生存時間データの2通り解析の仕方があると教えられた娘。上司に読むことを勧められた論文で、OS・DFSという用語が出てきたことを思い出すのだった。\n\n\n\n\n\n父「ん？寒くなってきたのに、遅くまでなに読んでるの？コーヒーでも淹れようか」\n\n\n私「あ、お父さん、ありがと。ミルクもお願い。いまね、胃がん手術の論文読んでるんだ。そうだ、前に全生存期間（OS）と無病生存期間（DFS）の違いについて教えてくれたでしょ」\n\n\nお父さん「そんなこともあったね」\n\n\n私「お父さんも臨床論文読んだりする？仕事で」\n\n\nお父さん「臨床試験の統計家やってるから、たまにね。どっちかっていうと、論文を書くことの方が多いけど。臨床の最新知識はそこまで仕事でいらないし」\n\n\n私「よかった。この論文、細かいところがよくわかんないんだ。特に統計っぽい言葉の意味がね。ちょっとこの図を見てよ。JCOG9502っていう胃がん手術の術式を比べた臨床試験の論文なの（Sasako, et al. 2006）。TH群は開腹創から下縦隔へアプローチする標準的な手術を受けた患者、LTA群は左開胸開腹連続切開によって下縦隔郭清も行った患者のことね」\n\n\n\nお父さん「この図は、いわゆるKaplan-Meier曲線だよ。図AがOS、図BがDFSだね。どちらの図でも、TH群（青の曲線）よりLTA群（赤の曲線）の方が下にある。つまりTH群の方が、治療成績がいい」\n\n\n私「そこまではわかるの。知りたいのは細かいところなんだってば。最初につまずいたのが、生存曲線の下に書いてあるアットリスク数 （number at risk）でね。これって時点ごとの人数のことでしょ。図Aと図Bの手術時点の人数を見てよ。図Aは82人と85人、図Bは76人と75人で、左右で解析された人数が違うの。理由はわかる？」\n\n\nお父さん「これは結構難しいな。臨床試験で解析対象から除外されるって、プロトコール逸脱とかよっぽどのことだと思うけど。コーヒーおかわりくれる？ふむ。DFSの解析を行うには再発したかどうかを評価しないといけないよね。そのあたり、なにか理由はありそう？」\n\n\n私「そっか、腫瘍組織が完全に切除できなかったら、再発とみなしていないのかもしれない。えーっと、論文を読むと、確かにR0切除ができたのは151人って書いてある。そのせいだな多分。それとね、7年目あたりから人数が数人しかいなくなってるの。これってどう思う？」\n\n\nお父さん「この試験って登録何年で、追跡何年なの？それによるでしょ」\n\n\n私「登録期間は1995年から2003年だから、8年。生存時間データは2006年までのものを解析したって書いてあるな。そうすると追跡期間は最短で3年かな」\n\n\nお父さん「そうすると、必ずしも術後3年以上追跡されるわけじゃないよね。以前、打ち切りについて話したことがあったよね。生存時間データは、イベントと打ち切りから構成される。3年以内に打ち切りが多いのは不自然だけど、3年以降に追跡が打ち切られるのは計画通りのことだよ」\n\n\n私「打ち切りがいつ起きたかなんて、論文を読んでも書いてないよね？」\n\n\nお父さん「そんなことはない。生存曲線にひげが立ってるでしょ」\n\n\n私「このぴょこぴょこしたやつ？」\n\n\nお父さん「そうそう。それが打ち切りのシンボル。時間原点の直後にひげがたくさん立ってたら、なにが起きてると思う？研究を始めたらすぐ、患者さんが追跡できなくなって、打ち切りになったってこと。そんな変な研究にはバイアスがあるかもしれないよね」\n\n\n私「図では、3年以内のひげは数えるほどしかない。じゃあほとんどの患者は3年以上追跡できたんだ。いい研究なんだね。今までの話をまとめると、こういうことか」\n\n\nアットリスク数は時点ごとの人数を表す\nひげは打ち切りを表す\n図に示されない情報だが登録期間・追跡期間も要確認\n\n\n私「よく考えたら10年以上かかったんだ、この図を描くのに。スタッフは大変だっただろうな。そういえばさ、臨床試験の研究計画書の話がでたでしょ、この前。計画書って参加施設の倫理委員会に出すじゃない。そうしたら基本的に変更しないよね、手続きもいるし」\n\n\nお父さん「そうだね」\n\n\n私「10年後の先を見越して、しかも誰が読むかもわからないのに、計画を文章にするって怖いよね。100人以上の患者さんも関わってくるし。そりゃあ、アウトカムひとつとっても言葉の意味を固めときたくもなるわ。あ、あとさ、生存曲線まわりの英語についてなんだけど、”hazard ratio”、”95% CI”、”one-sided p”、”two-sided p”は日本語でなんていうか教えてよ」\n\n\nお父さん「ハザード比、95%信頼区間、片側p値、両側p値かな。このあたりの指標は、生存時間解析の定番だよ。ハザード比とかp値は、Cox回帰で計算するんだけど、本格的な話は、また今度ゆっくりやろうか」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n予後がどのくらいかを説明するために、がん患者の余命を用いることがあります。胃がん手術後の余命をJCOG9502の図から読み取ることができるでしょうか。\n\n図A（OSのKaplan-Meier曲線）から読み取ることができる\n図B（DFSのKaplan-Meier曲線）から読み取ることができる\n図AとBどちらからも読み取ることができない\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は1です\n\n胃がん手術後の余命を表す指標として、生存期間の平均値または中央値がありますが、図から読み取りやすいのは生存期間中央値です。\n生存期間は、日数や年数のような数値データですから、連続データに近い特徴を持っています。連続データでは、中央値（median）は上位50%に相当する値のことですよね。半数以上の対象者がイベントを起こして、生存期間が確定すれば、たとえ打ち切りがあっても、生存期間中央値を求めることができます。\n具体的には、生存期間中央値は、50%が生存している時点、すなわち図AのSurvivalが50%になる時点に対応しています。つまりKaplan-Meier曲線が50%まで下がった時点を読み取ればよいのです。\n\n\n\n\n\n文献\n\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\n\n\n\nエピソード、用語集、Rスクリプト\n\nReading a Paper over a Cup of Coffee\n[P-Value Explanations That Seem Plausible at First Glance]\n[Beyond 0.05: Interpreting P-Values in a Clinical Trial]\n[R Demonstration of Bias in Kaplan-Meier Under Competing Risks]\n[Understanding Confidence Intervals via Hypothetical Replications in R]\n[Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size]\nStatistical Terms in Plain Language\nfrequentist.R"
  },
  {
    "objectID": "jp/effects-5.html",
    "href": "jp/effects-5.html",
    "title": "From Risk and Rate to Survival and Hazard",
    "section": "",
    "text": "Effects and Time V − From Risk and Rate to Survival and Hazard\n\nKeywords: effect measure, survival/competing-risk\n\n\n\nリスクと時間の関係\n\n\n私「お父さんさ、以前聞いた寄与割合の話を思い返して気づいたんだけどね。まだ納得感が足りないの」\n\n\nお父さん「なに？コーヒーと一緒にこういう話をするのは歓迎だよ」\n\n\n私「がん検診後、10年、12年、20年って見ていくと、寄与割合が変わるって話だったでしょ。リスクには時間の概念があるって。あれって、2値データじゃなくて生存時間データになってない？ていうか、あれは生存曲線か」\n\n\nお父さん「そうだよ。リスクと生存曲線は表裏一体なんだ」\n\n\n私「生存曲線からある時点の生存確率を読み取ると、1-リスクになっているっていう意味ね。うんうん。そして、疫学の教科書に出てくる率（rate）が、生存時間解析のハザード（hazard）に対応しているっていうのもわかる。でも、気になるのはハザード比（hazard ratio）なんだ。寄与割合とかリスク比とかって、時間とともに変化するっていうけど、ハザード比は変化しないんだっけ」\n\n\nお父さん「変化しない。正確にいうと、生存曲線をみると変化している状況もあり得るんだけど、無理やり時間を通じてハザード比は一定と仮定して、計算してる」\n\n\n私「リスク比は変化するけどハザード比は変化しないの？矛盾してない？」\n\n\nお父さん「えーっと、リスク比が変化しないわけじゃなくて…。ちょっと紙ナプキンとペンをとってくれる？教科書通りに説明するとこうなるんだけど。まずはリスクとハザードからはじめるね」\n\n\n\n\n\n\n\n\n生存曲線とハザードの関係\n\n\n\nこれまでのエピソードでは、ある時点までのリスクを扱ってきましたが、今度は“時間に沿って変化するリスク”を推定したKaplan-Meier曲線について正式に説明します。Kaplan-Meier曲線は、そもそも2値データではなく生存時間データに用いられる手法でした。そのため、Kaplan-Meier曲線は時間軸を横にとったグラフですし、いわゆるハザード比との関係も知りたいところですよね。ここでは、ハザードが時間を通じて一定という単純な状況で、そのあたりを整理しましょう。\nKaplan-Meier曲線は、生存時間データから計算された推定値を、時間軸（\\(x\\)軸）に沿ってグラフにしたものです。これを数式で書くなら、「生存曲線を時間\\(x\\)の関数\\(S(x)\\)で表す」ということになります。\n関数\\(S(x)\\)を具体的に書くこともできます。生存時間が、ハザードが時間を通じて一定ということは、指数分布に従うと仮定したことになります（これはKaplan-Meier曲線とは別ものです）。指数分布の形状を決めるパラメータ（ハザード）は、\\(λ\\)という記号で表すことが普通です。このとき指数分布の生存関数とハザードには、以下のような関係があります。\n\\(S(x)=\\mathrm{exp}(-\\lambda x)\\)\nここまでくれば簡単なのですが、最後に、疾患リスクとハザードの関係を確認しましょう。疾患リスク\\(π\\)は、特定時点\\(x\\)までに疾患を発症する確率を表しています。つまり、疾患リスク\\(π\\)とハザード\\(λ\\)は、時点\\(x\\)の生存関数を\\(S(x)\\)を介して、以下の式で結びついています。\n\\(\\pi=1-S(x)=1-\\mathrm{exp}(-\\lambda x)\\)\n\n\n\n\n\n\n\n\ngenerate_data()のコードはこちら（データ生成に使用）\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # 再発のハザード（大きいほど早く起こる）\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # 死亡のハザード（大きいほど早く起こる）\n  hazard_censoring &lt;- 0.05                               # 打ち切りハザード（群に依存しない）\n  \n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)   # 再発までの潜在時間\n  t_death     &lt;- rexp(n, rate = hazard_death)     # 死亡までの潜在時間\n  t_censoring &lt;- rexp(n, rate = hazard_censoring) # 打ち切りまでの潜在時間\n  \n  ## --- 全生存期間（OS） ----------------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = 死亡, 0 = 打ち切り\n  \n  ## --- 無再発存期間（RFS） -------------------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # 再発\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # 死亡\n  \n  ## --- 累積再発率（CIR） + 競合リスク --------------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # イベント1: 再発\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # イベント2: 競合リスクとしての死亡\n  \n  ## --- データフレームにまとめる --------------------------------\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n}\n\n\n\n\n\n\n\n\n\n\ncifplot()によるKaplan-Meier曲線\n\n\n\nイメージしやすいように、以前cifplot()で描いたKaplan–Meier曲線とcoxph()の結果を置いておきます。\n\n\n\n\n\n\n\n\ncifplot()のRコードと結果はこちら\n\n\n\n\n\n\n# devtools::install_github(\"gestimation/cifmodeling\") #インストールが必要なら実行 \nlibrary(cifmodeling)\nset.seed(46)\ndat &lt;- generate_data(hr1=2, hr2=1.5) #再発ハザード比2, 死亡ハザード比1.5のデータ生成\ncifplot(Event(time_os, status_os) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncoxph()のRコードと結果はこちら\n\n\n\n\n\n\n# install.packages(\"survival\") #インストールが必要なら実行\nlibrary(survival)\nfit &lt;- coxph(Surv(time_os, status_os) ~ stoma, data = dat)\nsummary(fit)\n\nCall:\ncoxph(formula = Surv(time_os, status_os) ~ stoma, data = dat)\n\n  n= 200, number of events= 144 \n\n                  coef exp(coef) se(coef)     z Pr(&gt;|z|)  \nstomaWITH STOMA 0.3199    1.3769   0.1693 1.889   0.0589 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\nstomaWITH STOMA     1.377     0.7262    0.9881     1.919\n\nConcordance= 0.544  (se = 0.024 )\nLikelihood ratio test= 3.51  on 1 df,   p=0.06\nWald test            = 3.57  on 1 df,   p=0.06\nScore (logrank) test = 3.6  on 1 df,   p=0.06\n\n\n\n\n\n\n\n私「わからん。数式はわからん」\n\n\nお父さん「そう？数学の難しさ自体は高校レベルなんだけど。きっと理解しにくいのは、数式がデータ上のどういう概念を結びつけているのかっていう部分なんだと思うんだけど。ハザードを具体的に考えるときは、生存時間中央値と結びつけるのが手だよ」\n\n\n\n\n\n\n\n\nハザードと生存時間中央値の関係\n\n\n\nさて、ハザードは生存曲線が下がるスピードを決める数値です。生存時間がどのくらいの長さなのかは、中央値で測ることができます。生存時間中央値\\(M\\)は、生存確率50%つまり\\(S(x)=0.5\\)になるような時間\\(x\\)のことです。つまり、指数分布では\n\\(0.5=\\mathrm{exp}(-\\lambda M)\\)\nと関係が成り立つので、生存時間中央値\\(M\\)は、ハザード\\(λ\\)から以下のように計算することができます。\n\\(M = \\frac{\\log 2}{\\lambda} \\approx \\frac{0.7}{\\lambda}\\)\n\n\n\n\n私「あ、これはちょっとわかった気がする。寿命（生存時間中央値）とハザードが逆数の関係ってことね。つまり寿命が2倍になったらハザードは1/2になる」\n\n\nお父さん「そうだね、たとえるならハザードはコーヒーにとっての気温みたいなもの。寒いとコーヒーが覚める時間が短くなる。これがハザードが高いってこと。正確に逆数になるのは、指数分布の下で計算するときだけどね。ハザード比は、まさにハザードの比をとったものだよ。2つの集団の生存曲線を比較するときに使う」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n生存時間中央値を報告してよいのは、どのような場合でしょうか？\n\n目安としてサンプルサイズが100人以上のとき\nすべての対象者が予定された追跡期間を終了したとき\n半数以上の対象者がイベントを起こしたとき\n1、2、3すべて誤り\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です\n\n生存時間データでは一部の対象者で打ち切りがあること（これ以上生存時間が長いことしかわからない）、中央値（median）の定義を思い出してください。半数以上の対象者がイベントを起こし、生存時間が確定しないと、生存確率は50%以下になりません。\n\n\n\n\n\nエピソード、用語集、Rスクリプト\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nUnderstanding Collapsibility of Effect Measures in Marginal and Stratified Analyses with R\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nDistinguishing Time-Point, Time-Constant, and Time-Varying Effects: An R Example\nStatistical Terms in Plain Language\nfrequentist.R"
  },
  {
    "objectID": "jp/effects-3.html",
    "href": "jp/effects-3.html",
    "title": "Understanding Collapsibility of Effect Measures in Marginal and Stratified Analyses with R",
    "section": "",
    "text": "Effects and time III − Understanding Collapsibility of Effect Measures in Marginal and Stratified Analyses with R\n\nKeywords: bias, confounding/collapsibility, effect measure, generalized linear model, simulation\n\n\n\nリスク差、リスク比、オッズ比、どれを使う？\n\n\n私「お父さん、なにか甘いものない？お腹すいちゃって」\n\n\nお父さん「大福だったら買い置きがあるよ。コーヒーとお茶、どっちにする？」\n\n\n私「コーヒー。ミルクも入れて。お茶もいいけど、統計の話を聞きたいときはコーヒーの気分なんだ。このあいだも、疫学で使う統計の話をしてくれたでしょ。でも、医学部で講義を受けたのが昔すぎてさ。疫学ってなにか忘れちゃったな」\n\n\nお父さん「疫学か。疫学は、集団における病気について調べる分野だよね。病気の原因を調べたり、予防方法や公衆衛生対策を立てたりする。がん、循環器、感染症など扱う病気によってだいぶ違うよね。まあ、疫学の基本はなにかっていったら、コホート研究とリスクかな」\n\n\n私「そうだったね、最初の話題はワクチン有効率だったけど、あれも発症リスクの指標だった。後はリスク比、オッズ比、ハザード比だっけ？」\n\n\nお父さん「そんな話をしたね。じゃあ、リスク比とオッズ比の話をしようか。コーヒー飲みながら気楽に聞いてね。統計学が気にするのは、それぞれの指標の意味・解釈の違いもあるけど、それ以上に数学的な性質を考えているんだよね。オッズ比は数学的にいい面と悪い面がある。いいところは、”リスクの数値”と”1からリスクを引いた数値”が対称に出てくるような数式をしていること。生存確率と死亡確率をひっくり返しても同じっていったらいいかな」\n\n\n私「ふーんそうなんだ」\n\n\nお父さん「後は、ケース・コントロール研究のような、コホートの一部の情報しかない状況でも計算できるし、ロジスティック回帰のようなモデリングするとき利用しやすいのがいいところかな。悪い面はね、層別解析をしたとき、ちょっと不自然な計算結果になる」\n\n\n私「ケース・コントロール研究って、データベースとかを使って後ろ向きに調査するやつね。これも疫学。そうねえ、不自然な数字になるのは困るんじゃない？層別なんてしたこと私はないけど」\n\n\nお父さん「そうだね、次の2つの表は層別する前とする後の結果なんだけど、比べてみてよ」\n\n\n\n\n\n\n\n\n層別した指標の併合可能性\n\n\n\n表1と表2は、がん患者100人のランダム化臨床試験を想定して作った数値例です。表1では100人全体における死亡リスクを、表2はステージIIIの50人とステージIVの50人に層別した死亡リスクを示しています。\nまず、抗がん剤投与群の死亡リスクをみてください。ステージIIIでは死亡リスクは20%と低く、ステージIVでは40%と高いことがわかります。そして全体の死亡リスクは、ステージIIIとステージIVの平均（30%）です。このように、リスクには、層別する前の値が、層別した後の平均になるという性質があります。\nこれを踏まえて、リスク比、リスク差、オッズ比の性質を考えてみましょう。表1と表2を比べると、リスク比はすべて0.50倍です。このように、層別する前後でリスク比が変化しないことは、治療効果を測るために好ましい性質です。なぜなら、ステージIIIでリスクが半分になり、ステージIVでも半分になるなら、2つの層を合計してもリスクが半分になってほしいからです。リスク差は、2つのリスクの差をとったものです。したがって、リスクと同じように層別する前の値が、層別した後の平均になります。層ごとのリスク差が等しければ（この数値例ではそうなっていませんが）、層別前のリスク差も、層別後のリスク差と同じ値になるはずです。リスク差とリスク比の持つこの性質を、併合可能性（collapsiblity）と呼んでいます。\n一方で、オッズ比は層の併合可能性を持たないことが知られています。表1と表2において、オッズ比は0.29倍、0.38倍、0.17倍と変化していますよね。リスク比は一定であるにも関わらず、同じ比の指標がばらつくのは、好ましい性質ではありません。\n\n\n\nステージによる層別前ステージによる層別後\n\n\n表1. 仮想的ながんランダム化臨床試験におけるリスク差・リスク比・オッズ比\n\n\n\n\n緩和療法群\n抗がん剤投与群\n効果の指標\n\n\n\n\n合計（100人）\n\n\n\n\n\n　死亡\n30\n15\n\n\n\n　生存\n20\n35\n\n\n\n　死亡リスク\n60%\n30%\n\n\n\n　リスク差\n\n\n-30%\n\n\n　リスク比\n\n\n0.50倍\n\n\n　オッズ比\n\n\n0.29倍\n\n\n\n\n\n表2. 層別後の死亡リスクとリスク差・リスク比・オッズ比\n\n\n\n\n緩和療法群\n抗がん剤投与群\n効果の指標\n\n\n\n\nステージIII（50人）\n\n\n\n\n\n　死亡\n10\n5\n\n\n\n　生存\n15\n20\n\n\n\n　死亡リスク\n40%\n20%\n\n\n\n　リスク差\n\n\n-20%\n\n\n　リスク比\n\n\n0.50倍\n\n\n　オッズ比\n\n\n0.38倍\n\n\nステージIV（50人）\n\n\n\n\n\n　死亡\n20\n10\n\n\n\n　生存\n5\n15\n\n\n\n　死亡リスク\n80%\n40%\n\n\n\n　リスク差\n\n\n-40%\n\n\n　リスク比\n\n\n0.50倍\n\n\n　オッズ比\n\n\n0.17倍\n\n\n\n\n\n\n\n\n私「なるほどね、オッズ比は層別解析で不安定な指標だってことね。でもさ、そもそも論なんだけど。どうせ割合同士を比べるんだから、わざわざ比をとらなくてもいいんじゃない？パーセントの差でよくない？+10%とか-10%とか。リスクの違いはこれでじゅうぶん伝わるでしょ」\n\n\nお父さん「うん、リスク差はもっと使われていいと思う。でも、リスク差にも欠点がある。複数の研究を集めてメタアナリシスをするとき、それぞれの研究から得られたリスク差やリスク比をひとつの値に要約するでしょ」\n\n\n私「ああ、みたことある」\n\n\nお父さん「このとき問題になるのが、コントロール群（プラセボ群や緩和療法群）で観察されたリスクが、研究によって低かったり高かったりすることなんだ。同じ疾患や治療を扱っていても、予後のいい患者ばかり集めた研究もあれば、予後の悪い患者を対象にした研究もあるでしょ」\n\n\n私「そりゃあるよね」\n\n\nお父さん「リスク差、リスク比、オッズ比で、どれがコントロール群のリスクの影響を受けやすいかを、55件のメタアナリシスのデータを使って調べた研究がある（Furukawa, Guyatt, Griffith 2002）。その結果、以下のようなことがわかった」\n\n\n\nリスク差は、研究ごとにリスクが変動すると、その影響にともなうばらつきが大きい\nリスク比やオッズ比は、研究間を通じて数値が安定していた\n\n\n\nお父さん「つまりね、指標によって解釈のしやすさや統計的な特徴が違うっていうこと。リスク差だけでも、リスク比やオッズ比のような比の指標だけでも、論文で示す情報としては不足があるっていうのが結論」\n\n\n私「じゃあどうしたらいいのよ」\n\n\nお父さん「結局、臨床研究で観察された差って、リスク差やワクチン有効率のようなひとつの数字で要約できないんだと思う。結果を報告するときは、絶対指標（リスク差）と相対指標（リスク比やハザード比）の両方を示したり、Kaplan-Meier曲線やAalen-Johansen曲線をグラフにするのが正解なんじゃないかな。数字しか出せないなら、いちばんバランスがいいのは、リスク差+リスク比かもね」\n\n\n\n\n\n\n\n\nglm()を用いたリスク差、リスク比、オッズ比の計算\n\n\n\nリスク差、リスク比、オッズ比はいろいろな手段で計算できますが、汎用性が高いのは一般化線型モデル（glm関数）を用いる方法です。リンク関数を選ぶことで、リスク差（link=“identity”）、リスク比（link=“log”）、オッズ比（link=“logit”）を選択することができ、交絡因子の調整もしやすいのが便利なところです。ただし、リスク比とオッズ比では、回帰係数の指数をとるひと手間が必要です。表1のリスク差、リスク比、オッズ比を再現するコードを示しておきますので、参考まで。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\ndat &lt;- data.frame(\n  treat = factor(c(\"palliative\", \"palliative\", \"chemotherapy\", \"chemotherapy\"), levels = c(\"palliative\", \"chemotherapy\")),\n  death = c(1, 0, 1, 0),\n  n     = c(30, 20, 15, 35)\n)\ndat\n\n         treat death  n\n1   palliative     1 30\n2   palliative     0 20\n3 chemotherapy     1 15\n4 chemotherapy     0 35\n\nfit_identity &lt;- glm(\n  death ~ treat,\n  family  = binomial(link = \"identity\"),\n  weights = n,\n  data    = dat\n)\nrisk_difference &lt;- coef(fit_identity)[[\"treatchemotherapy\"]]\nprint(risk_difference)\n\n[1] -0.3\n\nfit_log &lt;- glm(\n  death ~ treat,\n  family  = binomial(link = \"log\"),\n  weights = n,\n  data    = dat\n)\nrisk_ratio &lt;- exp(coef(fit_log)[[\"treatchemotherapy\"]])\nprint(risk_ratio)\n\n[1] 0.5\n\nfit_logit &lt;- glm(\n  death ~ treat,\n  family  = binomial(link = \"logit\"),\n  weights = n,\n  data    = dat\n)\nodds_ratio &lt;- exp(coef(fit_logit)[[\"treatchemotherapy\"]])\nprint(odds_ratio)\n\n[1] 0.2857143\n\n\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n一般化線型モデルの一種であるロジスティック回帰は、「確率」ではなく「オッズ」をモデル化しており、オッズ比を求めるためによく用いられます（田中2022）。さて、ロジスティック回帰を用いて、リスク比を計算することができるでしょうか。\n\nロジスティック回帰を用いてリスク比を計算できる\nロジスティック回帰を用いてリスク比を計算できない\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は1です\n\nロジスティック回帰の共変量に、数値を代入することで、確率を計算することができます。共変量として、2群（たとえば抗がん剤投与群と緩和療法群）を指定すれば、それぞれの群の確率が求まりますよね。その比をとれば、リスク比が計算できます。\n\n\n\n\n\n文献\n\nFurukawa TA, Guyatt GH, Griffith LE. Can we individualize the ‘number needed to treat’? An empirical study of summary effect measures in meta-analysis. Int J Epidemiol 2002; 31: 72-6\n田中司朗. 医学研究のための因果推論I. 一般化線型モデル. 東京: 朝倉書店; 2022\n\n\n\nエピソード、用語集、Rスクリプト\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nUnderstanding Collapsibility of Effect Measures in Marginal and Stratified Analyses with R\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nDistinguishing Time-Point, Time-Constant, and Time-Varying Effects: An R Example\nStatistical Terms in Plain Language\nfrequentist.R"
  },
  {
    "objectID": "jp/effects-1.html",
    "href": "jp/effects-1.html",
    "title": "Silent Confusions Hidden in Percentages",
    "section": "",
    "text": "Effects and Time I − Silent Confusions Hidden in Percentages\n\nKeywords: effect measure, observational study, language/writing\n\n\n\n95%って聞いたら100人いたら95人に効くって思わない？\n\n\n\n\n\n\n前回までのあらすじ\n\n\n\n\n\nはじめて研究に取り組む娘と統計家の父。父に研究仮説は”PICO”を”PECO”で整理するといいとアドバイスされ、医師である娘は、がんサバイバーにおけるストーマ造設と復職状況の関係を調査することに決める。それからというもの、父は娘に統計の話をふるチャンスをうかがっていた。\n\n\n\n\n\nお父さん「あれ、お風呂あがったの。コーヒーでも淹れようか」\n\n\n私「カフェラテ」\n\n\nお父さん「いつものやつ？あれはカフェラテじゃなくて、ただのコーヒーミルクだよ」\n\n\n私「いいのよ。そういえばこの前出たワクチンについてなんだけどね。外来で”有効率95%“って患者さんに聞かれたんだけど、こういう統計って私もちょっと混乱するんだよね」\n\n\nお父さん「うん、あれは話題になったよね。ワクチン有効率（vaccine efficacy）って意外と計算が難しいんだよ。まず”率”って用語には要注意だね」\n\n\n私「そう？罹患率とか死亡率とかよく使うけど」\n\n\nお父さん「それとは別。うん、そこは日本語特有の言い回しだから間違えやすいよね。この場合の率は百分率の意味で使っているんだけど、疫学でいう率（rate）とは計算が違うんだ。ややこしいのはそこだけじゃない。この場合の95%は、プラセボに比べて発症リスクが95%って意味だから」\n\n\nワクチン有効率は疫学一般で用いられる率ではない\nプラセボ効果との相対比較のための指標\n\n\n私「ん？100人いたら95人に効くって意味じゃないの？」\n\n\nお父さん「違う違う。プラセボの効果との相対比較。プラセボを打ったときに比べ、どのくらい感染を予防できるっていう意味のパーセントなんだ。論文ではともかく日常会話ではほとんど誤解されて伝わっちゃう。“リスク”までさかのぼらないと、わからないと思う。ちょっと、そこにある紙ナプキンとペンをとって。式で書いてあげるよ。いくつか疫学の指標を書くけど、“98%という数字はどのリスクとどのリスクをどう比べているのか”だけが、はっきりすればいい。そのために、こういう分割表で集計したデータを頭に浮かべよう」\n\n\n\n\n\n\n\n\nリスクを比較するための基本的な指標\n\n\n\n医学では分野によってさまざまな指標が用いられており、特に割合を比較する指標にはわかりにくいものが少なくありません。割合を理解するための最初のステップは分割表です。\n\n\n\n\n群1\n群2\n\n\n\n\n発症あり\nA人\nB人\n\n\n発症なし\nC人\nD人\n\n\n発症リスク\n\\(\\pi_1\\)\n\\(\\pi_2\\)\n\n\n\nこの表では人数や割合を、具体的な数字ではなく、A、B、C、Dや群1・群2の発症リスク\\(\\pi_1\\)と\\(\\pi_2\\)を使って表しています。2群ごとの割合\\(\\pi_1\\)と\\(\\pi_2\\)の比較では、以下のような指標が用いられます。\n\nリスク差（risk difference、絶対リスク減少）\n\n\\[\nRD={\\pi_1}-{\\pi_2}\n\\]\n\nリスク比（risk ratio）\n\n\\[\nRR=\\frac{\\pi_1}{\\pi_2}\n\\]\n\nオッズ比（odds ratio）\n\n\\[\nOR=\\frac{\\pi_1/(1-\\pi_1)}{\\pi_2/(1-\\pi_2)}\n\\]\nこれらの指標を使うときは、どちらの群を基準に比較しているかを意識することが大切です。上の式では群2を基準にとっています。\n\n\n\n\n\n\n\n\n治療の有効性を比較するための指標\n\n\n\n特に、2種類の治療のどちらが有効か調べるために比較するケースでは、以下の指標もよく用いられます。どちらの指標でも\\(\\pi_2&gt;\\pi_1\\)と想定されています。ワクチン有効率では、群2はプラセボを受けていると考えてください。\n\nNumber needed to treat（NNT）\n\n\\[\nNNT=\\frac{1}{\\pi_2-\\pi_1}=-\\frac{1}{RD}\n\\]\n\nワクチン有効率（相対リスク減少）\n\n\\[\nVE=\\frac{\\pi_2-\\pi_1}{\\pi_2}=1-RR\n\\]\n\n\n\n\n私「へー、ワクチン有効率はイメージしてたパーセントじゃないね。リスク比をちょっといじっただけの式じゃない。でも、“有効率”っていわれたり、パーセントが単位だと、いわゆる割合と思いがちだよね。お父さんって、頭の中にいつもこんな計算式があるの？いきなり式が出てくると違和感あるなあ。統計学と医学ってだいぶ雰囲気が違うね」\n\n\nお父さん「もう慣れちゃったのかもね。でも、式で書かないと、ワクチン有効率がなんなのか、わからないでしょ。それにね、この数字には数式よりずっとリアルな意味がある」\n\n\n私「なによ、持って回った言い方して、授業じゃないんだから」\n\n\nお父さん「いや、聞けばすぐわかるよ。ワクチン有効率の数字は、臨床データから推定されたものでしょ。たくさんの参加者を対象に臨床試験を行って、実際に観察されたという経験が、ぎゅっと要約された結果が、この数字なんだ。でも、データ上でどんな結果が観察されたか、ワクチン有効率だけでは伝わらないでしょ。こういうのを”数字が独り歩きする”っていうんだ」\n\n\n\n\n\n\n\nワクチンランダム化臨床試験の数値例\n\n\n\n次の表は、ワクチンとプラセボを比較した仮想的な臨床試験のデータです。表の人数からワクチン有効率を計算すると以下のような結果が得られます。\n\n\n\n\nワクチン群\nプラセボ群\n\n\n\n\n発症あり\n40\n800\n\n\n発症なし\n960\n200\n\n\n発症リスク\n4%\n80%\n\n\n\n\\(\\pi_1 = 40/1000 = 0.04\\)\n\\(\\pi_2 = 800/1000 = 0.8\\)\n\\(VE=\\frac{\\pi_2-\\pi_1}{\\pi_2}=95 \\%\\)\n\n\n\n私「確かにね。95%有効っていう数字だけみると、”ほぼ確実に救える”って意味に捉えがちだけど、よく考えたらワクチンにそこまでの効果はないよね。パーセントを使ったレトリックに騙されちゃいそう」\n\n\nお父さん「解析結果はね。解釈するときに言語そのもの以外の情報が不可欠なんだ。同じ98%でも奏効率とワクチン有効率は別の計算だからね。でも日常会話でそんなこと気にしてられないでしょ。だから間違って使われることが多い。パーセント表記が逆に誤解を生んでる疫学の指標は、他にもあるよ」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n奏効率（response rate）とは、抗がん剤による治療を行った結果、何割の患者で腫瘍が縮小したか（完全奏効または部分奏効を達成したか）や血液から腫瘍細胞が消えたか（完全寛解）を表す指標です。この用語は広く用いられていますが、Japan Clinical Oncology Group（JCOG）という臨床試験グループでは奏効割合（response proportion）という表現を好んでいます（Japan Clinical Oncology Group 2025）。\nさて、次の指標のうち、率（rate）に該当するのはどれでしょうか。\n\n打率\n男女比率\n有病率\n死亡率\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は4です。\n\n割合、率、比の3つの違いについて説明しましょう。比とは、ある量を別の量で割ったもののことです。たとえば、BMIは体重を身長で割ったものですから比の一種で、単位はkg/m2です。割合は、一部の数を全体の数で割ったもの（言い換えると、分母が分子を含んでいるもの）です。割合は、もちろん2値データや分類データを要約するために用いられる指標ですよね。この指標は、言葉の定義からいって、比の一種です。しかし、割合は、100%を超えなく、そして人数を人数で割っているためキャンセルして単位がない（無単位）という特徴があります。割合と区別してほしいのが率です。たとえば胃がんの発生率（incidence rate of gastric cancer）というと、一定時間に胃がんが発生するスピードで、人年法（胃がんの発生数/観察人年）で計算されます。人数を人数×年で割っているため、単位は1/年（より一般には1/時間）です。\n「打率」は安打数÷打数であり、「割合」になります。\n「男女比率」は男性の人数÷女性の人数であり、「比」になります。\n「有病率」は疾患を有する人の人数÷全体の人数であり、「割合」になります。\n「死亡率」は死亡件数÷観察人年であり、「率」になります。\n\n\n\n\n\n文献\n\nJCOGプロトコールマニュアル version 3.8 [Internet]. 東京: Japan Clinical Oncology Group; 2025\n\n\n\nエピソード、用語集、Rスクリプト\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nUnderstanding Collapsibility of Effect Measures in Marginal and Stratified Analyses with R\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nDistinguishing Time-Point, Time-Constant, and Time-Varying Effects: An R Example\nStatistical Terms in Plain Language\nfrequentist.R"
  },
  {
    "objectID": "jp/causal-inference-3.html",
    "href": "jp/causal-inference-3.html",
    "title": "DAGs and Conditional Distributions: Two Languages for the Same Structure",
    "section": "",
    "text": "Causal inference III − DAGs and Conditional Distributions: Two Languages for the Same Structure\n\nKeywords: bias, causal model, clinical trial, confounding/collapsibility, observational study, probability model\n\n\n\n調整すべき因子かどうかってどうやって見分けるの？\nお父さん「まだ話は続くよ。ここからの話題はDAGと確率変数の関係について。まず、確率の基本について思い出してみよう」\n\n\n\n\n\n\nNote\n\n\n\n 確率の復習\n同時確率と条件付確率\n複数の事象を扱うとき、事象が同時に起こる確率（同時確率）と、順番に起こる確率（条件付確率）を区別することが大切です。たとえば2種類の事象AとBがあったとしましょう。「AまたはBが起きる」という事象は、和集合\\(A\\cup{B}\\)で表します。「AかつBが起きる」という事象は、積集合\\(A\\cap{B}\\)で表します。\n\n\n同時確率は、AとB両方が同時に起きる確率のことです。集合の記号を用いると、\\(\\mathrm{Pr}(A\\cap{B})\\)と書くことができます。\n条件付確率は、先にどちらかの事象が起きて、その結果を知った後に、別の事象が起きる確率のことです。事象Bが起きたことを条件付けた下で事象Aの起きる確率は、AとBの積事象の確率を、Bが起きる確率で割ったもので表すことができます。\n\\(\\mathrm{Pr}(A|B)=\\frac{\\mathrm{Pr}(A\\cap{B})}{\\mathrm{Pr}(B)}\\)\nベン図で表すなら、この確率の分母は集合Bに、分子は積集合\\(A\\cap{B}\\)に対応します。また、上の式を変形することで、同時確率と条件付確率に、\\(\\mathrm{Pr}(A\\cap{B})=\\mathrm{Pr}(A|B)\\mathrm{Pr}(B)\\)という関係があることがわかります。\n\n独立性と条件付き独立性\n定義をきちんと思い出してほしいことがもうひとつあります。それは独立性です。事象AとBが独立であるとは、積集合の確率が、それぞれの事象の確率の積と等しいことと定義されます。\n\\(\\mathrm{Pr}(A\\cap{B})=\\mathrm{Pr}(A)\\mathrm{Pr}(B)\\)\n事象AとBに加えて、第3の事象Cがあるとき、Cで条件付けたAとBの同時分布を考えることができますよね。この分布における独立性を、「Cで条件付けた独立性」や「条件付独立性」といいます。条件付独立性もまた、積集合の確率が、それぞれの事象の確率の積と等しいことと定義することができます。\n\\(\\mathrm{Pr}(A\\cap{B}|C)=\\mathrm{Pr}(A|C)\\mathrm{Pr}(B|C)\\)\n\n\nお父さん「準備が整ったので、DAGと確率変数の関係について説明しよう」\n私「ふむふむ」\nお父さん「Aの確率分布がBに依存することを、矢印で表すことにする。つまり、Bで条件付けたAの確率は、B→Aで表される。逆に、AとBが独立なら、矢印はない。このルールを使えば、DAGを条件付確率と対応付けることができそうでしょ。そうすると独立性や相関性について考えることができる」\n私「確率分布って正規分布とかそういうの？」\nお父さん「そうきたか。えっとね、正規分布は条件付確率じゃない。でも、たとえばロジスティック回帰だったら、条件付確率を表すから、それをイメージしてもいい。ここでは具体的な確率分布を意図しているわけじゃなくて、もっと定性的で、一般的な話をしてるんだけどね」\n私「ふーん」\nお父さん「確率変数によって別の確率変数が影響を受けるためには、なんらかの関連が必要だよね」\n私「そりゃそうだ」\nお父さん「統計学では、一般に、それは条件付確率だったり、相関だったりする。一方で、DAGではそれをグラフ上の有向パスで表している。胃がんの例で用いたDAGに、このルールを適用してみてよ。たとえばAからDに入る矢印はないでしょ。このことは、A以外の変数であるB、C、Eで条件付けると、DはAと独立という意味になる」\n私「えーっと、Aは性格、Dは胃がん発生だっけ。年齢も、体質も、ピロリ菌除菌の有無も同じだったら、性格に関係なく、胃がんリスクは等しいと仮定しているって意味なのかな？」\nお父さん「そういうこと。次に、DAG全体について考えてみてよ。さっきのグラフでは、AからB、BからA、AからD、BからEへの矢印はないよね。このことは、AはBに直接影響せず、BはAに直接影響せず、AはDに直接影響せず、BはEに直接影響しないという仮定を表している。もっといえば、これは、さらに、AがBを介して伝わるDへの効果はない、という意味にもなる。このような依存関係を条件付分布で表すと、以下の5つの式のようになる。これがさっきのDAGに対応する確率分布だよ」\n\\(\\mathrm{Pr}(A|B,C,D,E)=\\mathrm{Pr}(A)\\)\n\\(\\mathrm{Pr}(B|A,C,D,E)=\\mathrm{Pr}(B)\\)\n\\(\\mathrm{Pr}(C|A,B,D,E)=\\mathrm{Pr}(C|A,B)\\)\n\\(\\mathrm{Pr}(D|A,B,C,E)=\\mathrm{Pr}(D|B,C,E)\\)\n\\(\\mathrm{Pr}(E|A,B,C,D)=\\mathrm{Pr}(E|A,C)\\)\n私「ふーん。なんだか具体性がなくて、それでって思っちゃうよ。話の終着点がみえない」\nお父さん「そっか。ここまでの話ではね、DAGと条件付確率を対応付けるルールを説明したかったんだ。簡単にいうと、条件付けの方の変数から、条件を付けられる変数の方に、矢印が入るようなルールで、DAGと条件付確率を結びつけることができる。このルールを踏まえて、合流点の意味を考えてみてよ。この図でEとDに相関はある？相関はない？」\n\n私「じゃあもうちょっとだけ話に付き合ってあげる。うーんと。この図にはE→CとD→Cがある。これって、\\(\\mathrm{Pr}(C|D,E)\\)って意味だっけ？」\nお父さん「そうだったね」\n私「さらに、EとDに入る矢印はない。つまり、CとDとEの確率分布は、それぞれ\\(\\mathrm{Pr}(C|D,E)\\)と\\(\\mathrm{Pr}(D)\\)と\\(\\mathrm{Pr}(E)\\)ってことになる。でもここからがわかんないな」\nお父さん「確率の復習で述べた同時分布と条件付確率の関係を思い出してみて。同時確率は、\\(\\mathrm{Pr}(C,E,D)=\\mathrm{Pr}(C|D,E)\\mathrm{Pr}(D)\\mathrm{Pr}(E)\\)と表されるでしょ。この式がポイントなんだ。これって、EとDは独立という意味でしょ」\n私「うん。確率分布が積で書けてるからね」\nお父さん「さらに、この図は、最初に示した合流点の図とは違って、E→Dはない。つまり、曝露変数とアウトカムに因果関係はない状況を想定したものといえる。っていうことはさ。Cについてなにも操作しなくても、EとDに相関があれば因果関係があるし、相関がなければ因果関係はないってことになるでしょ。相関があるかどうかは、曝露変数EとアウトカムDのデータを集めれば、確認できるよね」\n私「なんとなくいいたいことがわかってきた。この図みたいにCが合流点だったら、調整なんかせずにEとDの相関を調べればいいってことね」\nお父さん「簡単にいうとそういうこと。合流点があると、変数間の相関関係がトリッキーになるんだ」\n\n\n\n\n\n\nNote\n\n\n\n 合流点の性質\n合流点を含むパスは相関を生じさせない\n合流点という名前は、有向パスが合流するノードという意味に由来します。パスの上に合流点が1つ以上あるとき、合流点からの影響は別のノードへ伝わりません。このことを、合流点があるとそのパスはブロックされる、という言い方をします。逆に合流点が含まれないとパスはブロックされません。実際、合流点を含むパスが確率変数同士を結びつけても、それだけでは相関は生じません。\n合流点は調整すべきではない\n上で述べた性質を踏まえて、下に示すDAGについて考えてみてください。結論から先に言うと、この場合もEとDは独立ですが、条件付けによって相関が生じます。\nCで条件付けたとき、つまりCを特定の値に固定すると、なにが起きるでしょうか。Cの値が固定されると、A→Cのパスがあるため、Cの影響でAの分布が変化します。さらに、B→Cのパスがあるため、Bの分布も変化します。\n次に問題になるのは、このDAGにA→CとB→Dというパスがあることです。AとBの確率分布が変化すると、A→CとB→Dのパスによって、EとDに同時に影響します。そうすると、Cを固定することによって、E-A-C-B-Dというパスを通じて、EとDに相関が生じることになります。\nまとめると、以下のように、合流点を含むパスは、共通原因・中間媒介因子しか含まないパスとは逆の性質を持っています。\n\n合流点があるとそのパスはブロックされる。合流点を1つでも含むパスは相関を生じさせない\n合流点を交絡因子として調整すると、もともと相関がなかったとしても、相関が生じる\n\n\nまとめ\nこの表は、原因から結果までのパスを、有向か無向か、合流点をいくつ含んでいるかに従って、4分類して、パスの性質を整理したものです。すでに述べたように、調整するかどうか検討の候補になるのは、原因から結果までの無向パスです。もし、無向パスが合流点を含まないなら、パス上のどこかの変数を調整しない限り、そのパスはブロックされません。言い換えると、パス上の変数を調整し、このパスをブロックすることで、バイアスを防ぐことができるかもしれません。無向パスが合流点を1つ含むとき、調整しなくてもこのパスは合流点でブロックされますが、合流点のみを調整すると、ブロックが解けてしまいます。ただし、非合流点を調整すると、合流点を調整したとしても、そのパスはブロックされます。合流点を1つ以上含む場合も、考え方は同じです。調整していない合流点があるか、非合流点を調整すると、このパスはブロックされます。しかし、すべての合流点のみを調整すると、ブロックが解けてしまいます。\n\n\n\n\n\n\n\n\n\n調整しないとき\nパス上の変数を調整したとき\n\n\n\n\n原因から結果までの有向パス\nブロックされていない（定義から合流点を含まない）\n調整しなくてよい\n\n\n原因から結果までの無向パス（合流点を含まない）\nブロックされていない\n調整によりブロックされる\n\n\n原因から結果までの無向パス（合流点1つ含む）\n合流点でブロックされる\n(1)合流点のみ調整するとブロックが解けてしまうが、(2)非合流点を調整すると（合流点を調整したとしても）ブロックされる\n\n\n原因から結果までの無向パス（合流点1つ以上を含む）\n合流点でブロックされる\n(1)すべての合流点のみを調整するとブロックが解けてしまうが、(2)調整していない合流点があるとブロックされ、(3)非合流点を調整してもブロックされる\n\n\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nこのDAGの解釈として正しいのはどちらでしょうか。\n\nEとDに相関がある\nEとDは独立\n\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は1です。\n\nこのDAGは、\\(\\mathrm{Pr}(E|C)\\)と\\(\\mathrm{Pr}(D|C)\\)を意味しています。そのため、どう変形しても、EとDの同時確率を\\(\\mathrm{Pr}(E)\\mathrm{Pr}(D)\\)という積の形で表すことができません。つまり、EとDを結ぶ直接の矢印はないにもかかわらず、EとDは相関しています。\n別の回で扱ったコーヒーとすい臓がんの例で、喫煙によって見かけの相関が生じていたことを覚えていますか？喫煙は、上のDAGにおけるC（共通原因）に相当します。\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nピロリ菌と胃がんの因果関係を表すDAGをもう一度示します。このDAGにおいて、交絡因子として調整すべき変数の集合として正しいのは、次のうちどれでしょうか。\n\nB\nC\nAとB\nAとC\n\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は4です。\n\nこのDAGは、上のクイズで扱ったDAGにパスE→Dを加えたものなので、調整すべき交絡因子は同じです。そして、先ほど考えたように、Cは合流点でもあり、共通原因でもあります。したがって、Aだけ、Bだけ、AとBだけを調整すると、パスE←C→Dによる疑似相関が残ってしまいます。さらに、Cは合流点なので、調整するとパスE←A→C←B→Dによる相関が生じてしまいます。\n結論をいうと、パスE←A→C←B→Dをブロックするため、Cに加えて、AまたはBを調整する必要があります。\n\n\n\n\n\nエピソード、用語集\n\nThree-Variable DAGs: The Smallest Building Blocks of Causal Structure\nCommon Causes and Confounders\nDAGs and Conditional Distributions: Two Languages for the Same Structure\nBackdoor Paths and Confounders\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/causal-inference-1.html#ランダム化臨床試験の第3の因子はどうする",
    "href": "jp/causal-inference-1.html#ランダム化臨床試験の第3の因子はどうする",
    "title": "Three-Variable DAGs: The Smallest Building Blocks of Causal Structure",
    "section": "ランダム化臨床試験の第3の因子はどうする？",
    "text": "ランダム化臨床試験の第3の因子はどうする？\n\nお父さん「この考え方はランダム化臨床試験でも応用できる。JCOG9912っていう臨床試験の論文を読んだことがあったよね（Sasako, et al. 2006）。あれは、手術方法（TH群またはLTA群）を比較して全生存期間に差があるかを調べた研究だった」\n\n\n私「うん。だけど、ランダム化しているから第3の因子ってないんじゃない？だってTH群とLTA群をランダムに割付けてるもの」\n\n\nお父さん「正解。でも、この試験ではハザード比を求めるとき、腫瘍径やBorrman分類などがんの進行度を表す変数で調整している。使ったのはロジスティック回帰じゃなくてCox回帰だけどね。」\n\n\n私「そうなのか。じゃあ調整した方がいいのかな、さっきの”共通原因だけ調整”の話と矛盾するけど」\n\n\nお父さん「ここでもDAGを使って考えられる。Eを手術方法、Dを全生存期間、Cを腫瘍径とすると、図はこうなる。試験結果では有意な関連はなかったけど、わかりやすいようにE→Dの矢印は残したよ」\n\n\n\n私「やっぱり共通原因ではないね」\n\n\nお父さん「そう。JCOG9912では、腫瘍径は交絡因子ではないから、調整する必要はなかった。でも、Cox回帰によって全生存期間をモデル化するとしたらどうかな。腫瘍径のような癌の進行度をモデルに入れたくならない？」\n\n\n私「それは入れたくなる。腫瘍径だけじゃなくてリンパ節転移とか、残存腫瘍の有無とかもモデル化したくなる」\n\n\nお父さん「この図の場合、Cは交絡因子じゃないから、調整しなくてもバイアスは生じない。でも、真に近いモデルを当てはめて、ハザード比の推定精度を高めるという観点からは、Cを調整してもいいんだ」"
  },
  {
    "objectID": "en/study-design-5.html",
    "href": "en/study-design-5.html",
    "title": "When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys",
    "section": "",
    "text": "Study Design 5 − When Bias Creeps In\n\nKeywords: observational study, outcome, simulation, survival/competing-risk, study design\n\n\n\n“Hard endpoints” and soft feelings\n\n\nMe: “I’m home…completely drained. Is there anything sweet?”\n\n\nDad: “There’s a strawberry daifuku. And I just brewed coffee.”\n\n\nMe: “You are objectively improving my quality of life. Today was rough. Clinic was packed, and the train home was rush-hour level insane.”\n\n\nDad: “That sounds like classic Japanese hospital plus Tokyo commute. Here, coffee.”\n\n\nMe: “Thanks. So, there’s something I wanted to ask. You know how people in oncology love to say ‘hard endpoint’ and ‘soft endpoint’?”\n\n\nDad: “Yes, people say that a lot.”\n\n\nMe: “One of my senior colleagues is really into clinical trials. She keeps saying things like:\n\n‘Return-to-work is such a soft endpoint.\nOS is a hard endpoint.\nSoft is bad, hard is good.’\n\nAnd every time she says that, I feel like my return-to-work study is being gently dissed. I sort of get what she means, but not really.”\n\n\nDad: “I can imagine the tone. The way people use those words is a bit loose. If we want to be clearer, it might help to think in terms of objective measure vs subjective measure.”\n\n\nMe: “So OS is ‘hard’ because it’s objective?”\n\n\nDad: “Pretty much. For overall survival (OS), you only need date of death or the last date of confirmation of being alive. That’s relatively straightforward. For something like progression-free survival (PFS), you need to decide when progression happened. That depends on factors unrelated to disease status:”\n\n\nimaging timing\nhow you interpret the scans\nsometimes even symptoms unrelated to cancer\n\n\nDad: “There’s more judgment involved. That’s why people call it a soft endpoint.”\n\n\nMe: “And return-to-work is even more ‘soft’, right? We’re asking about patients’ own perceptions, jobs, feelings…”\n\n\nDad: “Right, but that doesn’t make it meaningless. I think what your colleague meant was something like:\n\n‘When you work with soft endpoints,\ntry to measure them as consistently and objectively as possible.’”\n\n\n\nMe: “So not ‘soft = trash’, but ‘soft = more room for bias, so be careful’.”\n\n\nDad: “Exactly. Even ‘hard’ endpoints like death can be biased if follow-up is sloppy. If, for example, you only track deaths in patients who keep coming to the hospital, you might systematically miss deaths in those who stop showing up. So hard endpoints are not automatically free of bias.”\n\n\nMe: “Okay, that makes me feel better about my study. I’ll phrase it as: ‘a soft endpoint, measured with hard discipline.’”\n\n\nDad: “That’s actually a great line for the methods section. To be precise, you don’t need perfect information on every death. What matters is that the process of collecting death information is not related to patients’ health status. If whether we obtain death information depends on how sick someone was, that creates bias.”\n\n\nMe: “It means censoring is no longer independent of prognosis, right?”\n\n\nDad: “Yes. Remember the Kaplan–Meier and Aalen–Johansen curves I showed you? Those estimators can handle censoring, but they only remain unbiased if censoring occurs randomly, unrelated to the outcome. For example, when all patients are censored at 1 year because the study ends, or when an external reason stops follow-up for some patients.”\n\n\nMe: “I get the idea. But there are situations where we just can’t track deaths perfectly. We can only do our best.”\n\n\nBias in Kaplan–Meier curves\n\nMe: “Okay…besides that, what other types of bias should I be careful about in my survey?”\n\n\nFather: “As I said before—competing risks. In time-to-event data, ignoring competing risks can lead to bias. Can you take out your laptop?”\n\n\nMe: “What? I literally just came back from work…”\n\n\nFather: “It’ll be quick. I’ll tweak the R script we used last time and show you what statistical bias looks like with a simple simulation.”\n\n\n\n\n\n\n\n\n\nBias of the Kaplan–Meier curve in a simulated dataset with recurrence and competing risks\n\n\n\nIn our previous simulations of cumulative incidence of recurrence (CIR), we generated patients who could die before experiencing recurrence (a competing risk). With a simple experiment, you can confirm that the Kaplan–Meier estimator becomes biased in the presence of competing risks.\n\n\n\n\n\n\n\n\nCode of generate_data() used for data generation\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # hazard for relapse\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # hazard for death\n  hazard_censoring &lt;- 0.05                               # hazard for censoring\n  \n  # Latent times to relapse, death, and censoring ----------------\n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)\n  t_death     &lt;- rexp(n, rate = hazard_death)\n  t_censoring &lt;- rexp(n, rate = hazard_censoring)\n\n  ## --- Overall survival (OS) -----------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = death, 0 = censored\n  \n  ## --- Relapse-free survival (RFS) -----------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # relapse\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # death\n  \n  ## --- Cumulative incidence of relapse (CIR) -------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # relapse\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # death (competing risk)\n\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n  return(dat)\n}\n\n\n\n\n\n\n\n\n\n\nAalen-Johansen curves for cumulative incidence of relapse (CIR)\n\n\n\nKaplan–Meier曲線とAalen-Johansen曲線は、どちらもcifmodelingパッケージのcifplot()を使って生成できますが、イベントのコーディングを入力するcode.event1、code.event2とデータの型を表すoutcome.typeを、指定する必要があります。generate_data()で生成したシミュレーションデータでは、CIRのイベントは以下のようにコーディングされていました。\n\nstatus_cir=1 : 再発\nstatus_cir=2 : 再発を経験しない死亡\nstatus_cir=0 : 打ち切り\n\n以下のRスクリプトでは、最初のcifplot()により、再発（code.event1=1）に関するAalen-Johansen曲線（aj_event1）を出力しています。縦軸は累積発生確率ではなく、1-累積発生確率を選んでいる点にも注意してください（type.y=\"surv\"）。そして次のcifplot()ではイベントを入れ替えて、再発を経験しない死亡（code.event1=1）に関するAalen-Johansen曲線（aj_event2）を出力し、cifpanel()に用いて2つの図を左右に配置したひとつの図を表示しています。左右の累積発生確率の和に注目してください。この図からは、再発の累積発生確率と（再発を経験しない）死亡の累積発生確率の和は、時間が経つにつれ1に近づくが、1を超えることはないことがわかります。仮に打ち切りがなかったとしたら、再発と（再発を経験しない）死亡のどちらか一方しか生じないため、Aalen-Johansen曲線の和が1を超えないのは自然なことです。\n\n# devtools::install_github(\"gestimation/cifmodeling\") #インストールが必要なら実行 \nlibrary(cifmodeling)\nset.seed(46)\ndat &lt;- generate_data(hr1=2, hr2=1.5) #再発ハザード比2, 死亡ハザード比1.5のデータ生成\n\naj_event1 &lt;- cifplot(Event(time_cir, status_cir) ~ stoma,\n  data         = dat,\n  outcome.type = \"competing-risk\", \n  type.y       = \"surv\",\n  code.event1  = 1, \n  code.event2  = 2\n)\naj_event2 &lt;- cifplot(Event(time_cir, status_cir) ~ stoma,\n  data         = dat,\n  outcome.type = \"competing-risk\", \n  type.y       = \"risk\",\n  code.event1  = 2, \n  code.event2  = 1\n)\naj_list &lt;- list(aj_event1$plot, aj_event2$plot)\naj_panel &lt;- cifpanel(rows.columns.panel = c(1,2), plots=aj_list)\nprint(aj_panel)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKaplan–Meier curves for cumulative incidence of relapse (CIR)\n\n\n\n実際の研究では、死亡を打ち切りとして扱った生存時間解析の結果をしばしば目にします。この解析に対応するKaplan–Meier曲線は、以下のようにイベントのコーディングを変更し、outcome.type=\"survival\"を指定することで出力できます。\n\nstatus_cir1=1 : 再発\nstatus_cir1=0 : 再発を経験しない死亡/打ち切り\nstatus_cir2=1 : 再発を経験しない死亡\nstatus_cir2=0 : 再発/打ち切り\n\n新しく作ったイベント変数status_cir1とstatus_cir2を用いると、再発のKaplan–Meier曲線と（再発を経験しない）死亡のKaplan–Meier曲線を描くことができます。これらのKaplan–Meier曲線を左右に配置した図を、先ほどのAalen-Johansen曲線の図と比べてみてください。Aalen-Johansen曲線の和とは異なり、Kaplan–Meier曲線の和が1を超えていることが読み取れたでしょうか。\n\ndat$status_cir1 &lt;- as.numeric(dat$status_cir==1)\nkm_event1 &lt;- cifplot(Event(time_cir, status_cir1) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\", \n  type.y       = \"surv\"\n)\ndat$status_cir2 &lt;- as.numeric(dat$status_cir==2)\nkm_event2 &lt;- cifplot(Event(time_cir, status_cir2) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\", \n  type.y       = \"risk\"\n)\nkm_list &lt;- list(km_event1$plot, km_event2$plot)\nkm_panel &lt;- cifpanel(rows.columns.panel = c(1,2), plots=km_list)\nprint(km_panel)\n\n\n\n\n\n\n\n\n\n\n\n\nThree familiar troublemakers: selection, information, confounding\n\n\nDad: “Sure. You’re mailing out questionnaires, right? When a lot of patients don’t respond, that introduces bias. For example, are you asking about annual income?”\n\n\nMe: “Maybe.”\n\n\nDad: “Then be careful. Sensitive questions can lower the response rate. If non-response is systematic, your sample no longer represents the target population. For example:”\n\n\nPatients who are doing well may be more likely to answer.\n\nPatients who are very sick, depressed, or busy may be less likely to answer.\n\n\nDad: “Then your estimated return-to-work proportion can be too optimistic. Also, suppose patients with a stoma are more likely to return the questionnaire than those without a stoma. Then comparing those two groups could be criticized because of differential response rates.”\n\n\nMe: “Is that… confounding?”\n\n\nDad: “You know the term? Nice. Confounding is a type of bias, but this is different. When the selection of participants itself depends on certain characteristics, we call it selection bias. And if the information collected is inaccurate—like when people overreport income — that’s information bias. In classes on study design and observational studies, we divide bias into three main categories:\n\n\nSelection bias\nInformation bias\nConfounding\n\n\nDad: “Most biases fall into one of these three. So when designing a study, we teach students:”\n\n\nMake sure you’re not selecting only certain types of people.\nCollect information in a way that avoids systematic errors.\nWhen comparing groups, adjust for characteristics other than the variable of interest.\n\n\nDad: “Keeping these three in mind makes countermeasures much easier.”\n\n\nMe: “Hmm… selection bias, information bias… Clinical research terminology is so confusing. But I definitely don’t want my survey to fail. I’ll write this down.”\n\n\n\n\n\n\n\n\nRandom error and bias\n\n\n\nStatistics is a discipline of uncertainty, but in clinical research it’s important to distinguish random error from bias.\n\nRandom error: variability centered around the truth. Decreases with larger sample size.\nBias: a systematic deviation from the truth. Does not disappear unless the study design and data collection are improved.\n\nA helpful analogy: Random error is like the spread of arrows around the bull’s-eye. Bias is when you’re consistently aiming off-center.\nThe bias you observed in the Kaplan–Meier curve under competing risks is not random error.\n\nReducing random error = increase sample size.\nReducing bias = improve study design.\n\nThat is one of the central themes of this Story.\n\n\n\n\nThis concludes the Study Design series. If you’d like to keep reading over your next cup of coffee, the following episodes are waiting:\n\n[Reading a Paper over a Cup of Coffee]\n[P-Value Explanations That Seem Plausible at First Glance]\n[Beyond 0.05: Interpreting P-Values in a Clinical Trial]\n[Understanding Confidence Intervals via Hypothetical Replications in R]\n[Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size]"
  },
  {
    "objectID": "en/study-design-3.html",
    "href": "en/study-design-3.html",
    "title": "A First Step into Survival and Competing Risks Analysis with R",
    "section": "",
    "text": "Study Design III − A First Step into Survival and Competing Risks Analysis with R\n\nKeywords: clinical trial, hypothesis/outcome/population, survival/competing-risk, language/writing\n\n\n\nWhat exactly is an outcome?\n\n\nMe: “Hey Dad, can I pick your brain again?”\n\n\nDad: “That depends. Is there coffee involved?”\n\n\nMe: “Already poured. So… about outcomes. In journal club, all these abbreviations show up: OS, DFS, RFS, PFS… Everyone talks like they’re obvious, but I’m honestly fuzzy on the details. I know they’re supposed to be outcomes, but what’s really different between things like DFS and RFS? You deal with these all the time, right?”\n\n\nDad: “I do. The one you probably see most is overall survival (OS). Then there’s disease-free survival (DFS) and relapse-free survival (RFS).”\n\n\nMe: “RFS sounds like ‘number of days until relapse’ in my head.”\n\n\nDad: “If we literally meant ‘number of days until relapse’, we may call it relapse-free time. You’ll also see terms like cumulative incidence of relapse (CIR).”\n\n\nMe: “Acronyms are multiplying, not shrinking. Help.”\n\n\nDad: “Let’s slow it down. In survival analysis, we’re always looking at time from some origin to an event. The twist is what we call an event. For DFS, we often count as events:\n\n\nrecurrence\nsecond primary cancer\ndeath\n\n\nWe’re asking:\n&gt; ‘How long do patients stay alive without recurrence and without second cancer?’”\n\n\nMe: “So if someone gets a second cancer, that’s already an event in DFS, even if they’re alive.”\n\n\nDad: “Exactly. For RFS, it’s usually:\n\n\nrecurrence\ndeath\n\n\nDad: “Second cancers generally don’t count as events there.”\n\n\nMe: “And OS is just time to death.”\n\n\nDad: “Right. So if you look at 3-year OS and 3-year DFS for the same trial, 3-year DFS is always less than or equal to 3-year OS, because DFS counts more things as events.”\n\n\nMe: “Got it. But from a patient’s point of view, ‘no recurrence and no second cancer’ sounds pretty important. So DFS feels meaningful. RFS… I’m less sure. And death is obviously the most serious event of all.”\n\n\nDad: “Agreed. But notice:\n\n\nIf someone relapses and later dies, they’re already an event in RFS at the time of relapse, even before death.\nIf someone dies before relapse, the cause might be an infection, accident, or something unrelated to the original cancer.”\n\n\nMe: “So not all deaths are equal in terms of ‘cancer story’.”\n\n\nDad: “Exactly. Let me show you a simplified table of common survival endpoints in cancer trials. Think of it as a map, not a legal document.”\n\n\n\n\n\n\n\n\nEndpoint\nWhat counts as an event?\n\n\n\n\nOverall survival (OS)\nDeath from any cause\n\n\nProgression-free survival (PFS)\nProgression or death\n\n\nRelapse-free survival (RFS)\nRelapse or death\n\n\nCumulative incidence of relapse (CIR)\nRelapse only, with death as a competing risk\n\n\nDisease-free survival (DFS)\nRelapse, second cancer, or death\n\n\nEvent-free survival (EFS)\nDeath, induction failure, relapse, second cancer (depends on trial)\n\n\n\n\nDad: “The key idea is:”\n\n\nOS cares only about death\nDFS cares about any recurrence / second cancer / death\nRFS sits in between\n\n\nMe: “Okay, that really helps. And the time origin is… usually when treatment starts?”\n\n\nDad: “Good question. Common choices for the time origin are:”\n\n\ndate of surgery\n\ndate of randomization/registration in a trial\n\ndate of diagnosis\n\n\nDad: “For a study on postoperative adjuvant therapy, using the date of surgery is natural. If you used date of discharge instead, deaths before discharge would be invisible in your analysis, which can be a big problem.”\n\n\nMe: “So if I’m evaluating adjuvant chemo after surgery, time zero = surgery date is the cleanest. If I pick a weird origin, I’m basically throwing away part of the story.”\n\n\nDad: “Exactly. Time origin is like the zero point on your ruler: if you set it wrong, all the distances become hard to interpret.”\n\n\nSurvival analysis and competing risks analysis\n\nDad: “Want to see how OS, RFS, and CIR behave in data?”\n\n\nMe: “That’s a dangerous question, but yes.”\n\n\nDad: “Let’s use R again. We’ll simulate two groups with and without stoma. We’ll give the stoma group a higher risk of relapse and death. And see how that shows up in:”\n\n\n\n\nOS curves\n\nRFS curves\n\nCIR curves with death as competing risks\n\n\n\n\n\n\n\nGenerating simulated data with relapse\n\n\n\nThe following code defines an R function, generate_data(), that produces a binary variable, stoma, and three related survival outcomes, OS, RFS and CIR. We’ll reuse generate_data() and this simulated dataset in later episodes.\n\nStoma: binary, from a binomial distribution using rbinom()\nSurvival time: from an exponential distribution using rexp() (calculated from random numbers for t_relapse, t_death, t_censoring)\n\nIn a previous episode, we summarized survival data without competing risks, and we used the Kaplan-Meier curve for that, right? In contrast, when there are competing risks, it is more appropriate to use the Aalen–Johansen estimator of the cumulative incidence function, rather than a Kaplan–Meier curve for relapse.\n\n\n\n\n\n\n\n\nCode of generate_data() used for data generation\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # hazard for relapse\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # hazard for death\n  hazard_censoring &lt;- 0.05                               # hazard for censoring\n  \n  # Latent times to relapse, death, and censoring ----------------\n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)\n  t_death     &lt;- rexp(n, rate = hazard_death)\n  t_censoring &lt;- rexp(n, rate = hazard_censoring)\n\n  ## --- Overall survival (OS) -----------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = death, 0 = censored\n  \n  ## --- Relapse-free survival (RFS) -----------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # relapse\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # death\n  \n  ## --- Cumulative incidence of relapse (CIR) -------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # relapse\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # death (competing risk)\n\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n  return(dat)\n}\n\n\n\n\n\n\n\n\n\n\nKaplan–Meier curves for OS\n\n\n\nSince OS and RFS are standard survival data, we will describe them using Kaplan–Meier curves, as before, using the cifplot() function from the cifmodeling package.\n\n# devtools::install_github(\"gestimation/cifmodeling\") # if needed \nlibrary(cifmodeling)\nset.seed(46)\ndat &lt;- generate_data(hr1=2, hr2=1.5)\n\ncifplot(Event(time_os, status_os) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\n\n\n\n\n\n\n\n\nIn this simulated data, patients with a stoma have clearly worse OS: their Kaplan–Meier curve drops faster and stays below the curve for patients without a stoma.\n\n\n\n\n\n\n\n\nKaplan–Meier curves for RFS\n\n\n\n\ncifplot(Event(time_rfs, status_rfs) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Relapse-free survival\"\n)\n\n\n\n\n\n\n\n\nFor RFS, the Kaplan–Meier curves drop faster and the gap is even larger, because both relapse and death are counted as events.\n\n\n\n\n\n\n\n\nAalen-Johansen curves for CIR\n\n\n\nThe following code inputs the risk of recurrence by coding Event(time_cir, status_cir).\n\nstatus_cir=1 : Event of interest (recurrence)\nstatus_cir=2 : Competing risk (death not experiencing recurrence)\nstatus_cir=0 : Censoring\n\nFurthermore, by specifying outcome.type = \"competing-risk\", it plots the Aalen-Johansen curve.\n\ncifplot(Event(time_cir, status_cir) ~ stoma,\n  data         = dat,\n  outcome.type = \"competing-risk\",\n  label.y      = \"Cumulative incidence of relapse\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\nMe: “Competing risk… like an event that ‘steals the chance’ for relapse to happen?”\n\n\nDad: “Exactly. If a patient dies before relapse, we’ll never see relapse in that patient’s timeline. Death ‘competes’ with relapse.”\n\n\nMe: “The curve for relapse looks a bit like a survival curve turned upside down.”\n\n\nDad: “Visually, yes. But conceptually it’s different. By the way, I mentioned wanting to use ‘cumulative incidence of relapse‘ instead of ‘relapse-free time‘ because a cumulative incidence curve or cumulative incidence function is the same as the Aalen-Johansen curve in the context of survival analysis. If you used Kaplan–Meier for relapse, you’d treat deaths as censored — as if they just disappeared from the risk set. But death isn’t the same as ‘lost to follow-up’. It’s a real, meaningful event. So for competing risks, we prefer to estimate the Aalen-Johansen curve, which respects the fact that death is another type of event. In other words, choosing ‘who is an event’ and ‘who is a competing risk’ changes how we interpret the outcome.”\n\n\nMe: “By the way, in journal club people love to say:”\n\n\nOS is the only real endpoint\nDFS is just a surrogate\n\n\nMe: “Is that fair?”\n\n\nDad: “It’s…simplified. Regulators and guidelines often treat OS as a clinical endpoint — an outcome that directly reflects patient benefit. Things like DFS or PFS are often used as surrogate endpoints. A surrogate endpoint is an outcome intended to substitute for a clinical endpoint, and expected to predict clinical benefit or harm. This is a formal terminology in drug approval contexts (Biomarkers Definitions Working Group 2001).”\n\n\nMe: “The obvious advantage is that you can finish the trial earlier, right? You don’t have to wait for OS to mature.”\n\n\nDad: “Exactly. Shorter trials, faster answers. But there’s a risk: sometimes surrogates don’t predict OS well. There are famous examples. In advanced colorectal cancer, combination therapy with 5-FU and leucovorin demonstrated tumor shrinkage in clinical trials. However, when evaluating OS, it became clear that this combination had little effect on prolonging life (Fleming and DeMets 1996). Surrogates can be very useful, but they’re not automatically ‘good enough’ on their own.”\n\n\nMe: “So in practice, we often look at OS when possible, and use DFS / PFS with a bit of skepticism and context.”\n\n\nDad: “That’s a healthy attitude.”\n\n\n\n\n\n\n\n\nA quiz related to this episode\n\n\n\nThis quiz focuses on how we define progression and events when using progression-free survival (PFS) as an endpoint in clinical trials. To measure PFS, we need to determine tumor progression based on imaging. Sometimes a central review committee evaluates images to make this more objective. In that case, there may be discrepancies between:\n\nthe progression date according to the central review, and\n\nthe progression date according to the local investigator.\n\nThis issue is called a disagreement between central and local assessment. Which of the following is not appropriate as a way to handle this in a clinical trial?\n\nIn the primary analysis, use the results of the central review, which is considered more objective.\n\nIn the primary analysis, define progression as whichever date comes first: central or local.\n\nHold a case review meeting and decide how to handle discrepant cases based on medical judgment.\n\nPerform two analyses: one using central assessment, and one using local assessment.\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 2.\n\nIf you define the event as “whichever progression date comes first (central or local)”, you are more likely to shorten PFS artificially, because you systematically choose the earlier of the two dates. That introduces bias.\nThis doesn’t mean you must always use central review; in some contexts, local assessment may better reflect real clinical decision-making. But “always take the earlier date” is not an appropriate general rule.\n\n\n\n\n\nReference\n\nBiomarkers Definitions Working Group. Biomarkers and surrogate endpoints: preferred definitions and conceptual framework. Clin Pharmacol Ther 2001;69(3):89-95\nFleming TR and DeMets DL. Surrogate end points in clinical trials: are we being misled? Ann Intern Med 1996;125(7):605-13\n\n\n\nEpisodes and R-script\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nA First Step into Survival and Competing Risks Analysis with R\n[Outcomes: The Bridge from Data Collection to Analysis]\n[When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys]\nstudy-design.R"
  },
  {
    "objectID": "en/study-design-1.html",
    "href": "en/study-design-1.html",
    "title": "A Story of Coffee Chat and Research Hypothesis",
    "section": "",
    "text": "Study Design I − A Story of Coffee Chat and Research Hypothesis\n\nKeywords: hypothesis/outcome/population, observational study, study design, language/writing\n\n\n\nA daughter starting her first research, and her statistician father\n\n\nMe: “So… you really are a professor in statistics, right?”\n\n\nDad: “In Japan, yes. One of the many.”\n\n\nMe: “My boss keeps telling me it’s time I do ‘some research’ and present at a conference. He’s really into supporting cancer patients in returning to work since the Basic Plan to Promote Cancer Control Programs in Japan was revised. Long story short, I think he wants me to run some kind of survey. I’m not against it, but this is clearly your territory, isn’t it? Statistics and all that.”\n\n\nDad: “Half my territory, half yours. You see the patients, I only see the data. So, do you have any clinical question or hypothesis in mind?”\n\n\nMe: “Honestly? Not really. I was sort of hoping I could just collect a lot of data first and think later. Is that illegal?”\n\n\nDad: “Not illegal, but not safe. Without at least a working hypothesis, it’s hard to design a good study.”\n\n\nMe: “Okay, okay. If I have to say something… I’m curious about which patients have a harder time staying in work. Not just men vs women, but things like tumor stage and treatment. I work in GI surgery, so I keep wondering about patients with a stoma. Can they really keep doing the same job as before surgery?”\n\n\nDad: “That’s already a good start. You’re close to a research question.”\n\n\nMe: “Really? I was just thinking out loud. Fine, I guess I’ll start drafting a questionnaire. That actually helped. Thanks.”\n\n\nDad: “Hold on. Have you decided on your study population yet?”\n\n\nMe: “Um… patients with cancer who had surgery at our hospital?”\n\n\nDad: “Do you see many stomas in gastric cancer patients?”\n\n\nMe: “It’s not impossible, but honestly, almost never.”\n\n\nDad: “Right. If your main interest is stomas, it might make sense to focus on cancers where stomas are common, like rectal cancer.”\n\n\nMe: “So you’re saying narrow the population?”\n\n\nDad: “Exactly. If you narrow the target population, you can ask more detailed questions and improve comparability between groups. If you want to compare patients with and without a stoma, it’s better to keep the cancer site consistent.”\n\n\nMe: “Comparability…such a statisticky word. But yeah, if the background is all over the place, it’s a mess. I do get that.”\n\n\nDad: “On the other hand, if you broaden the population, you gain generalizability: the results could potentially apply to a wider range of cancer patients. If your goal were to estimate the return-to-work rate among all cancer survivors in Japan, you wouldn’t limit the cancer site, and you might want data from multiple hospitals, not just ours.”\n\n\nMe: “Right now, with only our hospital, calling it a ‘real-world survey’ would be a bit bold. So ‘high generalizability’ basically means ‘other hospitals could actually use the results as a reference’?”\n\n\nDad: “That’s a good way to put it. See, you do think statistically.”\n\n\nMe: “Don’t flatter me just to get free clinical consulting.”\n\n\nDad: “In class, I tell my students this:\n\nWhen your clinical question is still vague,\ntry to express it using PICO or PECO before you design the study.\n\nIt sounds fancy, but it’s just a framework.”\n\n\nMe: “I’ve heard the words PICO, PECO…but nobody really explains what to do with them.”\n\n\nDad: “Let’s walk through it using your case. In PICO/PECO:\n\n\n\nWhat kind of patients? (Patients/Population)\n\nWhat factor are we focusing on? (Intervention/Exposure)\n\nWhat are we comparing it to? (Comparison)\n\nWhat outcomes are we interested in? (Outcome)\n\n\n\nThese four pieces are like the minimum ingredients for a study recipe. In a clinical trial, we usually talk about Intervention (I). In observational studies like your survey, we talk about Exposure (E).”\n\n\nMe: “Okay, P is like, ‘rectal cancer patients after curative surgery in our hospital’. For E and C… maybe ‘with stoma’ vs ‘without stoma’?”\n\n\nDad: “Exactly. And O is your outcome, that is to say, what you want to measure. In your case, something about return to work.”\n\n\nMe: “So outcome is the thing we call OS, DFS, response rate, that kind of stuff?”\n\n\nDad: “Right. In statistical analysis, the outcome variable is the most important part. So deciding what the outcome is is a key step in planning.”\n\n\nMe: “Can I really fix that before collecting any data? Feels like I’m committing too early.”\n\n\nDad: “If you don’t fix it before designing the questionnaire, you’ll regret it later. Once you start collecting data, by the way, what software are you planning to use?”\n\n\nMe: “R. That’s what everyone in my department uses.”\n\n\nDad: “How comfortable are you with R?”\n\n\nMe: “We had it in undergrad, but at this point I’ve forgotten everything except that semicolons stress me out less than parentheses.”\n\n\nDad: “So we’ll need to get you used to R again. Which R functions you use will depend on the type of outcome you choose.”\n\n\nMe: “So step zero is:\n\nTurn my vague hunch into a proper question using P, E, C, O\nDecide on the outcome\n\nThen figure out how to survive R and not embarrass myself at journal club\n\nThat’s the plan?”\n\n\nDad: “That’s a very good summary. If you bring me questions like that, I’m happy to be used as a resource.”\n\n\nMe: “Deal. I’ll bring the clinical mess, you translate it into statistics. Very efficient division of labor.”\n\n\n\n\n\n\n\n\nClinical questions and research hypotheses\n\n\n\nIn everyday clinical work in Japan, you naturally start to notice small curiosities:\n\n“Do my older patients really have worse outcomes?”\n\n“Is this new support program actually helping?”\n\nThese are clinical questions. To turn them into research, we want to re-express them as research hypotheses. A research hypothesis is built from the minimum elements needed for study design:\n\nP: Patients/Population\nI/E: Intervention/Exposure\nC: Comparison\nO: Outcome\n\nThat’s exactly what PICO/PECO helps you write down.\n\n\nExample: Research hypothesis 1\nAmong rectal cancer patients after curative resection in Japan, is there a difference in return-to-work within one year between those with and without a stoma?\n\nP: Rectal cancer patients after curative resection\n\nE: Stoma present\n\nC: Stoma absent\n\nO: Returned to work within one year after surgery (yes/no)\n\nHere you’d compare the return-to-work proportion between the stoma and non-stoma groups.\nWhat to choose for C (Comparison) is important. If you only know the return-to-work rate in the stoma group, it’s hard to say whether that number is “high” or “low”.\nHaving a clear comparison group improves interpretability.\n\n\n\nExample: Research hypothesis 2\nAmong cancer patients after curative surgery, does providing a guidebook on balancing work and cancer treatment increase the proportion who return to work within one year?\n\nP: Patients with cancer after curative surgery\n\nE: Received the guidebook\n\nC: Did not receive the guidebook\n\nO: Returned to work within one year after surgery (yes/no)\n\nHere P is broader, so the results could potentially apply to a wider range of patients. This is an example of higher generalizability.\n\n\n\nExample: Research hypothesis 3 (exploratory)\n“Are sex, age, stage, adjuvant chemotherapy, performance status, comorbidities, stoma, preoperative employment status, household income, cancer insurance, and use of employment support services associated with return-to-work within one year?”\nIn exploratory studies like this, P is clear, but E and C are not just one thing — we’re screening multiple potential risk factors.\nSo “structuring the question” doesn’t mean you have to force every study into a clean PECO shape. What matters is to identify the minimal set of elements needed to design a coherent study for your question.\n\n\n\n\n\nMe: “I see. While I’d be stuck if told to come up with an original hypothesis, I don’t mind the process of identifying research elements and deciding on them one by one. It’s something I’ll need to do eventually anyway.”\n\n\nFather: “Exactly. Plus, replacing your thinking with specialized terminology early on improves communication. Definitions of diseases and outcomes, detailed treatment regimens, and exposure specifics can vary slightly between clinicians and facilities. Neglecting precise language just breeds confusion.”\n\n\n\n\n\n\n\n\nA quiz related to this episode\n\n\n\nWhen formulating study design, the Latin expression “ceteris paribus” often appears. Which of the following best describes its meaning?\n\nIf there is a causal relationship, it will inevitably occur\nA universally generalizable law\nAll other conditions being equal\nObserving a sufficiently large amount of data\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 3.\n\nThe concept of “ceteris paribus” is very close to the idea of comparability between groups — one of the key themes of the story.\n\n\n\n\n\nEpisodes and R-script\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\n[A First Step into Survival and Competing Risks Analysis with R]\n[Outcomes: The Bridge from Data Collection to Analysis]\n[When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys]\nstudy-design.R"
  },
  {
    "objectID": "en/frequentist-5.html",
    "href": "en/frequentist-5.html",
    "title": "Story and Quiz ? Frequentist thinking V",
    "section": "",
    "text": "Story and Quiz ? Frequentist thinking V\nKeywords: sample size calculation, clinical trial, observational study\n\n\ngSoc how many patients do I actually need?h\nDad: gHey, got a minute?h\nMe: gWhat? You look unusually serious.h\nDad: gHave you calculated the sample size yet?h\nMe: gSample sizec for what?h\nDad: gFor your cancer survivor survey.\nThe number of patients youfre planning to include.h\nMe: gAh, that. I was thinking of surveying 100 patients.h\nDad: gLast time, we talked halfway through the topic.\nWe covered precision and confidence intervals.\nToday I want to talk about:\n\neHow many patients do we need\nif we actually want to detect a difference between groups?f\n\nIn other words:\nsample size for hypothesis testing.h\nMe: gOkay, continuation of the sample size story. Ifm listening.h\nDad: gPreviously we looked at sample size from the angle of\nhow wide a 95% confidence interval you can tolerate.\nBut if you want a study thatfs designed from the start to compare:\n\nstoma vs no stoma,\n\nand test a hypothesis about the difference in return-to-work rate,\nthen you need to think in terms of:\n\np-values,\n\n** error**, and\n\nﾀ error.h\n\nMe: gHypothesis testingc so this is where p-values come back in?h\nDad: gExactly.\nIf we go that route,\nwe need to talk about how ** error, ﾀ error, and p-values** are connected.\nRemember JCOG9502, the gastric cancer trial we talked about?\nWhere did we leave off?h\nMe: gWe talked about p-values and the ASA statement.\nBut I donft remember hearing much about eerrorf other than random error.h\nDad: gRight. Then letfs start from there.\nPass me that napkin and a pen, will you?h\nMe: gThis one?h\nDad: gThanks.\nTo explain error and ﾀ error,\nI really need a little 2~2 table.h\n\n\n\nerror and ﾀ error\nDad: gWefve been talking about JCOG9502 ?\nthe trial comparing the LTA and TH surgical approaches.\nIn that setting, we said there are two possible truths:\n\nLTA improves overall survival compared with TH, or\n\nLTA has no effect on overall survival compared with TH.\n\nOn the other hand, the result of the trial (in a simplified view)\ncan be either:\n\np &lt; (significant), or\n\np ? (not significant).\n\nCombine these and you get a 2~2 table:h\n\n\n\n\n\n\n\n\nTrial result\nTrue: no effect (H?)\nTrue: has effect (H?)\n\n\n\n\nNot significant (p ? )\n(correct)\nﾀ error\n\n\nSignificant (p &lt; )\n** error**\n(power = 1 ? ﾀ)\n\n\n\nDad: gOut of these four cells,\nthe ones we really worry about are the two error cases:\n\nThere is a true effect, but the result is not significant ﾀ error\n\nThere is no true effect, but the result comes out significant ** error**\n\nWe call them:\n\n** error (Type I error)**\n\nﾀ error (Type II error)\n\nand\n\nPower = 1 ? \u0001h\n\nMe: gRight, intuitively that makes sense.\n\nIt would be a mistake to say LTA is effective when it isnft.\n\nIt would also be a mistake to abandon a truly useful approach\njust because it failed to reach significance.h\n\nDad: gExactly.\nBut therefs an important point:\n\nerror and ﾀ error are not concepts that depend on p-values per se.\n\nYou could decide eeffective / not effectivef\nbased on something other than a p-value.\nThe key is this:\n\nWhen we use the rule ep &lt; 0.05f,\nwe are choosing a rule that controls error at 5%.\nIt says nothing about ﾀ error unless we also plan the sample size.h\n\n\n\n\nerror, ﾀ error, and p-values\nDad: gThink about the probabilities of error and ﾀ error.\nIf we increase the sample size,\nrandom error gets smaller.\nBoth and ﾀ errors tend to get smaller as well ?\nitfs harder to be fooled.\nBut with fixed sample size,\nand ﾀ have a trade-off:\n\nYou canft make both very small at the same time\nwithout increasing n.\n\nIf you insist on a very small ,\nﾀ will typically get bigger unless you also increase n.\n\nSo in practice, we usually:\n\nPrioritize error,\n\nChoose a test procedure that guarantees\nis not above some pre-specified level ?, and\n\nCall ? the significance level.\n\nUsing the rule ep &lt; 0.05f\nis just shorthand for e = 0.05f.h\nMe: gSo in JCOG9502,\nthey didnft use 0.05, right?h\nDad: gRight.\nBecause recruitment was difficult,\nthey changed the plan so that:\n\none-sided = 0.1\n\nﾀ = 0.2 (power = 0.8)\n\nIn other words,\nthey allowed themselves to compare the p-value to 0.1.\nIn that design:\n\nEven if LTA truly has no survival benefit,\n\nAbout 10% of the time\na trial like this would still declare eLTA is effectivef\njust by chance.\n\nSo when you increase the significance level from 5% to 10%:\n\nerror doubles,\n\nbut the required sample size can be smaller.h\n\nMe: gI get the table you drew on the napkin.\nBut once you start talking about , ﾀ, and probabilities,\nI feel like Ifm losing the thread.h\nDad: gThen letfs translate them into clinical consequences.\nIn a trial like JCOG9502,\nwhere wefre checking if a new treatment is effective,\nyou can think:\n\n** error**\nA treatment that is no better than standard\n(or even worse) ends up being adopted.\nThatfs a consumer risk:\npatients and society are hurt.\nﾀ error\nA treatment that is actually effective\nis abandoned during development.\nThatfs a producer risk:\ndevelopers lose the chance to bring a good treatment to patients.h\n\nMe: gFrom a doctorfs perspective,\nerror sounds more scary ?\ngiving ineffective or harmful treatment to patients.h\nDad: gI feel the same.h\n\n\n\nTypical choices for and ﾀ\nMe: gI still donft have an intuitive feel for the numbers.\nOf course itfs better to have smaller error probabilities,\nbut how small is esmall enoughf?h\nDad: gLook again at the JCOG9502 paper.\nWhat do they say about and ﾀ?h\nMe: gLet me seec\n\neThe amended sample size was 250,\nwith one-sided alpha error of 0.1 and beta error of 0.2.f\n\nSo:\n\none-sided = 0.1\n\nﾀ = 0.2 (power = 0.8)\n\nAnd that led to a total sample size of 250.h\nDad: gExactly.\nIn many clinical trials,\nﾀ is set to 0.1 or 0.2,\nmeaning power = 0.9 or 0.8.\nThe SWOG statisticians say in their oncology trials textbook:\n\neBecause new treatments that truly work are rare,\nwe generally recommend a power of 90%.f\n\nWhich is eﾀ error = 0.1f.h\nMe: gThen for my study,\ncanft I just say eLetfs also take 250 patientsf\nand call it a day?h\nDad: gThatfsc crude, but honestly not far off.\nYoufll see in a moment that\nyour required sample size is in that ballpark.\nBut instead of guessing,\nlet me show you actual sample size numbers\nin a simple setting, and wefll decide more carefully.h\n\n\n\nSample size tables for comparing two survival curves\nDad: gThere are many possible scenarios,\nbut Ifll show you the most commonly used settings:\n\nTwo-sided = 0.05\n\nﾀ = 0.2 (power = 0.8)\n\nor ﾀ = 0.1 (power = 0.9)\n\nWefll assume:\n\ntwo groups with equal size (allocation ratio 1:1),\n\nand we compare their survival probabilities at a fixed time\nusing methods like the log-rank test.\n\nThe sample sizes Ifm about to show\ncome from Machin et al.fs table for comparing two survival curves.\nWe denote the survival probabilities in the two groups by:\n\nﾎ? and ﾎ?.\n\nIn your research,\nthese will correspond to non-return-to-work probabilities\n(i.e., 1 minus the return-to-work rate).h\n\n\nTable 1. Sample sizes for comparing two survival curves (power 80%)\n\nTwo-sided = 0.05, power = 0.8 (ﾀ = 0.2)\n\nValues are total sample size (sum of the two groups, 1:1 allocation)\n\n\n\n\nﾎ?  ﾎ?\n0.10\n0.20\n0.30\n0.40\n0.50\n0.60\n0.70\n0.80\n\n\n\n\n0.15\n964\n?\n?\n?\n?\n?\n?\n?\n\n\n0.20\n296\n?\n?\n?\n?\n?\n?\n?\n\n\n0.25\n156\n1826\n?\n?\n?\n?\n?\n?\n\n\n0.30\n102\n506\n?\n?\n?\n?\n?\n?\n\n\n0.35\n74\n246\n2486\n?\n?\n?\n?\n?\n\n\n0.40\n58\n152\n658\n?\n?\n?\n?\n?\n\n\n0.45\n48\n104\n308\n2894\n?\n?\n?\n?\n\n\n0.50\n42\n78\n182\n744\n?\n?\n?\n?\n\n\n0.55\n36\n62\n122\n340\n3034\n?\n?\n?\n\n\n0.60\n32\n52\n90\n198\n764\n?\n?\n?\n\n\n0.65\n28\n42\n70\n130\n342\n2900\n?\n?\n\n\n0.70\n26\n38\n54\n92\n194\n712\n?\n?\n\n\n0.75\n24\n34\n38\n70\n124\n312\n2492\n?\n\n\n0.80\n22\n30\n38\n56\n86\n174\n592\n?\n\n\n0.85\n22\n26\n34\n46\n66\n110\n254\n1818\n\n\n0.90\n20\n26\n30\n38\n50\n136\n136\n414\n\n\n\n\n\n\nTable 2. Sample sizes for comparing two survival curves (power 90%)\n\nTwo-sided = 0.05, power = 0.9 (ﾀ = 0.1)\n\nValues are total sample size (sum of the two groups, 1:1 allocation)\n\n\n\n\nﾎ?  ﾎ?\n0.10\n0.20\n0.30\n0.40\n0.50\n0.60\n0.70\n0.80\n\n\n\n\n0.15\n1290\n?\n?\n?\n?\n?\n?\n?\n\n\n0.20\n396\n?\n?\n?\n?\n?\n?\n?\n\n\n0.25\n208\n2444\n?\n?\n?\n?\n?\n?\n\n\n0.30\n136\n676\n?\n?\n?\n?\n?\n?\n\n\n0.35\n100\n330\n3330\n?\n?\n?\n?\n?\n\n\n0.40\n78\n202\n880\n?\n?\n?\n?\n?\n\n\n0.45\n64\n138\n412\n3876\n?\n?\n?\n?\n\n\n0.50\n54\n104\n242\n996\n?\n?\n?\n?\n\n\n0.55\n46\n82\n162\n454\n4060\n?\n?\n?\n\n\n0.60\n42\n68\n120\n264\n1022\n?\n?\n?\n\n\n0.65\n38\n56\n90\n172\n456\n3880\n?\n?\n\n\n0.70\n34\n48\n72\n124\n258\n952\n?\n?\n\n\n0.75\n32\n42\n60\n92\n166\n416\n3336\n?\n\n\n0.80\n30\n40\n52\n74\n116\n232\n796\n?\n\n\n0.85\n28\n34\n46\n60\n88\n146\n338\n2436\n\n\n0.90\n26\n32\n38\n50\n68\n100\n180\n548\n\n\n\n\n\n\n\nMapping this to the return-to-work study\nDad: gNow, back to your project.\nFor the cancer survivor study,\nwe have two groups:\n\nWITH STOMA\n\nWITHOUT STOMA\n\nIfm going to treat ereturned to workf as the event,\nand analyze time to return-to-work as a survival outcome.\nLetfs think in terms of 1-year follow-up.\nIn the tables:\n\nﾎ? and ﾎ? are survival probabilities at 1 year.\n\nFor your study,\nthat corresponds to the probability of not returning to work\nwithin 1 year in each group.h\nMe: gSo if the 1-year return-to-work rates are:\n\n80% in the non-stoma group,\n\n60% in the stoma group,\n\nthen:\n\nnon-return probabilities are 0.2 and 0.4,\n\nso we plug in ﾎ? = 0.2, ﾎ? = 0.4.h\nDad: gExactly.\nNow look at Table 2 (power 90%), at ﾎ? = 0.2, ﾎ? = 0.4.h\nMe: gI see 202 there.\nSo we need 202 patients total?h\nDad: gYes ? in this simplified setting.h\nMe: gAnd if we can tolerate power 80%?h\nDad: gThen in Table 1,\nfor ﾎ? = 0.2, ﾎ? = 0.4,\nyoufll find 152.\nSo:\n\npower 90% about 202 patients\n\npower 80% about 152 patientsh\n\nMe: gHmmc\nStill feels big. I was thinking e100fch\n\n\n\nSurvival curves, log-rank test, and Cox regression\nMe: gIfm still a bit confused.\nIn JCOG9502, they compared two survival curves, right?h\nDad: gRight.h\nMe: gIn my study, wefre interested in the relationship between:\n\nstoma (yes/no) and\n\nreturn-to-work status.\n\nEarlier, you told me:\n\nfor binary data, we often use logistic regression\n\nfor survival data, we use Cox regression\n\nBut these tables are about comparing survival curves.\nIs that the same as running a Cox regression?h\nDad: gGood question.\nThe p-value for comparing two survival curves\ncan be obtained in several ways:\n\nLog-rank test\n\nCox proportional hazards model, and others.\n\nThe tables wefre using here\nwere originally made for the log-rank test.\nHowever, if the only covariate is group (stoma vs no stoma),\nthen:\n\nthe log-rank test and\n\nthe Cox model\n\ngive almost the same result,\nespecially with a moderate or large sample size.\nSo itfs fine to think of these tables\nas roughly applicable to the Cox model too.h\nMe: gOkay, so in the simplest two-group comparison,\nlog-rank and Cox are basically aligned.h\n\n\n\nWhat if group sizes are not 1:1?\nMe: gTherefs something else.\nThe tables say eallocation ratio 1:1f.\nThat means equal numbers in the two groups, right?h\nDad: gRight.\nMost randomized trials aim for 1:1 allocation.h\nMe: gBut in an observational study of cancer survivors,\nIfm guessing:\n\npatients with stoma will be fewer than\n\npatients without stoma.\n\nMaybe stoma is about half as common?h\nDad: gExactly.\nIn surveys and observational studies,\ngroup sizes are usually not equal.\nThe tables I showed are based on 1:1 allocation,\nbut when the settings get more complex,\nyou normally use:\n\nthe software supplied with the book, or\n\nan R package.\n\nHere we can use the R package powerSurvEpi.\nLetfs assume:\n\nReturn-to-work rate in stoma group = 60%\n\nReturn-to-work rate in non-stoma group = 80%\n\nThen the 1-year non-return probabilities are:\n\npE = 0.4 (event = not returning; here wefre parameterizing via return)\n\npC = 0.2\n\nTo go from these probabilities to a hazard ratio,\nwe can use the relationship between survival probability and hazard\nfrom the exponential model:\n\nsurvival = (1 ? p) = exp(?ﾉt)\n\nand rearrange to get a rough hazard ratio from the two probabilities.h\n\n\n\nSample size design using the powerSurvEpi package\n```r # install.packages(“powerSurvEpi”) # if needed library(powerSurvEpi)\nssizeCT.default( power = 0.9, k = 1, # allocation ratio (nE : nC) pE = 0.6, # return-to-work rate in stoma group pC = 0.8, # return-to-work rate in non-stoma group RR = log(1 - 0.8) / log(1 - 0.6), # approximate HR from return rates alpha = 0.05 )\n\n\n\nExample output:\n\n\nnE nC\n\n\n100 100\nMe: gSo with power = 0.9 and equal group sizes (k = 1), we need 100 stoma patients and 100 non-stoma patients, total 200.h\nDad: gRight.\nNow letfs change the allocation ratio:\nk = 0.5 2:1 (non-stoma : stoma)\nk = 0.25 4:1h\nr R[hRs[・ ssizeCT.default( power = 0.9, k = 0.5, # allocation ratio 1:2 pE = 0.6, pC = 0.8, RR = log(1 - 0.8) / log(1 - 0.6), alpha = 0.05 ) r R[hRs[・ # nE nC # 59 118 r R[hRs[・ ssizeCT.default( power = 0.9, k = 0.25, # allocation ratio 1:4 pE = 0.6, pC = 0.8, RR = log(1 - 0.8) / log(1 - 0.6), alpha = 0.05 ) r R[hRs[・ # nE nC # 41 161 Dad: gSo when:\nk = 1 (1:1): nE + nC = 100 + 100 = 200\nk = 0.5 (1:2): nE + nC = 59 + 118 = 177\nk = 0.25 (1:4): nE + nC = 41 + 161 = 202\nThe total sample size shifts a bit, but you still need plenty of patients.h\nMe: gWowc The sample size is larger than I expected. Ifll have to think about adding more participating hospitals.h\nDad: gI know the feeling.\nWhen you design a study strictly from a frequentist perspective ? controlling and ﾀ and using proper sample size calculations ? people almost always say:\neTherefs no way we can recruit that manycfh\nMe: gcThatfs exactly my reaction.h\nDad: gBut now that you understand what , ﾀ, power, and sample size mean,\nyoufre starting to say:\neItfs tough, but if I want a study to have real statistical value, then I have to aim for these numbers.f\nThatfs a key mindset shift.h\nMe: gTrue. If you imagine your study being repeated 1000 times, and in 200 of those the result fails to detect a true effect just because it was underpoweredc\nIfd hate to be that one failed realization.h\nDad: gExactly. Frequentist thinking is about imagining those repeated experiments in your head.\nOnce you internalize that, you start to see what it means for a study to be statistically trustworthy.h\nReferences Machin D, Campbell MJ, Tan SB, Tan SH. Sample Size Tables for Clinical Studies, 4th ed. (Japanese edition: 繩ŵ߂̃TvTCY݌v). Kyoto University Press; 2022.\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M; Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol. 2006;7(8):644?651.\nEnd of the episode on Frequentist thinking This is the last episode of the Frequentist thinking mini-series.\nFrom here, you now have:\nan intuition for p-values and what they are not,\na feel for 95% CIs as long-run properties of methods,\nand a practical sense of , ﾀ, power, and sample size.\nIn the next series, the father and daughter will move on to:\nEffects and time ? where we think more deeply about what kind of effect we are estimating and at which time points it matters."
  },
  {
    "objectID": "en/frequentist-3.html",
    "href": "en/frequentist-3.html",
    "title": "Story and Quiz ? Frequentist thinking III",
    "section": "",
    "text": "Story and Quiz ? Frequentist thinking III\nKeywords: OS/PFS/DFS/response, p-value, survival/competing-risk, clinical trial\n\n\nHow to interpret p-values the right way\nDad: “Remember when we talked about the survival curves and p-values in the JCOG9502 trial (Sasako et al. 2006)?\nThere’s something that’s been bothering me.\nWhy is it that p &lt; 0.05 is treated as the magic line for ‘statistical significance’?”\nMe: “Isn’t that just… the rule?”\nDad: “That’s exactly the problem.\nIf you treat it as a rule, you’ll misread papers.\nLet me ask: when you read a paper, you start from the Abstract, right?\nWhere do you usually go next?”\nMe: “The Results section, obviously.\nI want to know what they found as soon as possible.”\nDad: “I totally get that.\nBut when it comes to p-values,\nif you jump straight to the numbers without context,\nyou’re almost guaranteed to misunderstand them.\nThere has been so much confusion about p-values\nthat the American Statistical Association (ASA)\nactually issued an official statement\nfor non-statisticians?researchers, practitioners, science writers?\nto clarify what p-values can and cannot do.\nThe story started with this Q&A posted in an ASA forum back in 2014.”\nMe: “Hit me.”\nDad: “Paraphrasing:\n\nQ: Why do so many colleges and grad schools teach ‘p ? 0.05’?\nA: Because that’s what journals and the scientific community use.\n\n\nQ: Why do so many people still use ‘p ? 0.05’?\nA: Because that’s what they were taught in college and grad school.\n\nKind of a statistical Zen riddle, isn’t it?”\nMe: “Yeah, that’s circular enough to be called a koan.”\n\n\n\nThe ASA’s six principles (in plain language)\nDad: “In 2016, the ASA summarized six principles to promote better use and interpretation of p-values.”\nMe: “Can you translate those into normal human language?”\nDad: “Let me try. In my own words:\n\nA p-value is one measure of how incompatible the data are\nwith a specific statistical model (including the null hypothesis).\n\nA p-value is not\n\nthe probability that the hypothesis is true, or\n\nthe probability that the data came from ‘chance alone’.\n\n\nScientific conclusions and policy decisions should not rest solely on\nwhether a p-value is smaller or larger than some fixed cutoff.\n\nTo draw proper inferences, you need transparency:\nall analyses, not just the convenient ones, must be reported.\n\nA small p-value does not automatically mean\nthe effect is large or important.\n\nA p-value, by itself, is a weak piece of evidence\nabout models or hypotheses.\n\nThe big picture is:\n\nYou can’t interpret a p-value correctly\nwithout looking at the whole research process?\nstudy design, data collection, analysis choices,\nand how many tests were actually run.”\n\nMe: “So when people treat p &lt; 0.05 as a magic ‘publish’ button,\nthey’re ignoring basically all of that.”\nDad: “Exactly.”\n\n\nMe: “So that earlier exchange sparked a discussion at the conference about how to use p-values, huh? But it’s all pretty abstract and doesn’t really click for me.”\n\n\nDad: “Oh? I think it’s pretty clearly stated that ‘scientific conclusions should not be based solely on whether they exceed the significance level.’ Take the JCOG9502 paper—Principles 3 and 5 say we shouldn’t just look at the p-value, but carefully observe the survival curves before drawing conclusions. Of course, without specialized knowledge, it’s hard to grasp what the principles are aiming for. Principle 4, for example, relates to the issue of multiplicity.”\n\n\nMe: “Multiplicity?”\n\n\nDad: “In recent clinical trials, a statistical issue called multiplicity often lurks. Let me explain a bit more using the JCOG9502 paper as an example. Go back and read the section on Statistical Analysis. Alpha error, also called the significance level, refers to the threshold level compared to the p-value.”\n\n\n\nMultiplicity and selective inference: the ‘best’ p-value trap\nDad: “Look at Principle 4 again?about transparency.\nThe ASA statement warns that if you:\n\nrun many different analyses,\n\nthen only report the nicest-looking p-values,\n\nthose p-values are basically no longer interpretable.\nIn plain language:\n\nIf you fish long enough,\nyou’ll almost always catch something ‘significant’.”\n\nMe: “So this is what people call p-hacking or selective reporting, right?”\nDad: “Yes.\nIt’s a major reason why journals end up full of false positives.\nStatisticians call this whole mess multiplicity\nor selective inference.”\nMe: “So when I see a surprising p-value in a paper,\nI should quietly wonder:\n\n‘How many analyses did they really run\nbefore selecting this one?’”\n\nDad: “That’s the right instinct.”\n\n\n\nReading JCOG9502: why α = 0.1 shows up\nDad: “Let’s go back to JCOG9502 for a moment.\nTake another look at their Statistical Analysis section.\nThey say (paraphrased):\n\nAfter 8 years of slow accrual,\nthe data and safety monitoring committee\napproved an amendment to the sample size and analysis plan.\nThe amended plan used a total sample size of 250 patients,\none-sided alpha = 0.1,\nand beta = 0.2,\nwith 12 years of accrual and 8 years of follow-up.\n\nMe: “Wait.\nThey’re comparing p to 0.1?\nNot 0.05?”\nDad: “Yes.\nBecause recruitment was difficult,\nthey relaxed the significance level to 0.1\nas a kind of last resort.\nStrictly speaking,\nyou don’t want to change the alpha level mid-trial.\nBut the clinical question was important,\nand the trial still provided useful information,\nso it was written up and widely read.”\nMe: “I totally skipped that part.\nJCOG is… surprisingly flexible.”\n\n\n\nMultiple p-values in one figure: what do we read?\nDad: “Now look closely at the survival figures in JCOG9502.\nYou’ll see:\n\ntwo curves in Figure A (overall survival),\n\ntwo curves in Figure B (disease-free survival),\n\nand four p-values printed around them:\none-sided and two-sided for each.”\n\nMe: “That’s exactly why I came to you.\nI did think about it, you know.\nSince overall survival (OS) is the primary endpoint,\nFigure A is the main one to look at.\nBut even just in Figure A\nthere’s a one-sided p and a two-sided p.\nThat’s where my brain stalled.”\nDad: “The logic isn’t too bad once you separate policy from math.\nIn a typical clinical trial comparing:\n\na test treatment and\n\na standard treatment,\n\nwe can do:\n\na one-sided test:\ndeclare significance only if the test arm is better, or\n\na two-sided test:\nconsider both ‘test better’ and ‘test worse’ as important.”\n\nMe: “The JCOG9502 protocol said:\n\nLTA = test treatment\n\nTH = standard treatment\n\nprobably because LTA is more invasive,\nso they were hoping it would improve survival.\nSo they only wanted to declare success\nif LTA clearly beat TH.\nThat’s a one-sided hypothesis, right?”\nDad: “Exactly.\nBut here comes the twist:\n\nIn most modern trials,\ntwo-sided p-values are the default.\n\nJCOG, however, has a tradition of focusing on\n‘Is the experimental treatment better than standard?’\nand uses one-sided p-values accordingly.\n\nIn JCOG9502:\n\nthe one-sided p-values are used\nfor the primary decision about effectiveness,\n\nwhile the two-sided p-values are effectively\nprovided as reference.\n\nSo for the main efficacy question,\nFigure A’s one-sided p-value is the key.”\nMe: “Okay.\nThen for my project?\ncomparing return-to-work between stoma vs no stoma?\nthere’s no natural ‘test’ vs ‘standard’ treatment.\nSo I should stick with two-sided p-values.”\nDad: “Exactly.\nFrom both a statistical and clinical perspective,\ntwo-sided makes more sense there.”\n\n\n\nOne-sided vs two-sided p-values: the coin example\nDad: “Let’s step away from cancer trials and use a coin toss.\nSuppose you toss a coin and get six heads in a row.\nIs the coin biased?”\nMe: “Intuitively, it feels suspicious.”\nDad: “Under the null hypothesis:\n\nThe coin is fair; probability of heads = 1/2.\n\nthe probability of six heads in a row is:\n\n(1/2)? = 0.015625\n\nAnd the probability of six tails in a row is the same.\nIf you define ‘extreme’ as\n‘all outcomes on one side of the coin’, then:\n\none-sided p-value (heads only) ? 0.0156\n\ntwo-sided p-value (heads or tails) ? 0.0312\n\nSo:\n\none-sided p looks only at ‘heads-side extremeness’\n\ntwo-sided p looks at extremeness in either direction.”\n\nMe: “So for a cancer trial:\n\none-sided p-value:\n‘Do we see a difference in the expected direction\n(test treatment better)?’\n\ntwo-sided p-value:\n‘Do we see a difference,\nin either direction?’”\n\nDad: “Exactly.”\n\n\n\nThe frequentist mindset: repeating the trial in your head\nDad: “Back to JCOG9502.\nIn hypothesis testing we usually follow three steps:\n\nSpecify the hypotheses.\nIn JCOG9502, the two plausible truths are:\n\n‘LTA improves overall survival compared with TH’, or\n\n‘LTA has no effect on overall survival compared with TH’.\n\nHypothesis testing focuses on the ‘no effect’ statement\nas the null hypothesis.\nImagine the data under the null.\nThink about repeating the same randomized trial\nwith the same 167 patients\n(or an equivalent population) 1,000 times.\nThat’s the frequentist mindset:\neven if there’s truly no difference,\nrandom variation means sometimes LTA looks better,\nsometimes TH looks better,\nbut over many repetitions,\nthe observed differences will cluster around zero.\nCompare the actual data to that imagined distribution.\nThe p-value is:\n\nthe probability, under the null hypothesis,\nof getting a difference in survival curves\nat least as extreme as what we observed.\n\n\nIf the p-value is small, we say:\n“This kind of extreme difference\nwould almost never happen by chance alone\nif the survival curves were truly equal.”\nSo we reject the null.\n\nIf the p-value is large, we say:\n“This is the kind of difference\nthat happens all the time under the null.”\nSo we don’t reject the null.”\n\n\nMe: “So:\n\np-value =\n‘How surprising is our observed difference\nif the survival curves were actually the same?’\n\nnot:\n\n‘What’s the probability that the curves are the same?’”\n\nDad: “Exactly.”\n\n\n\nA quiz related to this episode\nIn most randomized clinical trials\n(excluding non-inferiority and equivalence trials),\nwhy are two-sided p-values used as the default?\n\nBecause we want to draw conclusions\nwhether the test treatment is better or worse\nthan the control whenever there is a difference.\n\nBecause statisticians agreed on it as a technical rule.\n\nBecause international regulators decided\nto standardize on two-sided p-values\nto avoid confusion across trials.\n\nBecause random error can fluctuate\nin both the positive and negative direction.\n\nAnswer\nThe intended best answer is 3.\nThis is largely a matter of regulatory history and harmonization.\n\nIn 1998, the ICH E9 guideline on Statistical Principles for Clinical Trials\nwas agreed upon by regulators in the US, Europe, and Japan.\n\nAs part of that harmonization,\nusing two-sided p-values as the default\nbecame standard practice for confirmatory trials.\n\nOf course:\n\n1 and 4 contain reasonable intuition about\nwhy two-sided testing is often appropriate,\nbut the main reason we see two-sided p-values\nin almost all registrational trials today\nis this international agreement.\n\nIn short:\n\nTwo-sided p-values are the default\nnot because 0.05 is sacred,\nbut because regulators decided\nthat the world needed a common convention.”\n\n\n\n\nReferences\n\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M; Japan Clinical Oncology Group (JCOG9502).\nLeft thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial.\nLancet Oncol. 2006;7(8):644?651.\nWasserstein RL, Lazar NA.\nThe ASA’s statement on p-values: Context, process, and purpose.\nThe American Statistician. 2016;70(2):129?133.\nInternational Conference on Harmonisation (ICH).\nE9: Statistical principles for clinical trials. 1998.\n(Japanese commentary) Yoshimura I.\nOn significance levels and the number of confirmatory clinical trials.\nJapanese Journal of Biometrics. 2003;24:S3?S9.\n\n\n\n\nContinuation of their story\n\nStudy design I\n\nStudy design II\n\nStudy design III\n\nStudy design IV\n\nStudy design V\n\nFrequentist thinking I\n\nFrequentist thinking II\n\nFrequentist thinking III (this page)\n\nFrequentist thinking IV (coming soon)\n\nFrequentist thinking V (coming soon)"
  },
  {
    "objectID": "en/frequentist-1.html",
    "href": "en/frequentist-1.html",
    "title": "Story and Quiz ? Frequentist thinking I",
    "section": "",
    "text": "Story and Quiz ? Frequentist thinking I\nKeywords: OS/PFS/DFS/response, p-value, survival/competing risks, clinical trial\n\n\nReading the numbers around a survival curve\n\nRecap from the previous series\nA junior doctor in Japan is starting her first research project,\nguided (sometimes pushed) by her statistician father.\nWith his help, she learned to use PICO/PECO to frame a question,\nand decided to study the relationship between stoma and\nreturn-to-work among cancer survivors.\nShe also learned that the same clinical question can be analyzed\nas binary data or survival time data.\nNow, her boss has recommended a surgical oncology paper,\nand she’s trying to decode the graphs.\n\n\nMe: “Dad, are you still awake? I’m making coffee.”\nDad: “If there’s coffee, I’m awake.\nWhat are you reading?”\nMe: “Thanks. And milk, please.\nI’m reading this gastric cancer surgery paper.\nIt’s a randomized trial called JCOG9502 that compares two surgical approaches.\nYou know, you explained OS and DFS to me the other day,\nand now they’re all over this paper. I thought I should actually understand them.”\nDad: “JCOG9502… yes, that’s the trial comparing\ntwo surgical approaches for tumors near the cardia.” :contentReferenceoaicite:0\nMe: “Right. They randomized patients to:\n\na standard transhiatal approach (the TH group), and\n\na left thoracoabdominal approach (the LTA group).\n\nThere’s a figure with two Kaplan?Meier curves:\n\nFigure A: overall survival (OS)\n\nFigure B: disease-free survival (DFS)\n\nIn both, the TH group (blue) looks better than the LTA group (red).\nSo far so good ? lower curve = worse outcome.\nBut what’s confusing me is all the numbers around the curves.”\nDad: “Let me guess: the number at risk and the little marks on the curves.”\nMe: “Exactly.\nUnder each figure there’s a row of numbers ?\nthat’s the number at risk, right?\nHere’s the first thing that bothered me:\nAt time zero, the numbers don’t match between OS and DFS.\n\nIn the OS figure, it’s 82 vs 85.\n\nIn the DFS figure, it’s 76 vs 75.\n\nSame trial, same randomization…\nso why are they analyzing different numbers of patients?”\nDad: “Good catch.\nIn a randomized trial, you usually start with the same number in each arm.\nIf the analysis set is smaller,\nit’s often because the outcome definition requires a certain condition.\nFor DFS, you need to know whether\nthe tumor was completely resected and then followed for recurrence.\nDoes the paper say anything about ‘R0 resection’?”\nMe: “Let me check…\nHere: it says 151 patients achieved R0 resection.\nSo they must be analyzing DFS only in those R0 patients\n? which explains why the DFS figure starts with fewer patients\nthan the OS figure.”\nDad: “Exactly.\nSo:\n\nOS: almost all eligible randomized patients\n\nDFS: only those with curative (R0) resection\n\nThat’s why the number at risk at time zero is different between the two plots.”\nMe: “Okay, that makes sense.\nThe other thing is the tail of the curves.\nAround year 7, the numbers at risk get really small ?\nonly a few patients left in each group.\nI was wondering:\ndoes that mean many patients were lost to follow-up?”\nDad: “Not necessarily.\nWe need to check:\n\naccrual period (when patients were enrolled), and\n\nfollow-up period (up to when outcomes were collected).”\n\nMe: “The paper says:\n\nRegistration period: 1995?2003\n\nSurvival data analyzed up to 2006\n\nSo accrual took about 8 years,\nand they followed up survival until 2006.”\nDad: “Right.\nThat means the minimum follow-up for the last patients enrolled\nis only about 3 years.\nSo:\n\nNot everyone gets 7+ years of follow-up.\n\nIt’s expected that the number at risk shrinks a lot in later years.\n\nFor survival time data,\nremember we talked about censoring before?\nSurvival data consists of:\n\nevents (like death), and\n\ncensored observations (end of follow-up without event).”\n\nMe: “I remember.\nBut the paper doesn’t list censoring times in a table.\nHow am I supposed to see them?”\nDad: “Look at the survival curves again.\nDo you see the little ticks on the lines?”\nMe: “These small vertical marks?”\nDad: “Yes. Those are the censoring symbols.\nEach tick marks a time when a patient was censored ?\nfor example, lost to follow-up or end of planned follow-up.\nIf you saw a ton of ticks very soon after time zero,\nyou’d worry:\n\n‘Are patients disappearing from follow-up\nright after enrollment?’\n\nThat could mean serious bias.”\nMe: “In this figure,\nthere are only a few ticks before year 3,\nand more after that.\nSo most patients were followed for at least 3 years,\nand later censoring is mainly due to the study ending,\nnot people disappearing.”\nDad: “Exactly.\nThat’s what you want to see.”\nMe: “So if I summarize what I’ve learned so far:\n\nNumber at risk = how many patients are still under observation\n(not yet had the event and not censored) at each time point.\n\nThe little ticks on the curve = censoring events.\n\nI should also check the accrual period and follow-up period\nto interpret long follow-up tails correctly.”\n\nDad: “Perfect summary.\nAlso, notice something else:\nfrom 1995 to 2006, this trial took over ten years\nto complete enrollment and collect survival data.\nEvery point on that curve\nrepresents a lot of work by clinicians, staff,\nand of course patients.”\nMe: “Yeah…\nlooking at the figure that way makes it feel heavier.”\n\n\n\nHazard ratio, confidence interval, and p-values\nMe: “By the way, around the curves,\nthere are all these stats words:\n\nhazard ratio\n\n95% CI\n\none-sided p\n\ntwo-sided p\n\nI know the English, but I don’t know if I really understand them.”\nDad: “In Japanese we usually say:\n\nハザード比 = hazard ratio\n\n95%信頼区間 = 95% confidence interval\n\n片側p値 = one-sided p-value\n\n両側p値 = two-sided p-value\n\nThese are classic frequentist summaries in survival analysis.\nMost of them come from Cox regression,\nwhich estimates hazard ratios between groups.”\nMe: “And we’re about to dive into those in this series, right?”\nDad: “Exactly.\nIn ‘Frequentist thinking’,\nwe’ll unpack:\n\nwhat hazard ratios actually mean,\n\nwhat a 95% confidence interval is (and isn’t), and\n\nwhat we’re really saying when we quote a p-value.”\n\nMe: “Okay.\nThen for now I’ll just memorize the names\nand wait for the proper explanations.”\n\n\n\nA quiz related to this episode\nSometimes clinicians use “remaining life expectancy”\nto explain prognosis after gastrectomy.\nLooking at the JCOG9502 figures,\ncan we read postoperative life expectancy directly from the curves?\n\nYes, from the OS Kaplan?Meier curve (Figure A).\n\nYes, from the DFS Kaplan?Meier curve (Figure B).\n\nNo, we can’t read it directly from either.\n\nAnswer\nThe best choice is 1.\nTo describe “how long patients live after surgery”,\nwe use overall survival time.\nTwo common summary measures are:\n\nthe mean survival time, and\n\nthe median survival time.\n\nFrom a Kaplan?Meier curve,\nthe median survival time is easier to read:\n\nSurvival time is a time-to-event variable (continuous-like).\n\nThe median is the time by which 50% of the patients have had the event.\n\nOn the OS curve, that corresponds to the time when\nthe survival probability drops to 50%.\n\nSo, if the OS curve reaches 50%,\nyou can read off the median survival time at that point.\nIn contrast, DFS mixes together:\n\nrecurrence,\n\nsecond cancers, and\n\ndeath.\n\nIt doesn’t directly answer\n“how long do patients live after surgery?”\nSo for “remaining life expectancy after surgery”,\nOS is the relevant curve.\n\n\n\nReferences\n\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M; Japan Clinical Oncology Group (JCOG9502).\nLeft thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia:\na randomised controlled trial. Lancet Oncol. 2006;7(8):644?651. :contentReferenceoaicite:1\n\n\n\n\nContinuation of their story\n\nStudy design I\n\nStudy design II\n\nStudy design III\n\nStudy design IV\n\nStudy design V\n\nFrequentist thinking I\n\nFrequentist thinking II (coming soon)"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Coffee and Research",
    "section": "",
    "text": "Shiro Tanaka is a biostatistician and currently Professor of Clinical Biostatistics at the Graduate School of Medicine, Kyoto University.\nHe has served as a trial statistician in translational research at Kyoto University Hospital, as well as in nationwide clinical trial groups in oncology (JCOG), pediatric oncology (JCCG) and osteoporosis (A-TOP). He is an advisory expert for the Pharmaceutical and Medical Devices Agency, a councilor for the Japanese Society for Pharmacoepidemiology and the Biometric Society of Japan, and serves on multiple editorial boards.\nHis training in causal inference and survival analysis has been shaped by work that crossed borders freely – books, open-source software, and resources shared by colleagues and collaborators around the world. He has been fortunate to work with researchers such as Marc A. Brookhart, Jason P. Fine, and Thomas H. Scheike. This site is his small way of giving back in the same spirit.\n\n\n\nIf you’ve ever wondered why my accounts are called gestimation, the name comes from g-estimation in causal inference — a class of methods introduced by James Robins. In my own work, I have found this approach very useful in clinical research:\n\nTanaka S, Matsuyama Y, Shiraki M, Ohashi Y. Estimating the effects of time-varying osteoporosis treatments on incidence of fractures among Japanese postmenopausal women. Epidemiology 2007;18(5):529–36.\nTanaka S, Brookhart MA, Fine JP. G-estimation of structural nested mean models for competing risks data using pseudo-observations. Biostatistics 2020;21(4):860–75.\nTanaka S, Brookhart MA, Fine JP. G-estimation of structural nested mean models for interval-censored data using pseudo-observations. Statistics in Medicine 2023;42(21):3877–91.\n\nThese are not required reading for the stories here. But if you ever feel like following the path from coffee chats → DAGs → g-estimation, this is one of the places it eventually leads."
  },
  {
    "objectID": "about/index.html#about-shiro-tanaka",
    "href": "about/index.html#about-shiro-tanaka",
    "title": "Coffee and Research",
    "section": "",
    "text": "Shiro Tanaka is a biostatistician and currently Professor of Clinical Biostatistics at the Graduate School of Medicine, Kyoto University.\nHe has served as a trial statistician in translational research at Kyoto University Hospital, as well as in nationwide clinical trial groups in oncology (JCOG), pediatric oncology (JCCG) and osteoporosis (A-TOP). He is an advisory expert for the Pharmaceutical and Medical Devices Agency, a councilor for the Japanese Society for Pharmacoepidemiology and the Biometric Society of Japan, and serves on multiple editorial boards.\nHis training in causal inference and survival analysis has been shaped by work that crossed borders freely – books, open-source software, and resources shared by colleagues and collaborators around the world. He has been fortunate to work with researchers such as Marc A. Brookhart, Jason P. Fine, and Thomas H. Scheike. This site is his small way of giving back in the same spirit."
  },
  {
    "objectID": "about/index.html#why-gestimation",
    "href": "about/index.html#why-gestimation",
    "title": "Coffee and Research",
    "section": "",
    "text": "If you’ve ever wondered why my accounts are called gestimation, the name comes from g-estimation in causal inference — a class of methods introduced by James Robins. In my own work, I have found this approach very useful in clinical research:\n\nTanaka S, Matsuyama Y, Shiraki M, Ohashi Y. Estimating the effects of time-varying osteoporosis treatments on incidence of fractures among Japanese postmenopausal women. Epidemiology 2007;18(5):529–36.\nTanaka S, Brookhart MA, Fine JP. G-estimation of structural nested mean models for competing risks data using pseudo-observations. Biostatistics 2020;21(4):860–75.\nTanaka S, Brookhart MA, Fine JP. G-estimation of structural nested mean models for interval-censored data using pseudo-observations. Statistics in Medicine 2023;42(21):3877–91.\n\nThese are not required reading for the stories here. But if you ever feel like following the path from coffee chats → DAGs → g-estimation, this is one of the places it eventually leads."
  },
  {
    "objectID": "en/frequentist-2.html",
    "href": "en/frequentist-2.html",
    "title": "Story and Quiz ? Frequentist thinking II",
    "section": "",
    "text": "Story and Quiz ? Frequentist thinking II\nKeywords: OS/PFS/DFS/response, p-value, survival/competing risks, clinical trial\n\n\nSurvival curves and hazard ratios\n\nRecap\nOur junior doctor in Japan is reading the JCOG9502 gastric cancer trial,\ncomparing two surgical approaches:\n\nTH: transhiatal approach\n\nLTA: left thoracoabdominal approach\n\nIn Frequentist thinking I, she learned how to read the Kaplan?Meier curves\nand the numbers at risk.\nNow she wants to understand the hazard ratios printed next to the curves.\n\n\nMe: “Dad, coffee refill.\nCan we keep talking about JCOG9502 and these hazard ratios?”\nDad: “Thanks. Let’s do it.\nYou’re looking at:\n\nFigure A: hazard ratio of death = 1.36\n\nFigure B: hazard ratio of recurrence or death = 1.29\n\nBoth summarize the difference between the TH and LTA groups.\nHere the LTA group has worse prognosis,\nso its hazard is higher,\nand the Kaplan?Meier curve for LTA lies below the TH curve.”\nMe: “The paper says ‘hazard ratio 1.36’,\nbut visually it just looks like one curve is sitting below the other.\nWhat does it mean to say it ‘summarizes’ the difference?”\nDad: “Look at the shape of the curves:\n\nThe TH curve is nicely above the LTA curve\n\nThey don’t really cross,\nexcept maybe at the far right where only a handful of patients remain\n\nThat’s exactly the kind of situation\nwhere a single hazard ratio summarizes the difference well.”\nMe: “Because the curves are ‘roughly parallel’, right?”\nDad: “Yes ? in a log-hazard sense.\nThe Cox proportional hazards model assumes:\n\nThe hazard in one group\nis a constant multiple of the hazard in the other group\nover time.\n\nThat’s the proportional hazards assumption.\nIf the curves cross a lot,\nor get closer then farther apart,\na single hazard ratio is harder to interpret.”\nMe: “So if they cross badly,\nthe model is forcing a single number on something\nthat doesn’t really have a single-number story.”\nDad: “Exactly.\nIn JCOG9502, both OS and DFS curves look fairly well behaved,\nand the hazard ratios for OS and DFS point in the same direction.\nThat makes the results very interpretable.”\nMe: “Okay, that’s the big picture.\nNow, how do we actually get a hazard ratio in R?”\nDad: “Time to meet coxph() from the survival package.”\n\n\n\nEstimating the hazard ratio with coxph()\nDad: “Remember the simulation function we used earlier, generate_data()?\nIt creates:\n\na stoma group and a non-stoma group, and\n\nsurvival times for overall survival (OS) and other endpoints.\n\nWe’ll use that again.”\n```r generate_data &lt;- function(n = 200, hr1, hr2) { # Stoma: 1 = with stoma, 0 = without stoma stoma &lt;- rbinom(n, size = 1, prob = 0.4) # Sex: 0 = WOMAN, 1 = MAN sex &lt;- rbinom(n, size = 1, prob = 0.5) # Age: stoma group slightly older age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n# Hazards (larger = earlier event) hazard_relapse &lt;- ifelse(stoma == 1, hr1 * 0.10, 0.10) hazard_death &lt;- ifelse(stoma == 1, hr2 * 0.10, 0.10) hazard_censoring &lt;- 0.05\n# Latent times t_relapse &lt;- rexp(n, rate = hazard_relapse) t_death &lt;- rexp(n, rate = hazard_death) t_censoring &lt;- rexp(n, rate = hazard_censoring)\n## — Overall survival (OS) — time_os &lt;- pmin(t_death, t_censoring) status_os &lt;- as.integer(t_death &lt;= t_censoring) # 1 = death, 0 = censored\n## — Relapse-free survival (RFS) — time_rfs &lt;- pmin(t_relapse, t_death, t_censoring) status_rfs &lt;- integer(n) status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # relapse status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1 # death\n## — Cumulative incidence of relapse (CIR) with competing risk — time_cir &lt;- pmin(t_relapse, t_death, t_censoring) status_cir &lt;- integer(n) status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # event 1: relapse status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2 # event 2: death\ndata.frame( id = 1:n, sex = factor(sex, levels = c(0, 1), labels = c(“WOMAN”, “MAN”)), age = age, stoma = factor(stoma, levels = c(0, 1), labels = c(“WITHOUT STOMA”, “WITH STOMA”)), time_os = time_os, status_os = status_os, time_rfs = time_rfs, status_rfs = status_rfs, time_cir = time_cir, status_cir = status_cir ) }\nNow fit a Cox model for overall survival:\n\n\n\ninstall.packages(“survival”) # if needed\nlibrary(survival)\nset.seed(46) dat &lt;- generate_data(hr1 = 2, hr2 = 1.5) # true HR for death = 1.5\nfit &lt;- coxph(Surv(time_os, status_os) ~ stoma, data = dat) summary(fit)\nYou might see an output like:\nn= 200, number of events= 140\n              coef exp(coef) se(coef)    z  Pr(&gt;|z|)\nstomaWITH STOMA 0.277 1.319 0.171 1.62 0.105\n          exp(coef) exp(-coef) lower .95 upper .95\nstomaWITH STOMA 1.319 0.758 0.944 1.843\nMe: “Okay, so:\nexp(coef) = 1.319 → the estimated hazard ratio (WITH STOMA vs WITHOUT STOMA)\np-value ? 0.10 → not ‘significant’ at the 0.05 level.\nRoughly speaking, that means:\n‘Survival tends to be worse in the stoma group, but the difference is not statistically significant.’\nRight?”\nDad: “As a first pass, yes.\nAlso notice:\nexp(coef) = 1.319 is close to the true HR we built into the data: 1.5\nThe 95% CI (about 0.94 to 1.84) includes 1, which matches the p-value being &gt; 0.05.”\nMe: “And hazard ratio itself is… a kind of rate ratio, right?”\nDad: “Exactly:\nThe hazard is like an instantaneous event rate (events per person-time).\nThe hazard ratio compares those rates between two groups.\nOther measures like risk ratios and odds ratios don’t account for follow-up time, so they’re not the main characters in survival analysis.\nIf you’re studying cancer clinical trials, you really want to be comfortable with hazard ratios. That’s where books like Clinical Trials in Oncology by the SWOG statisticians are very helpful. ”\nWhat p-values are not\nMe: “About p-values though…\nI’ve been saying things in journal club like:\n‘p &lt; 0.05, so the result is significant,’\nwithout feeling I actually understand them.\nLet me try to say what I thought they meant:\n‘The hazard ratio is less than 1, so LTA is worse than TH.’\n‘If p &lt; 0.05, it’s statistically significant, so we’ve found something scientifically important.’\n‘If p ? 0.05, there’s no significant difference, so we can say the treatments are equivalent.’\nIs that all wrong?”\nDad: “Some of it is okay, but the details matter.\nLet’s look at three common statements people make about p-values:\n‘The p-value is the probability that the null hypothesis is true.’\n‘If the p-value is small and statistically significant, that means we’ve found a scientifically important result.’\n‘If the result is not statistically significant, we should accept the null hypothesis as true.’\nWe’ll poke holes in each of these.”\n\n“p is the probability the null is true”\n\nDad: “In JCOG9502, a natural null hypothesis is:\nH?: ‘The survival curves of the LTA and TH groups are equal.’\nDo you think the p-value is ‘the probability that H? is true’?”\nMe: “Honestly? That’s what I’ve been telling myself.”\nDad: “Let’s be a bit pedantic for a moment.\n‘H? is true’ is a statement, a proposition. It’s either true or false. It’s not a random variable.\nIn the frequentist framework, we define probabilities for random events (like results of repeated trials), not for truth values of hypotheses.\nSo saying ‘p is the probability that H? is true’ isn’t really meaningful.”\nMe: “So the null hypothesis doesn’t have a ‘chance of being true’ in the frequentist world. It’s either true or not; we just don’t know which.”\nDad: “Exactly. The p-value is something else entirely ?we’ll come back to its proper definition in a later episode.”\n\n“Small p-value = scientifically important”\n\nDad: “Next: ‘If p is small and statistically significant, the result is scientifically important.’ True or false?”\nMe: “It feels true. When people present at conferences, everyone gravitates to the p&lt;0.05 results.”\nDad: “Look at the JCOG9502 paper again. They report several p-values, none particularly small.\nWould you say the trial was scientifically unimportant just because the p-values aren’t tiny?”\nMe: “No. The conclusion that LTA doesn’t beat TH and might actually be worse is clinically important, even if p isn’t spectacularly small.”\nDad: “Exactly.\nScientific importance depends on:\neffect size,\nclinical context,\nsafety profile,\ncost,\nand many other things.\np-values can flag results that are unlikely under the null, but they don’t tell you whether a result is medically meaningful, affordable, or practice-changing.”\nMe: “So:\n‘Small p = important’\nis a bad habit, not a theorem.”\nDad: “Right.”\n\n“Non-significant = treatments are equivalent”\n\nDad: “The third statement:\n‘If the result is not statistically significant, we should accept the null hypothesis as true.’\nWhat do you think?”\nMe: “I remember reading something like:\n‘p-values are designed for rejecting hypotheses, not for accepting them.’\nSo I guess this is wrong too. But in practice, people really do say ‘no significant difference → treatments are equivalent.’”\nDad: “In Japan, there was a period historically when non-inferiority trials were used as the basis for drug approval. Based on that experience, I think we really need to be careful about how we strictly define the relationship between research hypotheses and statistical criteria.”\nDad: “And that can be dangerous.\nIn drug development there’s a classic story about cerebral circulation-improving drugs in Japan.\nFor a long time, me-too drugs were compared to an older drug (ホパンテン酸カルシウム, often known as Hopate) and judged ‘non-inferior’ because there was no significant difference between the two.\nBut those studies weren’t properly designed as non-inferiority trials? they just said:\n‘p ? 0.05, so the new drug is not inferior.’\nLater, when placebo-controlled trials were finally done, none of those drugs proved clearly better than placebo, and the original reference drug was even withdrawn over safety concerns.\nIt’s often called the ‘Hopate tragedy’.”\nMe: “…yikes. So ‘non-significant’ was used as if it meant ‘good enough’, and then it turned out nothing was actually working.”\nDad: “Exactly.\nTo claim:\nequivalence (‘the two treatments are similar enough’), or\nnon-inferiority (‘new is not worse than standard by more than X’),\nyou need a specific study design and analysis:\npre-specified margins,\nappropriate sample size,\nand tests tailored to those hypotheses.\nJust seeing p ? 0.05 in a standard superiority test is not enough.”\nMe: “So let me summarize:\np is not the probability the null is true.\n‘Small p = scientifically important’ is wrong.\n‘Non-significant = treatments are equivalent’ is wrong.\nAnd statistics is pretty fussy about the difference between ‘no evidence of difference’ and ‘evidence of no difference.’”\nDad: “Beautifully put.”\nA small twist: significance level is not always 0.05\nDad: “One more nuance:\nWe often learn that:\n‘If p &lt; 0.05, the result is significant.’\nBut the significance level doesn’t have to be 0.05. In some trials, especially with interim analyses, the effective significance threshold is smaller.\nIn JCOG9502, there was an interim analysis, and the trial was stopped early because the LTA approach had little chance of ever beating TH ? a futility stopping, not a victory.\nSo even the ‘0.05’ part is not universal.”\nMe: “Right, so saying\n‘p &lt; 0.05 = significant’\nis already making an assumption about α. That’s okay as shorthand in some contexts, but not a definition of what a p-value is.”\nDad: “Exactly.”\nA quiz related to this episode\nFrom a frequentist perspective, which of the following statements about the p-value is correct?\nIt is the probability that the null hypothesis is true.\nIt is the probability that the alternative hypothesis is true.\nIf it is smaller than 0.05, the result is significant.\nNone of the above.\nAnswer\nThe best answer is 4: none of the above.\n1 and 2: In the frequentist framework, we do not assign probabilities to ‘the null is true’ or ‘the alternative is true’; hypotheses are not random variables.\n3: The threshold for ‘significance’ (the significance level, α) is chosen in advance and doesn’t have to be 0.05. With interim analyses or special designs, α may be lower than 0.05.\nThe (informal) textbook definition you may have seen is closer to:\n“The p-value is the probability, under the null hypothesis, of observing a result as extreme as or more extreme than the one actually observed.”\nEven that wording hides some subtleties, but it’s already very different from “the probability the null is true.”\nWe’ll unpack the formal definition and its implications in the next Frequentist thinking episodes.\nReferences\nSasako M, Sano T, Yamamoto S, et al.; Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol. 2006;7(8):644?651.\nGreen S, Benedetti J, Smith A, Crowley J. Clinical Trials in Oncology, 3rd ed. Chapman & Hall/CRC; 2012.\nPMDA and related reports on re-evaluation of cerebral circulation?improving drugs and placebo-controlled trials."
  },
  {
    "objectID": "en/frequentist-4.html",
    "href": "en/frequentist-4.html",
    "title": "Story and Quiz ? Frequentist thinking IV",
    "section": "",
    "text": "Story and Quiz ? Frequentist thinking IV\nKeywords: OS/PFS/DFS/response, survival/competing-risk, clinical trial\n\n\ngDad, is that 95% confidence interval really 95%?h\nDad: gCoffeefs ready.h\nMe: gPerfect, thanks. Soc therefs something Ifve been wondering.\nPeople say ethis is a 95% confidence intervalf in such a matter-of-fact way.\nBut is it really 95%? Like, does it actually hit the true value 95% of the time?h\nDad: gGood question.\nUnder the assumed probability model, yes ? in theory it does.\nWe can even prove it mathematically.h\nMe: gSo itfs just true.\nAlmost never wrong. That soundsc suspiciously strong.h\nDad: gI agree it feels abstract.\nSo today, why donft we check it with R?\nLetfs look at the coverage probability of the 95% confidence interval\nfor a hazard ratio, using simulation.h\nMe: gCoverage meaningc\nhow often the interval actually contains the true hazard ratio,\nif you repeat the study many times?h\nDad: gExactly.\nWefll simulate data over and over,\ncalculate a 95% confidence interval each time,\nand count how often the interval includes the true value.\nThat proportion is the coverage.\nThis is a kind of virtual experiment\nto see how well frequentist promises are kept.\nLetfs set the stage: you want to compare two survival curves, right?h\nMe: gYes. Stoma vs no stoma.h\nDad: gRight ? letfs compare overall survival (OS)\nbetween WITH STOMA and WITHOUT STOMA.\nWefll assume the true hazard ratio is 1.5:\nthe stoma group has a 1.5-times higher hazard of death,\ni.e. shorter survival.\nIf we simulate 1,000 datasets under that model\nand build a 95% confidence interval for the hazard ratio each time,\nwe expect the interval to contain 1.5 in roughly 950 out of 1000 runs.h\nMe: gThat proportion ? how often it hits 1.5 ?\nis the coverage.h\nDad: gExactly.\nWefll generate survival times from exponential distributions\nfor both groups,\nand use another exponential for censoring times.\nIn this set-up, all the assumptions of the Cox model are satisfied,\nso theoretically the 95% confidence interval\nshould have 95% coverage.h\nMe: gSo all we need to do is check\nwhether reality matches theory in simulation.h\n\n\n\nSimulating 95% CI coverage with coxph()\nDad: gThere are several ways to estimate a hazard ratio,\nbut one of the most common is coxph() from the survival package.\nRemember our generate_data() function from earlier episodes?\nWefll reuse it.h\n```r generate_data &lt;- function(n = 200, hr1, hr2) { # Stoma: 1 = WITH STOMA, 0 = WITHOUT STOMA stoma &lt;- rbinom(n, size = 1, prob = 0.4) # Sex: 0 = WOMAN, 1 = MAN sex &lt;- rbinom(n, size = 1, prob = 0.5) # Age: stoma group slightly older age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n# Hazards (bigger = earlier event) hazard_relapse &lt;- ifelse(stoma == 1, hr1 * 0.10, 0.10) hazard_death &lt;- ifelse(stoma == 1, hr2 * 0.10, 0.10) hazard_censoring &lt;- 0.05\n# Latent times t_relapse &lt;- rexp(n, rate = hazard_relapse) t_death &lt;- rexp(n, rate = hazard_death) t_censoring &lt;- rexp(n, rate = hazard_censoring)\n## — Overall survival (OS) — time_os &lt;- pmin(t_death, t_censoring) status_os &lt;- as.integer(t_death &lt;= t_censoring) # 1 = death, 0 = censored\n## — Relapse-free survival (RFS) — time_rfs &lt;- pmin(t_relapse, t_death, t_censoring) status_rfs &lt;- integer(n) status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # relapse status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1 # death\n## — Cumulative incidence of relapse (CIR) with competing risk — time_cir &lt;- pmin(t_relapse, t_death, t_censoring) status_cir &lt;- integer(n) status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # relapse status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2 # death\ndata.frame( id = 1:n, sex = factor(sex, levels = c(0, 1), labels = c(“WOMAN”, “MAN”)), age = age, stoma = factor(stoma, levels = c(0, 1), labels = c(“WITHOUT STOMA”, “WITH STOMA”)), time_os = time_os, status_os = status_os, time_rfs = time_rfs, status_rfs = status_rfs, time_cir = time_cir, status_cir = status_cir ) }\nDad: gNow wefll write a function that repeatedly generates data, fits a model, and checks whether the 95% confidence interval covers the true hazard ratio.h\ncalculate_coverage &lt;- function(model = c(“coxph”, “finegray”), n, hr1, hr2, hr_true) { model &lt;- match.arg(model) set.seed(46) replications &lt;- 1000 covered &lt;- logical(replications)\nfor (r in seq_len(replications)) { dat &lt;- generate_data(n, hr1, hr2)\nif (identical(model, \"coxph\")) {\n  fit &lt;- coxph(Surv(time_os, status_os) ~ stoma, data = dat)\n} else if (identical(model, \"finegray\")) {\n  # Fine?Gray model for competing risks (subdistribution hazards)\n  dat$fstatus_cir &lt;- factor(dat$status_cir,\n                            levels = 0:2,\n                            labels = c(\"censor\", \"relapse\", \"death\"))\n  fgdat &lt;- finegray(Surv(time_cir, fstatus_cir) ~ ., data = dat)\n  fit &lt;- coxph(Surv(fgstart, fgstop, fgstatus) ~ stoma,\n               weight = fgwt, cluster = id, data = fgdat)\n}\n\nci_log &lt;- confint(fit)  # CI for log(HR)\ncovered[r] &lt;- (ci_log[1] &lt;= log(hr_true) && log(hr_true) &lt;= ci_log[2])\n}\nmean(covered) # estimated coverage }\nNow run the simulation for n = 200, true hazard ratio hr_true = 1.5:\n\n\n\ninstall.packages(“survival”) # if needed\nlibrary(survival)\ncoverage_200 &lt;- calculate_coverage( model = “coxph”, n = 200, hr1 = 2, hr2 = 1.5, hr_true = 1.5 ) print(coverage_200) # [1] 0.955 (for example)\nMe: gSo about 95.5% of the intervals contained the true HR of 1.5. Thatfs pretty close to the promised 95%.h\nDad: gExactly.\nThis is what we mean by saying a 95% confidence interval has 95% coverage in the long run, when the model assumptions hold.h\nWhat 95% CI does not mean\nMe: gSo how should I interpret a 95% confidence interval in words?\nBefore I ask, let me say what Ifve been secretly thinking:\neIn this one study, there is a 95% probability that the true hazard ratio lies inside this interval.f\nThatfs wrong, isnft it?h\nDad: gFrom the frequentist viewpoint, yes, thatfs not correct.\nThe classic textbook explanation is:\nIf we repeated the same kind of study many times, and each time constructed a 95% confidence interval in the same way, then 95% of those intervals would contain the true value.\nSo 95% refers to the procedurefs long-run performance, not the probability that ethis particular interval is correctf.h\nMe: gSo the interval itself is either:\neluckyf (includes the true value), or\neunluckyf (misses it),\nbut we donft attach a probability to that within a single completed study.h\nDad: gExactly. The 95% is attached to the method, not the one realized interval.h\nDoes sample size affect coverage?\nMe: gIf coverage is about long-run behavior, does sample size matter?\nI mean, if I have fewer patients, shouldnft the method emissf the true value more often?h\nDad: gGood instinct, but in theory, for a correctly specified model, a 95% confidence interval should have 95% coverage no matter what the sample size is.\nLetfs check with the simulation:\nn = 100\nn = 200\nn = 400\nn = 800h\ncoverage_100 &lt;- calculate_coverage(model = “coxph”, n = 100, hr1 = 2, hr2 = 1.5, hr_true = 1.5) coverage_400 &lt;- calculate_coverage(model = “coxph”, n = 400, hr1 = 2, hr2 = 1.5, hr_true = 1.5) coverage_800 &lt;- calculate_coverage(model = “coxph”, n = 800, hr1 = 2, hr2 = 1.5, hr_true = 1.5)\nprint(coverage_100) print(coverage_200) print(coverage_400) print(coverage_800) # For example: # [1] 0.956 # [1] 0.955 # [1] 0.968 # [1] 0.953\nMe: gTheyfre all around 0.95.\nSo with fewer patients, the coverage is still about 95%. Does that mean sample size doesnft matter?h\nDad: gThatfs the trap.\nCoverage stays about the same, but interval width changes a lot.\nWith small n:\nintervals are wider,\nestimates are noisier.\nWith large n:\nintervals are narrower,\nestimates are more precise.h\nMe: gRightc I forgot about the length of the interval.\nSo for my cancer survivor survey, I canft just say ecoverage is fine, any sample size works.fh\nDad: gExactly.\nSample size is about how precisely you can estimate something, not whether the 95% procedure hits 95% in the long run.h\nFrom CI to sample size: how many patients do we need?\nMe: gBack to real life.\nFor our return-to-work study, I was vaguely thinking:\neIf we get around 100 responses, that would be great.f\nDo we really need to do more math than that?h\nDad: gYou just said coverage was fine with n=100, so that sounded like e100 is enoughfc didnft it?h\nMe: gGuilty as charged.h\nDad: gLetfs be more systematic.\nThere are roughly two approaches to sample size planning:\nThe confidence interval approach\nThe hypothesis testing approachh\nMe: gWhatfs the difference?h\nDad: gIn the confidence interval approach, you start from:\nthe parameter you want to estimate (e.g. the return-to-work proportion), and\nhow narrow you want the interval to be.\nTherefs a classic table in Machin et al.fs sample size book that gives required sample sizes for estimating a proportion with a given 95% CI width.\nFor example (paraphrased):\nIf the true proportion ﾎ is 0.5 and you want a 95% CI with total width 0.20 (i.e. 50% }10%), you need about 93 patients.\nIf ﾎ is 0.2 and you want the same width 0.20 (20% }10%), you need about 60 patients.\nSo for a return-to-work rate around 80% (i.e. non-return rate 20%), 60 patients might be enough to estimate the proportion with that level of precision.h\nMe: gSo my rough target of 100 responses doesnft sound completely crazy, at least for estimating the overall rate.h\nDad: gRight.\nBut your actual plan is not just:\neEstimate the return-to-work rate in all patients.f\nItfs:\neCompare the return-to-work rate between stoma vs no stoma groups.f\nThatfs more a hypothesis-testing style question.h\nMe: gSo we need the other approach.h\nTwo approaches to sample size\nDad: gFormally:\n\nConfidence interval approach\n\nOften used for surveys or exploratory studies. To plan the sample size, you specify:\nThe anticipated true proportion (e.g. return-to-work rate)\nThe acceptable width of the 95% confidence interval\nThe table (or formula) then tells you how many patients you need.\n\nHypothesis testing approach\n\nMore common in clinical trials and confirmatory studies. Here you need at least:\nSignificance level (, often 5%)\nPower (1?ﾀ, often 80?90%)\nEffect size you want to be able to detect (e.g. difference in survival at 5 years, or a target hazard ratio)\nThis is matched to the idea of Type I error () and Type II error (ﾀ). In a sense, sample size planning is the partner of p-values: instead of only controlling , you also deliberately control ﾀ by planning n.h\nMe: gSo for my stoma vs no stoma comparison, I should really:\ndecide what difference in return-to-work rate would be clinically meaningful, and\nchoose and power,\nthen calculate the sample size from there.h\nDad: gExactly. Thatfs hypothesis-testing-based sample size planning.h\nMe: gRight. Okay, I need to sleep ? clinic starts early tomorrow.\nLetfs continue the sample size story next time.h\nDad: gDeal. Sweet dreams.h\nTwo sides of the same coin: normal ranges and 95% CI\nMe: gBefore we wrap up, one last question.\nLaboratory test reports often show a enormal rangef. People sometimes say:\neThat range corresponds to 95% of healthy individuals.f\nIs that tied to the same 95% as confidence intervals?h\nDad: gGood question. Theyfre related, but not the same thing.\nRoughly:\nA reference (normal) range is about where most individualsf test values lie.\nA 95% confidence interval is about how precisely you have estimated a mean or parameter.\nFor a normally distributed test:\nemean } 1.96 ~ standard deviation (SD)f captures about 95% of individual values.\nemean } 1.96 ~ standard error (SE)f is a 95% confidence interval for the mean.h\nMe: gSo SD = variability between individuals, SE = uncertainty in the mean.h\nDad: gExactly.h\nA quiz related to this episode\nWhich of the following best describes the meaning of a normal reference range for a lab test?\nThe mean } 1.96 ~ standard deviation in a random sample from some population.\nThe range that contains 95% of values in a healthy reference population.\nThe mean } 1.96 ~ standard error in a healthy reference population.\nThe range that contains 95% of values in any random sample from any population.\nAnswer\nThe best answer is 2.\nStandard deviation (SD) describes how much individual test values vary between people.\nStandard error (SE) describes how precise our estimate of the mean is.\nFor a normally distributed test:\nmean } 1.96 ~ SD ? the range containing 95% of individual values\nmean } 1.96 ~ SE ? the 95% confidence interval for the mean\nSo:\n\nis just a formula; it doesnft say which population.\nconfuses SE with SD.\nis too vague and not restricted to a healthy population.\n\nA reference (normal) range is defined by the distribution of values in a healthy population, not by the uncertainty in the mean.\nReferences\nMachin D, Campbell MJ, Tan SB, Tan SH. Sample Size Tables for Clinical Studies, 4th ed. (Japanese edition: 繩ŵ߂̃TvTCY݌v).\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M; Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol. 2006;7(8):644?651.\nGreen J, Benedetti J, Smith A, Crowley J. Clinical Trials in Oncology, 2nd Japanese edition (original 3rd ed)."
  },
  {
    "objectID": "en/index.html#episodes",
    "href": "en/index.html#episodes",
    "title": "Brew a coffee, start a conversation. As the steam rises and fades, time passes — and the world of statistics slowly opens up.",
    "section": "Episodes",
    "text": "Episodes\n\n1. Study design — Where research begins\nEvery study starts with a question. How do we frame PICO/PECO? How do we choose outcomes? How do we protect against bias? The daughter asks her father about the very starting point of clinical research.\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\n[A First Step into Survival and Competing Risks Analysis with R] (coming soon)\n[Outcomes: The Bridge from Data Collection to Analysis]\n[When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys]\n\nYou can download the full R script for this episode here. If you are curious about the R packages and concrete analysis steps, feel free to take a look.\n\nstudy-design.R\n\n\n\n2. Frequentist thinking — Practicing statistics\nUsing a cancer clinical trial as a running example, the father talks about the frequentist idea of “what would happen to these numbers if we could repeat the study many times?”\n\n[Reading a Paper over a Cup of Coffee]\n[P-Value Explanations That Seem Plausible at First Glance]\n[Beyond 0.05: Interpreting P-Values in a Clinical Trial]\n[Understanding Confidence Intervals via Hypothetical Replications in R]\n[Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size]\n\n\n\n3. Effects and time — How effects evolve\nRisk difference, risk ratio, hazard ratio, vaccine efficacy, attributable fractions, and effects that change over time are explored through survival curves and cumulative incidence functions. Before stepping fully into causal inference, you quietly develop a three-dimensional way of looking at data.\n\n[Silent Confusions Hidden in Percentages]\n[Who Is This Percentage About? Target Populations and Attributable Fractions]\n[Collapsibility of Effect Measures in Marginal and Stratified Tables]\n[Risk Ratios and Odds Ratios: When Approximation Works]\n[Distinguishing Time-Point, Time-Constant, and Time-Varying Effects: An R Example]\n\n\n\n4. Adjusting for bias — The landscape of regression\nHere we meet logistic regression for adjustment and confounding — what it is, and what it is not.\n\n[Adjusting for bias I]\n[Adjusting for bias II]\n[Adjusting for bias III]\n[Adjusting for bias IV]\n[Adjusting for bias V]\n\n\n\n5. Causal inference — Thinking about “what if”\nDirected acyclic graphs (DAGs), common causes, colliders, mediators, backdoor paths. We try to talk about the language of causality needed to think about “what would have happened if…?”, using as few formulas as possible.\n\n[Causal inference I]\n[Causal inference II]\n[Causal inference III]\n[Causal inference IV]\n[Causal inference V]\n\n\n\n6. The Craft of Research — The work of doing research\nHow do we present results? How do we design figures and tables? How do we revise a manuscript, and how do we live with peer review? This series is a quiet set of lectures on “life after statistics” for people doing research.\n\n[The Craft of Research I]\n[The Craft of Research II]\n[The Craft of Research III]\n[The Craft of Research IV]"
  },
  {
    "objectID": "en/index.html#how-to-read-this-site",
    "href": "en/index.html#how-to-read-this-site",
    "title": "Brew a coffee, start a conversation. As the steam rises and fades, time passes — and the world of statistics slowly opens up.",
    "section": "How to read this site",
    "text": "How to read this site\n\nIf you start with Study design I–V,\nyou will get a first outline of “what question to ask, and what data to collect to answer it.”\nIf you want to choose by interest:\n\nTo build a better footing for reading papers → Frequentist thinking / Effects and time\n\nTo tidy up your analysis practice → Adjusting for bias\n\nTo organize how you think about causality → Causal inference\n\nTo eventually publish your work as a paper → The Craft of Research\n\nEach episode is written so that you can read it on its own.\nBut if you read across the series, a mental map of “what research is as a practice” starts to form in the background.\n\nPick any place that catches your eye, grab your favourite drink, and read at the pace that feels right for you."
  },
  {
    "objectID": "en/study-design-2.html",
    "href": "en/study-design-2.html",
    "title": "Data Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes",
    "section": "",
    "text": "Study Design II − Data Have Types\n\nKeywords: clinical trial, hypothesis/outcome/population, probability model, simulation, survival/competing-risk\n\n\nThis post is the second episode of my Story and Quiz series. Over a cup of coffee, a clinician daughter and her statistician father build a rough mental map from data types (continuous, binary, count, survival) to common R functions: mean(), t.test(), glm(), fisher.test(), survfit(), and cifplot(). We simulate a small stoma-surgery dataset in R, look at histograms, tables, and survival curves, and end with a short quiz about oncology endpoints and FDA approvals. If you’d like to start from the beginning, you can find the first episode here:\nStudy Design I − A Story of Coffee Chat and Research Hypothesis\n\nFour types of data items\n\n\nMe: “Okay, coffee is ready. Can I keep you a bit longer?”\n\n\nDad: “If coffee is involved, yes.”\n\n\nMe: “You said something earlier that stuck with me: the R function we use depends on the outcome. I didn’t really get that. In the end, aren’t all data just … numbers?”\n\n\nDad: “They’re all numbers, yes. But for statistics, the type of data matters a lot. Very roughly, we use four big categories.”\n\n\n\nContinuous data\nBinary / categorical data\nCount data\nSurvival time data\n\n\n\nMe: “Continuous data is things we measure, right? Like age or blood pressure. Binary data I get — like ‘with stoma’ vs ‘without stoma’ in the study I want to do.”\n\n\nDad: “Perfect. Count data is when you literally count events, like the number of traffic accidents. Survival data is things like lifespan — time from some starting point until an event, such as death. In your case, that could be time from surgery to returning to work, or time to relapse.”\n\n\nMe: “When you say it like that, they definitely feel like different beasts. But in the R course I took, we just typed whatever they put on the slides — t.test(), glm(), survfit()… It all felt like a spellbook.”\n\n\nDad: “That’s a common side effect of R lectures. Do you have your laptop?”\n\n\nMe: “That sounds like the beginning of homework.”\n\n\nDad: “Let’s just say it’s a practical demonstration. Bring it here — we’ll install RStudio if it’s not there.”\n\n\nMe: “I knew this was coming. Look, I know my stats skills are still beginner level, and I do need R for my own research. So fine, I’ll get my laptop. But I expect maximum efficiency from this session.”\n\n\nDad: “I’ll try. In R, for continuous data, we often use mean() and t.test().”\n\n\nMe: “Those at least sound familiar.”\n\n\nDad: “For binary data, we summarize with table(), and to get p-values we use fisher.test(). For more complex analyses, we move to regression models like glm(family = binomial). For survival data, we use things like survfit(), coxph(), and cifplot().”\n\n\nMe: “There’s no way I can memorize all that. I’ll just mix everything up again.”\n\n\nDad: “You don’t need to memorize every function name.”\n\n\nMe: “I like where this is going.”\n\n\nDad: “What you do want is a rough map in your head. If you can picture the data type, the appropriate R functions become much easier to remember.”\n\n\nMe: “So instead of memorizing spells, I should recognize the kind of creature I’m dealing with.”\n\n\nDad: “Exactly. And one more layer down, we’re also thinking about probability distributions.”\n\n\nMe: “Ah, here comes the math.”\n\n\nDad: “Nothing too heavy. You’ve heard of the normal distribution, right?”\n\n\nMe: “That one survived from undergrad, yes.”\n\n\nDad: “For statistics, we imagine that behind the data there’s some probability distribution:\n\nContinuous data: often normal distribution\nBinary data: binomial distribution\nCount data: Poisson distribution\nSurvival data: there’s no single standard, but a simple one is the exponential distribution. Often, though, we just treat it nonparametrically without any specific distributions.\n\nYou don’t have to remember the formulas, just the general matching. ”\n\n\n\ncontinuous: normal-ish\n\nyes/no: binomial-ish\n\ncounts: Poisson-ish\nsurvival: nonparametric\n\n\n\nMe: “So how does that help with R?”\n\n\nDad: “For example, we often talk about proportions and rates in medicine. We casually throw around words like prevalence or mortality rate. But in statistics they are clearly different.”\n\n\n\nProportion: a parameter of the binomial distribution\n\nRate: a parameter of Poisson distribution\n\n\n\nMe: “But in normal conversation, proportion and rate are almost interchangeable.”\n\n\nDad: “Right, in everyday language they get blurred. In a scientific context, they’re different. A proportion is something you’d express as a percentage, such as “60% of the participants were women.” It is clearly bounded between 0 and 1, and describes ’how many out of this group’. A rate relates to events over time, and is expressed per unit of time. For example, think of annual rate of traffic accidents in Tokyo. You wouldn’t express that as ’120% per year’. It’s something like ’X accidents per year’.”\n\n\nMe: “Okay, that’s finally clicking. So proportion is like ‘out of this group, how many have the characteristic’, and rate is like ‘how fast things are happening over time’.”\n\n\nDad: “Exactly. And with that in mind, let’s do a small R demo — nothing painful.”\n\n\nMe: “You always say that right before something painful.”\n\n\nDad: “We’ll simulate age (continuous data), sex, stoma (binary data) and survival time. Then we’ll run some basic summaries.”\n\n\nMe: “Okay. I’ll type what you tell me, but I want to understand the big picture, not just more spells.”\n\n\nDad: “Deal. First, a quick note about R packages. To install a package on your computer, you use install.packages(). To use an installed package in your current session, you use library(). R is like a bookshelf.”\n\n\n\ninstall.packages(): buy the book and put it on the shelf\n\nlibrary(): pull the book off the shelf and open it.”\n\n\n\nMe: “So install is a one-time thing, and library() is what I run each time I actually use it.”\n\n\nDad: “Exactly. Reinstalling every time would be like going out to buy coffee beans every single morning.”\n\n\nMe: “No, thank you. Okay, show me the simulated data.”\n\n\n\n\n\n\n\n\nGenerating simulated data\n\n\n\nHere we’ll use R to create a simple dataset and run basic analyses for continuous, binary, and survival data. The theme is a two-group comparison: patients with and without a stoma.\n\nAge: continuous, from a normal distribution using rnorm()\nSex, stoma: binary, from a binomial distribution using rbinom()\nSurvival time: from an exponential distribution using rexp()\n\n\nset.seed(46)\n\n# Stoma: 1 = with stoma, 0 = without stoma\nstoma &lt;- rbinom(200, size = 1, prob = 0.4)\n\n# Sex: 0 = WOMAN, 1 = MAN\nsex &lt;- rbinom(200, size = 1, prob = 0.5)\n\n# Age: normal distribution (stoma group slightly older)\nage &lt;- rnorm(200, mean = 65 + 3 * stoma, sd = 8)\n\n# Survival time: exponential distribution\n#   expected survival 10 years (with stoma) vs 15 years (without)\nhazard &lt;- ifelse(stoma == 1, 1 / 10, 1 / 15)\ntime   &lt;- rexp(200, rate = hazard)\n\n# Random censoring: 0 = censored, 1 = event\nstatus &lt;- rbinom(200, size = 1, prob = 0.9)\n\ndat &lt;- data.frame(\n  age    = age,\n  sex    = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n  stoma  = factor(stoma, levels = c(0, 1),\n                  labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n  time   = time,\n  status = status\n)\n\nhead(dat)\n\n       age   sex         stoma      time status\n1 59.19077 WOMAN WITHOUT STOMA 17.939751      1\n2 59.46486   MAN WITHOUT STOMA 18.189251      1\n3 55.34491   MAN WITHOUT STOMA  2.445121      1\n4 60.68207   MAN WITHOUT STOMA 46.737429      1\n5 61.79577   MAN WITHOUT STOMA  0.149128      1\n6 62.84530 WOMAN    WITH STOMA  0.298167      1\n\n\n\n\n\n\n\n\n\n\nSummarizing continuous and binary data\n\n\n\nFirst, let’s describe age and sex in the stoma vs non-stoma groups using a histogram and contingency table. You should see that the age distribution for the stoma group is slightly shifted to the right (older on average), because that’s how we simulated it.\n\n# install.packages(\"ggplot2\") # if needed\nlibrary(ggplot2)\n\nggplot(dat, aes(x = age, fill = stoma)) +\ngeom_histogram(alpha = 0.5, position = \"identity\", bins = 10) +\nlabs(x = \"AGE\", y = \"FREQUENCY\", fill = \"STOMA\") +\ntheme_minimal()\n\n\n\n\n\n\n\ntable(STOMA = dat$stoma, SEX = dat$sex)\n\n               SEX\nSTOMA           WOMAN MAN\n  WITHOUT STOMA    43  76\n  WITH STOMA       44  37\n\n\n\n\n\n\n\n\n\n\nSummarizing survival data with survival curves\n\n\n\nFor survival data, we want to describe how long patients survive without the event. Here we use cifplot() from the cifmodeling package to draw the Kaplan-Meier curves. Event(time, status) tells R which variables represent the time and event indicator. outcome.type = \"survival\" asks for a survival curve. Under our simulation, the non-stoma group should have better survival, so its curve will lie above the stoma group.\n\n# devtools::install_github(\"gestimation/cifmodeling\") # if needed\nlibrary(cifmodeling)\ncifplot(Event(time, status) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA quiz related to this episode\n\n\n\nThis quiz connects the idea of outcomes to real drug approvals in oncology. From 2009 to 2014, 83 drugs in the oncology field were approved by the FDA. Select the correct percentage of these 83 drugs that were approved based on clinical trials using response rate (tumor shrinkage or complete remission) as the primary endpoint.\n\n0～24%\n25～49%\n50～74%\n75～100%\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 2.\n\nAccording to the review by Kim and Prasad (2016), 31 out of 83 products were reported to have been approved based on response rate results. Furthermore, the breakdown of endpoints differs between standard approval and accelerated approval. For standard approval, 48 out of 55 products were evaluated based on overall survival, progression-free survival, or disease-free survival. In contrast, for accelerated approval, the majority of products were based on Phase II trial results where response rate was the primary endpoint.\n\n\n\n\n\nReference\n\nKim C and Prasad V. Strength of validation for surrogate end points used in the US Food and Drug Administration’s approval of oncology drugs. Mayo Clin Proc 2016; S0025-6196(16)00125-7\n\n\n\nEpisodes and R-script\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\n[A First Step into Survival and Competing Risks Analysis with R]\n[Outcomes: The Bridge from Data Collection to Analysis]\n[When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys]\nstudy-design.R"
  },
  {
    "objectID": "en/study-design-4.html",
    "href": "en/study-design-4.html",
    "title": "Outcomes: The Bridge from Data Collection to Analysis",
    "section": "",
    "text": "Study Design IV − The Bridge from Data Collection to Analysis\n\nKeywords: generalized linear model, outcome, simulation, survival/competing-risk\n\n\n\nTurning a questionnaire into “data”\n\n\nMe: “Hey Dad, quick question. And yes, there’s coffee.”\n\n\nDad: “Then I’m listening.”\n\n\nMe: “You remember that return-to-work survey for cancer survivors? I finally drafted the questionnaire we’re going to mail from our hospital. Can you take a look and tell me if it’s…statistically suicidal?”\n\n\nDad: “Let’s see…How exactly are you going to define the return-to-work proportion?”\n\n\nMe: “That’s already a hard question?”\n\n\nDad: “Yup. It always is.”\n\n\nMe: “Okay…here’s how I was thinking. Among all patients who had curative surgery, I want to know who has returned to work and who hasn’t within a certain time period. I don’t want to restrict the denominator to only those who say they want to go back to work, because some people might have given up because of workplace issues.”\n\n\nDad: “Good. That’s a thoughtful choice. So what time window are you using?”\n\n\nMe: “I don’t want to use ‘survey date’ because the response timing will vary a lot between patients. So I was thinking of defining it as:\n\n‘Returned to work within 1 year after surgery.’\n\nAnd then I realized… I should probably ask for the actual date of return-to-work in the questionnaire.”\n\n\nDad: “Yes, that date is very useful. If you have it, you can turn the same answer into:”\n\n\nCategorical data (returned within 1 year: yes/no)\nSurvival data (time from discharge to return-to-work)\n\n\nMe: “Two birds with one question. Efficient. What about patients who die after surgery, though?”\n\n\nDad: “Important point. If someone dies after your time origin, you shouldn’t quietly drop them from the denominator. That would create bias—especially in a cancer survivor study.”\n\n\nMe: “So what should I do?”\n\n\nDad: “In follow-up studies of cancer patients, I always tell people:”\n\n\nDecide a clear time origin – for you, I’d recommend the discharge date.\n\nDecide a follow-up period – here, ‘1 year after discharge’.\n\nMake a serious effort to collect outcome information for all patients in the target population, including deaths.\n\n\nDad: “If the target population is ‘rectal cancer patients after curative surgery at our hospital’, you want to know what happened to all of them, not just the ones who kindly mail back questionnaires.”\n\n\nMe: “Right. I don’t want to design a study where the only people included are those with good energy and good stationery habits.”\n\n\nCategorical data vs survival time data\n\nDad: “Let’s organize this a bit. What is your outcome in this study?”\n\n\nMe: “The main one is:\n\nReturned to work within one year after discharge (yes/no).”\n\n\n\nDad: “Perfect. That gives you binary data. You can then compute the return-to-work proportion in each group, and compare them.”\n\n\nMe: “Including patients who died, as ‘did not return’, right?”\n\n\nDad: “Yes, as long as that’s clearly defined and consistent. But if you want a richer picture,\nyou could use three categories instead of just two:”\n\n\nReturned within 1 year\n\nAlive but did not return within 1 year\n\nDied within 1 year without returning to work\n\n\nDad: “That already separates ‘can’t work because I died’ from ‘still alive but didn’t go back’.”\n\n\nMe: “Okay, that does sound more honest.”\n\n\nDad: “Now, if you also collect the date of return-to-work, you can create survival data.”\n\n\nMe: “Even though the event is not ‘death’?”\n\n\nDad: “Right. ‘Survival time’ is a bit misleading as a name. Statistically, what matters is:\n\ntime from the time origin to the event of interest.\n\nIn your case, the event is ‘return-to-work’.”\n\n\nMe: “So if someone is discharged on April 1 and returns to work on April 30, time-to-event = 30 days.”\n\n\nDad: “Exactly. Now think about patients who haven’t returned to work by the time you close the survey. For them, time-to-return isn’t observed yet. That’s where censoring comes in.”\n\n\nMe: “Right. They’re still in limbo.”\n\n\nDad: “So survival data always comes as a pair:“\n\n\na time variable\na censoring indicator\n\n\nMe: “I can imagine an example like:”\n\n\n\n\ntime = min( time to return-to-work, time to last follow-up )\n\nstatus = 1 if returned, 0 if not returned by last follow-up\n\n\n\n\n\n\n\nHandling survival data in R\n\n\n\nSince survival data consists of pairs of variables, they must be specified as pairs when inputting into R functions. The survfit() and coxph() functions in the survival package actually provide a dedicated input function, Surv(). Input specifications vary across packages; for example, the mets package uses Event(). The cifplot() function in the cifmodeling package supports both Surv() and Event().\n\nlibrary(survival)\nlibrary(cifmodeling)\n\nsurvfit(Surv(time, status) ~ stoma,\n  data         = dat\n)\ncifplot(Surv(time, status) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\ncifplot(Event(time, status) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\",\n  label.y      = \"Overall survival\"\n)\n\n\n\n\n\nMe: “But where do deaths go in that picture?”\n\n\nDad: “There are two ways to think about it. One is a simple approach that treats deaths as ‘did not return to work’. In the censoring indicator, death would be coded as no event if you only care about return-to-work. But there is a more refined approach. In competing risks analysis, death is not just censored — it’s a competing event that prevents return-to-work from happening.”\n\n\nMe: “Competing risks again. You really like those.”\n\n\nDad: “They show up a lot in medical data. If you treat all deaths as just censored, you’re implicitly saying:\n\n‘If they hadn’t died, their chance of returning-to-work\nwould be the same as for people still alive.’\n\nIn reality, that’s often not true.”\n\n\nMe: “Yeah, that would be…optimistic.”\n\n\n\nA quick map of data types and methods\n\nDad: “Since we’ve talked about data types a few times now, let’s draw a little map. Say we’re thinking about:\n\nwhat kind of outcome we have,\n\nwhether we have repeated measurements, and\n\nwhether we need to adjust for confounding.”\n\n\n\nMe: “This sounds like the part where you normally pull out a slide.”\n\n\nDad: “Today we get the short version.”\n\n\n\n\n\n\n\n\n\n\nData type\nRepeated within person?\nConfounding?\nTypical methods\n\n\n\n\nContinuous\nNo\nNo\n\\(t\\) test, Wilcoxon rank-sum\n\n\nContinuous\nNo\nYes\nLinear regression\n\n\nContinuous\nYes\nYes\nRandom-effects model, GEE\n\n\nBinary\nNo\nNo\n\\(\\chi^2\\) test\n\n\nBinary\nNo\nYes\nLogistic regression\n\n\nBinary\nYes\nYes\nRandom-effects logistic, GEE\n\n\nCount\nNo\nYes\nPoisson regression\n\n\nSurvival\nNo\nNo\nKaplan–Meier curve\n\n\nSurvival\nNo\nYes\nCox regression\n\n\nCompeting risks\nNo\nNo\nAalen–Johansen curve\n\n\nCompeting risks\nNo\nYes\nFine–Gray model\n\n\n\n\nMe: “So for my study, ‘returned to work within 1 year’ is binary and can be handled with logistic regression. For ‘time from discharge to return-to-work’, are Kaplan–Meier/Cox and Aalen–Johansen/Fine–Gray typical statistical methods?”\n\n\nDad: “Exactly. That’s already a good grasp of the landscape.”\n\n\n\nRepeated measurements and confounding\n\nMe: “Where do repeated measures come in?”\n\n\nDad: “Imagine you use the same questionnaire multiple times for each patient:”\n\n\npre-surgery\n\nat 6 months\n\nat 12 months\n\n\nDad: “Then you’d have multiple data points within each person. Those are correlated — your own responses are more similar to each other than to some random patient’s.”\n\n\nMe: “So I can’t just pretend they’re all independent.”\n\n\nDad: “Right. That’s when you use methods like random-effects models or generalized estimating equations (GEE). They’re built to handle within-person correlation.”\n\n\nMe: “And confounding is lack of comparability or ’ceteris paribus‘, right? So in randomized trials, we use random allocation of treatments to balance those things in advance. But in observational studies like mine, we depend more on modeling and design.”\n\n\nDad: “Precisely. That’s the big difference between ‘trial data/experimental data’ and ‘real-world data’.”\n\n\n\n\n\n\n\n\n\nA quiz related to this episode\n\n\n\nIn which situation is the Kaplan–Meier method appropriate for estimating a survival curve?\n\nWhen survival times follow a normal distribution.\n\nWhen the reasons for censoring are unrelated to prognosis.\n\nWhen the censoring proportions of two groups do not differ significantly in a hypothesis test.\n\nWhen the proportional hazards assumption holds between the treatment and control groups.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correct answer is 2.\n\nThe Kaplan–Meier method does not require:\n\nnormality of survival times (that’s more for \\(t\\)-tests), nor\n\nproportional hazards (that’s a key assumption for the Cox model).\n\nWhat it does assume is that censoring is non-informative. If sicker patients are more likely to be lost to follow-up, or if follow-up intensity depends strongly on prognosis, Kaplan–Meier curves can become biased.\n\n\n\n\n\nEpisodes and R-script\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nA First Step into Survival and Competing Risks Analysis with R\nOutcomes: The Bridge from Data Collection to Analysis\n[When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys]\nstudy-design.R"
  },
  {
    "objectID": "index.html#r-package-cifmodeling",
    "href": "index.html#r-package-cifmodeling",
    "title": "Coffee and research are best when they’re hot.",
    "section": "R package cifmodeling",
    "text": "R package cifmodeling\nA toolkit for survival and competing risks analysis in R — a more technical side of my work.\n\nKaplan-Meier and Aalen-Johansen estimation and visualization\n\nDirect polytomous regression of cumulative incidence functions\nIntegration with ggsurvfit, modelsummary, and modern R workflows\n\nVisit the R package cifmodeling site"
  },
  {
    "objectID": "index.html#a-conversation-on-causality-at-our-table-how-i-learned-research-from-my-father",
    "href": "index.html#a-conversation-on-causality-at-our-table-how-i-learned-research-from-my-father",
    "title": "Coffee and research are best when they’re hot.",
    "section": "A Conversation on Causality at Our Table — How I Learned Research from My Father",
    "text": "A Conversation on Causality at Our Table — How I Learned Research from My Father\nA series of short, warm stories about learning research, written in both English and Japanese. Through conversations between a father and daughter, the essentials of research unfold naturally. All of it is shared freely — like something warm to drink during a hallway conversation at a conference, there whenever you need a quiet break.\n\nFor readers who want to grasp the feel of research before opening a textbook\n\nLight, conversational chapters you can read in a few minutes\n\nFrom Study Design → Frequentist Thinking → Understanding Effects and Time → Adjusting for Bias → Causal Inference → Publication\n\nRead in English / Read in Japanese"
  },
  {
    "objectID": "index.html#books-and-related-contents",
    "href": "index.html#books-and-related-contents",
    "title": "Coffee and research are best when they’re hot.",
    "section": "Books and related contents",
    "text": "Books and related contents\n\nCausal Inference for Medical Research I. Generalized Linear Models (in Japanese)\nPublisher site\nCausal Inference for Medical Research II. Rubin Causal Models (in Japanese)\nPublisher site\nLearning materials for this series\nProfessor Giant Salamander’s Medical Statistics Seminar: Paper Reading Level Up 30 (in Japanese)\nPublisher site\nLearning materials for this book\nSample Sizes for Clinical, Laboratory and Epidemiology Studies (Japanese translation)\nPublisher site\nLearning materials for this book"
  },
  {
    "objectID": "index.html#about-the-author",
    "href": "index.html#about-the-author",
    "title": "Coffee and research are best when they’re hot.",
    "section": "About the author",
    "text": "About the author\n\nShiro Tanaka is a biostatistician and Professor of Clinical Biostatistics at Kyoto University. His work sits at the intersection of causal inference and clinical research. This site collects some of his research, teaching materials, and essays, shared freely for anyone who finds them useful.\nMore information"
  },
  {
    "objectID": "jp/causal-inference-2.html",
    "href": "jp/causal-inference-2.html",
    "title": "Story and Quiz − Causal inference II",
    "section": "",
    "text": "Story and Quiz − Causal inference II\n\n　　　　　　　　　　　　　　　　　　　　Keywords: DAG, intermediate factor, confounding/information-bias/selection-bias, covariate selection, observational study\n\n\n\n後ろ扉を閉ざすなんて映画みたい\n私「お父さん、この前の続きなんだけど。DAGっていう矢印を使った図があったじゃない。あれ、3変数しかないのは単純すぎない？現実はもっと複雑な気がするんだけど」\nお父さん「もちろんDAGの変数を増やすこともできるよ。そうすると、もっと統計学っぽい理屈になっちゃうけど」\n私「そうなんだ。でもごまかさず説明くらいしてよ」\nお父さん「じゃあ変数を5つに増やした例を使って、正式な解説をしてみようか」\n\n\n\n\n\n\nNote\n\n\n\n DAGの例\n因果関係の例として、ピロリ菌と胃がんを取り上げます。このふたつの変数には、抗生物質を飲んでピロリ菌を除菌することで、胃がん発生を予防できることが知られていますよね。言い換えると、ピロリ菌除菌は「原因」、胃がん発生は「結果」に対応します。\nしかし、胃がんに関連する変数は、これだけではありません。たとえば、若いうちは胃がんにはなりませんが、高齢になると胃がんリスクが高くなりますし、同じ年齢でも胃の炎症など様々な体質の違いが胃がんの発生に関連することがわかっています。これを踏まえて、以下の3つの仮定を置きます。\n\n年齢が高くなるにつれ、胃がんリスクは高くなるが、その一部は胃の炎症の程度に反映される。胃の炎症がひどくなると、胃がんにかかりやすくなり、さらに医療機関に受診して、ピロリ菌を除菌してもらう確率が高くなる\n心配性な人もまたピロリ菌除菌を受けやすい。心配性な性格だと、胃の炎症も起こしやすい。ただし、性格はピロリ菌除菌と胃の炎症への影響を通してのみ、胃がんに関連する\n年齢、性格、体質、ピロリ菌以外に、胃がん発生に関連する重要な変数はない\n\n5つの変数をAからEまでの記号で表すと、上の3つの仮定は、以下のようなDAGで表現できます。\n\n\nA: 性格（心配性）\nB: 年齢\nC: 体質（胃の炎症）\nD: 胃がん発生\nE: ピロリ菌除菌\n\n\n\nお父さん「前回の話を思い出しながら、このDAGを考えてみてよ。交絡因子として調整しないといけない変数はどれだろう」\n私「ん？共通原因、中間媒介因子、合流点っていう3パターンがあったんだっけ。共通原因を見つければいいから、Cかな。いや、真に近いモデルを当てはめる、なんてことも言ってたよね。だからBとC。どうかな、あってる？」\nお父さん「結果論だけどあってる。実はね、このDAGはトリッキーで、Cを調整するだけじゃ、バイアスが残る例なんだ。そのあたりも説明するから、話の続きを聞いててね」\n\n\n\n\n\n\nNote\n\n\n\n DAGの用語\n次に、DAGで用いられる用語を整理しておきます（Greenland, Pearl, Robins 1999）。ここで説明する用語は、ノード、矢印、有向パス、バックドアパス、祖先と子孫です。\nグラフ上の変数を表す点を、ノードといいます。上のグラフには5つのノードがありますよね。2つのノードは、線や矢印で結ばれます。A→Bという矢印で結ぶと、それはAからBへの方向性があることを意味します。因果推論の文脈では、原因から結果への直接的な結びつきを表しています。このグラフでは、AとCは隣接しているが、AはBやDとは結ばれていません。これは、AのCへの直接的影響があるという意味です。直接的影響があるとは、もっというと、グラフ上の他の変数に媒介されない影響がある、ということです。\n胃がんの例では、性格は、ピロリ菌除菌と体質を通じて胃がん発生をもたらすと仮定しました。この仮定は、AからBやDへの矢印がないことに対応しています。\n矢印で結びついたグラフは、必ず、矢印の頭から入り、頭から出るような一続きの矢印で辿ることができます。直接的または間接的にノードを結びつける矢印の組み合わせのことを、パスといいます。特に、矢印の方向に従って辿ることのできるパスを、方向性のあるパスという意味で有向パスと呼んでいます。上のグラフでは、A→C→Dのパスは有向パスです。\n次にE←C→Dについて考えてみましょう。こちらは有向パスではありません。有向パス以外のものを無向パスといいます。\n無向パスのうち重要なのは、あるノードから矢印をさかのぼって出て、別のノードに入るパスです。これをバックドアパスといいます。このグラフでは、EからDへのパスは、直接のパス以外はすべてバックドアパスです。\nそして、あるノードを出て別のノードに入っていく有向パスがあるとき、前者を祖先、後者を子孫といいます。文献によっては、祖先を原因、子孫を結果と呼んでいることもあります。このグラフでいえば、A、B、Cは、すべてEとDの祖先です。逆に、EとDは、A、B、Cの子孫です。そしてEはDの祖先であり、DはEの子孫です。\n\n\n私「ややこしいね。覚えきれない」\nお父さん「どこかポイントか説明しておこうか。まず、DAGとは、directedつまり有向パスだけで構成された、acyclicな循環していないグラフっていう意味。つまりDAGって言ったときは、ノード間の結びつきがすべて矢印で表されており、しかも矢印がループ状にぐるぐるまわったりしないってことを前提にしている。有向パスっていうのは、A→B→C→Dのような矢印で連鎖しているノードの集合のことで、この場合はAからDの順に因果関係が伝わることを意味している。ここでひとつ確認してほしいことがあるんだ」\n私「どんなこと？」\nお父さん「それは、DAGにおいて、ブロックされていないパスは、有向パスと共有原因を経由するバックドアパスの2種類しかありえないってこと」\n私「バックドアパスってなに？」\nお父さん「ノードに入る矢印を通じたパスのこと。矢印は出るか入るかしかないでしょ」\n私「ああ、バックドアっていうから後ろ扉かと思った。後ろ扉を閉じて地震を防ぐっていう映画があってね」\nお父さん「ふーん」\n私「えっと、とりあえず胃がんの例で確認してみるね。このDAGには、EとDを結ぶパスは、両者を直接結び付ける有向パスが1つ、バックドアパスが4つある（E←A→C←B→D、E←A→C→D、E←C←B→D、E←C→D）。でも、確かにバックドアパスは、必ず共通原因Cを経由してるね」\nお父さん「そうでしょ。ここがDAGの特徴のひとつ。前回の説明を思い出してみて。共通原因は交絡因子として調整すべきっていったよね。DAGが複雑になると、バックドアパスが増えるけど、基本は同じ。すべてのバックドアパスをブロックできるような共通原因を探して、調整すればいいんだ」\n\n\n\n\n\n\nNote\n\n\n\n バックドア基準\nあるDAGが与えられたとき、どのノードを交絡因子として調整すればじゅうぶんなのかを判断するための基準のひとつがバックドア基準です。原因と考えているノードをE、結果と考えているノードをDとします。DAG上のノードの集合Sが以下の条件を満たすなら、Sを交絡因子として調整すればじゅうぶんです\n\nEからDへの合流点を含まないバックドアパスは、Sによりブロックできる\nEからDへのバックドアパス内に合流点あり、それがSに含まれるか、Sの子孫だとする。このときSは、そのバックドアパス内の非合流点を含まなければならない\n\n\n\nお父さん「厳密にいうと、バックドア基準っていう上のようなルールを使うんだけどね。合流点・ブロックについては、後で説明するよ。要は、共通原因を調整して、バックドアパスをブロックすれば、交絡を防ぐことができる。疫学ではDAGは交絡因子を探すために用いられるんだ」\n私「やはり要石で後ろ扉を閉じるみたいな話だったか」\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n下のDAGにおいて、破線で示したパスA-C-Bに注目してください。このパスにおいて、Cは次のうちどれでしょうか。\n\n中間媒介因子\n共通原因\n合流点\n1、2、3のどれでもない\n\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です。\n\nここで注目してほしいのは、Cは共通原因でもあり、合流点でもある、という点です。このようなとき、機械的にCだけを調整すればいいと、判断することはできません。バックドア基準を使うべきです。\n詳しくは次回述べますが、もし理由を説明するなら、以下のようになります。パスE←A→C←B→Dに注目してください。このパスは合流点Cを含むため、なにも調整しなくてもブロックされています。つまり、これだけをみると、Cは調整しなくてもよいのです。\nその一方で、パスE←A→C→Dについて考えると、AもCも合流点ではありません。つまりこのパスは、なにも調整しないとブロックされていないのです。つまり、このDAG全体でみると、EとDには相関が生じています。さらに、E→Dという因果関係はないことから、この相関は疑似相関です。したがって、なにも調整しなくていい、という判断も間違いです。\n\n\n\n\n\nエピソード、用語集\n\nThree-Variable DAGs: The Smallest Building Blocks of Causal Structure\nCommon Causes and Confounders\nDAGs and Conditional Distributions: Two Languages for the Same Structure\nBackdoor Paths and Confounders\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/causal-inference-4.html",
    "href": "jp/causal-inference-4.html",
    "title": "Story and Quiz − Causal inference IV",
    "section": "",
    "text": "Story and Quiz − Causal inference IV\n\n　　　　　　　　　　　　　　　　　　　　Keywords: DAG, intermediate factor, confounding/information-bias/selection-bias, covariate selection, observational study\n\n\n\nブロックの意味\n私「お父さんがDAGを説明してくれたときにさ、ブロックって用語が出てきたでしょ。合流点がパスをブロックするとか」\nお父さん「出てきたね」\n私「あれって、因果の流れが止まるって意味だよね」\nお父さん「うーん、その言い回しは厳密じゃない気がするなあ。ブロックは、DAG上のパスの性質について述べたもので、因果関係とは直接関係ない。パスが合流点を含んでいたり、非合流点を交絡因子として調整したりすることを指すんだけど」\n私「合流点があると、そのパスはなにもしなくてもブロックされる。非合流点については、調整するとパスがブロックされるってことね」\nお父さん「うん。専門的には、パスをブロックすると、ノードとノードを”有向分離”できるっていうのがポイントなんだけどなあ。有向分離の定義にも触れておいた方が誤解がなさそうだね」\n\n\n\n\n\n\nNote\n\n\n\n 有向分離（d-separation）\nDAG上に、異なるノードを要素とする3つの集合があるとし、それぞれをA、B、Cと表す。以下の2条件を満たすとき、CはAとBを有向分離する（Greenland 1999）。\n\nAとBを結ぶ合流点を含まないすべてのパスは、Cの要素を含んでいる\nCに、AとBを結ぶパス上の合流点が含まれているとする。このとき、合流点を調整することでAとBを結ぶパスが生じたとしても、そのパスはCの別の要素を調整することでブロックできる\n\n\n\n私「話がややこしくなってきた」\nお父さん「そうでしょ。ノードの数が増えると、ノードの集合を考えないといけなくなって、定義が複雑になっちゃう。だから単純なケースで意味を確かめよう。この3つのDAGで、CはEとDを有向分離すると思う？」\n\n私「まず、EとDを結ぶパスはどのDAGもひとつ。上の2つのDAGは合流点を含んでいないし、パス上にCがある。だから有向分離してるはず。一番下はどうだろう。Cは合流点だし、パスE-C-Dは、別の要素で遮断できないよね。だから有向分離の条件に当てはまらない」\nお父さん「その通り。”共通原因や中間媒介因子で調整するとパスがブロックされる”とか”合流点で調整すると、パスがブロックされなくなる”っていうことを正確に表現すると、上の定義になるってことがわかったでしょ。もう少しDAGが複雑になると、この定義のよさがわかると思う。このDAGで、EとDを有向分離するのは、どのノードの集合だろう」\n\n私「合流点はないよね。だから有向分離するのはAとC？」\nお父さん「それだけじゃないよね。Aだけ、またはCだけでも、有向分離の条件を満たすでしょ」\n私「確かにそうね。ということは、AとCのどちらかのデータを取っておけば、交絡を調整できるってこと？」\nお父さん「そういうこと。じゃあ次のDAGについて考えようか」\n\n私「まだやるの？こっちから話しかけといてわるいけど、これで最後ね、お父さん。えっと、この図を考えればいいのね。AとBはそれぞれ有向分離するんじゃない？Cは合流点だから、有向分離できない」\nお父さん「そこまでは正しい。だけど有向分離できるのはそれだけじゃない。AとC、またはBとCはどうだろう。Cは合流点だけど、AまたはBによってパスE←A→C←B→Dは遮断できるでしょ」\n私「なるほど、二つ目の条件を使ったわけだ。丁寧に説明してくれたおかげで、どういうとき有向分離してるかっていうのはわかったつもりだけど。どういう意味があるの、これ？」\nお父さん「今回の話は、ブロックをちゃんと説明するっていうのが目的だったんだけど、ぴんとこなかったかなあ。さっきのDAGについていえば、有向分離できる変数の集合を探すことで、バイアスを防げる交絡因子の組み合わせを見つけられたっていう話の流れだったんだけど。もうひとつだけ付け加えるなら、DAGを確率変数に置き換えると、有向分離は条件付独立性と同じっていうことが知られている。この結果を用いて、因果効果を識別するために必要な交絡因子を見つけることができるんだ（バックドア基準とフロントドア基準）（Pearl 1995）」\n\n\n\n\n\n\nNote\n\n\n\n 有向分離と条件付独立性\nDAGを用いて、CがAとBを有向分離することが確認できたとする。そのとき、確率変数Cを与えた下で、AとBが条件付独立ということもわかる（Pearl 1995）。\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nこのDAGの解釈として正しいのはどちらでしょうか。\n\nCを与えた下で、EとDは条件付独立である\nCを与えても、EとDの間には相関がある\n\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解と解説\n正解は2です。\nパスE←C→DはCで遮断できますが、パスE→Dは遮断できません。したがって、CではEとDを有向分離できません。ただし、この場合には、有向分離できない理由は、EとDを結ぶ直接の因果関係が残ってしまうことであるという点に注意してください。EのDへの効果を推定するときには、（パスE→Dがあるかどうかにかかわらず）Cを調整すべきです。\n\n\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nこのDAGの解釈として正しいのはどちらでしょうか。\n\nCで条件付けないとき、EとDは独立である。また、Cを与えた下でも、EとDは条件付独立である\nCで条件付けないとき、EとDには相関がある。一方で、Cを与えた下で、EとDは条件付独立である\nCで条件付けないとき、EとDは独立である。一方で、Cを与えると、EとDの間には相関がある\nCで条件付けないとき、EとDには相関がある。また、Cを与えても、EとDの間には相関がある\n\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は4です。\n\nこの場合、最初のクイズとは違って、EとDを結ぶ直接のパスはありませんが、Cは合流点という問題があります。そのためCで調整すると、E←A→C←B→Dというパスが生じてしまい、やはりCでEとDを有向分離することはできません。\n\n\n\n\n\nエピソード、用語集\n\nThree-Variable DAGs: The Smallest Building Blocks of Causal Structure\nCommon Causes and Confounders\nDAGs and Conditional Distributions: Two Languages for the Same Structure\nBackdoor Paths and Confounders\nStatistical Terms in Plain Language"
  },
  {
    "objectID": "jp/effects-2.html",
    "href": "jp/effects-2.html",
    "title": "Who Is This Percentage About? Target Populations and Attributable Fractions",
    "section": "",
    "text": "Effects and Time II − Who Is This Percentage About? Target Populations and Attributable Fractions\n\nKeywords: effect measure, hypothesis/outcome/population, observational study, language/writing\n\n\n\n疾患リスクとターゲット集団\n\n\n私「コーヒーおかわりいる？お父さん」\n\n\nお父さん「ああ、ありがとう。ワクチンとは別の話題なんだけど、喫煙歴のあるがんの患者さんって、減ったと思う？」\n\n\n私「そうね、昔よりは少なくなったんじゃない？」\n\n\nお父さん「でも、日本のがんの統計上は、まだまだ喫煙は健康問題のひとつなんだ。がん罹患のリスク要因は、感染症、喫煙、飲酒の順に影響が大きいと推定されている」\n\n\n私「喫煙率は下がってるのにちょっと意外だね。でもどのがん登録でも、喫煙情報は絶対調べるよね」\n\n\nお父さん「感染症、喫煙、飲酒が、がん罹患に寄与する割合は、16%、15%、6%っていわれてる。この指標を、集団寄与割合っていうんだけど、これもただのパーセントじゃない」\n\n\n私「それはそうだよね。喫煙者の15%ががんになる、なんて思わないもの。でも正確な意味はわかんないな」\n\n\nお父さん「ほら、喫煙者のがん罹患を真っ先にイメージしちゃうでしょ。そこも誤解ポイント。集団寄与割合が想定している集団は、喫煙者じゃないんだ」\n\n\n\n\n\n\n\n\n寄与割合とその関連指標1. 集団寄与割合\n\n\n\n疫学研究では、一般集団を対象にして、環境物質や生活習慣といったリスク因子を調べることが多く、そのために寄与割合（attributable fraction/excess fraction）という指標も用いられます。寄与割合は、特定の集団におけるリスク因子への曝露が、どのくらい疾患発症に寄与するかを表す指標です。ただし、寄与割合には、歴史的に異なる定義のものが複数あり、どのような集団をターゲットとするかで計算方法も変わるので、じゅうぶん意味を確認する必要がある指標です。\nあるリスク因子が国民全体の疾患発症にどの程度寄与するかを反映する指標は、集団寄与割合（population attributable fraction）と呼ばれています。ここで\\(RR\\)はリスク比、\\(p\\)は集団全体のうち群1が占める割合を意味しています。\n\n集団寄与割合（population attributable fraction）\n\n\\[\nPAF=\\frac{p(RR-1)}{p(RR-1)+1}\n\\]\n\n\n\n\n私「ふーん。集団寄与割合はリスク比だけじゃなくて、リスク因子の割合がわからないと計算できないんだね。でも、まあ、これもワクチン有効率と同じパターンだね。パーセントっていわれるとただの割合と思っちゃう。集団寄与割合のパーセントって、よく考えるとなにを意味するのか謎」\n\n\nお父さん「うん。でもね、問題はそこだけじゃない。集団寄与割合にすごく似た別の指標が説明なしに使われることが結構あるってこと。リスク因子の割合が不要な指標もあって、集団寄与割合と混同されていることもある。実はこれはワクチン有効率とほとんど同じ式だったりする」\n\n\n\n\n\n\n\n\n寄与割合とその関連指標2. 集団全体とはターゲット集団が別の寄与割合\n\n\n\n曝露がリスク因子として働くときに用いられる指標として、多くの疫学の教科書で説明されているのは、以下の定義によるものです。この指標では、群1が曝露あり、群2が曝露なしと考えています。そして、群1から曝露を取り除いたとき、どのくらい疾患が減るかを表しています。\n\n過剰寄与割合（excess fraction） \\[\nEF = \\frac{\\pi_1 - \\pi_2}{\\pi_1} = 1 - \\frac{1}{RR}\n\\]\n\nその一方で、たとえば喫煙に対する禁煙のように、曝露が予防的に作用するとき、以下の指標が用いられます。群1が曝露あり、群2が曝露なしという点は同じですが、ターゲットは群2です。なお、この式はワクチン有効率と同じです。\n\n予防寄与割合（preventable fraction） \\[\nPF=\\frac{\\pi_2-\\pi_1}{\\pi_2}=1-RR\n\\]\n\n曝露集団をターゲットにする意義は、具体的な状況をイメージすると理解しやすくなります。環境疫学では、たとえば化学物質や放射線被ばくなど環境要因の健康影響を評価することが求められます。この場合では、集団全体ではなく、実際に環境要因に曝露した集団における被害を定量化する必要があるため、曝露集団をターゲットとしたexcess fractionがしばしば用いられます。同じような理由で、ワクチン・検診・運動などの予防法の新規導入が、個人のリスクをどれだけ下げたか知りたいときは、preventable fractionが好まれています。\n\n\n\n\n\n\n\n\n指標\nターゲット集団\n何を表す？\n\n\n\n\nPAF（集団寄与割合）\n曝露+非曝露\n集団全体の疾患のうち、どれだけがその曝露のため生じているか\n\n\nEF（過剰寄与割合）\n曝露だけ\n曝露集団のうち、どれだけの割合が曝露のため疾患を生じたか\n\n\nPF（予防寄与割合）\n曝露だけ\n曝露集団のうち、どれだけ予防的な曝露が疾患を防いだか\n\n\n\n\n\n\n\n私「余計にわかんない。使い分けもわかんないしパーセントがなにを意味するのか謎」\n\n\nお父さん「まあコーヒーを飲んでゆっくり考えよう。まずは具体的な計算結果をみてみてよ」\n\n\n\n\n\n\n\n\nコホート研究の数値例\n\n\n\nリスクや効果の指標について数値例をみるとイメージしやすいと思います。この表は、 喫煙と膵がんリスクの関係を調べる仮想的なコホート研究から得られたデータを表しています。上の式を用いて、リスク差、リスク比、オッズ比、excess fractionを求めると、以下のような結果が得られます。ワクチン有効率と同じように、excess fractionもパーセントで示すことがあるため、要注意です。\n\n\n\n\n喫煙あり\n喫煙なし\n効果の指標\n\n\n\n\n合計\n\n\n\n\n\n　膵がんあり\n15\n12\n\n\n\n　膵がんなし\n365\n868\n\n\n\n　リスク\n3.9%\n1.4%\n\n\n\n　リスク差\n\n\n2.5%\n\n\n　リスク比\n\n\n3倍\n\n\n　オッズ比\n\n\n3倍\n\n\n　Excess fraction\n\n\n74%\n\n\n\n\n\n\n\n私「同じパーセントでも、リスク差の2.5%とexcess fractionの74%は印象がだいぶ違う」\n\n\nお父さん「でしょ、言葉と認識にギャップがあるよね。それに、ただの計算だと思うとかえって理解しにくいところもある。たとえ話をさせてよ。60歳になってがん検診にきた人が4人いたとする。話をわかりやすくするために、4人の健康状態はまったく同じだとしよう。そのうち、最初の2人はがん検診が陽性で、根治切除できたとする。その後、71歳と79歳まで生きることができた。つまり、がん検診後の生存期間は11年と19年」\n\n\n私「ふんふん」\n\n\nお父さん「残りの2人は、本当はがんだったのに、検診では見つけられなかった。そのため、67歳と73歳で亡くなった。つまり、がん検診後の生存期間は7年と13年」\n\n\n60歳がん検診で陽性になり根治手術、71歳まで生存\n60歳がん検診で陽性になり根治手術、79歳まで生存\n60歳がん検診で偽陰性、手術を受けず、67歳まで生存\n60歳がん検診で偽陰性、手術を受けず、73歳まで生存\n\n\nお父さん「仮にこの2人を60歳のとき根治切除できたとしたら、生存期間は何割長くなるだろう」\n\n\n私「えっと、がん検診陽性の2人の生存期間は平均15年でしょ。がん検診陰性の2人の生存期間は平均10年。だから、(15-10)/10=0.5だから、50%の延長」\n\n\nお父さん「じゃあ、別の質問をするよ。もし、がん検診陽性の2人を60歳のとき根治切除できなかったとしたら、生存期間はどれくらい失われる？」\n\n\n私「(10-15)/15=-0.33だから、33%減っちゃうね」\n\n\nお父さん「そう。つまり、陽性2人と陰性2人のどちらをターゲットにするかで、データは同じでも、根治切除の生存期間に寄与する割合が変わってくる。ここが寄与割合の複雑なところなんだ。この例では生存期間で説明したけど、疾患リスクでもターゲット集団に依存する点は同じ。Excess fractionは、この例でいうと根治切除できなかった2人をターゲットと考えている。Preventable fractionのターゲットは、根治切除できた2人に対応している」\n\n\n私「なるほど、ターゲット集団を分母にとるのね。ターゲットがあるのが、リスク差とかリスク比とかとの違いってわけだ」\n\n\nお父さん「そういうわけでもないんだ。効果の指標にはどれも、表に出ないだけでターゲット集団がある。たとえば術後の大腸がん患者を対象にランダム化臨床試験をして、補助化学療法をすると死亡リスク差が-5%になったとするでしょ。これって、術後の大腸がん患者全体に補助化学療法をすべきって解釈にならない？」\n\n\n私「まあねえ」\n\n\nお父さん「つまり臨床試験の集団全体がターゲット集団になる。因果リスク差とか、因果リスク比っていう言葉があるんだけど、これは集団全体に別の治療をしたときや、集団全体がリスク因子に曝露したとき、リスクがどう変化するかを表してるんだ」\n\n\n私「ふーん。じゃあ効果の指標はどれも、単に数式が違うだけじゃなくて”どの集団について語っているか”という言語の問題が潜んでいるんだね。診療科で論文読むことがあるけど、まさか指標によって集団が変わるなんて認識してないんじゃないかな。この前のワクチン有効率はどうなの？」\n\n\nお父さん「ワクチン有効率も臨床試験で推定するよね。だからそのワクチンのターゲット全体が、ワクチンを接種したとき、それがプラセボだったときに比べ、何割感染症が減るかっていう解釈になる。現場では、既存のワクチンが普及していることがほとんどでしょ。そこにワクチン有効率98%の新しいワクチンを投入しても、感染症が98%減ることにはならない」\n\n\n\n\n\n\n\n\nターゲット集団\n\n\n\n治療や曝露とアウトカムの因果関係を扱うときには、どのような集団を考えているかをはっきりさせる必要があります。一例として、根治切除後の直腸がん患者におけるストーマ造設の有無と復職率との因果関係を考えてみましょう。このときストーマ保有者と非保有者を比較する因果リスク差は、「根治切除後の直腸がん患者全体」をターゲット集団としています。ストーマ保有者と非保有者という別の集団を比べているのに、患者全体がターゲットというのは奇妙にみえるかもしれません。しかし因果推論では、「患者全体がストーマを造設したとき」と「患者全体がストーマを造設しなかったとき」という仮想的な状況を対比することで、ストーマ造設が復職率を低下させたかがわかる、という反事実の考え方をするのです。\n\n\n\n\nお父さん「もうひとつ気を付けないといけないのは、リスクには時間の概念が隠れていること。検診後10年時点の死亡確率を考えてみよう。陽性2人の死亡確率は0%、陰性2人の死亡確率50%だよね。このときのexcess fractionはわかる？」\n\n\n私「うん。(0.5-0)/0.5=1でしょ」\n\n\nお父さん「そう、つまり根治切除していれば、がん陰性の2人の死亡は100%防げたという意味になる。でもさ、がん検診後、12年経つとどうなる？」\n\n\n私「(0.5-0.5)/0.5=0になるね」\n\n\nお父さん「じゃあ、がん検診後、20年経つと？」\n\n\n私「生存者はいなくなるね。(1-1)/1=0かな」\n\n\nお父さん「そういうこと。寄与割合は、時間とともに変化することがあり得るんだ。時間が隠れているっていうのは、リスク比やオッズ比も同じだけどね」\n\n\n私「なるほどね」\n\n\nお父さん「まとめるとね、“何%減る”とか”何%に効く”というパーセントを見たら、どの集団のことなのか、どの時点のリスクかを意識しよう、ということだね」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n今回みたように、寄与割合は、excess fractionやpreventable fraction以外に、曝露・非曝露を合わせた集団全体をターゲットにすることがあります（population attributable fraction）。先ほど用いたがん検診の例で考えましょう。仮にがん検診の精度が高くなって、感度を100%にできたとしましょう。先ほどの状況（感度50%）に比べて、検診後15年後に死亡している人数は、4人のうち、どのくらい減ると期待されるでしょうか。\n\n0%\n33%\n50%\n100%\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です\n\nこの4人の生存期間は、11年、19年、7年、13年なので、15年後の死亡数は3人です。また、根治切除後の死亡率は50%なので、根治切除後できなかった2人が、仮にがん検診でがんを見つけられて、根治切除できたとしたら、死亡率は50%と期待されます。この仮想的な状況における死亡数は、1+2×50%=2人です。つまり、検診後15年後に死亡している人数は33%減ったことになります。\nこの計算は、集団全体をターゲットとする寄与割合を求めていることに他なりません。集団全体における曝露割合を\\(p\\)で書くと、集団寄与割合は、以下の式で表されます。\n\\(PAF=\\frac{p(RR-1)}{p(RR-1)+1}\\)\nがん検診の例では、\\(p=0.5\\)、15年死亡リスク比は\\(RR=2\\)なので、これを代入すると、\\(PAF=0.5(2-1)/{0.5(2-1)+1}=0.33\\)となり、上の正解と一致します。\n\n\n\n\n\nエピソード、用語集、Rスクリプト\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nUnderstanding Collapsibility of Effect Measures in Marginal and Stratified Analyses with R\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nDistinguishing Time-Point, Time-Constant, and Time-Varying Effects: An R Example\nStatistical Terms in Plain Language\nfrequentist.R"
  },
  {
    "objectID": "jp/effects-4.html",
    "href": "jp/effects-4.html",
    "title": "When Odds Ratios Approximate Risk Ratios—and When They Fail",
    "section": "",
    "text": "Effects and Time IV − When Odds Ratios Approximate Risk Ratios—and When They Fail\n\nKeywords: bias, effect measure\n\n\n\nリスク比とオッズ比って、結局同じ？\n\n\n私「お父さんの話を聞いててね、国試の勉強してたときのことを思い出したよ。保健統計だったか、疫学だったかの問題で、オッズ比の計算問題を解いたことがあったなあ。リスク比とオッズ比って結局同じ使い方をするの？みたいな」\n\n\nお父さん「ああ、この前、膵がんの数値例で計算したとき、リスク比とオッズ比はどちらも3倍だったね。でも、これはたまたま。もっと正確にいうと、膵がんのように、リスクの値が低いときはリスク比とオッズ比は近い値になるんだ。ほら、リスク比とオッズ比の数式を見比べてよ。リスク比とオッズ比の違いって、\\(1-\\pi_1\\)と\\(1-\\pi_2\\)があるかどうかでしょ。リスクが低いと、ここがほとんど1になるから、リスク比とオッズ比の差がなくなる」\n\n\n私「まあ、私も論文読むとき別に区別してないけど」\n\n\nお父さん「えーっと、状況によってはそれはよくない。疾患や対象集団によっては、リスクが低いときばかりじゃないからね。最近の論文だと、オッズ比をリスク比の代わりに使うなら、そのままの値じゃなくて、オッズ比の平方根を報告した方がいいっていう説もある（VanderWeele 2017）」\n\n\n私「なにそれ、またお作法が増えたの？」\n\n\nお父さん「お作法があるわけじゃないんだけど、オッズ比をリスク比の近似として使うことがあるからね。そういうときに限っては、オッズ比の代わりにオッズ比の平方根でもいいんじゃないっていう主張かな。どっちにしても近似バイアスはそれなりに残るんだけど。リスク比とオッズ比の使い分けの話をするときは、まずは具体的な計算結果をみた方がわかりやすいと思う」\n\n\n\n\n\n\n\n\nリスク比はオッズ比の近似か\n\n\n\n表1は、2群の疾患リスク\\(\\pi_1\\)と\\(\\pi_2\\)の数値を0.1から0.9まで動かして、リスク比、オッズ比、オッズ比の平方根（square root of OR）を計算したものです。\n\\(RR=\\frac{\\pi_1}{\\pi_2}\\)\n\\(OR=\\frac{\\pi_1/(1-\\pi_1)}{\\pi_2/(1-\\pi_2)}\\)\n\\(SOR=\\sqrt{\\frac{\\pi_1/(1-\\pi_1)}{\\pi_2/(1-\\pi_2)}}\\)\n\\(\\pi_1\\)と\\(\\pi_2\\)のどちらかが0.2を超えると、リスク比とオッズ比はまったく違う値になることがわかります。リスク比とオッズ比が1より小さいとき、オッズ比はリスク比より必ず小さくなります。また、\\(\\pi_1\\)と\\(\\pi_2\\)が0.2～0.7の範囲であれば、リスク比とオッズ比の平方根は、高々0.11しか違いません。\n\n\n\n疾患リスク0.1～0.4疾患リスク0.5～0.8\n\n\n表1. 2群の疾患リスクを0.1から0.9まで動かしたときのリスク比（RR）、オッズ比（OR）、オッズ比の平方根（SOR）\n\n\n\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n\n\n\n\n0.1\nRR=1\n0.50\n0.33\n0.25\n0.20\n0.17\n0.14\n0.13\n0.11\n\n\n\nOR=1\n0.44\n0.25\n0.17\n0.11\n0.07\n0.05\n0.03\n0.01\n\n\n\nSOR=1\n0.67\n0.51\n0.41\n0.33\n0.27\n0.22\n0.17\n0.11\n\n\n0.2\n\nRR=1\n0.67\n0.50\n0.40\n0.33\n0.29\n0.25\n0.22\n\n\n\n\nOR=1\n0.58\n0.38\n0.25\n0.17\n0.11\n0.06\n0.03\n\n\n\n\nSOR=1\n0.76\n0.61\n0.50\n0.41\n0.33\n0.25\n0.17\n\n\n0.3\n\n\nRR=1\n0.75\n0.60\n0.50\n0.43\n0.38\n0.33\n\n\n\n\n\nOR=1\n0.64\n0.43\n0.29\n0.18\n0.11\n0.05\n\n\n\n\n\nSOR=1\n0.80\n0.65\n0.53\n0.43\n0.33\n0.22\n\n\n0.4\n\n\n\nRR=1\n0.80\n0.67\n0.57\n0.50\n0.44\n\n\n\n\n\n\nOR=1\n0.67\n0.44\n0.29\n0.17\n0.07\n\n\n\n\n\n\nSOR=1\n0.82\n0.67\n0.53\n0.41\n0.27\n\n\n\n\n\n表1. 2群の疾患リスクを0.1から0.9まで動かしたときのリスク比（RR）、オッズ比（OR）、オッズ比の平方根（SOR）\n\n\n\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n\n\n\n\n0.5\n\n\n\n\nRR=1\n0.83\n0.71\n0.63\n0.56\n\n\n\n\n\n\n\nOR=1\n0.67\n0.43\n0.25\n0.11\n\n\n\n\n\n\n\nSOR=1\n0.82\n0.65\n0.50\n0.33\n\n\n0.6\n\n\n\n\n\nRR=1\n0.86\n0.75\n0.67\n\n\n\n\n\n\n\n\nOR=1\n0.64\n0.38\n0.17\n\n\n\n\n\n\n\n\nSOR=1\n0.80\n0.61\n0.41\n\n\n0.7\n\n\n\n\n\n\nRR=1\n0.88\n0.78\n\n\n\n\n\n\n\n\n\nOR=1\n0.58\n0.26\n\n\n\n\n\n\n\n\n\nSOR=1\n0.76\n0.51\n\n\n0.8\n\n\n\n\n\n\n\nRR=1\n0.89\n\n\n\n\n\n\n\n\n\n\nOR=1\n0.44\n\n\n\n\n\n\n\n\n\n\nSOR=1\n0.67\n\n\n\n\n\n\n\n\n私「この表、いっぱい数字があって見方がわからないな。対角のところがRR=OR=SOR=1になるのは、\\(\\pi_1\\)と\\(\\pi_2\\)が同じ値だからだよね」\n\n\nお父さん「ごめんごめん、説明が必要だよね。RRに近いのは、ORとSORのどっちかをみてほしいんだ。さっき話した通り、古い教科書ではオッズ比はリスク比の近似だって教えるけど、実際にいろんな組み合わせで計算すると、そうならないことがある。っていうか、表をみるとRRとOR、結構ずれてない？むしろオッズ比の平方根をとった方がいいんじゃないかって話」\n\n\n私「平方根なんて論文書くとき勝手に計算していいのかね」\n\n\nお父さん「リスク比を推定することが目的なら、オッズ比の平方根を論文で示してもいいかもって気はする。推定方法の一種として、論文のMethodsで説明していればね。でも、よっぽど特殊な状況じゃなければ、リスク比を計算するのが素直だと思うけど」\n\n\n私「そう？私の周りではオッズ比の方がよく聞くけど？まあ胃がんや大腸がんの研究だと、ハザード比をダントツよく使うけど」\n\n\nお父さん「オッズ比が出てくるのは疫学の教科書とか国試対策でしょ。あれはケース・コントロール研究を教える都合ってだけだよ。リスクって疾患や死亡が起きる確率そのものでしょ。その差や比を直接とったリスク差・リスク比が基本だって理解しとかないと、単なる暗記になっちゃう。ハザード比は、ハザード関数っていう時間の関数の理解がないと取扱注意だし、前回話したように、層別などの調整を行うとき、リスク比はとても扱いやすい指標だからね」\n\n\n\n\n\n\n\n\nケース・コントロール研究とオッズ比\n\n\n\n古典的なケース・コントロール研究は、コホートの中から疾患を発生したケースを特定し、疾患を発生しなかったものの中からコントロールを選択し、ケースとコントロールの曝露状況を比較する研究です。言い換えると、この研究デザインでは、一部の集団のみ（ケースとコントロールのみ）について、過去の曝露状況を調査します。そうすると、コホートの一部しか曝露状況がわからないから、曝露群・非曝露群のリスクの分母がわかりませんよね。そこで、リスク比の代わりに「曝露オッズ比」を求める、と疫学の教科書には書かれています。ただし、古典的なケース・コントロール研究とは違い、最近ではデータベースが利用できたり、研究デザインを工夫していたりするため、リスク比を計算できる状況も増えてきています。\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nリスク比とオッズ比が1より小さいとき、オッズ比はリスク比より必ず小さくなるといいました。それでは、2群をオッズ比で比較するときのp値は、リスク比で比較するときのp値より、小さくなる（つまり有意になりやすく、検出力が向上する）のでしょうか。ただし。実際にデータから計算されたp値だと、検定の種類の選び方に影響されるし、偶然性も入ります。理論上の期待値がどうなるか考えてみてください。\n\nオッズ比のp値は、リスク比のp値より、期待値の上で小さい\nオッズ比のp値は、リスク比のp値より、期待値の上で大きい\nオッズ比のp値は、リスク比のp値と、期待値の上で等しい\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です\n\nリスク比やオッズ比は最尤法で推定することが普通です。最尤法を用いるとき、検定の性能（検出力など）は、指標の選び方によらず一定、ということが統計学で知られています。直感的な説明をすると、“同じデータから同じ情報を引き出している”から、どの指標を使って差を推定しても、検定としての力は変わらないのです。\n\n\n\n\n\n文献\n\nVanderWeele T. On a square-root transformation of the odds ratio for a common outcome. Epidemiology 2017;28(6):e58–e60\n\n\n\nエピソード、用語集、Rスクリプト\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nUnderstanding Collapsibility of Effect Measures in Marginal and Stratified Analyses with R\nWhen Odds Ratios Approximate Risk Ratios—and When They Fail\nFrom Risk and Rate to Survival and Hazard\nDistinguishing Time-Point, Time-Constant, and Time-Varying Effects: An R Example\nStatistical Terms in Plain Language\nfrequentist.R"
  },
  {
    "objectID": "jp/effects-6.html",
    "href": "jp/effects-6.html",
    "title": "Distinguishing Time-Point, Time-Constant, and Time-Varying Effects: An R Example",
    "section": "",
    "text": "Effects and Time VI − Distinguishing Time-Point, Time-Constant, and Time-Varying Effects\n\nKeywords: bias, effect measure, simulation, survival/competing-risk\n\n\n\nハザード比が意味を持つとき、持たないとき\n\n\n私「お父さん、正直にいうと生存曲線とかの数式はわからなかったんだけど、ひとつだけすごく気になったことがあって。それがこの式なの」\n\n\n\n指数分布のハザード比 \\[\nHR=\\frac{\\lambda_1}{\\lambda_2}\n\\]\nCox回帰のハザード比 \\[\nHR=\\frac{\\lambda_1(x)}{\\lambda_2(x)}\n\\]\n\n\n\n私「\\(x\\)が時間で、\\(\\lambda_1\\)と\\(\\lambda_2\\)が2群それぞれのハザードだっていうことはわかるよ。\\(HR\\)はハザード比（hazard ratio）だよね。でも、どうみても上も下も同じ式じゃない？」\n\n\nお父さん「ああ、文脈がないとそう読むのが普通かもね。指数分布の式の方はね、ハザードが\\(x\\)に依存しないでしょ、この式以前に。つまりハザード自体がもともと一定なんだ。下のCox回帰（Cox regression）をみると、\\(\\lambda_1(x)\\)と\\(\\lambda_2(x)\\)は時間\\(x\\)の関数なんだけど、この式はハザード比だけが一定っていうある種の制約を表している」\n\n\n私「つまり？」\n\n\nお父さん「つまりこの式が出た時点で、はじめて比例ハザード性が仮定された、あるいは構造が決まったっていうような文脈でとらえてほしいんだ」\n\n\n私「やっぱり違うのか。Cox回帰の式は、ロジスティック回帰に比べてシンプルすぎて見てて不安になるな。比例ハザード性っていう聞き覚えのある単語で説明されてやっと安心する」\n\n\nお父さん「この式は本質的なところしか書いてないからね。Cox回帰のよさはいくつもあるけど、\\(\\lambda_1(x)\\)と\\(\\lambda_2(x)\\)はどんな関数でもいいという点が、とても実用的なんだ。指数分布はハザードが定数だから、ずっと融通が利かない。データへの当てはまりが悪いんだ」\n\n\n私「Cox回帰は使いやすいってこと？ほぼほぼCox回帰しかみないけど」\n\n\nお父さん「そう。比例ハザード性はCox回帰の特徴そのもので、これさえ満たされれば、Cox回帰はどんなデータにも使えるんだけど、たまに比例ハザード性が崩れたデータをみることがある。これはオンコロジー領域では必須知識かもしれない。このKaplan-Meier曲線をみてよ（Mok, et al, 2009）。生存曲線がクロスした有名なケースなんだ」\n\n\n私「あ、よかった。数式ばかりで眠くなりかけてた」\n\n\n\n\n\nお父さん「これはステージIIIB～IVの肺がん患者の臨床試験で、ゲフィチニブと化学療法を比較している。図Aでは6ヶ月まではゲフィチニブ群の無増悪生存確率が低く、それ以降は高くなっているでしょ。こういうときは比例ハザード性が成り立っていないから、ハザード比に意味はない」\n\n\n私「どうしてこうなっちゃったの？」\n\n\nお父さん「それはゲフィチニブがEGFR変異陽性の肺がん患者に特に有効だったからだといわれている。図Bは、EGFR変異陽性だった261人を対象にしたKaplan-Meier曲線なんだけど、生存曲線はクロスせず、最初から最後までゲフィチニブ群の方が化学療法群より予後がいいでしょ」\n\n\n私「そうだね。この試験のKaplan-Meier曲線では、治療成績が交差して、どっちが効くのか悩ましいってことはわかるよ、数式はともかくとして」\n\n\nお父さん「はっきりいうとね、ハザードやハザード比が直感的にわかる人の方が少ないよ。だから安心していい」\n\n\n私「え、そうなの？なんか“知らないといけない基本”みたいに思って焦った」\n\n\nお父さん「ハザードはね、患者さんの健康状態を表す“見えない時計”だと思うといい」\n\n\n私「見えない時計？」\n\n\nお父さん「治療Aを受けた患者は、ちょっと速く進む時計を持っている。治療Bの人は、少し遅い時計を持っている。ハザード比は、2つの時計が“どれくらい違う速さで動くか”の比なんだ」\n\n\n私「なるほど、時間が進むスピードの違いなら、イメージしやすいかも」\n\n\nお父さん「ただし、ここが重要。時計の進み方は、必ずしも一定とは限らない。最初は治療Bが有利でも、途中から追いつかれることだってある」\n\n\n私「それ、実際の患者さんでもあるかも！」\n\n\nお父さん「まとめると、このたとえ話の主張はこんなこと。\n\nハザード比は、2つの時計が“どれくらい違う速さで動くか”の比に例えられる。 比例ハザード性が成り立たないと、最初は一方の治療が有利でも、途中から追いつかれることもある\n\nそれなのに多くの論文で“ハザード比＝一定”という前提で解析する。Cox回帰が標準的に使われるからね。だから、比例ハザード性が破綻すると、ハザード比の解釈が急に怪しくなる」\n\n\n\n\n\n\n\n\nシミュレーションデータにおける時点ごとのリスク比の推定\n\n\n\nさっきの「見えない時計」をデータで眺めてみましょう。以前と同じ、ストーマ造設の有無で死亡のハザードが異なる生存時間データをシミュレーションし、時点ごとのリスク比（RR） を推定してみます。ハザード比は「時計の速さの比」でしたが、「術後10年時点の死亡リスクは、ストーマあり群が何倍か」のようにリスク比の方が、解釈しやすいこともあります。Cox回帰では時点を通じて1つのハザード比を仮定するのに対して、cifmodelingパッケージのpolyreg()では、時点を通じて一定のリスク比だけでなく、任意の時点ごとのリスク比も推定できます。\n先ほどのシミュレーションデータを使って、time.pointを変えたpolyreg()を当てはめることで、術後5年・10年・20年時点の死亡リスク比を推定します。アウトカム（OS）はEvent(time_os,status_os)、曝露変数であるストーマの有無はexposure=\"stoma\"で指定しています。\n\n\n\n\n\n\n\n\ngenerate_data()のコードはこちら（データ生成に使用）\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # 再発のハザード（大きいほど早く起こる）\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # 死亡のハザード（大きいほど早く起こる）\n  hazard_censoring &lt;- 0.05                               # 打ち切りハザード（群に依存しない）\n  \n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)   # 再発までの潜在時間\n  t_death     &lt;- rexp(n, rate = hazard_death)     # 死亡までの潜在時間\n  t_censoring &lt;- rexp(n, rate = hazard_censoring) # 打ち切りまでの潜在時間\n  \n  ## --- 全生存期間（OS） ----------------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = 死亡, 0 = 打ち切り\n  \n  ## --- 無再発存期間（RFS） -------------------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # 再発\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # 死亡\n  \n  ## --- 累積再発率（CIR） + 競合リスク --------------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # イベント1: 再発\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # イベント2: 競合リスクとしての死亡\n  \n  ## --- データフレームにまとめる --------------------------------\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n}\n\n\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\nlibrary(cifmodeling)\nset.seed(46)\ndat &lt;- generate_data(hr1=2, hr2=1.5) #再発ハザード比2, 死亡ハザード比1.5のデータ生成\nrr_at_5 &lt;- polyreg(nuisance.model=Event(time_os,status_os)~1, exposure=\"stoma\", data=dat, \n                    effect.measure1=\"RR\", time.point=5, outcome.type=\"survival\")\nsummary(rr_at_5)\n\n\n                      event 1 (no competing risk)\n---------------------------------- \nstoma, WITH STOMA vs WITHOUT STOMA \n                      1.367       \n                      [1.006, 1.856]\n                      (p=0.045)   \n\n---------------------------------- \n\neffect.measure        RR at 5     \nn.events              89 in N = 200\nmedian.follow.up      3.54        \nrange.follow.up       [0.03, 28.20]\nn.parameters          2           \nconverged.by          Converged in objective function\nnleqslv.message       Function criterion near zero\n\nrr_at_10 &lt;- polyreg(nuisance.model=Event(time_os,status_os)~1, exposure=\"stoma\", data=dat, \n                    effect.measure1=\"RR\", time.point=10, outcome.type=\"survival\")\nsummary(rr_at_10)\n\n\n                      event 1 (no competing risk)\n---------------------------------- \nstoma, WITH STOMA vs WITHOUT STOMA \n                      1.126       \n                      [0.744, 1.704]\n                      (p=0.576)   \n\n---------------------------------- \n\neffect.measure        RR at 10    \nn.events              117 in N = 200\nmedian.follow.up      3.54        \nrange.follow.up       [0.03, 28.20]\nn.parameters          2           \nconverged.by          Converged in objective function\nnleqslv.message       Function criterion near zero\n\nrr_at_20 &lt;- polyreg(nuisance.model=Event(time_os,status_os)~1, exposure=\"stoma\", data=dat, \n                    effect.measure1=\"RR\", time.point=20, outcome.type=\"survival\")\nsummary(rr_at_20)\n\n\n                      event 1 (no competing risk)\n---------------------------------- \nstoma, WITH STOMA vs WITHOUT STOMA \n                      1.078       \n                      [0.720, 1.613]\n                      (p=0.714)   \n\n---------------------------------- \n\neffect.measure        RR at 20    \nn.events              137 in N = 200\nmedian.follow.up      3.54        \nrange.follow.up       [0.03, 28.20]\nn.parameters          2           \nconverged.by          Converged in objective function\nnleqslv.message       Function criterion near zero\n\n\n\n\n\n\n\n私「ハザード比は一定のデータを作ったのに、リスク比は1.367、1.126、1.078と徐々に小さく推定されてる。冒頭のKaplan-Meier曲線でも、最初の5年あたりがいちばん差が開いているもんね。時間と効果って、分けて考えられないんだね」\n\n\nお父さん「だってそうでしょ？効果って時間とともに生じるものだもの。それが因果の定義のひとつでもある。時間とともに効果の大きさが変化するなら、ハザード比に頼ることはできない。もっと丁寧に時点ごとにリスクを比べないと」\n\n\nTime-constant effect: 1つのハザード比で全期間を説明する（Cox回帰）\nTime-varying effect: 効果の大きさが時間とともに変わる（Kaplan-Meier曲線で記述）\nTime-point effect: ある時点のリスクや生存確率に注目して比べる（polyreg）\n\n\n私「そういわれると納得感あるなあ、ハザード比だけ使えばいいって方がシンプルで私好みだったんだけど。生存曲線を見るっていうのは、因果効果に時間の視点を加えるってことなんだね」\n\n\n\n\n文献\n\nMok TS, Wu YL, Thongprasert S, Yang CH, Chu DT, Saijo N, Sunpaweravong P, Han B, Margono B, Ichinose Y, Nishiwaki Y, Ohe Y, Yang JJ, Chewaskulyong B, Jiang H, Duffield EL, Watkins CL, Armour AA, Fukuoka M. Gefitinib or carboplatin-paclitaxel in pulmonary adenocarcinoma. N Engl J Med 2009;361(10):947-57\n\n\n\nThis concludes the Effects and Time series. If you’d like to keep reading over your next cup of coffee, the following episodes are waiting:"
  },
  {
    "objectID": "jp/frequentist-2.html",
    "href": "jp/frequentist-2.html",
    "title": "P-Value Explanations That Seem Plausible at First Glance",
    "section": "",
    "text": "Frequentist Thinking II − P-Value Explanations That Seem Plausible at First Glance\n\nclinical trial, hypothesis/outcome/population, p-value, survival/competing-risk, language/writing\n\n\n\n生存曲線とハザード比\n\n\n私「お父さん、コーヒーもう一杯、淹れ直したよ。続けてJCOG9502のハザード比について教えてよ」\n\n\nお父さん「あつつ。それは図Aのhazard ratio of death 1.36、図Bのhazard ratio of recurrence or death 1.29についてだね。どちらもKaplan-Meier曲線の違いを要約していて、TH群よりLTA群の方が予後がよかったことを表している。ハザードが高いってことは、Kaplan-Meier曲線が下がりやすいっていう意味だからね。大事なのは、図Aの全生存期間（OS）、図Bの無病生存期間（DFS）のどちらも、ハザード比で要約しやすい形状をしていることかな」\n\n\n\n私「要約しやすい？」\n\n\nお父さん「うん。どちらの図でもTH群のKaplan-Meier曲線が、きれいにLTA群の上にあるでしょ、右端の人数が4人しかいないところでは交差しているけど。ハザード比は、2本の生存曲線が、ハザードのスケールで比例関係にあることが前提なんだ。この関係を、Cox回帰（Cox regression）とか比例ハザードモデル（proportional hazards model）って呼んでいる」\n\n\n私「比例関係だったら交差したらまずいよね」\n\n\nお父さん「そういうこと。それに、OSとDFSの結果が一貫している。これもすごく素直な結果だよね。解釈しやすい。この話題は後で話すとして、まずはCox回帰をRでやってみよう。パソコンはある？」\n\n\n\n\n\n\n\ncoxph()を用いたハザード比の推定\n\n\n\nハザード比を推定する方法はいくつかありますが、もっともポピュラーなのはsurvivalパッケージのcoxph()です。以前のエピソードでは、関数generate_data(hr1, hr2)を用いて、ストーマの有無やOSのデータを生成しました。今回は同じデータにCox回帰を当てはめ、ストーマあり群とストーマなし群のハザード比を計算してみます。この関数では、死亡ハザード比の真値はhr2という引数で指定できます。\n\n\n\n\n\n\n\n\ngenerate_data()のコードはこちら（データ生成に使用）\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # 再発のハザード（大きいほど早く起こる）\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # 死亡のハザード（大きいほど早く起こる）\n  hazard_censoring &lt;- 0.05                               # 打ち切りハザード（群に依存しない）\n  \n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)   # 再発までの潜在時間\n  t_death     &lt;- rexp(n, rate = hazard_death)     # 死亡までの潜在時間\n  t_censoring &lt;- rexp(n, rate = hazard_censoring) # 打ち切りまでの潜在時間\n  \n  ## --- 全生存期間（OS） ----------------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = 死亡, 0 = 打ち切り\n  \n  ## --- 無再発存期間（RFS） -------------------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # 再発\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # 死亡\n  \n  ## --- 累積再発率（CIR） + 競合リスク --------------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # イベント1: 再発\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # イベント2: 競合リスクとしての死亡\n  \n  ## --- データフレームにまとめる --------------------------------\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n}\n\n\n\n\n\n\n\n\n\n\ncoxph()のコードと結果はこちら\n\n\n\n\n\n\n# install.packages(\"survival\") #インストールが必要なら実行\nlibrary(survival)\ndat &lt;- generate_data(hr1=2, hr2=1.5) #再発ハザード比2, 死亡ハザード比1.5のデータ生成\nfit &lt;- coxph(Surv(time_os, status_os) ~ stoma, data = dat)\nsummary(fit)\n\nCall:\ncoxph(formula = Surv(time_os, status_os) ~ stoma, data = dat)\n\n  n= 200, number of events= 135 \n\n                  coef exp(coef) se(coef)     z Pr(&gt;|z|)   \nstomaWITH STOMA 0.4698    1.5996   0.1770 2.655  0.00794 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\nstomaWITH STOMA       1.6     0.6252     1.131     2.263\n\nConcordance= 0.576  (se = 0.024 )\nLikelihood ratio test= 6.83  on 1 df,   p=0.009\nWald test            = 7.05  on 1 df,   p=0.008\nScore (logrank) test = 7.17  on 1 df,   p=0.007\n\n\n\n\n\n\np値に関する一見正しそうな説明\n\n私「ハザード比とp値は知ってる。ハザード比は、TH群が基準になってて、ハザード比が1より小さいとき、TH群よりLTA群の方がOSやDFSがいいってこと？p値は0.05より小さいと統計学的に有意なんでしょ。つまり、LTA群の方が、治療成績が悪かったけど、p値をみると2群に有意差はないんだよね」\n\n\nお父さん「そういうことだね。ハザードはイベント/観察人年で求める“率”で、ハザード比はその2群間の“比”だから。生存時間解析で使う指標だね」\n\n\n私「うんうん。でもそういうのって統計の教科書に書いてないよね。平均とか回帰係数ばっかり」\n\n\nお父さん「分野によって使われる統計手法が違うからね。がんの臨床試験データの解析を勉強するなら、米国で有名な臨床試験グループ（SWOG）の統計家が書いた臨床試験の教科書がいいよ（Green, et al. 2013）。話を戻すとさ。大まかな理解はあってるけど、p値の正確な意味は誤解されてることが多いんだよ。まあ、頻度論（frequentist）の立場で統計学をきっちりやらないと、なかなか難しいんだけどね。まず、試験によってはp値と比べる基準（有意水準）が5%でないこともある。たとえば中間解析（interim analysis）があるかな。論文の抄録を読んでごらん。実はJCOG9502では最終解析の前に、中間解析をする計画になっていて、この論文はそのとき早期中止になった結果を報告しているみたいだよ。中間解析では、5%より低い有意水準で検定するのが一般的なんだ」\n\n\n私「じゃあ有意差がついたから早期中止したってこと？」\n\n\nお父さん「いや、JCOG9502が早期中止した理由は、有意差がついたからではなく、LTA群が有意に勝つ見込みがないと、効果安全性評価委員会が判断したためだけどね。他にも典型的な誤解はある。p値に関する説明をいくつかしてみようか」\n\n\np値は帰無仮説（null hypothesis）が正しい確率である\np値が小さく、統計学的に有意であることは、科学的に重要な知見が得られたことを意味する\n統計学的に有意でない結果は、帰無仮説が正しいので採択すべきであることを意味する\n\n\nお父さん「JCOG9502の場合、帰無仮説は”LTA群の全生存曲線は、TH群の全生存曲線と等しい”ってことだよ。まず1について聞くけど、JCOG9502のp値は、”LTA群とTH群に生存曲線に差がない確率”を意味すると思う？」\n\n\n私「それでいいんじゃない？p値が0.05だったら100回に5回は正しい」\n\n\nお父さん「さっきの生存曲線を見ると、差がある確率より、差がない確率の方が高そうだもの。ここではね、言葉を正確に選んで考えてみてほしいんだ。“LTA群とTH群に生存曲線に差がない”っていう命題や仮説は、確率変数かな？確率変数ではないよね。命題は、正しいかどうかのどちらかしかないもの。確率変数ではないのに、確率が定義されるのは学問的におかしい」\n\n\n私「はーん。そういう理屈っぽいことがいいたかったわけね。じゃあそういう言い回しはやめます」\n\n\nお父さん「うんうん。じゃあ100回に5回ってどういう意味でいった？」\n\n\n私「へ。言葉通りだけど？JCOG9502を100回やったらどうなるかって意味」\n\n\nお父さん「その通り。同じ試験を100回繰り返したらp値が100個出てくるでしょ。これがこの場合の確率の定義なんだ。頻度論的確率っていって。じゃあ次。p値が小さいことは、“科学的に重要な知見が得られたこと”を意味すると思う？」\n\n\n私「普通そう考えるんじゃない？」\n\n\nお父さん「でもさっきの図のp値を見てよ。p=0.15からp=0.92まで4つのp値が示されているけど、どれも小さくはないでしょ」\n\n\n私「うん」\n\n\nお父さん「じゃあ科学的に重要じゃないってこと？」\n\n\n私「そういう意味でいったわけじゃないけど」\n\n\nお父さん「だよね。p値が小さい方が重要な研究結果だって考えがちだけど、それははっきりとした間違いだと考えてください。論文を読むとき、p値に注目すると見方が偏ってしまう」\n\n\n私「はいはい。お父さん、話長くない？」\n\n\nお父さん「もう最後にするよ。それにコーヒーも残ってるじゃない。三つ目の説明“統計学的に有意でない結果は、帰無仮説が正しいので採択すべきであることを意味する”についてはどう？これは正しいかな？」\n\n\n私「教科書かなにかで、p値は、仮説を棄却するためのもので、採択しちゃだめって読んだ気がする。この最後の説明も、やっぱり間違いなんでしょ。でもさ、実際問題として、有意差がつかなかったらどうなるの？たとえば実薬AとBを比較する臨床試験だったとして、AとBの効果は同等と結論に書いていいの？」\n\n\nお父さん「それはルール違反だよ。この問いは、そういう間違いをさせないために出したんだ。帰無仮説が正しいことは、AとBの効果は同等っていう意味になるけど、有意差がないからって、それを採択してはいけない。“同等”や“劣らない”という結論を出すには、同等性 （equivalence）試験や非劣性 （non-inferiority）試験を組む必要がある」\n\n\n私「ふーん。そんなことわざわざやるかなあ。統計学は“有意差がないこと”と“同等”の区別にうるさいってことね」\n\n\nお父さん「そうだね、仮説にはうるさいね。これは日本の話なんだけど。昔、薬事承認の根拠として非劣性試験を行っていた時代があってね。その時代の経験を踏まえると、研究仮説と統計的な判断基準の関係は、厳密に考えとかないとちょっとまずいと思うんだ」\n\n\n\n\n\n\n\n\n\nホパテの悲劇\n\n\n\n脳循環改善薬という古い薬をご存知でしょうか？この薬はかつて脳血管障害の後遺症や認知症などに使われ、累計8,000億円ほどの売上げがあったようです。脳循環改善薬にはいくつかの類似薬がありましたが、そのほとんどが、最初に承認されたホパンテン酸カルシウム（販売名ホパテ）と比較した「非劣性試験」を根拠に承認されていました。しかし当時行われていたのは、正式な非劣性の解析ではなく、「ホパンテン酸カルシウムと比べて有意差がない」ことにもとづいて非劣性を判定していました。1998年にホパンテン酸カルシウムは副作用のため市場から撤退しました。同時期に、厚生省（当時）は製薬企業にプラセボ対照試験による再評価を求めました。その結果、脳循環改善薬は、すべてプラセボに勝てなかったのです。この悲劇は、有意差がつかなかったとき、同等や非劣性と結論するのは間違いであることを明確に示しています。\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n\nこの人は誰でしょう。\n\nKaplan\nMeier\nCox\nWilcoxon\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です\n\nこの方がCox先生です。\nDavid Cox (statistician)\n\n\n\n\n\n文献\n\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\nGreen J, Benedetti J, Smith A, Crowley J. 米国SWOGに学ぶがん臨床試験の実践 第2版（原書第3版）. 東京: 医学書院; 2013\n\n\n\nエピソード、用語集、Rスクリプト\n\nReading a Paper over a Cup of Coffee\n[P-Value Explanations That Seem Plausible at First Glance]\n[Beyond 0.05: Interpreting P-Values in a Clinical Trial]\n[R Demonstration of Bias in Kaplan-Meier Under Competing Risks]\n[Understanding Confidence Intervals via Hypothetical Replications in R]\n[Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size]\nStatistical Terms in Plain Language\nfrequentist.R"
  },
  {
    "objectID": "jp/frequentist-4.html",
    "href": "jp/frequentist-4.html",
    "title": "R Demonstration of Bias in Kaplan-Meier Under Competing Risks",
    "section": "",
    "text": "Frequentist Experiments I − R Demonstration of Bias in Kaplan-Meier Under Competing Risks\n\nKeywords: probability model, simulation, survival/competing-risk\n\n\n\nモデルを立ててバイアスを確かめる\n\n\n私「おはよう、今朝は冷えるね。ご飯食べてるところ悪いんだけど、ちょっと気になったことがあって。以前、統計学にはランダム誤差とバイアスがあるっていってたよね、覚えてる？あ、コーヒーもらっていい？」\n\n\nお父さん「覚えてるよ。コーヒーもどうぞ、まだ冷めてないと思う」\n\n\n私「バイアスって疫学で習うものだよね。統計学の本を読んでもバイアスなんて出てこないよ」\n\n\nお父さん「そうだね、不偏推定量（unbiased estimator）っていう概念があるんだけど、数理統計学の話だから目にしないと思う」\n\n\n私「そうなんだ。でも聞いた感じ、疫学のバイアスとは別でしょ？データを解析した結果とどういう関係があるの？」\n\n\nお父さん「ああ、そういうことね。確かに、疫学で出てくる研究実施上のバイアスそのものは、統計学の教科書にあまり登場しないね。でも、推定した結果が真値からずれるっていう意味では同じもの。少し時間ある？カバンの中のパソコン出せる？」\n\n\n私「え？朝からなにするの？」\n\n\nお父さん「統計学ではよく、シミュレーションっていってデータを乱数で発生させて実験するんだ。Kaplan-Meier曲線を描くとき、競合リスクの扱いによってはバイアスが生じるってことをみせてあげるよ、バイアスがどれくらい困ったことなのか実感ないみたいだから。前に使ったRスクリプトをいじるだけですぐ終わるから」\n\n\n私「仕方ないな」\n\n\nお父さん「パソコンを立ち上げる間に何をするか話そう。競合リスクを含むデータは、こういう仕組みで生まれる」\n\n\n再発までの時間を発生させる\n死亡までの時間を発生させる（競合リスク）\n打ち切りまでの時間を発生させる\n\n\nお父さん「実際に観測されるのは、もちろんそのうち一番先に起きたイベント、つまりこの3つの値の最小値をとる」\n\n\n私「なるほど、それなら再発より先に死亡したら、再発は観測されないわけだ」\n\n\nお父さん「ここで問題になるのが競合リスクの扱い。よく死亡を打ち切りにした解析を見るでしょ。あのKaplan-Meier曲線は、現実世界で再発が生じる確率を過大評価しているんだ。この解析じゃなくてAalen-Johansen曲線を推定すると、正しく再発確率が求められる。ではRでデータを発生させてみよう」\n\n\n\n\n\n\n\n\nシミュレーションデータ（再発あり）におけるKaplan-Meier曲線のバイアス\n\n\n\n以前生成したシミュレーションデータにおける累積再発率（CIR）の解析では、再発の前に死亡した患者（競合リスク）を発生させたことを覚えていますか？競合リスク存在下でKaplan-Meier曲線を用いるとバイアスが生じることは、簡単な実験で確かめることができます。\n\n\n\n\n\n\n\n\nデータ生成に用いるgenerate_data()のコードはこちら\n\n\n\n\n\n\ngenerate_data &lt;- function(n=200, hr1, hr2) {\n  stoma &lt;- rbinom(n, size = 1, prob = 0.4)\n  sex &lt;- rbinom(n, size = 1, prob = 0.5)\n  age &lt;- rnorm(n, mean = 65 + 3 * stoma, sd = 8)\n  hazard_relapse   &lt;- ifelse(stoma == 1, hr1*0.10, 0.10) # 再発のハザード（大きいほど早く起こる）\n  hazard_death     &lt;- ifelse(stoma == 1, hr2*0.10, 0.10) # 死亡のハザード（大きいほど早く起こる）\n  hazard_censoring &lt;- 0.05                               # 打ち切りハザード（群に依存しない）\n  \n  t_relapse   &lt;- rexp(n, rate = hazard_relapse)   # 再発までの潜在時間\n  t_death     &lt;- rexp(n, rate = hazard_death)     # 死亡までの潜在時間\n  t_censoring &lt;- rexp(n, rate = hazard_censoring) # 打ち切りまでの潜在時間\n  \n  ## --- 全生存期間（OS） ----------------------------------------\n  time_os   &lt;- pmin(t_death, t_censoring)\n  status_os &lt;- as.integer(t_death &lt;= t_censoring)  # 1 = 死亡, 0 = 打ち切り\n  \n  ## --- 無再発存期間（RFS） -------------------------------------\n  time_rfs &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_rfs &lt;- integer(n)\n  status_rfs[time_rfs == t_relapse & time_rfs &lt; t_censoring] &lt;- 1 # 再発\n  status_rfs[time_rfs == t_death & time_rfs &lt; t_censoring] &lt;- 1   # 死亡\n  \n  ## --- 累積再発率（CIR） + 競合リスク --------------------------\n  time_cir &lt;- pmin(t_relapse, t_death, t_censoring)\n  \n  status_cir &lt;- integer(n)\n  status_cir[time_cir == t_relapse & time_cir &lt; t_censoring] &lt;- 1 # イベント1: 再発\n  status_cir[time_cir == t_death & time_cir &lt; t_censoring] &lt;- 2   # イベント2: 競合リスクとしての死亡\n  \n  ## --- データフレームにまとめる --------------------------------\n  dat &lt;- data.frame(\n    id         = 1:n,\n    sex        = factor(sex, levels = c(0, 1), labels = c(\"WOMAN\", \"MAN\")),\n    age        = age,\n    stoma      = factor(stoma, levels = c(0, 1),\n                        labels = c(\"WITHOUT STOMA\", \"WITH STOMA\")),\n    time_os    = time_os,\n    status_os  = status_os,\n    time_rfs   = time_rfs,\n    status_rfs = status_rfs,\n    time_cir   = time_cir,\n    status_cir = status_cir\n  )\n}\n\n\n\n\n\n\n\n\n\n\n累積再発率（CIR）のAalen-Johansen曲線\n\n\n\nKaplan-Meier曲線とAalen-Johansen曲線は、どちらもcifmodelingパッケージのcifplot()を使って生成できますが、イベントのコーディングを入力するcode.event1、code.event2とデータの型を表すoutcome.typeを、指定する必要があります。generate_data()で生成したシミュレーションデータでは、CIRのイベントは以下のようにコーディングされていました。\n\nstatus_cir=1 : 再発\nstatus_cir=2 : 再発を経験しない死亡\nstatus_cir=0 : 打ち切り\n\n以下のRスクリプトでは、最初のcifplot()により、再発（code.event1=1）に関するAalen-Johansen曲線（aj_event1）を出力しています。縦軸は累積発生確率ではなく、1-累積発生確率を選んでいる点にも注意してください（type.y=\"surv\"）。そして次のcifplot()ではイベントを入れ替えて、再発を経験しない死亡（code.event1=1）に関するAalen-Johansen曲線（aj_event2）を出力し、cifpanel()に用いて2つの図を左右に配置したひとつの図を表示しています。左右の累積発生確率の和に注目してください。この図からは、再発の累積発生確率と（再発を経験しない）死亡の累積発生確率の和は、時間が経つにつれ1に近づくが、1を超えることはないことがわかります。仮に打ち切りがなかったとしたら、再発と（再発を経験しない）死亡のどちらか一方しか生じないため、Aalen-Johansen曲線の和が1を超えないのは自然なことです。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\n# devtools::install_github(\"gestimation/cifmodeling\") #インストールが必要なら実行 \nlibrary(cifmodeling)\nset.seed(46)\ndat &lt;- generate_data(hr1=2, hr2=1.5) #再発ハザード比2, 死亡ハザード比1.5のデータ生成\n\naj_event1 &lt;- cifplot(Event(time_cir, status_cir) ~ stoma,\n  data         = dat,\n  outcome.type = \"competing-risk\", \n  type.y       = \"surv\",\n  label.y      = \"1-Aalen-Johansen\",\n  code.event1  = 1, \n  code.event2  = 2\n)\naj_event2 &lt;- cifplot(Event(time_cir, status_cir) ~ stoma,\n  data         = dat,\n  outcome.type = \"competing-risk\", \n  type.y       = \"risk\",\n  label.y      = \"Aalen-Johansen\",\n  code.event1  = 2, \n  code.event2  = 1\n)\naj_list &lt;- list(aj_event1$plot, aj_event2$plot)\naj_panel &lt;- cifpanel(rows.columns.panel = c(1,2), plots=aj_list)\nprint(aj_panel)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積再発率（CIR）のKaplan-Meier曲線\n\n\n\n実際の研究では、死亡を打ち切りとして扱った生存時間解析の結果をしばしば目にします。この解析に対応するKaplan-Meier曲線は、以下のようにイベントのコーディングを変更し、outcome.type=\"survival\"を指定することで出力できます。\n\nstatus_cir1=1 : 再発\nstatus_cir1=0 : 再発を経験しない死亡/打ち切り\nstatus_cir2=1 : 再発を経験しない死亡\nstatus_cir2=0 : 再発/打ち切り\n\n新しく作ったイベント変数status_cir1とstatus_cir2を用いると、再発のKaplan-Meier曲線と（再発を経験しない）死亡のKaplan-Meier曲線を描くことができます。これらのKaplan-Meier曲線を左右に配置した図を、先ほどのAalen-Johansen曲線の図と比べてみてください。先ほどのAalen-Johansen曲線の和とは違い、Kaplan-Meier曲線の和が1を超えてしまって計算が合わないことが読み取れたでしょうか。\n\n\n\n\n\n\n\n\nRコードと結果はこちら\n\n\n\n\n\n\ndat$status_cir1 &lt;- as.numeric(dat$status_cir==1)\nkm_event1 &lt;- cifplot(Event(time_cir, status_cir1) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\", \n  type.y       = \"surv\",\n  label.y      = \"Kaplan-Meier\"\n)\ndat$status_cir2 &lt;- as.numeric(dat$status_cir==2)\nkm_event2 &lt;- cifplot(Event(time_cir, status_cir2) ~ stoma,\n  data         = dat,\n  outcome.type = \"survival\", \n  type.y       = \"risk\",\n  label.y      = \"1-Kaplan-Meier\"\n)\nkm_list &lt;- list(km_event1$plot, km_event2$plot)\nkm_panel &lt;- cifpanel(rows.columns.panel = c(1,2), plots=km_list)\nprint(km_panel)\n\n\n\n\n\n\n\n\n\n\n\n\n\nお父さん「わかった？シミュレーションデータを発生させたアルゴリズムは確率モデルっていって、研究でなにが起きるかを抽象化した数理モデルなんだ。どんな統計手法も使用条件みたいなものがあって、前提にしている確率モデルからずれるとバイアスが生じる。モデルの誤特定なんて言い方をするね」\n\n\n私「なるほどね。再発確率と死亡確率を足して1を超えることはあり得ない、Kaplan-Meier曲線にバイアスが生じていることの証拠だっていいたいのね。確かに、百聞は一見に如かず」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nKaplan-Meier法による生存曲線の推定が妥当な状況として正しいのは、次のうちどれでしょうか。\n\n生存時間が正規分布するとき\n打ち切りの理由が疾患の悪化によらないとき\n2群の打ち切り確率に統計学的な有意差がなかったとき\n試験治療群とコントロール群の間で比例ハザード性が成り立つとき\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は2です\n\nKaplan-Meier法では、生存時間が正規分布したり、比例ハザードが成り立ったりする必要はありません（これはそれぞれt検定とCox回帰の前提条件ですね）。疾患の悪化に伴って、試験の途中で患者が追跡できなくなると、推定された生存曲線にバイアスが生じてしまいます。2群の生存曲線を比べるとき、それぞれの群の打ち切り確率を比較することがあります。有意差があればバイアスがあるといえますが、たとえばサンプルサイズが小さいときは有意差が出ませんから、Kaplan-Meier法が妥当という証拠にはなりません。逆にいうと、打ち切りがランダムに起きていることが、Kaplan-Meier法の基本的な前提条件です。\n\n\n\n\n\nエピソード、用語集、Rスクリプト\n\nReading a Paper over a Cup of Coffee\n[P-Value Explanations That Seem Plausible at First Glance]\n[Beyond 0.05: Interpreting P-Values in a Clinical Trial]\n[R Demonstration of Bias in Kaplan-Meier Under Competing Risks]\n[Understanding Confidence Intervals via Hypothetical Replications in R]\n[Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size]\nStatistical Terms in Plain Language\nfrequentist.R"
  },
  {
    "objectID": "jp/frequentist-6.html",
    "href": "jp/frequentist-6.html",
    "title": "Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size",
    "section": "",
    "text": "Frequentist Experiments III − Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size\n\nKeywords: probability model, p-value, simulation, study design, survival/competing-risk\n\n\n\nあれ？何人に調査すればいいんだろう\n\n\nお父さん「ちょっといいかな」\n\n\n私「なに？お父さん、たばこくわえながら真面目な顔して」\n\n\nお父さん「サンプルサイズって計算した？」\n\n\n私「サンプルサイズってなんのこと？」\n\n\nお父さん「ほら、がんサバイバーの調査するんでしょ。その人数のこと」\n\n\n私「ああ、あれね。100人に調査するつもりだよ」\n\n\nお父さん「この前は話が中途半端だったでしょ。続きを説明したくて。前回は“精度”の話。今日は“差を見つけたいとき”の話」\n\n\n私「ん、わかった。サンプルサイズの話の続きね。なになに」\n\n\nお父さん「前回は信頼区間とサンプルサイズだったよね。でも、もしストーマ造設ありとなしの復職率を比べるような仮説検証を目指した研究をしたいなら、仮説検定の考え方にそってサンプルサイズを計算しないといけない」\n\n\n私「仮説検定ってp値のこと？」\n\n\nお父さん「そうそう。そっちの話をするなら、p値とαエラー・βエラーの関係を説明しないとだな。この前、JCOG9502の論文もってきたとき、どこまで話したっけ？」\n\n\n私「p値とかASA声明については聞いたよね。でも、エラーって言葉はでてこなかったな」\n\n\nお父さん「じゃあ、話はそこからだね。ちょっとそこのナプキンとペンをとって」\n\n\n私「ん？これのこと？」\n\n\nお父さん「ありがとう。αエラー・βエラーは、表にしないと説明できないからね」\n\n\n\n\n\n\n\n\nαエラーとβエラー\n\n\n\nこれまで、臨床試験JCOG9502（Sasako, et al. 2006）の文脈に沿って、片側p値と両側p値の違いも交えながら、p値について解説してきました。しかし本質的に重要なのは、p値を用いた判断に、どのような合理性があるのか、ということです。\nJCOG9502を題材に考えてみましょう。この場合の真実は「LTA群はTH群に比べ全生存期間を延長する効果がある」と「効果がない」の2通りがあるといいました。一方で、試験の結果もp&lt;0.05とp≥0.05の2通りです。これらを組み合わせは2×2の4通りがあります。\nこのうち、臨床試験の結果から判断を誤ってしまうケースは2つです。つまり、効果があるのにp≥0.05になってしまうケースと、効果がないのに（帰無仮説が正しいのに）p&lt;0.05になってしまうケースです。仮説検定では、前者をαエラー（alpha error）、後者をβエラー（beta error）と呼んでいます。また、βエラーを1から引いたものを検出力（power）と呼んでいます。\n\n\n\n研究結果\n真に効果がない（帰無仮説）\n真に効果がある（対立仮説）\n\n\n\n\n有意差なし（p値≥有意水準）\n\nβエラー\n\n\n有意差あり（p値&lt;有意水準）\nαエラー\n検出力=1-β\n\n\n\n\n\n\n\n私「まあ当たり前だよね。左開胸開腹連続切開をしたLTA群で予後がよくならないのに、有意に効いたって判断したら間違いだし、逆にいい術式なのに、結果的に有意にならなかったらそれも研究失敗だし」\n\n\nお父さん「そうだね。でも、正確にいうと、αエラー・βエラーは”統計学的に有意”とかp値とかとは、直接関係する概念じゃない。別に、効果があるかどうか判定する基準は、p値じゃなくてもいいわけだからね。ポイントはね、\n\np&lt;0.05は、αエラーだけを制御する基準\n\nだってこと」\n\n\n\n\n\n\n\n\nαエラー、βエラー、p値\n\n\n\nαエラーとβエラーが生じる確率を考えてみましょう。理論的に考えると、サンプルサイズが大きくなるほど、ランダム誤差は小さくなります。αエラーとβエラーも同じで、サンプルサイズが大きいほど小さくなる（判断を誤りにくくなる）性質があります。しかし、2つのエラーはトレードオフの関係にあります。サンプルサイズが一定だと、両方同時に小さくすることはできません。そこで通常は、αエラーを優先して、事前に決めた水準よりも小さく保たれるような判定方式を用います。これが仮説検定であり、事前に決めた水準のことを有意水準と呼びます。実は、p&lt;0.05で判定することと有意水準を5%と設定することは、同じ意味です。\nややこしいのですが、JCOG9502では症例登録に予定より時間がかかったため、有意水準10%、つまり全生存期間の片側p値を0.1と比べる方式が採用されました。この方式では、LTAに延命効果がなくても、100回に10回はαエラーが生じてしまい、LTAが有効と判定してしまうことになります。つまり、有意水準が5%から10%に高くなると、判断を誤る確率が増える代わりに、サンプルサイズが小さくて済むわけです。\n\n\n\n\nサンプルサイズ設計によるβエラーの制御\n\n\n私「紙ナプキンに描いてくれた表自体はわかるんだけどね。そこからαとかβとか確率とかいわれてもなあ。ついていけないな」\n\n\nお父さん「まずはαエラーとβエラーが臨床試験のどんな結果を表しているか考えると、イメージしやすいかもね。まず、αエラーとβエラーの意味から確認させて」\n\n\nαエラー: 「効果がない」という確率モデル上で計算されたエラーの確率\nβエラー: 「効果がある」という確率モデル上で計算されたエラーの確率\n\n\nお父さん「JCOG9502のように試験治療の有効性を検証する試験では、αエラーは標準治療と差がないかそれより劣る治療方法が普及してしまうことにつながる。いわば、”αエラー=消費者リスク”といえる。一方で、βエラーは試験治療が本当は有効なのに、開発中止してしまうことを意味する。だから”βエラー=生産者リスク”といわれる。医師の視点で気になるのは、やっぱりαエラーの方だよね」\n\n\n私「理屈じゃなくて、数字の実感がないのよ。判断ミスをする確率なんて低い方がいいに決まってるよね。でもどのくらいの確率にするものなの？」\n\n\nお父さん「JCOG9502の論文読んだんでしょ。どう書いてあった？」\n\n\n私「はいはいみますみます。”The amended sample size was 250, with one-sided alpha error of 0.1 and beta error of 0.2”って書いてある。片側検定で、αエラー0.1、βエラー0.2ってことね。そうすると、予定変更後のサンプルサイズは250人になったんだ」\n\n\nお父さん「そういうこと。βエラーは0.1か0.2が一般的かな。米国臨床試験グループSWOGの統計家たちは、教科書で以下のように述べている（Green, et al. 2013）。\n\n新しい治療法が見つかることはさほど多くないため、我々は原則として90%の検出力を推奨している\n\n検出力90%はβエラー0.1のことね」\n\n\n私「私の研究でもサンプルサイズは250人でよくない？」\n\n\nお父さん「雑だけどいい線いってる。大体それくらいになりそうだけど、サンプルサイズの計算結果を表にしてあげるから、ちゃんとそれをみて決めよう。いろんな状況があり得るけど、両側αエラー0.05で、βエラーは0.2（検出力0.8）と0.1（検出力0.9）という設定がもっともよく用いられるから、そのときのサンプルサイズを紹介するね。同じ人数の2つの群を比較することを想定しているから、群ごとの人数はサンプルサイズの半分になる」\n\n\n検出力80%検出力90%\n\n\n表1. 2群の生存曲線を比較するためのサンプルサイズ\n両側 α=0.05, 1−β=0.8\n※ 数値は「2群合計のサンプルサイズ」（割付け比1:1）\n\n\n\n\\(\\pi_2\\)\n\\(\\pi_1=0.1\\)\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n\n\n\n\n0.15\n964\n—\n—\n—\n—\n—\n—\n—\n\n\n0.20\n296\n—\n—\n—\n—\n—\n—\n—\n\n\n0.25\n156\n1826\n—\n—\n—\n—\n—\n—\n\n\n0.30\n102\n506\n—\n—\n—\n—\n—\n—\n\n\n0.35\n74\n246\n2486\n—\n—\n—\n—\n—\n\n\n0.40\n58\n152\n658\n—\n—\n—\n—\n—\n\n\n0.45\n48\n104\n308\n2894\n—\n—\n—\n—\n\n\n0.50\n42\n78\n182\n744\n—\n—\n—\n—\n\n\n0.55\n36\n62\n122\n340\n3034\n—\n—\n—\n\n\n0.60\n32\n52\n90\n198\n764\n—\n—\n—\n\n\n0.65\n28\n42\n70\n130\n342\n2900\n—\n—\n\n\n0.70\n26\n38\n54\n92\n194\n712\n—\n—\n\n\n0.75\n24\n34\n38\n70\n124\n312\n2492\n—\n\n\n0.80\n22\n30\n38\n56\n86\n174\n592\n—\n\n\n0.85\n22\n26\n34\n46\n66\n110\n254\n1818\n\n\n0.90\n20\n26\n30\n38\n50\n136\n136\n414\n\n\n\n\n\n表1. 2群の生存曲線を比較するためのサンプルサイズ\n両側 α=0.05, 1−β=0.9\n※ 数値は「2群合計のサンプルサイズ」（割付け比1:1）\n\n\n\n\\(\\pi_2\\)\n\\(\\pi_1=0.1\\)\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n\n\n\n\n0.15\n1290\n—\n—\n—\n—\n—\n—\n—\n\n\n0.20\n396\n—\n—\n—\n—\n—\n—\n—\n\n\n0.25\n208\n2444\n—\n—\n—\n—\n—\n—\n\n\n0.30\n136\n676\n—\n—\n—\n—\n—\n—\n\n\n0.35\n100\n330\n3330\n—\n—\n—\n—\n—\n\n\n0.40\n78\n202\n880\n—\n—\n—\n—\n—\n\n\n0.45\n64\n138\n412\n3876\n—\n—\n—\n—\n\n\n0.50\n54\n104\n242\n996\n—\n—\n—\n—\n\n\n0.55\n46\n82\n162\n454\n4060\n—\n—\n—\n\n\n0.60\n42\n68\n120\n264\n1022\n—\n—\n—\n\n\n0.65\n38\n56\n90\n172\n456\n3880\n—\n—\n\n\n0.70\n34\n48\n72\n124\n258\n952\n—\n—\n\n\n0.75\n32\n42\n60\n92\n166\n416\n3336\n—\n\n\n0.80\n30\n40\n52\n74\n116\n232\n796\n—\n\n\n0.85\n28\n34\n46\n60\n88\n146\n338\n2436\n\n\n0.90\n26\n32\n38\n50\n68\n100\n180\n548\n\n\n\n\n\n\n\nお父さん「ストーマ造設あり・なしの2群があるとして、復職率はそれぞれどれくらいになりそうなの？仮の値でいいよ」\n\n\n私「むずいな。どのくらいなんだろう。なにも不利なことがないなら、手術した後、1年以内に80%は復職してほしいかな。ストーマがあると20%から30%くらいは復職率が下がるんじゃない？調査してみないとわかんないけどね」\n\n\nお父さん「なるほど。もし復職状況を生存時間データとして解析するとしたらね。復職できた時点でイベントが発生し、それ以外の患者は打ち切りになる。表1と2は、2群の生存確率を比較するためのもので、生存確率を\\(\\pi_1\\)と\\(\\pi_2\\)と表記している。\\(\\pi_1\\)と\\(\\pi_2\\)は、がんサバイバー研究でいうとグループごとの”非復職確率”に対応する。つまり復職率が80%と60%だったら、\\(\\pi_1=0.2\\)と\\(\\pi_2=0.4\\)になる。この数字を使うってことは、暗黙の裡に、1年間追跡することを想定してるんだけどね。表2の対応箇所をみてみてよ」\n\n\n私「202人って書いてある。これが調査しないといけない人数ってこと？」\n\n\nお父さん「そういうこと」\n\n\n私「もし、202人の全員が1年間で追跡できなかったらどうするの？半年までしか調査できなかったとか」\n\n\nお父さん「この表のサンプルサイズは、術後1年間100%追跡できるという前提で計算している。サンプルサイズの計算では、本来、それぞれの群のハザード比や生存期間中央値から必要なイベント数を求め、それを観察するために必要な期間を考慮したうえで人数を決める。結構ややこしいでしょ。今回は、2パターンの検出力だけみればいいように状況を単純化している。さっき検出力について説明したじゃない、対立仮説の下で有意になる確率ね。表2は、検出力90%の検定を行うために必要なサンプルサイズで、表1はそれを検出力80%に緩めたときのもの。表1をみると、検出力80%でよければ、152人に調査すればいいみたいだね」\n\n\n私「ふむ。この人数も、確率モデルで計算したの？」\n\n\nお父さん「もちろん、この書籍の著者が、別世界の誰かに手紙を出してね」\n\n\n私「ふむふむ。まだよくわかんないな。JCOG9502では、2本の生存曲線を比べてたでしょ」\n\n\nお父さん「うん」\n\n\n私「いま考えてる統計解析って、ストーマ造設あり・なしと復職状況の関係を調べてたんだよね。以前に聞いた話だと、2値データだとロジスティック回帰、生存時間データだとCox回帰を使うんじゃなかったっけ。生存曲線とCox回帰は別の統計手法じゃない？」\n\n\nお父さん「正確にいうとね、生存曲線を比較するためのp値はいくつかの統計手法で計算できる。よく使うのはログランク検定とCox回帰のふたつで、表1と2は、ほんとはログランク検定用なんだけど。Cox回帰を使ったとしても、ストーマ造設あり・なし以外の因子がなければ、ログランク検定とほとんど同じ結果になる。特にサンプルサイズが大きければね」\n\n\n私「お父さん、あとね。表1と2に割付け比1:1って書いてあるでしょ。これって2群の人数が同じってことだよね」\n\n\nお父さん「そうだよ、たいていの臨床試験の割付け比は1:1だからね」\n\n\n私「でもストーマ保有者って、非保有者より少ないと思うんだけど。半数くらいかな」\n\n\nお父さん「調査や観察研究だと、群ごとの人数は同じにならないよね。さっきは、書籍（Machin, et al. 2022）の表を利用させてもらったんだけど、設定が複雑になると、付録のソフトウェアやRを利用することになる。 powerSurvEpiパッケージで、あの表とほぼ同じ計算ができるはず。割付け比を、1:1から2:1、4:1に変えて、ストーマ保有者が33%、20%のときの計算をしてみよう」\n\n\n\n\n\n\n\n\nRパッケージを用いたサンプルサイズ設計のコードはこちら\n\n\n\n\n\n\n# install.packages(\"powerSurvEpi\") #インストールが必要なら実行\nlibrary(powerSurvEpi)\n\nssizeCT.default(\n  power = 0.9,\n  k     = 1,\n  pE    = 0.6,                     # ストーマあり群の復職率\n  pC    = 0.8,                     # ストーマなし群の復職率\n  RR    = log(1-0.8)/log(1-0.6),   # 復職率からハザード比を計算\n  alpha = 0.05\n)\n\n nE  nC \n100 100 \n\nssizeCT.default(\n  power = 0.9,\n  k     = 0.5,\n  pE    = 0.6,                     # ストーマあり群の復職率\n  pC    = 0.8,                     # ストーマなし群の復職率\n  RR    = log(1-0.8)/log(1-0.6),   # 復職率からハザード比を計算\n  alpha = 0.05\n)\n\n nE  nC \n 59 118 \n\nssizeCT.default(\n  power = 0.9,\n  k     = 0.25,\n  pE    = 0.6,                     # ストーマあり群の復職率\n  pC    = 0.8,                     # ストーマなし群の復職率\n  RR    = log(1-0.8)/log(1-0.6),   # 復職率からハザード比を計算\n  alpha = 0.05\n)\n\n nE  nC \n 41 161 \n\n\n\n\n\n\n\nお父さん「割付け比\\(K\\)は\\(K:1\\)を意味している。\\(K=1\\)（1:1）、\\(K=0.5\\)（2:1）、\\(K=0.25\\)（4:1）だと、必要サンプルサイズ（\\(nE+nC\\)）は100+100人から19+118人、41+161人に変化するみたいだね」\n\n\n私「えー、\\(K\\)ってストーマありの割合だよね、そんなのまだわからないもの。思ったより人数が必要かもってことだよね。調査する施設を増やすかどうか考えないと」\n\n\nお父さん「気持ちはわかるよ。頻度論の立場で厳密に研究をデザインすると、だいたい最初は”そんなに集められないよ”って顔になるからね」\n\n\n私「でも、サンプルサイズの意味がわかったから、しょうがないやるかって思ったよ。シミュレーション1000回のうち失敗しちゃった調査が、私の調査だったらきっついもん。ひとつの調査を繰り返したときのことをイメージできると、統計的な意味のある研究ってなにかが見えてくるね」\n\n\n\n\n文献\n\nMachin D, Campbell MJ, Tan SB, Tan SH. 医学のためのサンプルサイズ設計（原著第4版）. 京都: 京都大学学術出版会; 2022\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006;7(8):644-51\n\n\n\nThis concludes the Frequentist Thinking series. If you’d like to keep reading over your next cup of coffee, the following episodes are waiting:\n\nSilent Confusions Hidden in Percentages\nWho Is This Percentage About? Target Populations and Attributable Fractions\nCollapsibility of Effect Measures in Marginal and Stratified Tables\nRisk Ratios and Odds Ratios: When Approximation Works\nFrom Risk and Rate to Survival and Hazard\nDistinguishing Time-Point, Time-Constant, and Time-Varying Effects: An R Example"
  },
  {
    "objectID": "jp/index.html#エピソード一覧",
    "href": "jp/index.html#エピソード一覧",
    "title": "コーヒーを淹れて、言葉を交わす。湯気とともに時は流れ、統計の世界が少しずつ広がっていく。",
    "section": "エピソード一覧",
    "text": "エピソード一覧\n\n1. Study Design — 研究の出発点\n研究は「どんな問いを立てるか」から始まります。PICO/PECO、アウトカムの選び方、バイアスの防ぎ方…。娘は父に研究の出発点について尋ねます。\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\n[A First Step into Survival and Competing Risks Analysis with R]　【12/15公開予定】\n[When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys]　【12/22公開予定】\n\nこのエピソードのRスクリプト一式は、こちらからダウンロードできます。R パッケージや、ここで紹介した解析手順をもう一度たどってみたい方はぜひ。\n\nstudy-design.R\n\n\n\n2. Glossary — 統計学のことば\n\nStatistical Terms in Plain Language\n\n\n\n3. Frequentist Thinking — 統計学の思考\nがん臨床試験を題材に「仮想的に何度も研究を繰り返したときに、数字はどう振る舞うか？」という頻度論的なものの見方を父は語ります。\n\n[Reading a Paper over a Cup of Coffee]\n[P-Value Explanations That Seem Plausible at First Glance]\n[Beyond 0.05: Interpreting P-Values in a Clinical Trial]\n\nこれとこの次のエピソードのRスクリプト一式はこちらから。\n\nfrequentist.R\n\n\n\n4. Frequentist Experiments — 統計学の実証\n頻度論が導く法則は、ただの抽象ではなくシミュレーション実験で確認することができます。Rに不慣れな方も、スクリプトを流すだけですので結果を再現してみてください。\n\n[R Demonstration of Bias in Kaplan-Meier Under Competing Risks]\n[Understanding Confidence Intervals via Hypothetical Replications in R]\n[Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size]\n\nこれとこの次のエピソードのRスクリプト一式はこちらから。\n\nfrequentist.R\n\n\n\n4. Effects and Time — 効果は時間とともに\nリスク差・リスク比・ハザード比、ワクチン有効率、寄与割合、そして時間とともに変化する効果を、生存曲線・累積発生曲線とともに紐解きます。因果推論に先立って立体的なデータの見方が静かに育ちます。\n\n[Silent Confusions Hidden in Percentages]\n[Who Is This Percentage About? Target Populations and Attributable Fractions]\n[Understanding Collapsibility of Effect Measures in Marginal and Stratified Analyses with R]\n[When Odds Ratios Approximate Risk Ratios—and When They Fail]\n[From Risk and Rate to Survival and Hazard]\n[Distinguishing Time-Point, Time-Constant, and Time-Varying Effects: An R Example]\n\nこのエピソードのRスクリプト一式はこちらから。\n\neffects.R\n\n\n\n5. Adjusting for Bias — 回帰モデリングの風景\nロジスティック回帰の結果の見方、表の作り方から、使用上の落とし穴まで、父の手ほどきを受けるエピソード。そして…。\n\n[From Risk to Logistic Regression]\n[Logit: How a Transformation Shapes an Effect]\n[Where My Logistic Regression Went Wrong]\n[Why Logistic Regression Fails in Small Samples]\n[Simpson’s paradox]\n\nこのエピソードのRスクリプト一式はこちらから。\n\nlogistic-regression.R\n\n\n\n6. Truth — 真実\n\n[What Data Cannot Tell Us]\n[What Could Have Happened]\n[What Is It That You Want to Know?]\n\n\n\n7. Causal Inference — 因果を見つけるために\n有効非循環グラフ（DAG）、共通原因、合流点、中間媒介因子、バックドア基準。「もし〜だったら？」を統計的に考えるための因果の言葉を、確率に関する必要最小限の数式を交えて扱います。\n\n[Three-Variable DAGs: The Smallest Building Blocks of Causal Structure]\n[Common Causes and Confounders]\n[DAGs and Conditional Distributions: Two Languages for the Same Structure]\n[Backdoor Paths and Confounders]\n\n\n\n8. Publishing a Paper — 研究の営み\n研究結果をどう伝えるか、図表の作り方、推敲のコツ、査読の向き合い方。統計の“その先”を扱う、研究者のための静かな講義。\n\n[Publishing a paper I]\n[Publishing a paper II]\n[Publishing a paper III]\n[Publishing a paper IV]"
  },
  {
    "objectID": "jp/index.html#読み方",
    "href": "jp/index.html#読み方",
    "title": "コーヒーを淹れて、言葉を交わす。湯気とともに時は流れ、統計の世界が少しずつ広がっていく。",
    "section": "読み方",
    "text": "読み方\nまずは Study designシリーズを読めば、臨床研究の風景や「どんな問いを立てて、どんなデータを集めるか」という輪郭が見えてきます。そこから先は物語を追っても、興味の向くレイヤーを選んでも構いません。\n\n論文を読む足場を整えたい: Frequentist Thinking\n数字の意味や統計解析の実際をもう少し深く知りたい: Effects and Time / Adjusting for bias\n因果という見えない構造を整理したい: Causal Inference\n研究を形にして届けるところまで見通したい: Publishing a Paper\n\nどのエピソードも独立して構成されていますが、全体を読むと、生活・臨床・因果・データ・認識・言語がひとつの流れとしてつながり、研究という営みの地図が、少しずつ頭の中にスケッチされていきます。お好みの飲み物を片手に、ふたりの会話の旅をどうぞお楽しみください。"
  },
  {
    "objectID": "jp/logistic-regression-2.html",
    "href": "jp/logistic-regression-2.html",
    "title": "Logit: How a Transformation Shapes an Effect",
    "section": "",
    "text": "Adjusting for Bias II − Logit: How a Transformation Shapes an Effect\n\nKeywords: effect measure, generalized linear model\n\n\n\n数式を使ってロジスティック回帰を教えてよ\n\n\nお父さん「ああ、ここにいたんだ。コーヒーと大福？」\n\n\n私「うんうまいよ」\n\n\nお父さん「食べながらでいいから聞いてよ。ロジスティック回帰はね、医学研究でよく使うから知っておいた方がいいと思って。簡単にいうと、2値データのための回帰モデルの一種。ストーマ造設、年齢、性別、年収といった共変量が、復職の有無のような2通りの値をとるアウトカムとどの程度相関するかを、調べることができる」\n\n\n私「もうちょっと統計っぽく教えてよ」\n\n\nお父さん「ん？統計手法には、パラメトリック法とノンパラメトリック法があるけど、ロジスティック回帰はパラメトリックモデルの一種として位置づけられる。最近の教科書では、一般化線型モデルのひとつとして扱われることが多いかな」\n\n\n私「そういうんじゃなくてさ。ほら、リンク関数とか出てきたでしょ。ああいうのがでてくると消化不良でさ」\n\n\nお父さん「数式使っていいの？」\n\n\n私「うん。数式でてくると、ところどころわからないんだけど。ごまかされるのもいや。ほら、このペン使っていいよ」\n\n\nお父さん「じゃあ、個人のリスクと共変量の関係から話せばいいのかな」\n\n\n\n\n\n\n\n\nロジスティック回帰\n\n\n\n\\(N\\)人の対象者に番号をつけて\\(i=1,...,N\\)で表すことにします。個人\\(i\\)のリスクを\\(\\pi_i\\)で表します。\\(\\pi_i\\)は、個人レベルの\\(N\\)個のパラメータですが、そのすべてを別々に推定したいわけではありません。\\(\\pi_i\\)に関連する\\(p-1\\)個の共変量\\(X_{i,1},X_{i,2},...,X_{i,p-1}\\)が測定されており、両者の関連の強さに関心があるとします。このとき\n\\(\\log(\\frac{\\pi_i}{1-\\pi_i})=\\beta_0+\\beta_1X_{i,1}+...+\\beta_{p-1}X_{i,p-1}\\)\nという関係が成り立つ確率分布をロジスティック回帰といいます。\nこの式の係数\\(\\beta_0,\\beta_1,...,\\beta_{p-1}\\)を回帰係数（regression coefficients）、特に\\(\\beta_0\\)を切片項（intercept）といいます。正規分布は平均と分散というパラメータで形状が決まりますよね。それと同じように、ロジスティック回帰の確率分布は、回帰係数\\(\\beta_0,\\beta_1,...,\\beta_{p-1}\\)で規定されます。\\(\\pi_i\\)は、\\(\\beta_0,\\beta_1,...,\\beta_{p-1}\\)が与えられれば計算できますが、直接推定するわけではありません。\n\n\n\n\n私「ふむふむ。ひとりひとりに\\(\\pi_i\\)と\\(X_{i,1},X_{i,2},...,X_{i,p-1}\\)がある。そしてロジスティック回帰の式で結びついているわけね。そして、その式の係数が回帰係数」\n\n\nお父さん「そう。ロジスティック回帰の裏には2項分布があって、実は\\(\\pi_i\\)は2項分布の確率に対応している。2項確率の式に、共変量\\(X_{i,1},X_{i,2},...,X_{i,p-1}\\)が含まれていて、アウトカムと共変量の関連の強さを、回帰係数が決めるんだ」\n\n\n私「この式まではわかったよ」\n\n\nお父さん「よかった。ちょっと補足するとね、確率分布に含まれる未知数のことを、統計学ではパラメータと呼んでいる。そしてパラメータの関数として、確率分布を書くことができるものを、パラメトリックモデルっていうんだ。こういう風に考えると、パラメータを推定したり、推定値に信頼区間をつけたりすることが、統計解析の目標になるよね。もうひとつ知っておいてほしいのが、ロジスティック回帰では、アウトカムと共変量の関係がロジット関数（logit function）で結びつくと仮定していること。glm()について話したの覚えてる？」\n\n\n私「うん。リンク関数をlinkで指定することは理解したよ。それがこの式？」\n\n\nお父さん「そうだよ。glm()の引数は、family、y ~ x1 + x2、linkなんだけどfamily=binomial()のように 2項分布を選ぶと自動的にロジット関数が使われる。ロジスティック回帰の左辺をみてよ」\n\n\n\n\n\n\n\n\nリンク関数とロジット関数\n\n\n\n個人のパラメータと共変量との関係を結びつける1対1の単調な変換\n\\(g(\\pi_i)=\\beta_0+\\beta_1X_{i,1}+...+\\beta_{p-1}X_{i,p-1}\\)\nのことを、一般にリンク関数（link function）といいます。ロジスティック回帰のリンク関数は\n\\(g(\\pi_i)=\\log(\\frac{\\pi_i}{1-\\pi_i})\\)\nです。この関数はロジット関数と呼ばれ、ロジスティック回帰を特徴付けています。\n\n\n\n\nロジット関数の特徴\n\n\n私「単に関数に名前をつけただけでしょ。もうちょっと解説が欲しいなあ」\n\n\nお父さん「そうだよね。ロジット関数も関数の一種だから、グラフにした方が特徴がつかみやすい。次の説明だとどうかな」\n\n\n\n\n\n\n\n\nロジット関数の形状\n\n\n\n仮に共変量が1個で、連続データだったとしましょう。確率\\(\\pi_i\\)と共変量\\(X_i\\)の関係は、ロジット関数を通じて\n\\(\\log(\\frac{\\pi_i}{1-\\pi_i})=\\beta_0+\\beta_1X_{i}\\)\nという式で表されることになります。\n図は、このロジット関数の\\(\\exp(\\beta_1)\\)の値を5、10、20、200と設定して、\\(X_i\\)を0から1までの範囲で変化させた、ロジット関数の逆関数のプロットです。\\(\\exp(\\beta_1)\\)は、\\(X_i\\)が1SD変化したときのオッズ比に相当します。つまり、図でもっとも傾きの小さい黒い曲線は、オッズ比5のときのものです。この曲線はそれほど変化が急にはみえませんが、医学研究ではオッズ比5でもかなり強い関連です。\nこのように、ロジット関数の逆関数はS字型の曲線を表しています。X軸方向にどんな値をとったとしても、Y軸方向の変化は0から1の範囲に収まることが、特徴のひとつです。そして、曲線の傾きは回帰係数\\(\\beta_1\\)によって決まります。\n\n\n\n\n\n私「やっとイメージがわいた。ロジット関数って、確率と共変量との関係を表してるんだ。どれくらい年齢が上がると、復職できる確率が下がるか、みたいなことね」\n\n\nお父さん「さらに、ロジスティック回帰は、がんサバイバー調査のように群を比較するときにも使われる。シンプルに2人の対象者を比べるとどうなるかって話をするね」\n\n\n\n\n\n\n\n\nロジット関数とオッズ比の関係\n\n\n\n共変量が1個のとき、ロジスティック回帰は\n\\(\\log \\left(\\frac{\\pi_i}{1-\\pi_i}\\right)=\\beta_0+\\beta_1X_{i}\\)\nと表すことができます。そして、対象者\\(i=1\\)では\\(X_{1}=0\\)、対象者\\(i=2\\)では\\(X_{2}=1\\)という値をとる状況を考えてみましょう。それぞれの対象者の共変量の値を、上の式に代入すると、以下のようになります。\n\\(\\log\\left(\\frac{\\pi_1}{1-\\pi_1}\\right)=\\beta_0\\)\n\\(\\log\\left(\\frac{\\pi_2}{1-\\pi_2}\\right)=\\beta_0+\\beta_1\\)\nここで、\\(\\pi_1\\)は対象者1の確率パラメータ、\\(\\pi_2\\)は対象者2の確率パラメータです。これらの確率パラメータから、オッズ比を求めるとどうなるでしょうか。それは、以下の式で計算されます。\n\\(\\left(\\frac{\\pi_2}{1-\\pi_2}\\right)\\div\\left(\\frac{\\pi_1}{1-\\pi_1}\\right)=\\exp(\\beta_0+\\beta_1)\\div \\exp(\\beta_0)=\\exp(\\beta_1)\\)\nこの結果は、回帰係数\\(\\beta_1\\)の指数をとるとオッズ比が得られることを意味しています。\n\n\n\n\n私「なるほど、回帰係数からオッズ比を計算できるってこういうことなのね」\n\n\nお父さん「このオッズ比の計算ができるのは、ロジット関数の特徴によるものでしょ。だから、ロジスティック回帰はオッズ比のモデルともいえるんだ。リスク比にはリスク比のモデルがあるし、リスク差にはリスク差のモデルがある。大事なのはfamily、y ~ x1 + x2、linkを選ぶことで、データの型にあった回帰モデルを指定できるってこと。yとxにそれぞれ連続変数を指定すると、散布図に回帰直線を掛くことができるし、計数データにPoisson回帰を当てはめたりもできる。一般化線型モデルは、生存時間データや経時データ以外ならほとんど対応できる汎用的な統計手法なんだ」\n\n\n\n\nロジスティック回帰の可逆性\n\n\n私「でもね、その説明だとみんなロジスティック回帰を使ってる理由にはなってないよね。link=\"logit\"よりlink=\"identity\"、つまり変換しなくたっていいじゃない」\n\n\nお父さん「それはリスク差のモデルだね。無変換のモデルが悪いわけじゃないんだけど、ロジット関数が選ばれた理由はちゃんとある。この話はちょっと難しいかもしれない。たとえるならね、ロジスティック回帰はルービックキューブのように構造が安定しているんだ」\n\n\n私「どういう意味？」\n\n\nお父さん「操作を加えても構造が維持されるっていうこと。どんな方向で、どんな順序で面を回しても、ルービックキューブは元に戻せる。解けば絵の向きもきちんと揃う。統計解析に話を戻すと、人工的にデータに変換を加えることがあるよね。たとえば死亡じゃなくて生存をアウトカムにしたり、LDLコレステロールの単位をmg/dLからmmol/Lに変えたり。これは共変量\\(X_i\\)のスケール変換のことだよ」\n\n\n私「それはよくやることだよね」\n\n\nお父さん「統計学者は、いろいろな回帰モデルのうち、変換に対して不変な構造はなにかって考えた。ここでいう変換は、数学では群作用（group action）っていうんだけど、ある変換を加えても意味が変わらない操作のこと。ほら、コインの表裏を入れ替えても、コイン投げの確率の本質に影響しないでしょ。考えた結果、2値アウトカムのモデルでは以下のパーツを使うしかないってことがわかった」\n\n\n確率分布: 2項分布（指数型分布族）\n回帰係数×共変量（線型結合）\nリンク関数: ロジット関数\n\n\nお父さん「ここで出てくるロジット関数は、変換しても可逆性（invertibility）を保つ唯一の関数なんだ。たとえば死亡確率を\\(\\pi=0.2\\)とするよ。このとき生存確率は？\\(1-\\pi=0.8\\)だよね」\n\n\n私「うん。当たり前」\n\n\nお父さん「この”死亡と生存を入れ替える”という操作が群作用に相当する。ここで問題にしているのはリンク関数\\(g\\)だったよね。確率\\(\\pi\\)を、リンク関数で別のスケール\\(g(\\pi)\\)に変換したとする。このとき、死亡と生存を入れ替えても、値が反転するだけで構造が維持されるには\\(g\\)はどんな性質を持つべき？」\n\n\n私「値が反転する、って？」\n\n\nお父さん「つまりこういうこと」\n\n\\[g(1−\\pi)=−g(\\pi)\\]\n\n私「へ？意味わかんない」\n\n\nお父さん「さっき、対象者1の\\(\\pi_1\\)と対象者2の\\(\\pi_2\\)を比べるとオッズ比が出てきたのを思い出して。あのとき、\\(g(\\pi_1)\\)と\\(g(\\pi_2)\\)の差をとっていた。\\(g\\)じゃなくてロジット関数そのものを使ったけどね。つまり、\\(g(\\pi)\\)は差のスケールで死亡リスクがどれくらい高いかを表す尺度なんだ。死亡と生存を入れ替えたらどうなる？\\(g(-1\\pi)\\)は死亡リスクの低さを意味するよね。つまり、死亡と生存の入れ替えによって、符号反転はするはず」\n\n\n私「なるほど。\\(g(1−\\pi)=−g(\\pi)\\)という関係が成り立つのはなにか探せばいいのね？」\n\n\nお父さん「もう少し条件がある。\\(g(\\pi)\\)という尺度に、上限と下限があったら不便だし、ゼロという基準が必要だよね。だから条件を追加する」\n\n\n\\(g(1−\\pi)=−g(\\pi)\\)\n\\(\\pi\\)が0に近づけば\\(g(\\pi)\\)は−∞に向かう\n\\(\\pi\\)が1に近づけば\\(g(\\pi)\\)は∞に向かう\n\\(\\pi=1/2\\)を基準にとって\\(g(1/2)=0\\)\n\n\nお父さん「この4つの条件を満たす滑らかな関数は、実はほとんどひとつしかない」\n\n\\[g(\\pi)=\\log \\left(\\frac{\\pi_i}{1-\\pi_i}\\right)\\]\n\n私「それがロジット関数ってことか。データを人工的に変換しても解析結果が変わらないってこと？」\n\n\nお父さん「あれ、そこまでは説明しなかったけど、その通り。可逆性があるモデルでは、データを変換しても構造もそれに合わせて変わってくれて、本質的に同じ解析結果が得られる。みんなが使っている統計手法はね、大半が人間が選んだだけじゃないんだ。数学的な法則がそっと姿を現しているんだよ」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n脳卒中発症の有無をアウトカム、LDLコレステロールを共変量としてロジスティック回帰を当てはめたとします。LDLコレステロールの単位をmg/dLからmmol/Lに変換したとき、オッズ比は何倍になるでしょうか。ただし\nLDLコレステロール(mmol/L) =LDL コレステロール(mg/dL) ×0.02586\nという関係が成り立ちます。\n\n0.02586倍\n1/0.02586倍\n変化しない\n1、2、3すべて誤り\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n正解は4です。\nこれは単位を換算するにはどうすればよいかという問題です。ある共変量Xの効果は、回帰係数βとの積（βX）で表され、それは共変量の単位によらず一定ですよね。このことに気づくと、答えに近づきます。Xの単位を定数倍すると、βは定数分の一に換算されます。ただし、ロジスティック回帰では、回帰係数からロジット関数を経由してオッズ比を求めるため、単位を換算するには、1/0.02586乗のようにべき乗の操作をすることになります。\n\n\n\n\n\n文献\n\n田中司朗. 医学研究のための因果推論II. Rubin因果モデル. 東京: 朝倉書店; 2022\n\n\n\nエピソード、用語集、Rスクリプト\n\nFrom Risk to Logistic Regression\nLogit: How a Transformation Shapes an Effect\nWhere My Logistic Regression Went Wrong\nWhy Logistic Regression Fails in Small Samples\nSimpson’s paradox\nStatistical Terms in Plain Language\nlogistic-regression.R"
  },
  {
    "objectID": "jp/logistic-regression-4.html",
    "href": "jp/logistic-regression-4.html",
    "title": "Why Logistic Regression Fails in Small Samples",
    "section": "",
    "text": "Adjusting for Bias IV − Why Logistic Regression Fails in Small Samples\n\nKeywords: bias, effect measure, generalized linear model\n\n\n\nなぜロジスティック回帰の計算ができなかったのか\n\n\n私「お父さん、コーヒー飲んで寛いでいるところわるいんだけど、時間あるかな。ロジスティック回帰についてなんだけど。説明してくれたのはありがたいんだけどね、群作用とか完全分離とか、途中でわかんなくなっちゃってさ。気になって、先に進めないわけよ」\n\n\nお父さん「そうだったのか。Rコードを見せてもらったけど、解析自体は間違ってなさそうだよ」\n\n\n私「いや、私自身の問題だよね。納得感というか自信というか。だからさ、完全分離について説明してくれない？この前の解析で、なにが起きたのか知りたいんだよね」\n\n\n\n\n\n\n\n\nロジスティック回帰の推定\n\n\n\n推定に用いられる関数\n以前、ロジスティック回帰の\\(\\pi_i\\)は2項分布の確率に対応しているといいました。2項分布の確率関数にはデータと\\(\\pi_i\\)が含まれていますが、この式にデータを代入すると、\\(\\pi_i\\)の式が得られます。さらに、\\(\\pi_i\\)は\\(\\beta_0,\\beta_1,...,\\beta_{p-1}\\)の関数です。したがって、確率関数の式は、\\(L(\\beta_0,\\beta_1,...,\\beta_{p-1})\\)というように、\\(\\beta_0,\\beta_1,...,\\beta_{p-1}\\)の関数とみなすことができます。この関数を尤度関数といいます。\nロジスティック回帰の回帰係数は、この尤度関数を最大化する値として計算されます。ただし、データから必ずしも解が求まるわけではありません。計算が収束しなかったり、不安定になったりする理由は、主に2通り考えられます。\n完全分離\n一つ目は、完全分離（complete separation）や擬似完全分離（quasi-complete separation）です。完全分離とは、\n\\(\\log(\\frac{\\hat\\pi_i}{1-\\hat\\pi_i})=\\hat\\beta_0+\\hat\\beta_1X_{i,1}+...+\\hat\\beta_{p-1}X_{i,p-1}\\)\nを計算したとき、その値によって、\\(Y_1,Y_2,...,Y_N\\)を100%の精度で0または1に判別できてしまう状況のことをいいます。擬似完全分離は、100%ではないものの、完全分離と同様に共変量からアウトカムが判別できてしまう状況です。別の言葉でいえば、共変量の情報に比べて、データに含まれる情報が不足していて、実質的にランダム性がないということを意味します。つまり、完全分離や擬似完全分離は、サンプルサイズに比べ、共変量の数が多すぎるときによく生じる問題です。\n多重共線性\n二つ目は、多重共線性（multicollinearity）です。これは、共変量同士の相関が強すぎることを意味します。仮に、年収が年齢に完全に比例する状況（つまり相関が1）を考えてみてください。このとき、ロジスティック回帰を用いて年収と年齢の影響を分離することはできません。これが多重共線性の一例です。言い換えると、相関の高い共変量は、推定が不安定になるため、同時にロジスティック回帰に含めない方がよい場合が多いです。\n\n\n\n\n私「あれ？回帰分析って最小2乗法を使うんじゃないの？尤度関数？」\n\n\nお父さん「大学の教科書ではそう教わるけどね。最小2乗法を使うのは連続データのときだけかな。別の推定方法もいろいろある」\n\n\n私「ふーん。新しい方法がいろいろありそうってのは知ってるよ。AIとか機械学習とか」\n\n\nお父さん「まあね。はやりだよね」\n\n\n私「統計学と機械学習ってどう違うの？同じ？」\n\n\nお父さん「お隣さんって感じかな。データを解析するって意味では同じことをしているわけだし、機械学習の教科書でも、ロジスティック回帰とかロジスティック判別とかは扱うもの。統計学で習うROC曲線なんかは、機械学習の範疇な気がするし。重なる部分は多いよ。まあ、機械学習の方がたくさんのパラメータを推定する傾向にあるとはいえるかな。ロジスティック回帰よりニューラルネットワークの方が、モデルも複雑だし、パラメータの数も多い。さっき共変量の数を減らそうっていったでしょ。機械学習では、ああいうパラメータの数を減らすって発想はしない」\n\n\n私「パラメータの数が少ないのが統計学の特徴ってわけ？」\n\n\nお父さん「うーん、でもそれは程度問題かもしれない。一番の違いはなんだろうね。統計学は確率モデルが必ず基礎にあるってことかな。そして、標本から母集団を調べるっていう考え方をする。手法でいうと、p値とか信頼区間とか、ああいうやつね」\n\n\n統計手法を選ぶ理由\n\n私「はやりだから使っていいのかな。ほら、ニューラルネットワークとかこの前の群作用とか、知らなくてもみんな使ってるよね。問題ないのかな」\n\n\nお父さん「でもね、2項分布とロジット関数のところまでは理解できなかった？」\n\n\n私「そこまではできた」\n\n\nお父さん「なら合格点だと思う。数理的な手法って奥が深いでしょ。だから、仮に数学的な真実があったとして、究極的には部分的な理解しかできないかもしれない。専門家とユーザーで程度は違うけどね。だから、みんな使ってるっていうのは、使ってもいい理由のひとつにはなる。医療でも、添付文書で有効性が確立していないって書かれた薬が、第一選択だったりするでしょ」\n\n\n私「ああ、コミュニティスタンダードのことね。そういうこともあるけど、すっきりはしてないよね、医師はみんな。それに、コミュニティスタンダードの薬は、単にみんな使っているから選ばれたわけじゃない。難病や希少疾患で他に候補がなかったり、エビデンスが足りなくても経験上は効果があるから、その薬を使って治療してるの」\n\n\nお父さん「それって、医療上の目的に対してじゅうぶん役に立ってるってことでしょ。ロジスティック回帰も同じじゃない？用途に見合った性能があるって自信を持っていえれば、ところどころ理解が追い付かなくても、使用していいと思う。世の中にはね、いろんな方法が使われてる。でも、すべて3つの理由で正当化されるんだよ」\n\n\n数学と自然科学が支えている\nコミュニティが支えている\n使用する目的が支えている\n\n\nお父さん「それぞれが100%じゃなくても、この3つが支えあえれば使う意味があるんだ」\n\n\n私「そういうもんかな。納得したような、まだ霧が残っているような気もする。まあいいや、疲れてきたし。性別のオッズ比が無限大になった理由はわかったよ。尤度関数にデータを代入したら、回帰係数の解が変になるような式になったってわけね」\n\n\n\n\n\n\n\n\n\nデータの型と統計手法\n\n\n\nアウトカムはデータの型によって4種類に分類されます。\n\n連続データ （例：血圧やQOL）\n分類データ （例：有害事象の有無）\n計数データ （例：有害事象の発生件数）\n生存時間データ （例：全生存期間）\n\nさらに、分類データはいくつかの種類があり、カテゴリが2通りのものを2値データ、カテゴリに順序があるものを順序データと呼んでいます。生存時間データの一種には、競合リスクを考慮した競合リスクデータがあります。データの型によって、正規分布や2項分布など確率分布が異なりますよね。そのため、それぞれ異なる統計手法が用いられます。詳しくは表をみてください。\n仮に、ストーマ造設あり・なしと復職状況の関係を調べたいとすると、2つの変数をモデルに当てはめることになるため、回帰モデルを用いて調べたいとします。このときアウトカムを復職の有無（2値データ）とするなら、ロジスティック回帰を選ぶべきです。もし復職までの期間（生存時間データ）とするなら、Cox回帰の方が適切です。\n個人内で反復測定があるか\n同一個人にくり返し臨床検査やアンケートを行うと、似たような検査結果になりますよね。たとえば、朝と晩に血圧を測ると、2つの測定値に相関が生じます。治療前と治療後に、QOL質問票に回答してもらう場合も、その測定値は独立ではありません。このように1人の患者に複数回の測定値があるデータを反復測定データといいます。反復測定データでは、個人内の測定値は独立ではありません。したがって、独立性を仮定している統計手法（たとえば対応のないt検定や\\(\\chi^2\\)検定）は不適切です。反復測定データの解析では、変量効果モデル（random-effects model）や一般化推定方程式（generalized estimating equation）と呼ばれるやや高度な手法が用いられます。この場合の変量効果は、「ひとりひとりの個人の効果」を表しています。これらの方法は、個人内でデータが独立ではないこと（データの相関）を考慮するものです。\n交絡の調整が必要かどうか\n交絡因子（confounder）とは、治療とアウトカムとの関係を歪める第三の因子のことです。仮に、ストーマ造設あり・なしと復職状況の関係に、年齢が強くかかわっているとしましょう。そして、ストーマ保有者と非保有者で、平均年齢が異なっているとします。このような場合、2群間の年齢の違いを無視するとバイアスが生じます。これを補正するために、ロジスティック回帰がよく用いられます。 ランダム化臨床試験では、比較する群間で実験条件が揃っているため、交絡の調整は不要です。一方、観察研究（コホート研究やケース・コントロール研究）では交絡の調整は必須です。今回題材にした復職率の調査も観察研究の一種ですから、統計解析ではロジスティック回帰やCox回帰が主に用いられるでしょう。最近では交絡を調整して、正しく因果関係を調べるために、因果推論の手法（プロペンシティスコアなど）を用いることが増えてきました（田中2022）。\n\n\n\n\n\n\n\n\n\n\nデータの型\n反復測定\n交絡調整\n統計手法\n備考\n\n\n\n\n連続データ\nなし\nなし\n対応のないt検定、Wilcoxon順位和検定\n平均の比較\n\n\n\n個人内で2回測定\nなし\n対応のあるt検定、Wilcoxon符号付順位検定\n対応のあるデータ\n\n\n\nなし\nなし\n正規線型モデル\n回帰モデルの一種\n\n\n\nあり\nあり\n変量効果モデル、一般化推定方程式\n回帰モデルの一種\n\n\n2値データ\nなし\nなし\n\\(\\chi^2\\)検定\n割合の比較\n\n\n\n個人内で2回測定\nあり\nMcNemar検定\n対応のあるデータ\n\n\n\nなし\nあり\nロジスティック回帰\n回帰モデルの一種\n\n\n\nあり\nあり\n変量効果モデル、一般化推定方程式\n回帰モデルの一種\n\n\n計数データ\nなし\nなし\n\\(\\chi^2\\)検定\n発生率の比較\n\n\n\nなし\nあり\nPoisson回帰\n回帰モデルの一種\n\n\n\nあり\nあり\n変量効果モデル、一般化推定方程式\n回帰モデルの一種\n\n\n生存時間データ\nなし\nなし\nKaplan-Meier曲線\n生存曲線の記述\n\n\n\nなし\nあり\nCox回帰\n回帰モデルの一種\n\n\n競合リスクデータ\nなし\nなし\nAalen-Johansen曲線\n累積発生率曲線の記述\n\n\n\nなし\nあり\nFine-Grayモデル\n回帰モデルの一種\n\n\n\n\n\n\n\nエピソード、用語集、Rスクリプト\n\nFrom Risk to Logistic Regression\nLogit: How a Transformation Shapes an Effect\nWhere My Logistic Regression Went Wrong\nWhy Logistic Regression Fails in Small Samples\nSimpson’s paradox\nStatistical Terms in Plain Language\nlogistic-regression.R"
  },
  {
    "objectID": "jp/publish-a-paper-1.html",
    "href": "jp/publish-a-paper-1.html",
    "title": "Story and Quiz − Publishing a paper I",
    "section": "",
    "text": "Story and Quiz − Publishing a paper I\n\n　　　　　　　　　　　　　　　　　　　　Keywords: paper writing\n\n\n\nEditorとReviewerってちがう人なんだ\n\n前回までのあらすじ\nはじめて研究に取り組む娘と統計家の父。父に研究仮説は”PICO”を”PECO”で整理するといいとアドバイスされ、医師である娘は、がんサバイバーにおけるストーマ造設と復職状況の関係を調査することに決める。調査は終ったが、いざ論文を書くとなると腰が重くなり、パソコンを閉じて父に話しかけるのだった。\n\n私「がんサバイバー調査についてなんだけどね。調査結果がまとまったから、論文を書かなきゃって思ってるんだけど…。お父さんって、どこかのジャーナルで統計エディターしてたよね？論文って、どんな感じで書くと採択されやすいのかな」\nお父さん「どんな感じねえ。医学が専門ってわけじゃないから話しにくいな。自分ではどう思ってる？」\n私「はやってる研究テーマは通りやすそう。免疫チェックポイント阻害薬みたいな新薬とか、新しい診断基準とか。あ、ランダム化臨床試験は、調査より注目されるし、きっと有利ね」\nお父さん「そのイメージはまずまずあってると思うよ。エディターをやってて感じるのはね、採択するときの基準は、突き詰めると2つしかない」\n\nその研究から得られた結論の価値（value）は高いか\n結論は妥当な方法論（methodology）で導かれているか\n\nお父さん「ランダム化臨床試験が絶対に正しい方法っていってるわけじゃないよ。臨床試験でも、観察研究でも、それぞれの分野で認められている方法論に従って行われているかを、エディターやレビュワーはチェックしてるんだ」\n私「あれ？エディターとレビュワーって違う人？」\nお父さん「もちろん。採択されるかどうかは、ピアレビュー（査読）の結果で決まるでしょ。レビュワーの役割は、論文や学会抄録を読んで、採点したり、修正（revise）を求めるときはどこを直してほしいかコメントしたりすること。エディターの役割は、一言でいうとジャーナルを編集すること。編集事務局を運営したり、編集方針を決めたり、レビュワーを割り当てたりする。採択するかどうかはエディターが判断するし、査読コメントを著者に送ることもある。たとえばね、カバーレターってあるでしょ。論文につける手紙」\n私「聞いたことないよ。そんなのあるんだ」\nお父さん「そっか。カバーレターの宛先は、レビュワーじゃなくてエディターだよっていおうとしたんだけど。カバーレターは、たいてい編集委員長（Editor-In-Chief）宛に書くんだ」\n私「ふーん。カバーレターって大切？」\nお父さん「どうだろうね。お父さんは、カバーレターで研究の価値をアピールする方だけど、定型文で十分っていう人もいる。周りの研究者に聞いても、どれくらい重視するかはまちまち。ろくに読まないエディターもいるのは事実」\n私「そういうもんか。ピアレビューが何かはどこかで聞いたことあるよ。ジャーナルからコメントがきて、著者がそれに回答するんだよね。でも、裏側では、エディターじゃなくてレビュワーが採点してるんだ」\nお父さん「ジャーナルによって、多段階評価だったり数字をつけたりするけどね。エディターがレビュワーから集めた採点結果とコメントをとりまとめて、著者にどういう意思決定になったかを伝える」\n\n採択（accept）\n大修正（major revision）\n小修正（minor revision）\n不採択（reject）\n\nお父さん「ピアレビューを経ないと、論文が粗製乱造されてしまう。だから、研究者はみんなピアレビューという仕組みを大切にしている」\n私「ちなみにお父さんお金もらってる？」\nお父さん「いや？ボランティア。利益相反とかいわれるとややこしいから、むしろどこからもお金を受け取りたくない。2019年にレビュワーの利益相反が問題になったことがあってね。それ以来、そのジャーナル（BMJ）は、査読コメントや著者の回答をサイトで公開するようになった。ピアレビューのプロセスが知りたければ、そのサイトをみてみたらいいよ。論文投稿するときは、論文を書くだけじゃなくて、英語でやり取りしなきゃいけないことが案外多いから、参考になるかもしれない」\n\n\n価値と方法論\n私「ふむふむ。話を戻すとさ。採択される基準は、価値と方法論っていってたよね。具体的にはどうすればいいの？」\nお父さん「エディターはたくさんの論文をさばかなきゃいけないから、ざっとタイトルと抄録だけ目を通すことが多い」\n私「ふむふむ」\nお父さん「たいていの臨床医学系のジャーナルでは、構造化抄録を採用しているから、なにをどこに書けばいいかはわかりやすい。JAMAの抄録がどんな要素から構成されてるかみてみようか」\n\nImportance（研究の重要性）\nObjective（目的）\nDesign, setting and participants（デザイン、状況設定、参加者）\nExposures（曝露）\nMain outcomes and measures（主要アウトカムとその測定方法）\nResults（結果）\nConclusions and relevance（結論と意義）\n\n私「JAMAの抄録はこうなのね。研究の価値は、”Importance”と”Conclusions and relevance”に書けばいい。研究方法も、どんな要素が求められるか、デザインから測定方法まで指定されてる。確かにわかりやすい。参加者、曝露、主要アウトカムは、PECOの通りに書けばいいよね」\nお父さん「それでいいと思う。がんサバイバーの調査の”価値”はなにって聞かれたらなんて答える？」\n私「まず、がん手術後に仕事に就けるかどうかは、生活に関わる大きな問題だっていうのが前提かな。その上で、どんな患者が苦労していて、就労支援を求めているのかを調べて、ストーマ造設が関連することがわかった。それが研究をやった意義だと思う」\nお父さん「うんうん。それが抄録を読んだ人に伝わるように書こう。たとえばこんな感じでどうだろう」\n\nImportance: Although prognosis of early rectal cancer has been improved, little is known about employment problems after surgery.\nObjective: To compare employment status between patients with and without stoma\nDesign, setting and participants: A mail survey was conducted at 3 hospitals in Japan. Participants were 20-to-80-year-old patients with clinical stage I–III rectal cancer who were employed at diagnosis and received curative surgery from 2010 to 2020. Participants were followed up using self-administered questionnaires for 12 months.\nExposures: Stoma creation\nMain outcomes and measures: Return-to-work at 12 months after surgery\nResults: Responses were obtained from AAA patients and the response rate was BB%. The median time to return-to-work was CC months and the proportion of working patients at 12 months after surgery was DD%. The odds ratio for delayed return-to-work was EEE (95% confidence interval FFF to GGG, p = HHH) after adjustment for age, sex and income.\n\nConclusions and relevance: Stoma creation in rectal cancer is associated with difficulty in returning to work. Further employment support may be necessary.\n\nお父さん「この文章で工夫した点は4つある。まず、今回みたいに日本で調査を行う場合、海外の研究者は日本の事情を知らないでしょ。だからどんな方法で参加者が選ばれたをきちんと書く。単に直腸がん患者って書くんじゃなくて”patients with clinical stage I–III rectal cancer who were employed at the time of diagnosis and received curative surgery from 20XX to 20YY”とかね」\n私「ふんふん」\nお父さん「2つ目の工夫は、回答率（response rate）を示すこと。回答率が低いと、選択バイアスがあるかもしれないからね」\n私「その次はなに？」\nお父さん「3つ目はさっき話した交絡調整だね。観察研究の査読では必ず確認されるポイントになってる。本文に書いてあれば十分だけど、抄録でも、オッズ比を示すときに”after adjustment for age, sex and income”のような説明があると、ちゃんとしてるなって思ってもらえるかもしれない」\n私「なるほどね。2つ目と3つ目は、バイアスがどれくらいあるかについて書いたんだね。最後のひとつは？」\nお父さん「つまらないテクニックなんだけど。“Return-to-work”や “20-to-80-year-old patients”のように、単語をハイフンでつなぐと、文字数を節約できる。普通に”patients aged 20 to 80 years”って書くと6文字も使っちゃうでしょ。抄録には文字数の制限があるからね」\n私「じゃあさ、少し話がそれるんだけど、主語と時制について聞いていい？”A mail survey was conducted at 3 hospitals in Japan.”っていう一文があるけど、受動態にするのが普通なの？それに、調査はすでに行われたから、時制は過去形なんだよね。IntroductionとConclusionsは現在形だけど」\nお父さん「論文を書くときは、Weを主語にしない方が、客観的だからいいっていう考え方がある。でも最近は、主語をはっきりさせたほうが、かえって正確だという意見もある。たとえば別の表現をとって”Study design was a mail survey at 3 hospitals in Japan”というように、研究方法を説明する文体にしてもいい。情報が増えたぶん、より正確で、かしこまったニュアンスになる。この場合は、受動態でも能動態でも、不自然ってことはないよ」\n私「時制については？」\nお父さん「普遍的な現象や法則性を表すときは現在形を使う。結論を現在形で書くと、「ストーマ造設は職場復帰の難しさに関わることが明らかになった」っていうニュアンスになる。過去形を使って、“Stoma creation in rectal cancer was associated with a difficulty in return-to-work.”と書くと、「今回の調査では」関連があったという限定的な意味になる」\n私「じゃあ主語と時制はいま教えられた通りで書いてみる」\nお父さん「うんうん。ちなみにね、凝った英語を使う必要はないよ。論文は、“concise”つまり簡潔な表現が好ましいとされる。接続詞や関係代名詞を多用しちゃって、一文が長くなりがちな人もいるけど、最初はそうしない方がいい。短い文章が続いていてもぜんぜん変じゃないからね」\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n文献を引用するときのスタイルは、ジャーナルの投稿規定で決められています。なかでも、もっとも多く採用されているのは、医学雑誌編集者国際委員会が1978年に定めたバンクーバースタイルです。\nJCOG9502論文を、バンクーバースタイルで表記すると、以下のようになります。さて、2つの□に入る記号として正しい組み合わせは、次のうちどれでしょうか。\nSasako M, Sano T, Yamamoto S, Sairenji M, Arai K, Kinoshita T, Nashimoto A, Hiratsuka M, Japan Clinical Oncology Group (JCOG9502). Left thoracoabdominal approach versus abdominal-transhiatal approach for gastric cancer of the cardia or subcardia: a randomised controlled trial. Lancet Oncol 2006 □ 7(8) □ 644-51\n\n“:”と”:”\n“;”と”;”\n“:”と”;”\n“;”と”:”\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n正解は4です。\nバンクーバースタイルでは、論文を引用するとき、文献リストを以下のように書きます。ただし、著者が多数のときは、”et al.”と省略することがあります。\n[著者名（苗字+名前のイニシャル）]. [記事名]. [ジャーナル名]. [発行年]; [巻]: [ページの範囲]\nちなみに、書籍を引用するときは、以下のように書きます。\n[著者名（苗字+名前のイニシャル）]. [書籍名]. [版]. [出版社の所在地]: [出版社]; [出版年]\n\n\n\n\n\nContinuation of their story\nStudy design I\nStudy design II\nStudy design III\nStudy design IV\nStudy design V\nClinical trial I\nClinical trial II\nClinical trial III\nEpidemiology I\nEpidemiology II\nEpidemiology III\nEpidemiology IV\nRegression I\nRegression II\nRegression III\nRegression IV\nCausal inference I\nCausal inference II\nCausal inference III\nCausal inference IV\nPublish a paper I\nPublish a paper II\nPublish a paper III\nPublish a paper IV"
  },
  {
    "objectID": "jp/publish-a-paper-3.html",
    "href": "jp/publish-a-paper-3.html",
    "title": "A Morning Just Before Submission",
    "section": "",
    "text": "Publish a Paper − A Morning Just Before Submission\n\n\n投稿する前の朝\n\n\n梅雨の雨音は夜の静けさをなぐさめてくれる。診療の後、私たちはパソコンに向かう時間をとることが多い。今夜も私はモニターに映る原稿を眺めていた。机の上には、論文と調査票、そして紙ナプキンに書かれたメモの上に、ルービックキューブがそっと置かれている。冷めかけたコーヒーに手を伸ばした。\n書いては止まり、止まってはまた戻る。\n\n「本研究の目的は―」\n\nこんなに短い一文に、こんなにも多くの意味が乗ってしまうことを、今の私は知っている。目的は、個人のものじゃない。研究仮説というフォーマットで、普遍的に共有できるように開かれていなければならない。それは私がどの地点から世界を眺め、どんな方向へ歩こうとしているのかを、そっと誰かに手渡すような行為だ。\n次に目が留まる。\n\n「本研究の主な結果は―」\n\nそこに置かれた数字も、以前とは違って見える。数字は患者さんになにが起きたか。そして、世界への問いかけへの返事なんだ。私たちはよい診療をしてきたの？問い方が変われば、返ってくる数字も変わる。数字はただ並んでいるだけに見えて、実はたくさんのことを語っている。\n患者さんを対象にした研究だからこそ、研究仮説には医療の価値観が滲む。それは「正しいかどうかを知る」というより「よりよい技術に近づくための知識を得る」という態度に近い。\nコーヒーは机の端で静かに冷えていた。モニターには、書き上げたばかりのConclusionが映る。調査をデザインしたときに抱いていた疑問に答えられているか、ひとつひとつ確かめる。私は軽く頷き、ゆっくりとキーボードを叩いた。\n\n\nAcknowledgements\nWe appreciate the advice from an anonymous statistician.\n\n\nThis concludes the story."
  },
  {
    "objectID": "jp/study-design-1.html",
    "href": "jp/study-design-1.html",
    "title": "A Story of Coffee Chat and Research Hypothesis",
    "section": "",
    "text": "Study Design I − A Story of Coffee Chat and Research Hypothesis\n\nKeywords: hypothesis/outcome/population, observational study, study design, language/writing\n\n\n\nはじめて研究に取り組む娘と統計家の父\n\n\n私「お父さんってさ、大学で統計学を教えてるんでしょ」\n\n\nお父さん「そうだよ」\n\n\n私「診療科の上司に、そろそろ研究して学会発表でもしてみないかって言われてさ。その先生、2016年がん対策基本法が改正されてからずっと、がん患者さんの就労支援に興味があるの。要するに、私にその調査をやらせたいみたい。まあやってみたくなくはないけどね。これって統計じゃない？」\n\n\nお父さん「まあね。なにか臨床的に知りたいことや仮説はあるの？」\n\n\n私「ないよ」\n\n\nお父さん「仮説がないと調査がデザインできないよ」\n\n\n私「まじか。データをとってから考えればいいと思ってた。うーん、やっぱり仕事を続けにくいのはどんな患者さんなのかが知りたいかな」\n\n\nお父さん「女性より男性の方が、復職率が高いとか？」\n\n\n私「性別にも興味あるけど、やっぱり知りたいのはがんのステージとか合併症とかかな。私が勤めているのは消化管外科なんだけど、ストーマをつけている患者さんは、手術前と同じ仕事を続けられているのだろうか、とか。うん、調査票つくってみる。ありがとう！」\n\n\nお父さん「待ちなさい。調査対象は決まってるの？」\n\n\n私「ん？うちの病院で手術したがん患者さん」\n\n\nお父さん「胃がんでストーマを造設することってあるの？」\n\n\n私「ゼロじゃないけど、みたことない」\n\n\nお父さん「でしょ。ストーマに興味があるなら、胃がんは外した方がいいんじゃない？」\n\n\n私「そうかなあ」\n\n\nお父さん「デザイン段階で、どのような対象に調査すべきか考えておくことは大切だよ。一般論だけど、対象集団を狭く限定した方が、質問項目を詳細にできるから。それに比較可能性（comparability）も高まる。ストーマ保有者と非保有者を比べるなら、がん種は統一したいよね」\n\n\n私「比較可能性とかお硬い言い方するね。でも、患者さんの背景がばらけるとやりにくいよね。なるべく揃っている方が比較しやすい、ってことはわかるよ」\n\n\nお父さん「比較可能性を高めるための統計手法やRパッケージもある。回帰調整のためのglm()やプロペンシティスコア調整のためのCBPS()とかね。一方で、対象集団は広い方が、一般化可能性（generalizability）が高い。がんサバイバーの復職率を推定したいんだったら、がん種を限定する必要はないし、できれば複数の施設で調査したいよね」\n\n\n私「確かに、うちの病院だけだと実態調査っていいにくい気もしてきた。一般化可能性が高い研究をしなさいっていうのは、ほかの施設の参考になるデータをとれって意味だよね」\n\n\nお父さん「うんうん。大学の授業だとね、こんな風に教えてるよ。\n\n研究で調べたい疑問がはっきりしないなら、“PICO”と”PECO”という要素を使って 研究をデザインしなさい\n\n研究の要素をひとつひとつ決めていく計画の立て方を、研究の構造化っていったりする」\n\n\n私「構造化？実際怪しいな、そこ。いや、聞いたことはある」\n\n\nお父さん「じゃあ軽く整理しよう。たとえばPICO/PECOのPは、患者（Patients）または集団（Population）の頭文字をとっている。どのような患者が対象かが、研究デザインの大切な1要素だってこと」\n\n\n\nどのような患者が対象か（Patients/Population）\nどのような要因に注目するか（Intervention/Exposure）\nそれを何と比較するのか（Comparison）\n患者にどのようなアウトカムが生じたのか（Outcome）\n\n\n\n私「ExposureとComparisonははじめて聞いたけど、私の場合はストーマ保有者と非保有者ってことだよね。Outcomeってなに？」\n\n\nお父さん「PICO/PECOのOはアウトカムっていって、治療結果や、転帰、予後のこと。統計解析ではアウトカムのデータがいちばん重要。だから、計画でここを固めるのがポイントになる」\n\n\n私「データが集まる前に固められなくない？」\n\n\nお父さん「いや、データが集まっちゃったら変更が効かないでしょ。調査票を確定する前には決めておきたいよね。ああ。そうだね、アウトカムのイメージがまだないんだ。アウトカムはね、どんなデータをどうやって解析するかに関わってくる。解析結果を左右するからきちんと考えておいた方がいいんだ。データが集まった後は、どの統計ソフトを使うつもり？」\n\n\n私「R。診療科の先輩が使ってるから」\n\n\nお父さん「Rは得意？」\n\n\n私「学部の頃、授業あったけどもうわすれたな」\n\n\nお父さん「じゃあRの使い方も身につけなきゃだね。どの関数を使うかも、アウトカムによって違うんだよ」\n\n\n\n\n\n\n\n\n臨床疑問と研究仮説\n\n\n\n日常診療をしていると、さまざまな疑問や知りたいことが生じることがあります。診療現場から生まれたありのままの疑問のことを、臨床疑問（clinical question）といいます。臨床研究をスタートするとき、意識してほしいのは、臨床疑問を研究仮説（research hypothesis）として表現することです。研究仮説は、研究デザインに最低限必要な要素で構成されます。たとえば典型的な臨床研究では、以下のような要素が含まれることが多いでしょう。\n\nPatients/Population\nIntervention/Exposure\nComparison\nOutcome\n\n上の会話で出てきた”PICO”や”PECO”は、この頭文字をとったものです。I（Intervention＝介入）かE（Exposure＝曝露）かは、その研究が薬の臨床試験のような介入研究か、今回のがんサバイバー調査のような観察研究かによって変わります。観察研究には患者さん一人ひとりを追跡するコホート研究、ある時点からさかのぼって調査するケースコントロール研究、ある1時点における要因とアウトカムを調査する横断研究がありますが、いずれもPECOで構造化が可能です。\nがんサバイバー調査を題材にして、研究仮説の例を3つ考えてみました。\n\n\n研究仮説1\nP: 根治切除後の直腸がん患者\n\nE: ストーマ造設あり\n\nC: ストーマ造設なし\n\nO: 手術後1年以内の復職の有無\nストーマ保有者と非保有者の復職率を比較する研究を想定してみました。この場合Cをどうするかは悩ましい問題ですが、復職率の数字が得られただけでは、それが高いかどうか判断が難しいので、なんらかの比較対照を設定した方がよいでしょう。なお、比較可能性とは、この場合EとCを正しく比べられるということを意味します。\n\n\n\n研究仮説2\nP: 根治切除後のがん患者\n\nE: 「仕事とがん治療の両立お役立ちノート」の配布あり\n\nC: 「仕事とがん治療の両立お役立ちノート」の配布なし\n\nO: 手術後1年以内の復職の有無\n就労支援の一環として作成された「仕事とがん治療の両立お役立ちノート」の効果を調べようという研究です。患者Pは、直腸がんに限定せず、アウトカムOは、手術後の復職の有無としました。こうした方が、幅広い患者に当てはまる調査結果が得られますよね。これが一般化可能性の一例です。アウトカムについては、別の例として、患者満足度や患者の経済状態なども考えられるでしょう。\n\n\n\n研究仮説3\n「性・年齢、ステージ、術後補助化学療法、パフォーマンスステータス、合併症、ストーマ、手術前の就労状況、家計収入額、がん保険、就労支援サービスの利用などの因子は、1年以内の復職率と関連するか」\nPECOになりにくい研究仮説もあります。たとえば、疾患発生と関連のあるリスク因子を探す、いわゆる探索的研究では、EとCははっきり決まっていません。構造化といっても、臨床疑問をかならずPECOの形式にしなければならないわけではありません。研究デザインに最低限必要な要素を特定することが大切です。\n\n\n\n\n\n私「なるほどね、オリジナル仮説を立てろっていわれたら困るけど、研究の要素を洗い出して、ひとつひとつ決めていく作業はきらいじゃないわ。いつかは必要なことだし」\n\n\nお父さん「そうでしょ。それに研究者の思考を、早い段階で専門的な表現に置き換えておくと、コミュニケーションもうまくなる。疾患やアウトカムの定義、治療や曝露内容は、医師や施設によって微妙な違いがあるものだからね。言葉をおろそかにすると混乱の種になる」\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\n研究計画を立てるとき、しばしば”ceteris paribus”というラテン語表現が登場します。この言葉の意味にいちばん近いのはどれでしょう。\n\n因果関係があるなら必ず起こる\n普遍的に一般化できる法則\n他の条件が同じである\nじゅうぶん多くのデータを観察する\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は3です\n\n“ceteris paribus”という概念は、比較可能性（comparability）を保つための条件と考えて問題ありません。\n\n\n\n\n\nエピソードとRスクリプト\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\n[A First Step into Survival and Competing Risks Analysis with R]\n[When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys]\nstudy-design.R"
  },
  {
    "objectID": "jp/study-design-3.html",
    "href": "jp/study-design-3.html",
    "title": "Outcomes: The Bridge from Data Collection to Analysis",
    "section": "",
    "text": "Study Design III − Outcomes: The Bridge from Data Collection to Analysis\n\nKeywords: clinical trial, hypothesis/outcome/population, survival/competing-risk, language/writing\n\n\n\nアウトカムってなに？\n\n\n私「さっきのアウトカムについてなんだけどね。診療科内で臨床試験の論文を読むんだけど、そこで出てくる”DFS”とか”RFS”とかの略語もアウトカムだよね？実はよくわからないんだけど、当たり前のように使われているから質問しにくいんだ。DFSとRFS、どっちもがんの再発を調べてるみたいなんだけど。お父さん詳しい？」\n\n\nお父さん「もちろん統計解析でDFSを扱うことはあるよ。一番よく出てくるOSは全生存期間（overall survival）だよね。DFSは無病生存期間（disease-free survival）、RFSは無再発生存期間（relapse-free survival）のこと」\n\n\n私「無再発生存期間って再発までの日数のこと？」\n\n\nお父さん「再発までの日数だったら無再発期間(relapse-free time)とかって言葉を選ぶかなあ。累積再発率（cumulative incidence of relapse）やCIRって呼ぶことの方が多いけど」\n\n\n私「よけいにわからん。ぜんぶ同じじゃないの？」\n\n\nお父さん「生存間解析ではね、細かいけど違うんだ。再発を経験せずに、死亡することもあるでしょ。無病生存期間のポイントは、再発・2次がん・死亡のうち、どれか最初のイベントまでの時間を扱うこと。だから、再発だけでなく、死亡したり別のがんを発症したりしたときも、イベントとして扱われるんだ」\n\n\n私「イベント扱いって？」\n\n\nお父さん「生存時間データは、一般に特定のイベントまでの経過時間なんだ。端的にいうとね、無病生存期間のデータから“3年無病生存確率”を計算するとするでしょ。それは“イベントが起こらない確率”に相当するんだけど、意味合いとしては3年時点で、再発も2次がんも経験せず、生存できる確率を求めることになる」\n\n\n私「そういうことか」\n\n\nお父さん「RFSでは、イベントは死亡と再発のするのが普通。つまり二次がんはイベントに含めない。無再発期間だったらイベントは再発だけ。図をみたら、イメージしやすくなるかな」\n\n\n\n私「ふんふん。私はね、無病生存期間の結果が重要だと思うな。再発と2次がん、どっちも起きない方がいい。無再発期間はあまり解析する意味を感じないな。死亡は一番重要なイベントじゃない？なんで省いちゃうのよ」\n\n\nお父さん「そうだね。でも、がんが再発した後に死亡した患者は、無再発期間だったとしてもイベント扱いになるよね」\n\n\n私「確かにね。よく考えたら、再発前に亡くなるケースって、感染症とか、交通事故とかだね。がん治療や原病とは関係ないかもしれない」\n\n\nお父さん「臨床試験で用いられるアウトカムは、”エンドポイント”とよばれることもあるよね。研究によって研究仮説が違うから、それにあわせて様々なエンドポイントが選ばれる。進行がんではがんの増悪に注目した無増悪生存期間、根治切除後の研究では無再発生存期間とかね。表に、がん臨床試験の主な生存時間エンドポイントを整理してあげるよ（Japan Clinical Oncology Group 2021）」\n\n\n\n\n\n\n\n\n\n\n\n\nエンドポイント\nイベント1\nイベント2\nイベント3\nイベント4\n打ち切り日\n\n\n\n\n全生存期間\n死亡\n\n\n\n最終生存確認日\n\n\n無増悪生存期間\n死亡\n増悪/再発\n\n\n最終無増悪確認日\n\n\n無再発生存期間\n死亡\n再発\n\n\n最終生存確認日\n\n\n無再発期間\n再発\n\n\n\n最終生存確認日\n\n\n無病生存期間\n死亡\n再発\n2次がん\n\n最終生存確認日\n\n\n無イベント生存期間\n死亡\n寛解導入失敗\n再発\n2次がん\n最終生存確認日\n\n\n治療成功期間\n死亡\n治療中止（治療中の増悪/再発を含む）\nプロトコール治療完了後の増悪/再発\n\n最終治療継続確認日または最終無増悪確認日\n\n\n\n\n私「でかした！」\n\n\nお父さん「この表は、臨床試験グループが研究計画書を作るときのものなんだ。研究計画書は、医師や統計家がチームになって書くからね。定義を決めておかないと混乱する。このグループでは”one word one meaning”がモットーなんだ」\n\n\n私「だよね、私もこんがらがり中だわ」\n\n\nお父さん「OSは、生存時間の原点（time origin）から死亡するまでの期間のこと。DFSは、時間原点から再発、2次がん、死亡のうち、最初のイベントまでの期間のこと。でも、さっき言ったみたいに、3年OSとか3年DFSという言い方をすることもある。この場合は期間じゃなくて確率の意味になる。OSとDFSの違いは、再発と2次がんが含まれること。そうすると、3年OSより3年DFSの方が、確率は小さくなるよね」\n\n\n私「時間原点ってはじめて聞いた。もう少し説明してよ」\n\n\nお父さん「じゃあ、どの時点から生存時間をスタートするか、典型的な決め方をいくつか紹介しようか。まず、DFSは根治手術後の再発状況を調べるため用いられるアウトカムだよね。だから、”手術日”がこの場合の時間原点の候補になる。手術日のように治療の起点がはっきりしている状況だと決めやすいよね」\n\n\n私「あーよくみるやつだわ」\n\n\nお父さん「でしょ。一方で、もし”退院日”を時間原点にすると、手術直後の死亡が評価対象にならなくなっちゃうから、研究によってはそこを批判されるかもしれない。もうひとつ典型的な決め方を挙げると、臨床試験の登録日があるかな。ランダム化臨床試験だと、登録日に治療をランダムに割付けるから、それを原点にして生存曲線を描くのが自然だよね」\n\n\n私「なるほどね、研究によって微妙に定義が違うもんね。実は今、調査票作っててね。お父さんがアウトカムにうるさいって周りに話したら、みんな意外とちゃんと区別してて。DFSとかOSを正確に知りたかったんだ。聞いてよかった、また相談するね」\n\n\n\n\n\n\n\n\n臨床エンドポイントと代替エンドポイント\n\n\n\nOS、DFS、RFSは、特に術後補助化学療法の有効性を評価するときに用いられるアウトカム（エンドポイントともいいます）です。それでは両者は、どのような考え方で使い分けられているのでしょうか。指針の1つになっているのが、医薬品の承認審査の考え方です。たとえば抗悪性腫瘍薬の臨床評価方法に関するガイドライン（厚生労働省2021）では、抗がん剤を承認するためには、生存期間の延長などにもとづき、確実な有効性を示す必要があると述べています。そのため、具体的な指標として、OSが臨床エンドポイント（clinical endpoint）とみなされ、こちらが重視されています（Biomarkers Definitions Working Group 2001）。\nその一方で、術後補助化学療法としての抗がん剤の有効性を評価する臨床試験では、代替エンドポイント（surrogate endpoint）として採用することがあります。代替エンドポイントとは、臨床エンドポイントの代わりになることが意図されたもので、臨床上の便益・害の有無を予測することが期待されるものと定義されます。DFSのような代替エンドポイントを用いる最大のメリットは、試験期間が短くなることです。ただし、過去の承認審査では、代替エンドポイントの利用が誤った医薬品評価につながったケースが数多く報告されています（Fleming and DeMets 1996）。たとえば、進行大腸がんにおける5FU+ロイコボリン併用療法は、臨床試験で腫瘍縮小がみられたにもかかわらず、臨床エンドポイントであるOSを評価すると、ほとんど延命効果がないことが明らかになりました（Fleming and DeMets 1996）。\n\n\n\n\n\n\n\n\nこのエピソードに関係するクイズです\n\n\n\nがん臨床研究で用いられるアウトカムのひとつに無増悪生存期間（progression-free survival）があります。このアウトカムを測定するには、画像による腫瘍増悪の判定が必要になります。このとき、客観性を高めるため、第三者が画像をみて増悪を判定すると、主治医による増悪の判定と一致しないことがあり得ます。この問題は、中央判定と施設判定の不一致と呼ばれます。以下の選択肢のうち、対処法として適切でないものを選びなさい。\n\n統計解析では、客観性が高い中央判定の結果を採用する\n統計解析では、中央判定と施設判定のうち、先に起きたものを採用する\n症例検討会を開き、中央判定と施設判定の結果が一致しない患者の扱いを医学的に決定する\n中央判定を採用した解析と、施設判定を採用した解析の、2通りを行う\n\n\n\n\n\n\n\n\n\n答えはこちら\n\n\n\n\n\n\n正解は2です\n\n中央判定と施設判定のうち、先に起きたものを採用すると、無増悪生存期間が短くなる方向にバイアスが生じるため、適切ではありません。\nひとつだけ注意があります。施設判定ではなく中央判定を必ず採用すべき、というわけではありません。施設で増悪になった後、それが追跡状況や画像検査の頻度に影響したり、施設の担当医の治療方針が変化したりすることがあります。このような状況では、施設判定を用いることが適切かもしれません。\n\n\n\n\n\n文献\n\nBiomarkers Definitions Working Group. Biomarkers and surrogate endpoints: preferred definitions and conceptual framework. Clin Pharmacol Ther 2001;69(3):89-95\nFleming TR and DeMets DL. Surrogate end points in clinical trials: are we being misled? Ann Intern Med 1996;125(7):605-13\nJCOGプロトコールマニュアル version 3.8 [Internet]. 東京: Japan Clinical Oncology Group; 2025\n薬生薬審発0331第1号. 抗悪性腫瘍薬の臨床評価方法に関するガイドライン [Internet]. 東京: 厚生労働省医薬・生活衛生局医薬品審査管理課長; 2021\n\n\n\nエピソードとRスクリプト\n\nA Story of Coffee Chat and Research Hypothesis\nData Have Types: A Coffee-Chat Guide to R Functions for Common Outcomes\nOutcomes: The Bridge from Data Collection to Analysis\n[A First Step into Survival and Competing Risks Analysis with R]\n[When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys]\nstudy-design.R"
  },
  {
    "objectID": "jp/study-design-5.html",
    "href": "jp/study-design-5.html",
    "title": "When Bias Creeps In: Selection, Information, and Confounding in Clinical Surveys",
    "section": "",
    "text": "Study Design 5 − When Bias Creeps In\n\nKeywords: bias, confounding/collapsibility, observational study, probability model, simulation, study design, survival/competing-risk\n\n\n\n調査で気をつけておくべきバイアス\n\n\n私「ただいまーつかれたー。お父さん、甘いものない？」\n\n\nお父さん「いちご大福ならあるよ。コーヒーもちょうど淹れたところだ」\n\n\n私「ああ助かる。この時間帯に仕事が終わるとちょうど満員電車でさ、きついんだよね。診療時間の間もハードだったし」\n\n\nお父さん「おつかれさま。コーヒーはいったよ」\n\n\n私「ありがとう。あのさ、ハードなエンドポイントとソフトなエンドポイントって言い回しがあるじゃない？」\n\n\nお父さん「あるね」\n\n\n私「臨床試験にあこがれてる先輩がいてね、復職状況はソフトなエンドポイントだからだめだ、全生存期間（OS）はハードなエンドポイントだからいいんだ、みたいな言い方をするのよ。私の調査が否定されてるみたいなんだけど、どういうことなのか、よくわかんなくて」\n\n\nお父さん「確かにがん臨床試験はOSをエンドポイントにすることが多いけど、それを基準にダメ出しするのもどうかと思うけどね。それに、慣用的にハード・ソフトっていう表現が用いられるけど、その意味を正確に伝えるなら、客観的・主観的って言った方がいいんじゃないかな」\n\n\n私「客観的？主観的？」\n\n\nお父さん「よくある議論を挙げると、OSはハード、無増悪生存期間（PFS）はソフトというのがある。OSは死亡日と最終生存確認日だけで決まるから、ハードなエンドポイント。PFSでは、死亡とがんの増悪がイベントとして定義されるんだけど、そうするとデータを集めるために増悪日の情報が必要になる。ところが臨床的には増悪がいつ起きたかは、主観的に判断されるケースがあるよね。全身状態や腫瘍マーカーが悪化したりするケースだね。臨床試験で、こういうケースをイベントとみなすかは議論がわかれるけど、意見がわかれること自体でPFSはソフトなエンドポイントっていう人もいるね」\n\n\n私「なるほど、ハード=客観的、ソフト=主観的ってことね。たしかに、私の調査票はソフトなエンドポイントっていわれるわけだ。そもそも患者さんの主観を尋ねるための調査だもんね」\n\n\nお父さん「まあ、その先輩が伝えたかったのは、復職状況を調べるうえで、できるだけあいまいな部分を排除して、客観的に測定しなさいってことじゃない？調査対象者が、退院後の就労日を正確に回答してくれるなら、十分に客観的な測定ができていると思うけどね」\n\n\n私「じゃあさ、ハードなエンドポイントにはバイアスがない、ソフトなエンドポイントにはバイアスがあるって考えていい？」\n\n\nお父さん「主観が入るとバイアスが生じやすいとはいえるけど、そんなに単純じゃないかな。調査がいい加減だったら、死亡が完全に特定できず、死亡率を過小評価することだってあるもの。ちょっとたばこを吸っていい？」\n\n\n私「どうぞご自由に。死亡調査って大変だよね」\n\n\nお父さん「そうそう。もっと細かいことをいうとね、死亡に至るまで100%の情報を集める必要はないんだ。でも、それは死亡情報の収集に偏りがないときだけ。死亡情報が集まるかどうかが、患者の健康状態に依存してしまうと、バイアスの原因になる。これは生存時間データの打ち切りが、ランダムでなくなるからなんだ。この前、RのKaplan-Meier曲線とAalen-Johansen曲線をみせたよね。あの曲線は、打ち切りがあっても描ける。でもバイアスがなく。正確であるためには、打ち切りが、病状や予後とは関係なくランダムに起きていることが前提になってる。たとえば追跡期間が1年って決まっていて、全員1年で打ち切りになるとか、外的要因のため一部の患者で観察が続けられなくなるとかね。結局、情報が偏るとバイアスが生じるのは、ハードなエンドポイントでもソフトなエンドポイントでも同じこと」\n\n\n\n\n\n\n\nランダム誤差とバイアス\n\n\n\n統計学は誤差を扱う学問ですが、臨床研究ではランダム誤差（random error）とバイアス（bias）を区別することが大切です。ランダム誤差は、基本的にはゼロを中心としたばらつきを想定しています。一方で、得られた推定値が真の値から系統的にずれていることを、バイアスといいます。臨床研究における統計学の目標は、ランダム誤差を制御し、バイアスを可能な限りゼロに近づけることです。\nたとえるなら、ランダム誤差は的の中心を狙って矢を放つときのばらつき、バイアスは狙いが中心からずれている状態といえます。競合リスクの扱いを間違ったとき生じるKaplan-Meier曲線のバイアスは、ランダム誤差ではありませんよね。ランダム誤差はサンプルサイズを大きくすることで減少させることができますが、バイアスは研究デザインやデータ収集方法を工夫しないと、解消できません。\n\n\n\n\nバイアスの分類\n\n私「そりゃあ、データが偏ったらバイアスっていうのは私にもわかるけど。死亡情報が集められないのはどうしようもないときだもの。ベストを尽くすしかないよね。じゃあさ、私の調査で、それ以外に気をつけておいた方がいいバイアスってある？」\n\n\nお父さん「そうだね。調査票を郵送するんでしょ。そういうとき、回答してくれない患者が多いと偏りが生じやすいから、回答率を上げるように工夫するといい。たとえば、調査票で年収って聞いてる？」\n\n\n私「聞くかもしれない」\n\n\nお父さん「経済状況のようなナイーブな質問内容には十分配慮した方がいいよ。それが理由で回答してくれないと、解析対象集団が調査対象全体を代表しているといえなくなってしまう」\n\n\n私「他には？」\n\n\nお父さん「他にはね、ストーマ非保有者よりストーマ保有者の方が、調査票への回答率が高くなっちゃうとか。そもそもストーマ非保有者とストーマ保有者の回答率に差があると、これらの集団を比較してもバイアスがあるって批判されるかもしれない」\n\n\n私「それって交絡のこと？」\n\n\nお父さん「交絡ってどこで聞いたの？よく知ってるね。あれもバイアスの一種だけど、今回のとは違う。回答率の差やなにか理由があって回答してくれない場合は、母集団からのサンプル抽出に影響する選択バイアスといって、区別されるんだ。それに、年収って尋ねられると、過大申告してしまいがちだよね。このように集めた情報自体に偏りがあることを、情報バイアスと呼んでいる。調査や観察研究の計画に関する授業では、バイアスを3種類に大別して考えるといいって教えている。\n\n\n選択バイアス（selection bias）\n情報バイアス（information bias）\n交絡（confounding）\n\n\n実際に研究を行うといろいろ理由でバイアスが生じるけど、研究デザインの段階では、この3つに分けて考えると対策を立てやすい。一部の対象者ばかり選ばれないようにしなさい、情報を集めるときはバイアスが入らないように配慮しなさい、集団を比較するときは、比較したい要因以外の特徴を揃えるようにしなさいってね」\n\n\n私「ふーん？選択バイアス、情報バイアスねえ？やっぱり臨床研究って言葉遣いがよくわかんないな」\n\n\n\n\n\nThis concludes the Study Design series. If you’d like to keep reading over your next cup of coffee, a glossary of terms in the story and further episodes are waiting:\n\nStatistical Terms in Plain Language\n[Reading a Paper over a Cup of Coffee]\n[P-Value Explanations That Seem Plausible at First Glance]\n[Beyond 0.05: Interpreting P-Values in a Clinical Trial]\n[Understanding Confidence Intervals via Hypothetical Replications in R]\n[Alpha, Beta, and Power: The Fundamental Probabilities Behind Sample Size]"
  },
  {
    "objectID": "jp/truth-2.html",
    "href": "jp/truth-2.html",
    "title": "What Could Have Happened",
    "section": "",
    "text": "Truth II − What Could Have Happened\n\nKeywords: bias, causal model, confounding/collapsibility, hypothesis/outcome, language/writing, probability model\n\n\n\n原因を変えたら結果はどうなっていたか\n\n\nお父さん「今から、“交絡調整”の意味を知るために必要な概念について話すね。これまでの例を思い出してごらん。胃がん手術の術式、ストーマ造設、コーヒー摂取、どれも知りたいのは別の選択をしていたら結果はどうなったかってことじゃない？別の術式だったら助かっていたか、とか」\n\n\n私「そうだね、それはその通り」\n\n\nお父さん「残念ながら回帰分析のレールに乗ったままでは、その真実にはたどり着けない。確率モデルではなく原因を変えたら結果はどうなっていたかという疑問からスタートすること。因果推論はその問いに答えるための方法論なんだ」\n\n\n私「げ。別の方法で解析をやり直せっていいたいの？」\n\n\nお父さん「ちがうちがう、今は抽象的な話をしている。たとえば実薬とプラセボを比較するランダム化臨床試験だったらどう？全員に実薬を投与した結果とプラセボを投与した結果の差が知りたいんじゃない？それがOSなら生存曲線の差になる。この差こそが因果効果なんだ」\n\n\n私「うーん。そうか。JCOG9502だったら、胃がん手術で術式THを選ぶか、術式LTAを選ぶかを決めたいんだものね。標準治療が決まったら全員その術式になるはずだもの、その話は納得だわ。論文に出ていた生存曲線の差が因果効果にあたるわけか。確かに、そこに確率分布も回帰モデルも出てこないね」\n\n\nお父さん「そう。でも、がんサバイバー調査は観察研究で、ランダム化されていない。JCOG9502と同じように考えたくても、“仮にストーマを造設しなかった場合のアウトカム”は実在しない。仮定の話だからね。だからこの観察研究では、観測できないアウトカムを、共変量や回帰モデルで予測するしかない。これはデータ上のアウトカムとは区別して、潜在結果変数（potential outcome）と呼ばれている。観測はできないけれど、医学的・論理的に定義できる”もうひとつの結果”というわけだね」\n\n\n私「実在しないものを定義しても仕方ないじゃない」\n\n\nお父さん「そうじゃない。どんな因果効果が知りたいかを定義して、それを推定するためにデータを集める。眼に見えるのは、6つあるルービックキューブの面の1つに過ぎない。別の面に潜在結果変数が描かれていたとしても観測できないんだ。でも同じ構造をもつルービックキューブをたくさん用意して、それぞれをランダムな向きで机の上に並べてごらん。どのキューブも一面しか見えないけれど、どんな絵が描かれているか推測することはできる。ランダム化臨床試験がやっているのはこれに似ている」\n\n\n私「ややこしい話になってきた。JCOG9502と私の調査のどこが違うんだろう」\n\n\nお父さん「一番の違いははっきりしている。ランダム化しているかどうか。そもそもランダム化臨床試験は、“介入したら結果はどうなるか”を調べるためにデザインされているからね。ターゲット集団も明確に定義されているし、介入もランダムに割付けられていてバイアスもない。がんサバイバー調査のような観察研究では、研究仮説やPECOをどんなに慎重に考えても、曖昧なところは残る。特にPatientsとControlsがね。比較可能性についても、交絡因子のデータがバイアスを調整するためじゅうぶんかどうかわからない」\n\n\n私「ふむ」\n\n\nお父さん「話を戻そう。Rubin因果モデルは、解析するモデルや交絡調整について考える前に、潜在結果変数を定義し、その差について推測するんだ」\n\n\n\n\n確率モデルと因果モデルの補完関係\n\n\n私「やっぱりわからないな。一般化線型モデルやCox回帰の結果って、なにを見てるの？回帰係数は因果効果とは違うの？」\n\n\nお父さん「ひとつの数字が二重、三重の意味を持っているっていったらいいかな。根っこをたどると、確率モデルと因果モデルは”二階建て”になっている」\n\n\n確率モデル: 観測されたデータがどう生じるかを記述する構造\n因果モデル: 観測された世界と、観測されなかった世界の両方で、原因を変えたら結果はどうなっていたかを表す構造\n\n\nお父さん「これはちょうど、データが発生する背後に因果モデルがあるという創造的な階層関係なんだ。因果的な構造に従って生じた現象を測定したものがデータだといってもいい。ほら、さっきいったように潜在結果変数は観測できないでしょ」\n\n\n私「うん」\n\n\nお父さん「だからね、データは影みたいなものなんだ。見たいものは、その少し向こう側にいる」\n\n\n私「そういわれると確かに因果関係の真実は、データの発生する前から存在するのかもね。実感はないけど理解はした。でも、それならどうして最初からロジスティック回帰じゃなくて因果モデルを教えなかったの？」\n\n\nお父さん「ふむ。もう少し説明が必要だね。ロジスティック回帰や層別解析を使っちゃいけないわけじゃない。それは方法なんだ。ルービックキューブの解き方みたいなもの。ルービックキューブの構造とは別物。ここで知ってほしかったのは、回帰係数やオッズ比を、因果関係を考えるための証拠として正しく解釈するためには、因果モデルが必要だってこと」\n\n\n私「お父さんは専門だからわかってないけど、私にとってはロジスティック回帰もRubin因果モデルも初めて聞く概念なんだよ。Rubin因果モデルって、ある患者に別の方法で治療したら結果はどうなっていたかを分析すればいいんでしょ？それって解剖・病態生理・薬理に関する基礎知識と臨床経験を組み合わせればできそうなことじゃない？」\n\n\nお父さん「本質的にはその通り。でも、それはあくまで患者ひとりひとりにとっての原因と結果を分析するアプローチになっている。個々の事象に関する因果を単一因果（token causation）っていうんだけど、それと一般法則としての因果には、まだギャップがあるよね」\n\n\n私「トークン？ぴんとこない言葉だけど」\n\n\nお父さん「たとえば”あの患者さんが助かったのはこの薬のおかげか？“というレベルの話がtoken causationに近い」\n\n\n私「ああ、そういうこと。個々の出来事と一般法則どっちも大事なのはわかる」\n\n\nお父さん「臨床試験や調査は集団を対象にしているよね。集団を統計的に分析することで法則性を見出そうとしているんだ。そのための道具を用意するためのベースになっているのが、確率分布や回帰モデルだっていう話だったでしょ。確率モデルと因果モデルは役割が違う」\n\n\n私「また、難しい話に戻ってきたね。コーヒーもう一杯くれる？」\n\n\n\n\nエピソード\n\nWhat Data Cannot Tell Us\nWhat Could Have Happened\nWhat Is It That You Want to Know?"
  }
]